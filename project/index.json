{
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#0": "Calcolatori  Elettronici T  Complementi ed Esercizi  di Reti Logiche  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#1": "Stefano Mattoccia  Ricevimento : su appuntamento via email    Telefono  : 051 2093860  Email   : stefano.mattoccia@unibo.it  Web   : www.vision.deis.unibo.it/smatt ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#10": "OE=0 0 1 U=? Quale valore logico assume U ? \nChe cosa è necessario garantire nella rete seguente ?  Quando il segnale U assume un valore logico significativo ? 1 U=? OE1 OE2 I1 I2 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#11": "Esercizio 1  Registro a 1 bit con uscita tri-state Utilizzando latch SR progettare una rete che, quando WE=1,memorizza sull\u0001uscita OUT il segnale di ingresso IN. L\u0001ultimo valore trasferito in uscita deve essere mantenuto per tutto il tempo in cui il segnale WE=0. La rete deve essere inoltre dotata di un segnale OE che, se a livello logico 0, pone il segnale di OUT nello stato di alta impedenza. WE IN OUT OE ? WE IN OE OUT ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#12": "S Q Q* R WE IN OE OUT Soluzione \nLa rete tratteggiata (8X) è un latch CD dotato di uscita tri-state ed esiste in forma integrata (‘373). Q \nNOTA - Perché le due reti seguenti NON sono equivalenti ? a b c b a c ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#13": "RSA notevoli: Flip-Flop D FFD D CK Q Q* D CK Q Q* FFD: RSA che assume il valore logico presente sull’ingresso D durante i fronti di salita (positive edge triggered) dell’ingresso CK \nIl FFD è tipicamente utilizzato come cella elementare di memoria  nelle reti sequenziali sincrone. In tal caso, il segnale CK, è un segnale di tipo periodico (clock). CK D Q ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#14": "FFD D CK Q Q* D CK Q Q* A_SET* A_RES* \nA_RES* A_SET* \nCK D Q* Q I FFD sono dotati di due ulteriori ingressi “asincroni” che consentono di settare (A_SET) o resettare (A_RES) Q indipendentemente da CK e D. A_SET* \nA_RES* Tipica realizzazione di  un FFD della famiglia  TTL (‘374) mediante 3  latch SR.  Q=0 se A_RES=1 Q=1 se A_SET=1  A_SET e A_RES sono  prioritari rispetto  a CK e D NOTA: i segnali asincroni di set e reset denominati nella slide (rispettivamente) A_SET e A_RES  sono spesso denominati (rispettivamente) PR e CL oppure S e R. Inoltre, se non indicati nello  schema logico si suppone che tali comandi siano non asseriti (A_SET=0 e A_RES=0). ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#15": "Vincoli di corretto impiego per i FFD   Tempi di Setup (τSU), Hold (τH) e Risposta (τR) FFD D CK Q Q* D CK Q Q* CK D Q τH τSU τR Il corretto funzionamento è garantito solo se τSU≥ τSUmin e τH ≥ τHmin. In caso contrario, metastabilità.   Cosa implicano i parametri τSUmin e τRmin indicati nei datasheet ? ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#16": "Il FFD come elemento fondamentale delle RSS \nD CK Q Se all’ingresso CK viene inviato un segnale periodico (clock):   il FFD ritarda (D = Delay) il segnale di uscita Q, rispetto al  segnale di ingresso D, di un tempo pari al periodo di clock T  Qn+1 = Dn FFD D CK Q Q* D CK Q Q* \nT T T T ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#17": "Vincoli di campionamento e metastabilità Il mancato rispetto dei vincoli sul campionamento dei segnali porta  a metastabilità.  CK D Q τSU τH ???????????? \n0 1 metastabile \nstabile stabile ? ? 1? 0? τ = ??? ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#18": "Sincronizzazione di segnali (non sincroni) FFD D CK Q I metastabile FFD D CK Q Stabile (?) I_sync I_M Normalmente i segnali provenienti dall’esterno (ma non solo) non sono sincroni con il clock della RSS. Questo è un problema molto comune.   Come gestire potenziali situazioni di metastabilità che potrebbero  compromettere il corretto funzionamento della RSS?  \nCK •  La soluzione mostrata garantisce che l’uscita I_sync assume il valore   di I nel momento in cui tale segnale è stato campionato?   •  Sono sufficienti due livelli di FF?  •  Quali sono gli effetti collaterali di questa soluzione? ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#19": "Reti Sequenziali Sincrone (RSS) ? k (k) FFD k k FFD sull’anello di retroazione  Tutti con lo stesso clock di periodo T S S* S S* CK S U S* It t+T t+2·T t-T Nel caso specifico: Moore o Mealy ? Lo stato cambia anche se non cambia l’ingresso ? L’uscita cambia anche se non cambia l’ingresso ? CK ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#2": "Introduzione Reti Logiche: sintesi mediante approccio “formale” \nCalcolatori Elettronici: sintesi mediante approccio “diretto” Grafo degli Stati Tabella di Flusso Tabella delle Transizioni Sintesi (Karnaugh, etc) Specifiche del Problema RL \nGrafo degli Stati Tabella di Flusso Tabella delle Transizioni Sintesi (Karnaugh, etc) Specifiche del Problema RL ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#20": "Alcune considerazioni sulle RSS •  Lo stato della rete cambia solo in corrispondenza dei fronti di   salita del clock che si susseguono con periodo T  •  La rete risponde ogni T ⇒ se si desidera massimizzare la velocità   di risposta della rete è necessario adottare il modello di Mealy   •  La rete è svincolata dai ritardi della rete G! Quindi, nessun   problema di corse critiche (purché T > τSUmin + τRmin !)  •  All’interno di uno stesso progetto sono tipicamente presenti più    RSS e non necessariamente per tutte le RSS il clock è lo stesso   e/o coincide con il clock del processore  •  Le RSS sono (più) facili da progettare delle RSA ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#21": "Clock gating e glitch sul clock Nelle reti sincrone è necessario evitare variazioni spurie (glitch) del segnale di clock che possono provocare commutazioni indesiderate dei FFD.   Ad esempio, per via dei reciproci ritardi tra i t segnali D[t-1..0] e/o le alee introdotte dalla rete combinatoria di decodifica, a causa del “clock gating“, può verificarsi quanto segue FFD D CK Q Q* D CK Q Q* CK P CK_G \nCK_G Glitch sul clock → commutazione spuria del FFD ! NO !! Rete di  Decodifica D[t-1..0] P t ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#22": "Il clock gating, oltre a generare potenziali glitch introduce  “clock-skew”. Ad esempio, consideriamo le due RSS seguenti Clock gating e clock-skew \nCK CK_G τAND FFD D CK Q Q* I1 CK B B* CK_G 1 FFD D CK Q Q* I2 CK A A* τAND \nτAND I clock delle due reti sono sfasati di un tempo pari al ritardo introdotto dall’AND. Tale fenomeno (“clock-skew”) è potenzialmente dannoso. Perchè ? \nIl “clock-skew” non è causato solo dal clock gating ma anche (ad esempio) da percorsi elettrici di lunghezza diversa. ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#23": "Esercizio 2  Progettare un registro a 8 bit con uscita tri-state utilizzando FFD positive edge triggered.  La rete, ad ogni fronte di salita del clock, memorizza il byte IN[7..0] in ingresso se WE=1 mentre mantiene il valore precedentemente memorizzato in caso contrario (WE=0). L’uscita OUT[7..0] della rete deve essere posta nello stato di alta impedenza quando il segnale OE=0. Inoltre, la rete deve essere dotata di un ingresso asincrono di RESET (A_RESET) che, se 1, pone al livello logico 0 l’uscita OUT[7..0] indipendentemente dal valore dei segnali WE, IN e CK. Quali condizioni devono essere soddisfatte perché sia garantito il corretto funzionamento della rete ? ? WE A_RESET IN[7..0] CK OUT[7..0] OE WE IN[7..0] OE OUT[7..0] ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#24": "WE OE FFD D Q Q* R IN OUT 0 1 Q A_RESET Soluzione Caso singolo bit \nNOTA  - Per garantire il corretto funzionamento della rete è   necessario rispettare tempi di setup e hold  - Il FFD esiste (8X) in forma integrata (74XX374) ed è dotato   di comando di OE CK ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#25": "NOTA  - La soluzione seguente NON è corretta in quanto:       a) variazioni spurie (glitch), dovute a instabilità del        segnale WE, possono causare commutazioni indesiderate         del flip-flop       b) il gate ritarda il segnale di clock del FFD e potrebbe        causare potenziali sfasamenti (“clock-skew”) tra i clock        dei vari componenti della rete sincrona complessiva WE OE FFD D Q Q* R IN OUT Q A_RESET CK ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#26": "FFD D Q Q* R IN7 WE OE OUT7 0 1 \nFFD D Q Q* R IN1 OUT1 0 1 \nFFD D Q Q* R IN0 OUT0 0 1 Q7 \nQ1 Q0 A_RESET Estensione a 8 bit CK ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#27": "Estensione a 8 bit (meglio) \nWE OE FFD D Q Q* R IN[7..0] OUT[7..0] 0 1 Q[7..0] A_RESET CK 8 8 8 8 8 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#28": "Esercizio 3  Progettare una rete che periodicamente dopo tre periodi di clock setta al livello logico 1 la propria uscita per un periodo clock. \nA_RESET CK OUT \nCK OUT (0) (1) (2) (0) (1) (2) (3) (3) ? OUT ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#29": "COUNTER X4 Una possibile soluzione si basa sull\u0001utilizzo di un contatore modulo 4.  Soluzione 3.1  \nCK u1 u0 OUT A_RESET Progettare un contatore modulo 4…. A_RES Perchè ? u1 u0 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#3": "Modello della Macchina a Stati Finiti (FSM) - Mealy F G k n I? r U S S* U=F(S,I) S*=G(S,I) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#30": "FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0  0 0  1 1  0 1  1 u1 u0 Contatore modulo 4 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#31": "Contatore modulo 4 con comando di ENABLE (EN) \nFFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0 1 EN 0 1 EN ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#32": "0  0 0  1 1  0 1  1 u1 u0 Contatore modulo 4 UP/DOWN (U/D*)  \nFFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 0 1 U/D* ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#33": "Contatore modulo 4 con LOAD (L) FFD D Q Q* FFD D Q Q* XOR u0 u1 R* R* CK A_RESET* 1 0 L 1 0 L i0 i1 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#34": "Esercizi E3-1) Progettare un contatore modulo 4 dotato dei segnali       U/D*, EN e L nei seguenti 2 casi:   a) segnale L prioritario rispetto a EN    b) segnale EN prioritario rispetto a L       In entrambi i casi si supponga che U/D* sia il     segnale meno prioritario tra i tre.  E3-2) Progettare un contatore modulo 8  E3-3) Progettare un contatore modulo 5 utilizzando un       contatore modulo 8 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#35": "Osservando le forme d\u0001onda mostrate sotto si può ottenere una soluzione alternativa alla precedente (3.1) Soluzione 3.2  CK u1 u0 OUT (0) (1) (2) (0) (1) (2) (3) (3) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#36": "FFD D Q Q* R* CK A_RESET* FFD D Q Q* R* OUT NOTA - Questa soluzione non può essere ottenuta con il metodo   della sintesi formale studiato a Reti Logiche ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#37": "ττττNOTA - Non è il caso della rete della pagina precedente, ma la   presenza di alee può creare problemi alle reti che seguono   se queste utilizzano come ingresso di clock un segnale che    presenta oscillazioni spurie (glitches).    Si consideri ad esempio il caso seguente: \nFFD D Q Q* c b a 1 1 IN OUT S u u S τττ\nAlea statica: provoca un campionamento indesiderato del FFD ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#38": "NOTA -  Le alee possono essere eliminate introducendo ulteriori   gates (vedi reti logiche)   -  In alcuni casi le alee possono essere filtrate dagli   stessi gates (ad esempio nel caso di ‘lentezza’ dei   dispositivi rispetto ai tempi del glitch); questa   possibilità deve essere verificata attentamente   analizzando i datasheets dei componenti utilizzati a b c a b c Un impulso troppo breve potrebbe essere filtrato dall\u0001AND ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#39": "Soluzione canonica ottenuta mediante sintesi formale. Soluzione 3.3  \nA,0 B,0 C,0 D,1 Grafo degli stati  \nTabella di flusso  sn sn+1 sn,u u A B 0 B C 0 C D 0 D A 1 Tabella delle  transizioni  y1n y0n u 0 0 0  1 0 0 1 1  0 0 1 0 1  1 0 1 1 0  0 1 y1n+1 y0n+1 Sintesi minima (mappe di Karnaugh,…) u = y1n·y0n y0n+1 = y0n* y1n+1 = y1n XOR y0n ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#4": "F G k n I? r U S S* U=F(S) S*=G(S,I) Modello della Macchina a Stati Finiti (FSM) - Moore ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#40": "FFD D Q Q* FFD D Q Q* XOR y0 y1 R* R* CK u NOTA  - Se si desidera aggiungere un segnale di ENABLE alla rete   precedente mediante il metodo della sintesi formale ?   - E\u0001 necessario ripetere tutti i passi precedenti (grafo,   diagramma stati, …) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#41": "Esercizio 4  Progettare un registro a scorrimento (shift-register) a 3 bit. ? IN A_RESET CK OUT1 OUT2 OUT0 IN A_RESET O1 O2 O0 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#42": "CK IN A_RESET OUT1 Soluzione \nOUT2 OUT0 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#43": "FFD D Q Q* R* A_RESET* FFD D Q Q* R* A_RESET* FFD D Q Q* R* A_RESET* IN OUT2 OUT1 OUT0 \nCK Esercizi E4-1) Progettare uno shift-register dotato di comandi         di enable EN e LOAD (parallelo e prioritario         rispetto all\u0001enable).  E4-2) Utilizzando due shift-register a 4 bit e un        contatore modulo 8: progettare un convertitore         serie parallelo a 8 bit dotato di un segnale (ACK)    che comunica l\u0001avventura ricezione degli 8 bit.  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#44": "Esercizio 5  Progettare una rete sincrona dotata di un ingresso  IN e di un’uscita OUT. L’uscita OUT deve asserirsi esattamente per un periodo di clock se viene rilevata una transizione da 0 a 1 del segnale di ingresso (monoimpulsore). Si noti che il segnale di ingresso potrebbe anche essere non sincrono (purché rispetti tempi di setup  e hold) ? IN CK OUT CK IN OUT IN OUT ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#45": "FFD D Q Q* FFD D Q Q* IN OUT CK Soluzione \nCK IN OUT ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#46": "FFD D Q Q* IN OUT CK Perchè questa soluzione è sbagliata (1) ? \nCK IN OUT ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#47": "Perchè questa soluzione è sbagliata (2) ? \nFFD D Q Q* IN OUT CK CK IN OUT ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#48": "Perchè questa soluzione è sbagliata (3) ? \nFFD D Q Q* IN OUT CK CK IN OUT ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#49": "Esercizio 6  Progettare un rete che controlla se gli ultimi tre caratteri che si sono presentati sull’ingresso IN[7..0] mentre il segnale EN era a livello logico 1 sono stati FFh (primo carattere della sequenza), 27h e 30h. Nel caso sia rilevata la sequenza FF-27-30, nel periodo di clock successivo a quello dell’ultimo carattere ricevuto (30h), deve essere asserita l’uscita OUT e rimanere tale fino a che non viene asserito il segnale (asincrono) di reset A_RESET. In seguito ad un reset deve riprendere immediatamente il controllo della sequenza in ingresso come se non fosse stato ricevuto alcun carattere. ? EN A_RESET IN[7..0] CK OUT EN A_RESET IN[7..0] OUT ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#5": "Reti Sequenziali Asincrone (RSA) ? k τk Retroazione diretta (τ: ritardo intrinseco della RC G) S U S* IS S* S S* \nt t+τ(1) (2) (3) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#50": "CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 30h 16h 80h \nOUT (1) (2) (3) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#51": "374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 \nEN \nFFD D Q Q* 1 0 OUT R* R* R* A_RESET* \nA_RESET* A_RESET* \nIl segnale EN condiziona l\u0001ultimo carattere della sequenza CK CK \nCK DEC_30 DEC_27 DEC_FF OE* OE* 0 0 Soluzione 6.1 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#52": "Soluzione 6.2 \nCK A_RESET* LOAD ENABLE 0 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*  ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  Una soluzione alternativa utilizzando un contatore dotato di  comando di LOAD \nC\u0001è un problema… ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#53": "CK A_RESET* LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*  ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  .. nella soluzione della pagina precedente cosa accade se i  caratteri ricevuti (con EN=1) sono FF-FF-27-30 ? \nDEC_FF ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#54": "Esercizi E5-1) Riprogettare la rete dell\u0001esercizio 6 in modo che     OUT assuma il valore logico 1 in seguito alla     ricezione anche non consecutiva (con EN=1) dei     caratteri FFh, 27h e 30h.          Ad esempio, OUT=1 se i caratteri ricevuti (mentre     EN=1) sono stati: FF-7A-80-9F-27-B2-30-…  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#55": "Esercizio 7  Modificare l\u0001esercizio precedente in modo che, in seguito al rilevamento della sequenza, l\u0001uscita OUT assuma il valore logico 1 per un solo periodo di clock. Appena ricevuta una sequenza completa il controllo dei caratteri in ingresso deve riprendere immediatamente. ? EN A_RESET IN[7..0] CK OUT OUT EN A_RESET IN[7..0] ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#56": "CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 30h 16h 80h \nOUT (1) (2) (3) Soluzione 7.1 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#57": "374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 \nEN \nFFD D Q Q* 1 0 OUT R* R* R* A_RESET* A_RESET* \nA_RESET* CK CK \nCK ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#58": "Soluzione 7.2 \nCK A_RESET LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30* + OUT ENABLE = ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30  Rispetto all\u0001esercizio 6.2 è sufficiente modificare il comando di LOAD facendo in modo che LOAD=1 quando OUT=1 ?  \nEN·DEC_FF \nCosa accade se (con EN=1) la sequenza è 45-FF-27-30-FF-27-30-… ? ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#59": "Esercizi E6-1) Riprogettare la rete dell\u0001esercizio 6 in modo che    OUT=1 in seguito alla ricezione anche non consecutiva    (con EN=1) dei caratteri FFh, 27h e 30h.         Ad esempio, OUT=1 se i caratteri ricevuti mentre EN=1    sono stati: FF-7A-80-9F-27-B2-30-…   E6-2) Cosa accade alle soluzioni 6.1 e 6.2 se (mentre EN=1)       la sequenza è: 45-FF-27-30-FF-27-30-… ?  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#6": "•  Le reti asincrone rispondono molto rapidamente (appena possibile)   alle variazioni degli ingressi •  Non è necessario un segnale di sincronismo (clock) •  Ridotta dissipazione di potenza Aspetti positivi delle RSA (vs RSS) Aspetti negativi delle RSA (vs RSS) •  Vincoli per il corretto impiego   - l’ingresso può variare solo quando la rete ha raggiunto     una condizione di stabilità   - i segnali di ingresso possono variare uno alla volta •  Esposte a potenziali malfunzionamenti (corse critiche)  •  Difficili da progettare In pratica, sono utilizzate per realizzare latch e flip-flop.  A noi interessano (maggiormente) le reti sincrone (RSS) ! ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#60": "Esercizio 8  Progettare un rete che controlla se gli ultimi tre caratteri che si sono presentati in ingresso IN[7..0] mentre il segnale EN=1 sono stati FFh (primo carattere della sequenza), 27h  e 30h. Nel caso sia rilevata tale sequenza, due periodi di clock successivi a quello dell’ultimo carattere della sequenza ricevuto deve essere asserita l’uscita OUT e rimanere tale fino a che il segnale di reset (asincrono) A_RESET non assume il valore logico 1. In seguito ad un reset (asincrono) la rete deve riprendere immediatamente  il controllo della sequenza in ingresso come se non fosse stato ricevuto alcun carattere.  ? EN A_RESET IN[7..0] CK OUT OUT EN A_RESET IN[7..0] ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#61": "CK IN[7…0] A_RESET EN 30h FFh FFh 27h 55h 30h 18h 16h 80h \nOUT (1) (2) (3) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#62": "374 D Q Q* 0 1 EN 8 8 374 D Q Q* 0 1 EN 8 8 30h IN[7…0] 27h FFh 8 \nEN \nFFD D Q Q* 1 0 OUT R* R* R* A_RESET* \nA_RESET* A_RESET* \nIl segnale EN condiziona l\u0001ultimo carattere della sequenza CK CK \nCK FFD D Q Q* R* A_RESET* CK Soluzione 8.1 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#63": "CK A_RESET* LOAD ENABLE 0 COUNTER X4 EN RES* Q1 Q0 L I1    I0 DEC 2:4 I1 I0 O1 O0 O3 O2 EN 1 OUT ATTESO_30 ATTESO_27 ATTESO_FF 30h IN[7…0] 27h FFh 8 DEC_30 DEC_27 DEC_FF LOAD = (ATTESO_FF·EN·DEC_FF* + ATTESO_27·EN·DEC_27* + ATTESO_30·EN·DEC_30*)·OUT_1*  ENABLE = (ATTESO_FF·EN·DEC_FF + ATTESO_27·EN·DEC_27 + ATTESO_30·EN·DEC_30)·OUT_1*  DEC_FF Soluzione 8.2 FFD D Q Q* R* A_RESET* CK OUT_1 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#64": "Esercizio 9  Progettare una rete dotata di tre ingressi E, A/I*, A_RES e un\u0001uscita OUT. Il segnale di ingresso A/I* influisce sulla rete solo se contemporaneamente E=1. L\u0001uscita della rete deve andare al livello logico 1 per un periodo di clock se viene rilevato per cinque volte, anche non consecutive, il valore 1 del segnale A/I* in presenza del segnale E=1. Ogni volta che il segnale A/I* assume il valore 0 (con E=1) deve essere ridotto di uno il numero di eventi rilevati fino a quel momento. Successivamente a un reset (segnale asincrono) o nel caso nessun evento sia stato ancora rilevato (o che il numero di incrementi sia stato compensato da un numero equivalente di decrementi la rete deve rimanere nello stato 000 anche se A/I*=0 ed E=1. Dopo avere rilevato cinque eventi la rete deve riprendere l’analisi degli ingressi. ? E A/I* A_RESET CLOCK OUT OUT E A/I* A_RES ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#65": "COUNTER X 8 EN U/D# LOAD I2 I1 I0 O2 O1 O0 E A/I* OUT OUT CLOCK 0 0 A/I* \nO2 O1 O0 A/I* RESET A_RESET Soluzione 9.1 E L’OR blocca il conteggio (EN=0), anche con E=1, se il contatore si trova nello stato 000 e il comando DOWN è asserito (A/I*=0). Perché ? \nO1 è strettamente necessario ?  (No, perché ?) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#66": "A,0 B,0 C,0 D,0 E,0 F,1 E A/I* 0 – 1 0 0 – 0 – 0 – 0 – 1 1 1 1 1 1 1 1 1 1 1 1 0 – 1 0 1 0 1 0 1 0 1 0 Soluzione mediante sintesi formale: grafo -> tabella di  flusso -> tabella delle transizioni,... NON SI USA !!!! Soluzione 9.2 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#67": "Esercizio 10  Utilizzando un microprocessore dotato di un bus indirizzi a 16 bit e di un bus dati a 8 bit: mappare nello parte bassa dello spazio di indirizzamento 12k di RAM e nella parte alta 16k di EPROM. ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#68": "Soluzione RAM (12K) \nEPROM (16K) 0000h  2FFFh \nC000h FFFFh A15..A12 A11..A8 A7..A4 A3..A0 0000 0000 0000 0000 (0000h)  \n1111 1111 1111 1111 (FFFFh) 0010 1111 1111 1111  (2FFFh) \n1100 0000 0000 0000 (C000h) RAM_1 (8k) RAM_2 (2k) RAM_3 (2k) \nEPROM (16k) 0001 1111 1111 1111 (1FFFh)  0010 0000 0000 0000  (2000h) 0010 0111 1111 1111  (27FFh) 0010 1000 0000 0000  (2800h) CS_RAM_1=A15*·A13* CS_RAM_2=A15*·A13· A11* CS_RAM_3=A15*·A13· A11 CS_EPROM=A15 Segnali di decodifica: ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#69": "- Il segnale CS_EPROM si attiva per ogni indirizzo maggiore   o uguale di 8000h (seconda metà dello spazio di   indirizzamento) 0000h  \nC000h FFFFh 8000h Indirizzi di memoria con A15=1 CS_EPROM=A15 NOTA  - La codifica semplificata implica l\u0001attivazione dei   segnali di selezioni anche per indirizzi diversi da   quelli in cui sono realmente presenti i dispositivi    di memoria.  \nEPROM (16K) EPROM (16K) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#7": "RSA notevoli: Latch SR SR S R Q Q* S R Q Q* S R 0 0 0 1 1 0 1 1 Q Q* Q Q* 0 1 1 0 \nQ = S’ ↑ (q ↑ R’) S’ R’ Q Q*  Q = R ↓ (S ↓ q) S R Q Q*  \nI comandi di set e reset devono avere una durata minima (vedi datasheet) per consentire il raggiungimento della condizione di stabilità ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#70": "- Il segnale CS_RAM_1 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=0:  0000h  \nFFFFh 8000h CS_RAM_1=A15*·A13* RAM_1 (8k) A15..A12  A11..A8    A7..A4   A3....A0 0000  0000  0000  0000 (0000h)  0001  1111  1111  1111 (1FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0100  0000  0000  0000 (4000h)  0101  1111  1111  1111 (5FFFh)  Quindi, CS_RAM_1=1 per entrambi i  seguenti intervalli di memoria: 1FFFh  4000h RAM_1 (8k) 5FFFh ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#71": "- Il segnale CS_RAM_2 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=1 e A11=0 :  0000h  \nFFFFh 8000h CS_RAM_2=A15*·A13·A11* A15..A12  A11..A8    A7..A4   A3....A0 0010  0000  0000  0000 (2000h)  0010  0111  1111  1111 (27FFh)  A15..A12  A11..A8    A7..A4   A3....A0 0011  0000  0000  0000 (3000h)  0011  0111  1111  1111 (37FFh)  Quindi, CS_RAM_2=1 per i seguenti quattro intervalli di memoria: 2000h  4000h 6000h A15..A12  A11..A8    A7..A4   A3....A0 0110  0000  0000  0000 (6000h)  0110  0111  1111  1111 (67FFh)  A15..A12  A11..A8    A7..A4   A3....A0 0111  0000  0000  0000 (7000h)  0111  0111  1111  1111 (77FFh)  RAM_2 (2k) RAM_2 (2k) 3000h  RAM_2 (2k) RAM_2 (2k) 7000h ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#72": "- Il segnale CS_RAM_3 si attiva per ogni indirizzo compreso   tra 0000h e 7FFFh (A15=0) per il quale A13=1 e A11=1 :  0000h  \nFFFFh CS_RAM_3=A15*·A13·A11 A15..A12  A11..A8    A7..A4   A3....A0 0010  1000  0000  0000 (2800h)  0010  1111  1111  1111 (2FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0011  1000  0000  0000 (3800h)  0011  1111  1111  1111 (3FFFh)  Quindi, CS_RAM_3=1 per i seguenti quattro intervalli di memoria: 2800h  6800h A15..A12  A11..A8    A7..A4   A3....A0 0110  1000  0000  0000 (6800h)  0110  1111  1111  1111 (6FFFh)  A15..A12  A11..A8    A7..A4   A3....A0 0111  1000  0000  0000 (7800h)  0111  1111  1111  1111 (7FFFh)  RAM_3 (2k) RAM_3 (2k) 3800h  RAM_3 (2k) RAM_3 (2k) 7800h ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#73": "0000h  \nFFFFh 2800h  RAM_2 (2k) RAM_3 (2k) RAM_1 (8k) 2000h  3800h  RAM_2 (2k) RAM_3 (2k) 3000h  4000h  6800h  RAM_2 (2k) RAM_3 (2k) RAM_1 (8k) 6000h  7800h  RAM_2 (2k) RAM_3 (2k) 7000h  EPROM (16K) EPROM (16K) 8000h  C000h Effetto di replica nella mappatura in memoria dovuto alla  decodifica semplificata. Nella figura seguente sono indicati  solo gli indirizzi iniziali. ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#74": "Esercizio 11  Utilizzando un microprocessore dotato di un bus indirizzi a 20 bit e di un bus dati a 8 bit:  - mappare nello parte bassa dello spazio di indirizzamento    32k di RAM e nella parte alta 32k di EPROM   Nel sistema sono presenti anche due dispositivi di I/O denominati D1 (dotato di due registri interni) e D2 (dotato di quattro registri interni):  - mappare in memoria anche i due dispositivi di I/O D1 e    D2 agli indirizzi 2000h e 1000h  Osservando che esiste una sovrapposizione tra gli indirizzi di una memoria e dei due dispositivi di IO, si scrivano i CS, in forma semplificata, di tutti i dispositivi presenti nel sistema riducendo al minimo gli indirizzi “sottratti” dai dispositivi di IO alla memoria. ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#75": "Soluzione  RAM: 1 chip da 32KB RAM  (00000h->07FFFh) CS_RAM = BA19*·CS_D1*·CS_D2*   EPROM: 1 chip da 32KB EPROM (F8000h – FFFFFh) CS_EPROM = BA19   D1: Mappato in memoria all\u0001indirizzo 02000h, occupa 2 locazioni (A0)     nello spazio di indirizzamento. CS_D1 = BA19*·BA14*·BA13·BA12*·BA11*·BA10*·BA9*·BA8*·BA7*·BA6*·          BA5*·BA4*·BA3*·BA2*·BA1*   D2: Mappato in memoria all\u0001indirizzo 01000h, occupa 4 locazioni (A1A0) nello spazio di indirizzamento.  CS_D2 = BA19*·BA14*·BA13*·BA12·BA11*·BA10*·BA9*·BA8*·BA7*·BA6*·       BA5*·BA4*·BA3*·BA2*  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#76": "Esercizio 12  Utilizzando un microprocessore dotato di un bus indirizzi a 20 bit e di un bus dati a 8 bit:    - mappare 32k di RAM nella parte bassa dello spazio di    indirizzamento, 32k di RAM a partire dall\u0001indirizzo     1C000h e 64k EPROM nella parte alta dello spazio di    indirizzamento ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#77": "RAM_1 (32k) RAM_2 (32k) \nEPROM (64k) 00000h 10000h 20000h 30000h \nF0000h 1C000h    0001 1100 0000 0000 0000  23FFFh    0010 0011 1111 1111 1111     \nFFFFFh Soluzione 00000h    0000 0000 0000 0000 0000  07FFFh    0000 0111 1111 1111 1111     \nF0000h    1111 0000 0000 0000 0000  FFFFFh    1011 1111 1111 1111 1111     CS_RAM_1=A19*·A17*·A16* CS_RAM_2=A19*·(A17 + A16) CS_EPROM=A19 CS_RAM_2=A19*·CS_RAM_1* oppure ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#8": "RSA notevoli: Latch CD CD C D Q Q* C D Q Q* C D 0 0 0 1 1 0 1 1 Q Q* Q Q* Q Q* 0 1 1 0 SR S R Q Q* C D Q Q* C D Q τSU τH τSU ≥ τSUmin τH≥ τHmin Vincoli: Tempo di risposta: τR > τH Latch CD: il problema/vantaggio delle “uscite trasparenti” ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\00_Complementi_Esercizi_Reti_Logiche.pdf#9": "Driver 3-state \nOE I U OE=0 I U OE=1 I U I OE U Quale è il valore della tensione  ? OE I 1 0 1 1 0 0 0 1 U 0 1 Z Z ? ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#0": "01 IntroduzioneCalcolatori Elettronici TIngegneria Informatica\nStefano Mattoccia",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#1": "DocentiStefanoMattocciaRicevimento:pressostudio,vicinoaula5.7,suappuntamentoconcordatoviaemailEmail:stefano.mattoccia@unibo.itHomepage:http://vision.disi.unibo.it/~smattMatteoPoggi(tutor,AA2020/21)Ricevimento:pressoLaboratoriodiComputerVision,suappuntamentoconcordatoviaemailEmail:m.poggi@unibo.itHomepage:https://mattpoggi.github.io/",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#10": "Struttura di una prova d’esame \nEsercizio 1: progetto di un sistema a microprocessore.Per superare l’esame, è necessario proporre una soluzione ragionevole. L’esercizio 1 determina il superamento/non superamentodella prova.Esercizi 2 e 3: domande di teoria che richiedono qualcheragionamento. Volutamente non è fornita la soluzione.",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#11": "Elaborazione delle informazioni\nInputOutputUnessereviventeelaboracontinuamentedelleinformazionieforniscedellerisposteoagisceinundeterminatomodoinbasealleinformazioniiningresso.\nUnsistemadiqualsiasinaturaperl’elaborazionedelleinformazioniisolatodall’esternoservirebbeabenpoco(meglio,nulla).Inputeoutputdebbonoesserecodificatiinmodoappropriato\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#12": "Elaborazione delle informazioniOvviamente,inquestocorso,siamointeressatiasistemidinaturaelettronicaperelaborareleinformazioni.Inparticolare,perleragionievidenziateaRetiLogicheT,siamointeressatiasistemidigitali->RetiLogiche\nInputOutput\nRL01101101011101",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#13": "Elaborazione delle informazioniUnprimoproblema:leretilogicheelaboranoinformazioniditipodigitaleMoltiinputeoutputdiparticolareinteressenonsonodinaturadigitalemaanalogica(quellapreferitadagliesseriumani)•Prossimitàaunsemaforoounostacolo•Monitor•Movimentodelmouse•Voce/Audio•Pressionetasti•Touchscreen•etc",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#14": "InputOutput\nRLA/D\nD/A\nPertanto,è(spesso)necessarioconvertiresegnalidinaturaanalogicainsegnalidigitalieviceversaElaborazione delle informazioni\n‘01001101’ ‘110111’ Inunsistemadielaborazione,iningressoeinuscitatroviamosolosegnalidigitali(binari)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#15": "Elaborazione delle informazioniAltroproblema:laretelogicacheelaboraleinformazionièspessomoltoefficienti/veloce/etcmaallostessotempopocoflessibileperquantoriguardaillinguaggioutilizzabileperfornireleinformazioni(digitali)ininputeinterpretareleinformazioni(digitali)elaborateinoutput.Sesidesiderainteragireconunsistemadielaborazionedigitaleenecessarioadeguarsiallinguaggiochelaretelogicautilizza.Questolinguaggioècodificatodall’evoluzionetemporaledialcunisegnali(ilminimoindispensabile)emessioricevibilidallaretelogica.L’evoluzionetemporalediquestisegnalisidefinisceciclodibus(buscycle).",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#16": "RLElaborazione delle informazioni\nttttttttQuindi,l’unicomodoperinteragireconunsistemadigitaleperl’elaborazionedelleinformazioniconsistenell’adottarequestaconvenzione(ie,iciclidibus,descrittiindettagliosuidatasheetcheilproduttoredelsistemarendesempredisponibili).\nciclo di busciclo di bus",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#17": "Quale rete logica utilizzare?Sonodisponibilidiversearchitetturedielaborazione(i,e,retilogiche).Qualescegliere?Dipendedalcontestoapplicativoedalleprestazioni,consumi,ingombri,peso,etc:-sistemageneralpurpose-sistemaembedded-sistemapervideogiochi-etcUnatipologiadiarchitettura,basatasulmodellodiVonNeumann,èmoltopiùflessibiledellealtreepuòessereutilizzata,anchesenonsempreconrisultatiottimali,inognicontesto.Questomodelloèl’oggettodiquestocorsoeutilizzacomeelementodibaseunaCPU(microprocessore).",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#18": "Esempi di architetture di elaborazione\n19\n•CPU(CentralProcessingUnit)•CPUMulticore•CPUEmbedded•SOC(SystemonaChip)•GPU(GraphicProcessingUnit)•FPGA(FieldProgrammableGateArray)•Sistemiibridi(e.g.FPGA+CPU)•...",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#19": "■Architetturadeltuttogeneralecheportaarealizzazionipocodipendentidalfunzionamentodesiderato■Ilfunzionamentodesideratoèespressointerminidi✸sequenzadiistruzioni(programma)✸memorizzatesuunsupportodimemoria■Percambiarefunzionamentoèsufficientecambiareilprogramma:questodifatto\u0001modifica\u0002laretelogicadicontrolloperogniistruzioneeseguita■L’architetturaèadattaatrattareproblemimoltopiùcomplessidiquellivistinelcorsodiretilogichemaconefficienza(tipicamente)inferiore■L'importanzaeladiffusionedeicalcolatoridipendefortementedallaflessibilitàdiquestomodelloIl modello di riferimento: Von Neumann",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#2": "Obiettivi del corsoApprendere,•i principi di funzionamento•le architetture•la progettazione hardware e softwaredei sistemi per l’elaborazione delle informazioni basati microprocessore(o CPU –Central Processing Unit)\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#20": "Rete combinatoriaUscite OjIngressi Xi  Variabilidi statoYk(n+1)Variabili di statoYk(n)Rete Sequenziale(Sincrona)RegistriSistema di elaborazione: rete sequenzialeIl sistema di elaborazione può essere schematizzato in modoastratto come una Rete Sequenziale (Sincrona), RSS",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#21": "Come cambiareil funzionamento della RL?\nRegistriUscite OjIngressi Xi Variabilidi statoYk(n+1)Variabilidi statoYk(n)RetecombinatoriaSegnali dicontrolloProgramma(software)RispettoaRetiLogiche,lanovitàèilsoftware(programma)checonsentedivariareilfunzionamentodellareteinbasealleesigenzedesiderate(ie,ilcodicescrittodalprogrammatore).",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#22": "In realtà le cose sono più complesse\nUscite OjIngressi Xi Variabilidi statoYk(n+1)Variabilidi statoYk(n)RCSegnali dicontrolloProgramma(software)Unità dicontrollo(RSS)Istruzioni (dalla memoria)\nL\u0001unitàdicontrollononsologovernalaretecombinatoriamaanchetuttelealtreretilogichepresentinelsistemaEsempio:abilitagliingressieleuscitequandonecessario,etcRegistri\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#23": "•Ilprogrammarisiedeinmemoriaedècostituitodaistruzionicodificateinformabinaria(linguaggiomacchina)•Inmemoriarisiedonoancheglioperandidelleistruzioni,cioèidatielaboratiedaelaborare(formabinaria)•LeistruzionivengonoeseguiteinsequenzadallaCPU•LaCPUèunamacchinasequenzialesincrona(conunclock)Modello di esecuzione del programma\nUscite\nistruzioniIngressiCPUIstr. #1Istr. #2. . .Istr. #NCk",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#24": "Alivellodimassimaastrazione,ilfunzionamentodell’interosistemapuòesseredescrittomedianteduesolistati:–StatoincuilaCPUleggeinmemorialaprossimaistruzionedaeseguire(INSTRUCTIONFETCHoIF)–StatoincuilaCPUeseguel\u0001istruzionelettainIF(EXECUTEoEX)ISTRUCTIONFETCH(IF)EXECUTE(EX)\nCPUIstr. #1Istr. #2. . .Istr. #N",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#25": "RL CPU e istruzioni•Leretilogichevistearetilogicheelaboravanoeproducevanosegnalibinari•SelaCPUèunaRL,comesonocodificateleistruzioni?•Ovviamenteinbinario...•Esempioistruzione#1->00010100000101111101010000010011istruzione#2->10110101100100011001010000011001......istruzione#N->01010110100101010101010110011110•OgniistruzioneindicaallaCPUqualeoperazionedevesvolgere/eseguire•Nonsembraessereunmodomoltocomodo(pergliesseriumani)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#26": "Esempi di istruzioni•QualiistruzionipossonoessereeseguitedaunaCPU?•Somme•Moltiplicazioni•Divisioni•Confronto•Letturedallamemoriaodaaltridispositivi*•Scrittureinmemoriaoversoaltridispositivi*•...EsistonosostanzialmenteduetipologiediCPU:•RISC(ReducedInstructionSetComputer)Pocheesempliciistruzioni,retilogichesempliciemoltoveloci(frequenzadiclockelevata).eg,ARM•CISC(ComplexInstructionSetComputer)Molteistruzioni,alcunemoltocomplesse,retilogichecomplicate.eg,InteleAMD",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#27": "RISC vs CISC•TipicamenteaunasolaistruzioneCISCcorrispondonopiùistruzioniRISC•Tuttavia,ognisingolaistruzioneRISCèeseguitaspessopiùrapidamentediunaistruzioneCISC•Spesso,ilcodiceRISC,anchesepiùdenso,èpiùveloce•LeRLRISCsonotipicamentepiùsemplicidiquelleCISC•Seleretisonopiùsemplicilospazio(silicio)puòessereutilizzatoperaltrefinalità(registri,cache,etc)•IprocessoriRISCsonomoltodiffusi(smartphone,tablete)•AncheiprocessoriCISCsonomoltodiffusi(PC)perviadelsoftwareesistente*•LeCPUCISCmodernesonoinrealtàinternamentedeiRISC",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#28": "•IndipendentementedaltipodiCPU,leistruzioniinformabinarianonsonofacilmenteinterpretabilieperquestononutilizzateinquestaformaquandosiscriveilcodice•Illinguaggiochesiutilizzaèl’assembler:ADDR1,R2,R3;poneinR1lasommatraregistriR2eR3Questaistruzionepotrebbeesserecodificatacon:00010100000101111101010000010011Iltraduttoreassembler->codicemacchinainbinarioèunaLookUpTable(LUT),ovverounatabellaL’assemblersembraessereunpassoavantinotevolema...Perchénonavetemaiutilizzatoillinguaggioassemblernonostantescrivetecodicedalprimoanno?Istruzioni in forma più comprensibile",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#29": "Compilatore e istruzioni binarie•Ilmotivoècheavetescrittocodiceadaltolivello(C)eutilizzatouncompilatore(e.g.,GCC)•Ilcompilatore,converteilcodicescrittoinlinguaggioadaltolivelloinistruzionimacchinabinarie#include<stdio.h>intmain(intargc,char**argv){inta=5;intb=6;intc;c=a+b;printf(“Lasommatra%de%dè%d\\n”,a,b,c);}GCC0001010000010111110101000001001110110101100100011001010000011001. . .01010110100101010101010110011110",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#3": "Orario lezioniOrario ufficiale:https://corsi.unibo.it/laurea/IngegneriaInformatica/orario-lezioni?anno=2&curricula=Lunedì inizio ore 9.00-11onlineGiovedì inizio ore 14.00-17.00Aula 6.1",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#30": "Come si accede alla memoria (e non solo)?•SappiamocheilcodicenelmodellodiVonNeumannrisiedeinmemoria•Comesilegge(escrivedallamemoria)?•Comesileggonoescrivonoidati?\nCPU\n?•L’unico modo è attraverso dei segnali predefiniti (con un ben definito andamento temporale, ciclo di bus)  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#31": "IndirizziBA[K..0]DatiBD[R..0] READControlloWRITEREADYINT\nCPU\nK+1R+1\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#32": "Come avviene la comunicazione?CPU\nK+1MemoriaPeriferica#i\nR+1•Tutto viaggia sui bus di sistema•Tutto è regolato da cicli di bus",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#33": "CKADDRESSMEMRDMEMWRDATADATA_INReady?Esempio di ciclo di lettura",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#34": "CKADDRESSMEMRDMEMWRDATADATA_OUTReady?Esempio di ciclo di scrittura",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#35": "Range di indirizzi•Sesonodisponibili32bit(BA[31..0])èpossibileavereaccessoa2^32elementi(memorie,periferiche)•32segnalidiindirizzo,4GB•Aogniindirizzoèassociatoundispositivo(memorie,periferiche)•E’necessariodecodificarel’indirizzoemessodallaCPUperdeterminareconqualedispositivolaCPUintendecomunicare•Quantibytepossonoesseretrasferitiduranteunciclodibus?Dipendedall’ampiezzadelbusdati",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#36": "Relazione tra hardware e software•ConsideriamounaistruzioneperleggeredallamemoriaunbyteaundeterminatoindirizzoxxxLBdestinazione,indirizzo;letturadiunbytePerprimacosaèeseguitoilfetchdell’istruzioneall’indirizzoxxx.come?Conunciclodibus,naturalmenteComefacciamoaconoscerel’indirizzoxxx?LaCPUhaaccessoalprogramcounterPCUnavoltalettaedecodificata,l’istruzioneèeseguita.Durantel’esecuzioneèeseguitounciclodibusdiletturaDuranteilciclodibusèemessol’indirizzo",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#4": "Materiale didatticoDisponibile in formato PDF sul sito del corso:http://vision.disi.unibo.it/~smatt/Site/Courses.htmlNel sito sono presenti anche numerose prove d’esameI lucidi non sono un libro, seguire con attenzione le lezioni è fondamentale per superare rapidamente e con buoni risultati l’esame...",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#5": "Materiale didattico per approfondimentiSeguendo il corso con attenzione e utilizzando i lucidiforniti NON è necessario utilizzare altro materialeper la preparazione dell’esame.Tuttavia, per chi desiderasse approfondire:–Hennessy & Patterson, \"Computer architecture: a quantitative  approach\u0001, Morgan Kaufmann, Anche in versione italiana. La seconda edizione (inglese, a dx) descrive approfonditamente il processore DLX-G. Bucci, \u0001Architettura e organizzazione dei calcolatori elettronici. Fondamenti\u0002, McGraw-Hill-J. Yiu, \u0001The definitive guide to the ARM Cortex M0\u0002, Newnes-Patterson &  Waterman, \u0001RISC-V\u0002, Strawberry Canyon\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#6": "RequisitiPer superare in modo proficuo il corso di Calcolatori Elettronici T è fondamentale avere compreso bene:1) Fondamenti di Informatica T2) Reti Logiche TPer Reti Logiche T è cruciale la progettazione diretta.Si sconsiglia vivamente di seguire questo corso senza avere solide basi in 1) e soprattutto di Reti Logiche T",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#7": "Avvisi e altre comunicazioni Eventuali comunicazione di carattere generale sarannoinserite nella pagina web del corso, nella sezione “Avvisi” di Calcolatori Elettronici T o chat Teams\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#8": "Modalità di svolgimento dell’esame •L’esame consiste in una prova SCRITTA di 2.5 ore•Nessuna prova orale• Non è possibile portare libri, appunti, computer, telefoni, smartphone, tablet, smartwatch, etc• E’ indispensabile (pena l’esclusione dall’esame) presentarsi con documento di identitàe badge•Esami gravemente insufficienti saranno verbalizzati",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\01_Introduzione.pdf#9": "Prossimi appelli d’esame \n•La date degli esami sono consultabili su Almaesami•L’iscrizioneagli appelli via Almaesamiè obbligatoria e si chiude (circa) una settimana prima• Non è ammessa alcuna deroghe all’iscrizione•Sono previsti 6 appelli all’anno: -3 Dicembre/Febbraio -2 Giugno/Luglio -1 SettembreNessun appello straordinarioSe possibile (aule, etc) il primo appello subito dopo il termine delle lezioni",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#0": "02 Mappinge decodificaCalcolatori Elettronici TIngegneria Informatica\nStefano Mattoccia",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#1": "Spazio di indirizzamento•Una CPU emette un certo numero di indirizzi e altri segnalisui bus di sistema per comunicare con altri moduli  •Il numero di diversi indirizzi emessi dalla CPU costituiscelo spazio di indirizzamento•Una CPU che emette un indirizzo a 20 bit ha uno spazio diindirizzamento di 1 MB (2^20)•Una CPU che emette un indirizzo a 32 bit ha uno spazio diindirizzamento di 4 GB (2^32)•Le prime CPU avevano spazi di indirizzamento molto ridottodi alcuni KB (e.g., 64 KB o meno)•Oggi è consuetudine avere almeno 32 bit di indirizzo",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#10": "11Memorie RAM (SRAM)\n•Memorie volatili, leggibili e scrivibili•Capacità a multipli di 4:8K, 32K, 128K, 512K, etc•DRAM: 1 transistore per  bit, maggiore capacità, più lenteAiCE*OE*I/OiTceTaccToe(Out)ReadCycleAiCE*WE*I/OiTawTwp(In)TdsWriteCycleNCA16A14A12A7A6A5A4A3A2A1A0I/O0I/O1I/O2GNDVCCA15NCWE*A13A8A9A11OE*A10CE*I/O7I/O6I/O5I/O4I/O31234567891011121314151632313029282726252423222120191817128K ´8RAM",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#11": "12\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#12": "13\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#13": "14\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#14": "15\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#15": "16\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#16": "17Integrati Notevoli: \u0001244\u00021A11A21A31A42A12A22A32A41Y11Y21Y31Y42Y12Y22Y32Y4EN1*EN2*74XX244ENx*xAixYiDriver 3-state ad 8-bit(strutturato in 2 gruppi di 4 bit) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#17": "18\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#18": "19\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#19": "20\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#2": "Un indirizzo per distribuire merci\nWR(consegna)RD(preleva)\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#20": "21EN*BiDIRAiA1A2A3A4A5A6A7A8B1B2B3B4B5B6B7B8EN*DIR74XX245IntegratiNotevoli: \u0001245\u0002Driver bidirezionale (transceiver) ad 8-bit.",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#21": "22\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#22": "23\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#23": "24\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#24": "25Integrati Notevoli: \u0001373\u0002D0D1D2D3D4D5D6D7O0O1O2O3O4O5O6O7COE*74XX373\nCDiQiOE*OiZCQiDCDiOE*OiLatch CD \nLatch a 8-bit con uscite 3-state",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#25": "26Integrati Notevoli: \u0001374\u0002D0D1D2D3D4D5D6D7O0O1O2O3O4O5O6O7CKOE*74XX374\nCKDiQiOE*OiZQiDCKDiOE*OiFlip-Flop D\nRegistro edge-triggeredcon uscite 3-state",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#26": "",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#27": "28\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#28": "29\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#29": "30Registro Edge-Triggered con WE*WE*D0OE*O0Flip-Flop DMUX10CKDQ0O1Flip-Flop DDQ1MUX10ON-1Flip-Flop DDQNMUX10D1\nDN-1D[0..N-1]WE*OE*O[0..N-1]",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#3": "CPU\nDecoder(RC)I livelloCS_ACS_BCS_CCS_DCS_ECS_FCS_GCS_HABCD\nEFGHUn indirizzo per distribuire dati (CPU)\nIl decoder di II livello è all’interno di ciascundispositivo (memoria, etc) \nBA[K-1..0]BD[R-1..0]",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#30": "Register File (1 read-port, 1 write-port)DEC01M-1EN*m  Read_AddressDEC01M-1EN*m  Write_AddressRD*WR*N  Write_DataRead_DataN CKD[0..N-1]WE*OE*O[0..N-1]R0D[0..N-1]WE*OE*O[0..N-1]R1\nD[0..N-1]WE*OE*O[0..N-1]RM-1N.B. :M=2m",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#31": "Mappingdi dispositivi da 8 bit in sistemicon bus dati da 8 bit•Consideriamodispositiviconportadatia8bit•Imponiamo(temporaneamente)l\u0001ulteriorecondizionecheilparallelismodelbusdatisiaa8bit•Inquesteipotesil\u0001assegnamentoaundispositivodiunafinestradiindirizziinunospaziodiindirizzamentoavverràingeneralenelrispettodelledueseguentiulterioricondizionirestrittive:–ladimensionedellafinestradiindirizziassociataaundispositivoèunapotenzadidue–lafinestraècompostadaindirizzicontigui",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#32": "33Dimensione della finestra occupata da un dispositivo -esempi•Undispositivoaccessibileattraversoilbusoccupaingeneralen=2^Kposizioninellospaziodiindirizzamento•nrappresentailnumerodioggettia8bitindirizzabiliall\u0001internodeldispositivo(es.numerodicelledimemorianelleRAMedEPROM)•K(numerodibitdiindirizzointernialdispositivo)èfortementevariabilealvariaredeldispositivo:–Ingeneraleneidispositividiinput/output(i.e.,leinterfacce)Kèpiccolo(e.g.,2)–ingeneraleneidispositividimemoriaKègrande(e.g.,perunaRAMda128KBsihaK=17)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#33": "Caratteristiche ai morsetti di un dispositivo indirizzabile su una finestra di n = 2^K byteQualunquedispositivoda8bitconall’internon=2^kelementiindirizzabiliseparatamentehaalsuointernoundecoder(IIlivello)diKvariabiliconingressodienablecheselezionaisingolioggettiindirizzabili–Read(RD),dettoancheOutputEnable(OE)èilcomandodilettura.QuandoRDeCSsonoattivi,ildispositivoesponeilsuBD[7..0]ilcontenutodellacellaindirizzata–Write(WR),èilcomandodiscrittura.QuandoCSasseritosulfrontedidiscesediWRècampionatoildaatopresentesuBD[7..0]DISPCSA[K-1..0].RDWRD[R..0]?KBA[K-1..0]CS_DISP8BD[7..0]RDWR",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#34": "350K32K8K8K8K8KSpazio di memoria8KDispositivo di memoria fisico che realizza una zona della memoria logica00001FFF0121314Ind. delBloccoIndirizzo interno al blocco\nCS = A14 AND A13*(Dispositivo da 8K di memoria)Esempio con 15 bit di indirizzo del sistema \nIn questo caso ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#35": "Mapping allineato di dispositivi da 8 bit in sistemi con bus dati da 8 bitSiconsideriundispositivoDdin=2^Kbyteindirizzabili•SidicecheDèmappatoall\u0001indirizzoAsegliindirizzideibytediDsonocompresitraAeA+(n-1),cioèseAèl\u0001indirizzopiùbassotratuttigliindirizziassociatiaD•SidicecheDèallineatoseAèunmultiplodin(numerodibytesinternialdispositivo),cioèse:(indirizzopiùbassodiD)MODn=0(condizionediallineamento)•SeDèallineatoalloraikbitmenosignificatividiAsonougualiazeroEsempi:•Undispositivodaduebyteèallineatoseèmappatoaunindirizzopari•Unadispositivoda8byteèallineatoseèmappatoaunindirizzoilcuivalorecodificatoinbinarioterminacon3zeri•Undispositivoda16byteèallineatoseilsuoindirizzoinizialeincodiceesadecimalehalaciframenosignificativaugualeazero•Undispositivoda64KBèallineatoseilsuoindirizzoincodiceesadecimalehalequattrocifremenosignificativeugualiazero",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#36": "Come individuare univocamente una finestra allineata di 2^K byte in uno spazio di indirizzamento•Supponiamo di mappare un dispositivo D di 2^k bytes(k=4) a un indirizzo A allineato di uno spazio di indirizzamento di 1 MB (bus di indirizzi di 20 bit): •Allora possiamo porre A = α ## (0)k(ex F8570) ove αè una configurazione binaria di 20 -K bit e gli indirizzi associati a D saranno compresi traAmin= A = α ## (0)k e Amax= Amin+ 2k -1 = α## (1)k    (Amin= F8570–Amax=  F857F)•Dunque, possiamo indicare l\u0001indirizzo  Aidell\u0001i-esimo byte di D come l\u0001insieme di due campi concatenati: Ai = α ## i(Ai = F8573)αindividua tra le 2^(20-K) finestre allineate di 2^K byte presenti nello spazio di indirizzamento, quella su cui è mappato (a = F857)iindividua l\u0001offset nel chip del byte indirizzato (i = 3)(NB ## è l’operatore simbolico concatenazione)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#37": "Campi in cui si suddivide l\u0001indirizzo di dispositivi mappati in uno spazio di indirizzamento -esempio n. 1IndirizzamentodiunbytediunaRAMall\u0001indirizzo40010Hinunospaziodiindirizzamentodi1MBnell\u0001ipotesididisporrediunchipda128KBmappatoall\u0001indirizzo40000H:L\u0001indirizzovienesuddivisoinduecampi:ilprimoidentificalafinestradi128KBincuièmappatalaRAM,ilsecondoidentifical\u0001offsetall’internodellaRAM\nA0A19A17A16Identificatore dellafinestra di 128Kin cui si trova la RAMOffset del byte indirizzato all\u0001interno del dispositivo di 128KB 0      1       00  0000  0000  0001  0000iα",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#38": "Campi in cui si suddivide l\u0001indirizzo di dispositivi mappati in uno spazio di indirizzamento -esempio n. 2Indirizzamentodiunbyteall’indirizzo1026HinundispositivodiI/Odi16bytemappatoall’indirizzo1020Hdiunospaziodiindirizzamentodi64KBL\u0001indirizzovienesuddivisoinduecampi:ilprimoidentificalafinestradi16Bincuièmappatoildispositivo,ilsecondoidentifical\u0001offsetneldispositivo\nA0A15A4A3Identificatore dellafinestra di 16Bin cui si trova DOffset del byte indirizzato all\u0001interno del dispositivo Ddi 16 Bindirizzato 0 0 0 1       0 0 0 0         0 0 1 00       1        1        0iα",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#39": "Decodifica degli indirizzi in caso di mappingallineato•Consideriamounospaziodiindirizzamentodi1MBincuisiamappatoundispositivodi2^Kbyte•PerindividuareunacelladiindirizzoAi=α##ipossiamodecodificaretuttii20bitchecompongonoAi•Questadecodificaèeffettuataricorrendoallastrutturadeidecoderadalbero,conalberodiduelivelli:–IlIlivelloèusatoperdecodificareα(cheidentificalaposizioneincuiilchipèmappato);perdecodificareαdobbiamodecodificare20-Kvariabili–ilIIlivellovieneutilizzatoperdecodificarei(cheidentificailbyteall\u0001internodelchip,serveundecoderdikvariabili)•IldecoderdiIIlivellositrovaall\u0001internodelchipmentreladecodificadiαèacaricodelprogettistadelsistemachepuòutilizzareundecoderdi20-kvariabiliconcuisidecodificaα•Ladecodificaècompletasesiutilizzanotuttii20-Kbitperdecodificareα,semplificatasesiutilizzasolounsottoinsieme(minimo)dei20-Kbit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#4": "Condizione di visibilità di un dispositivo da parte del software•Condizionenecessariaaffinchéundispositivofisico(memoria,interfaccia,oaltraentità)siaaccessibilealsoftwareè:–ildispositivodeveesseremappatoinunospaziodiindirizzamento•Mappareinunospaziodiindirizzamentosignifica:–associarealdispositivounafinestradiindirizzidiquellospaziodiindirizzamento•Siaccedeaidispositivimappatiinunospaziodiindirizzamentoconciclidibus",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#40": "0K32K8K8K8K8KSpazio di memoria8KIlmodulodimemoriafisicoèdifattoattivato(mappato)induedifferentizonedellamemorialogica00001FFF0121314Ind. delBloccoIndirizzo interno al bloccoCS = A14 A13*Segliindirizziusatidaunprogrammasonoquellichevannoda16Ka24K(overoda4000Ha5FFFH)equellida24Ka32K(da6000Ha7FFF)nonsonousatialloraèpossibileladecodificaincompletaoparzialeinquantolazona24K-32Knonvienemaiindirizzata.EspressioneCSpiùsemplice",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#41": "0K32K8K8K8K8KSpazio di memoria8KIlmodulodimemoriafisicoèattivato(mappato)induedifferentizonedellamemorialogicanonconsecutive00001FFF0121314Ind. delBloccoIndirizzo interno al bloccoCS = A14 A13Decodifica parziale 2/2",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#42": "EsercizioSiconsideriunsistemaconbusindirizzia16bitebusdatia8bit.Scrivereleespressionididecodificacompletaesemplificata(quelladausareall’esame)neiseguenticasi:1)Dispositivodimemoriada16KBmappatoa8000h2)Dispositivodimemoriada8KBmappatoa0000h3)EntrambiidispositiviprecedentiSec’èunsolodispositivo(casi1e2)ilCSèmoltoparticolare….",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#43": "44",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#44": "Mapping, read, write e set/reset di un FFD\n•Il FFD èun elementaredispositivodi memoria•Con unaCPU, come possiamo:•scriverenelFFD•leggerenelFFD •settareo resettarein modoasincronoilFFD FFDDQA_RESA_SET\nCPUMEMRDMEMWRBD[7..0]BA[19..0]?\nConsideriamo il caso di una CPU con bus dati a 8 bit con 20 bit di indirizzo. 64 K di RAM agli indirizzi alti e 64 K di EPROM agli indirizzi bassi",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#45": "NellepagineseguentiassumiamocheicomandidelFFDsianomappatineiseguentiindirizzi:CS_READ_FFD ->  80003hCS_WRITE_FFD ->  80002hCS_A_RES_FFD ->  80001hCS_A_SET_FFD ->  80000hAssumiamoinoltrediutilizzareilsegnaleBD0delbusdatiperleggereescrivereilsingolobitdidato.Ovviamentesarebbepossibileutilizzarealtriindirizzinonappartenentiallememorieeanchealtrisegnalidelbusdati(anchediversiperlettureescritture).Seiltestodell’esamenonspecificaqualiindirizziusarelasceltaèlasciataallostudente.Spesso,lasceltadegliindirizzisemplifica/complicaisegnalididecodifica.",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#46": "CKADDRESSMEMRDMEMWRDATADATA_INReady?Esempio di ciclo di lettura",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#47": "CKADDRESS\nDATADATA_OUTReady?Esempio di ciclo di scrittura\nMEMRDMEMWR",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#48": "FFDDQA_RESA_SETCS_A_RES_FFD\nCS_A_SET_FFDCS_READ_FFDCS_WRITE_FFDBD0BD0MEMWR*CS_RAM_H = BA19·BA18·BA15CS_RAM_H = BA19·BA18·BA15*CS_READ_FFD = BA19·BA18*·BA1·BA0·MEMRD (ist. lettura)CS_WRITE_FFD = BA19·BA18*·BA1·BA0*       (ist. scrittura)CS_A_RES_FFD = BA19·BA18*·BA1*·BA0·MEMWR(ist. scrittura)CS_A_SET_FFD = BA19·BA18*·BA1*·BA0*·MEMWR(ist. scrittura) CS_EPROM = BA19*Vedremo che istruzioni di lettura e scrittura sono (risp.)loadbyte (LB) e storebyte(SB).01",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#49": "FFD(x8)D[7..0]Q[7..0]A_RESA_SETCS_A_RES_FFD\nCS_A_SET_FFDCS_READ_FFDCS_WRITE_FFDBD[7..0]BD[7..0]MEMWR*Estensione a 8 bit\n01\nStessiCSdellapaginaprecedente,cambiasoloilnumerodibitdidatotrasferiti.8888",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#5": "Esempio: una CPU con K=3 bit di indirizzo\nCPU3•Lospaziodiindirizzamentosarebbedisolo8elementi•Supponiamodiavereduedispositividimemoria,da4byte:AeB76543210111110101100011010001000Decoder(RC)I livelloCS_ACS_BBA[2..0]",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#50": "Mapping, read, write e set/reset di un latch\n•Anche il latch CD è un elementare dispositivo di memoria•Con una CPU, come possiamo:•scriverenel latch•leggerenel latch •settare o resettare in modo asincrono il latch CDDQA_RESA_SET\nCPUMEMRDMEMWRBD[7..0]BA[19..0]\nConsideriamo il caso di una CPU con bus dati a 8 bit con 20 bit di indirizzo. 64 K di RAM agli indirizzi alti e 64 K di EPROM agli indirizzi bassiC?",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#51": "CDA_RESA_SETCS_A_RES_LATCH\nCS_A_SET_LATCHCS_READ_LATCHBD0BD0CS_WRITE_LATCHCS_RAM_H = BA19·BA18·BA15CS_RAM_H = BA19·BA18·BA15*CS_READ_LATCH = BA19·BA18*·BA1·BA0·MEMRD (ist. lettura)CS_WRITE_LATCH = BA19·BA18*·BA1·BA0*·MEMWR(ist. scrittura)CS_A_RES_LATCH = BA19·BA18*·BA1*·BA0·MEMWR(ist. scrittura)CS_A_SET_LATCH = BA19·BA18*·BA1*·BA0*·MEMWR(ist. scrittura) CS_EPROM = BA19*Vedremo che istruzioni di lettura e scrittura sono (risp.)loadbyte (LB) e storebyte(SB).CDQMappiamo i quattro comandi del latch agli stessi indirizzi usati per il FFD.",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#52": "Estensione a 8 bit\nStessi CS della pagina precedente, cambia solo il numero di bit di dato trasferiti.CD(x8)A_RESA_SETCS_A_RES_LATCH\nCS_A_SET_LATCHCS_READ_LATCHBD[7..0]CS_WRITE_LATCHCBD[7..0]888D[7..0]Q[7..0]",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#53": "Incrementare il parallelismo dei dati\n•Abbiamoconsideratofinoaorasistemiconunparallelismo(busdati)a8bit•Ognitrasferimentorichiedeunciclodibus•Nelementi(byte)->Nciclidibus•Sappiamochelememorie(enonsolo)sonolente(vsCPU)\n1",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#54": "i)\nii)\niii)\n111",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#55": "•Possiamo fare meglio?•Si, aumentando il parallelismo dei dati•Riducendo la dimensione di ciascuna memoria•Trasferendo più dati nello stesso ciclo di bus \n¼¼¼¼i)i)i)i)IS",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#56": "•CosaNON fare?•Trasferireglielementisequenzialmentein memoriepiùpiccole•Elementicontiguivannosumemoriediverse \n¼¼¼¼NOilparallelismodi ciascunamemoriaèsempre8 bit!\ni)ii)iii)iv)i)ii)iii)iv)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#57": "Memoria con processori a parallelismo > 8Il caso dei 16 bitIndirizzo fisicomemorie = Indirizzo logico/ 2Sul piedino  A0della memoria -> BA1busA1della memoria ->BA2 bus……………………………..\nMemorialogicaMemoriafisicaBUS ALTOBUS BASSO876543210876543210abcdefghi\nacegibdfhlWord(3) -> Byteh(1) e Byteb(2) -> 2 lettureLogicoFisicoFisicoLe memorie  fisiche vanno sempre in coppiaPer ogni \u0001banco\u0002ci deve essere un ByteEnableBE0 per banco 7-0 e BE1 per banco 15-8078bit 15Indirizzo interno ai chip\nMemorie sempre in coppia Ad esempio 2 x8K = 16 K (Lettura bytes 3 e 4 che però stanno a indirizzi fisici interni delle memorie differenti)(d ,e)(d )(e )",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#58": "Memorie con bus a 16 bitBE1      BE01           1       Word1           0       Byte alto (ind. dispari)0           1       Byte basso (ind. pari)0           0       Non possibile  Lo scambio byte alto esterno, byte basso del registro  e viceversa avviene all\u0001internodel microprocessore\nBA0del processorenon viene generato (di fatto seleziona il banco -al suo posto BE0 e BE1)BA1del processore connesso ai piedini A0delle memorieBA2del processore connesso ai piedini A1delle memorie etc. etc.7      015     8Memorie fisicheMicroprocessoreRiMUX",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#59": "MemorialogicaMemoriafisicaBUS ALTOBUS BASSO128K128K128K128KFFFFFh\n00000h64K64K070bit  740000h5FFFFh0000hFFFFhIndirizzi interni alle EPROM2 x 64K = 128KEPROM1BE1*EPROM0BE0*\nCSEPROM1= BA19*BA18BA17*BE1CSEPROM0= BA19*BA18BA17* BE0Individua la zona di memoria da realizzareLe memorie vanno sempre in coppia (16 bit)La decodifica si fa come se si avesse una memoria a 8 bit. Si usano dispositivi di taglia metà selezionati con BE0 e BE1Memoria con processori a parallelismo > 8Il caso dei 16 bit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#6": "•Comefacciamoadattivareunadelleduememorieinbaseall’indirizzoBA[2..0]emessodallaCPU?•Ovvero,comeèfattalaretedidecodifica(Ilivello)chegeneraiduesegnaliCS_AeCS_B?•CS_A=BA2CS_B=BA2*•Questisegnalisarannoinviatiaallememorie(decodificadiIlivello)•Poi,saràindividuatol’elementoall’internodellememoriaselezionata(decodificadiIIlivello)76543210111110101100011010001000BA2=1BA2=0II livello",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#60": "MemorialogicaMemoriafisicaBUS ALTOBUS BASSO128K128K128K128KFFFFFh\n00000h64K64K070bit  780000h9FFFFh0000hFFFFhIndirizzi interni alle EPROM2 x 64K = 128KEPROM1BE1*EPROM0BE0*\nCSEPROM1= BA19BA18*BA17*BE1CSEPROM0= BA19BA18*BA17*BE0Individua la zona di memoria da realizzareMemoria con processori a parallelismo > 8Il caso dei 16 bit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#61": "BUS BASSO4000540004400034000240001400005FFFF5FFFE5FFFD5FFFC5FFFBMemoria Logica\n128K0   Eprom Pin0    Bus Pin77EPROM0BE0 -64KFFFFFFFEFFFDFFFC0003000200010000BUS ALTO07EPROM1BE1 -64KFFFFFFFEFFFDFFFC0003000200010000Eprom PinBus Pin       15              8Indirizzi interni della EPROMIndirizzi interni della EPROM\nIndirizzi della memoria logicaMemoria con processori a parallelismo > 8Il caso dei 16 bit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#62": "Memoria con processori a parallelismo 32 bitMemorialogicaMemoriafisica\nBUS 3BE3876543210abcdefghi\naeibfl07815cgdh162324bit 3187654210BUS 2BE2BUS 1BE1BUS 0BE0Indirizzo fisico = Indirizzo logico/4",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#63": "64Bus enable con parallelismo 32 bitBE3      BE2     BE1     BE01            1            1           1       Word 32 bit0            0            1           1       Half word bassa 1            1            0           0      Half word alta  0            0            0           1       Byte 0-7  N.B. BA0 e BA1  del processorenon vengono generati (di fatto selezionano uno  dei banchi -al loro posto BE0, BE1, BE2, BE3)BA2del processore connesso ai piedini A0delle memorieBA3del processore connesso ai piedini A1delle memorie etc. etc.etc.0            0            1           0       Byte 15-8  Lo scambio fra i bytes (half word) dei banchi di memoria e i byte (half word)  dei registri  e viceversa avviene all\u0001internodel microprocessore",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#64": "65Memoria logicaMemoria fisica\nBUS 32MB2MB2MBFFFFFFFFh\n00000000h512K243140000000h401FFFFFh00000h7FFFFhIndirizzi interni alle EPROM\n4 Memorie x 512K= 2MBEPROM3BE3*\nCSEPROM3= BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE3CSEPROM2 = BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE2CSEPROM1 = BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE1CSEPROM0= BA31*BA30BA29*BA28*BA27*BA26*BA25*BA24*BA23*BA22*BA21*BE0Individua la zona di  memoria da realizzare512K1623EPROM2BE2*512K815EPROM1BE1*512K07EPROM0BE0*BUS 2BUS 1BUS0Selezionail BUS\nCS espressi in forma veraMemoria allineata11 bitdi indirizzosono fissiMemorie con parallelismo 32 bit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#65": "Memoria logicaMemoria fisicaBUS 3  -D24-312MB2MB2MBFFFFFFFFh\n00000000h512K40000000h401FFFFFh00000h7FFFFhEPROM3DLX512K512KEPROM2EPROM100000h7FFFFh00000h7FFFFh512KEPROM000000h7FFFFhBUS 2  -D23-16BUS1  -D15-8BUS 0  -D7-0BE0BE1BE2BE3\nEmessi dal processoreal posto di BA1e BA0Memorie con parallelismo 32 bit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#66": "Memoria logica(come vista dal programmatore)512K\n40000000h401FFFFFh\n00000h7FFFFhEPROM3Memoria fisica(come realizzatafisicamente)\ndh00001h2MB\n512K00000h7FFFFhEPROM2\ncg00001h512K00000h7FFFFhEPROM1\nbf00001h512K00000h7FFFFhEPROM0\nae00001habcde40000001h40000002h40000003h40000004hIndirizzi fisicidei singolidispositivi\n------x\nI dati di indirizzi logiciconsecutivisi trovano su dispositivi diversiLa cella x di indirizzo logico abcdefghsi troverà all\u0001indirizzo fisicoabcdefgh/4 del dispositivo EPROMi ove iè il resto della divisioneabcdefghMemorie con parallelismo 32 bit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#67": "Esempio:sivuolerealizzarenelDLX(bus32bit)unamemoriaRAMda256Kpostaall\u0001indirizzo84000000(allineata).Campodiindirizzamento84000000-8403FFFF.Dispositivi:8RAMda32K(leRAMda64KstaticheNONesistono!!!!)Difattoquindivisonoduebanchida128Kl\u0001uno:ilprimorealizzalamemoriada84000000a8401FFFFel\u0001altroda84020000a8403FFFF.Ichipdimemoriada32Kutilizzanoallorointerno(fisicamente)comeindirizzidiselezionedellecelleipinA14-A0chesonoperòcollegatirispettivamenteagliindirizziemessidalDLXBA16-BA2(ricordiamoinfatticheBA1eBA0delDLXNONsonoemessiealloropostovengonoemessiBE3,BE2,BE1eBE0).Sinotiilruolodell\u0001indirizzoDLXBA17chedivideiduebanchiPrimobanco(decodificanonsemplificata)CSRAM00=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE0CSRAM01=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE1CSRAM02=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE2CSRAM03=(BA31BA30*BA29*BA28*BA27*BA26.…BA18*BA17*)BE3Secondobanco(decodificanonsemplificata)CSRAM10=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE0CSRAM11=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE1CSRAM12=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE2CSRAM13=(BA31BA30*BA29*BA28*BA27*BA26….BA18*BA17)BE3Ovviamentenelcasodidecodificasemplificata(memorialogicaincompletamenterealizzatafisicamente)lefunzionididecodificavengonoridottedicomplessità.OvequestiduebanchifosserogliunicidarealizzareiCSdipenderebberosolodaBA17edaBEiMemorie con parallelismo 32 bit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#7": "Come è fatto un generico dispositivo?•Unqualsiasidispositivo(memoria,periferica,etc),comunicaconlaCPUmedianteunainterfacciastandardasxDISPCSA[K-1..0].RDWRD[R-1..0]?KBA[K-1..0]CS_DISPRBD[R-1..0]RDWRCPU•Lacomunicazioneconl’esternoavvienesecondomodalitàchesonospecifichedeldispositivoequindinonstandard•BA[K-1..0]utilizzati(internamente)perdecodificadiIIlivello",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#8": "9Memorie EPROM•Memorie non volatili a sola lettura•Capacità a multipli di 2:32K, 64K, 128K, 256K, etcVPPA16A15A12A7A6A5A4A3A2A1A0D0D1D2GNDVCCPGM*NCA14A13A8A9A11OE*A10CE*D7D6D5D4D3EPROM1234567891011121314151632313029282726252423222120191817128K ´8AiCE*OE*DiTceTaccToeCE*OE*DiCella M/bit i",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\02_Mapping_e_decodifica.pdf#9": "CQiDCella di indirizzo \u0001j\u0002A0  A1    An-1WR RDD0   DiDN-1La cella di una RAMDECODERIIj2n´N",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#0": "03 Linguaggio macchinaCalcolatori Elettronici TIngegneria Informatica\nStefano Mattoccia",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#1": "Instruction Set Architecture•L’insieme delle istruzioni e dei registri di una CPU costituiscono l’InstructionSet Architecture(ISA)•Mediante l’ISA è possibile accedere alle risorseinterne (e.g., registri) ed esterne (e.g., memoria)•Tipicamente le istruzioni in linguaggio macchina sono generate da un compilatore•Più raramente, come in questo corso, scritte daiprogrammatori•Purtroppo, (quasi) ogni CPU possiede un proprio ISA •A proposito di ISA, esistono due linee di pensiero:•RISC: insieme ridotto di istruzioni semplici -> moltiregistri interni (DLX, ARM, RISC-V, etc)•CISC: insieme ampio di istruzioni complesse -> pochiregistri (Intel X86)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#10": "Consentediesprimereefficacementeconfigurazionibinarie:•Traslazionelogicaasinistradinbit:<<n(inserendo“0”adestra)•Traslazionelogicaadestradinbit:>>n(inserendo“0”asinistra)•Concatenazionediduecampi:##•Ripetizionenvoltedix:(x)n•Ennesimobitdiunaconf.binariax:xn(ilpediceselezionaunbit)•Selezionediuncampoinunastringadibitx:xn..m(unrangeinpediceselezionailcampo)•Datalaconfigurazionebinariadi8bitC=011011002:–C<<2:101100002–C3..0##1111:1100|11112–(C3..0)2:110011002–(C6)4##C>>4:1111|000001102Notazioneper la costruzionedi configurazionibinarie",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#11": "•Trasferimentodiundato:←Ilnumerodibittrasferitièdatodalladimensionedelcampodestinazione;lalunghezzadelcampovaspecificatasecondolanotazioneseguentetuttelevoltechenonèaltrimentievidente•Trasferimentodiundatodinbit:←nQuestanotazionesiusapertrasferireuncampodinbit,tuttelevoltecheilnumerodibitdatrasferirenonèevidentesenzalarelativaindicazioneesplicita•Contenutodicelledimemoriaadiacentiapartiredall’indirizzox:M[x]Esempio:R1←32M[x]indicailtrasferimentodallamemoriaversoilregistroR1dei4byte:M[x],M[x+1],M[x+2],M[x+3]Altranotazione",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#12": "READYINTBA[31..2]BE3BE2BE0BE1BD[31..0]MEMRDMEMWRµPDLXCLOCKRESET\nREADYINTRESETBA[31..2]BE3BE2BE1BE0BD[31..0]RDWR\nIlsegnalediRESETèasserito,all’avvio,daunareteesterna.AncheisegnalidiREADY,INTsonogeneratidaretiesternemautilizzatiduranteilnormalefunzionamento.Segnali del processore DLX30\n32",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#13": "•Unicospaziodiindirizzamentodi4G•32registrida32bitGP(R0,…,R31,conR0=0)•Istruzionidilunghezzacostante,32bitallineate•Campidelleistruzionididimensioni/posizionifisse•3formatidiistruzione:I,R,J•Noncisonoistruzionipergestirelostack•Peristruzionicheprevedonounindirizzodiritorno(JAL/JALR),essoèsalvatoinR31•NonesisteunregistrodiFLAGsettatodalleistruzioniALU.Lecondizionisonosettateesplicitamenteneiregistri(istruzioniSET)•E’presenteun’unicamodalitàdiindirizzamentoinmemoria(indiretto,medianteregistro+offset)•Leoperazioniaritmetico/logichesonoeseguitesolotraregistri(nontraregistriememoria)•Esistonoalcuneistruzioni(MOVS2IeMOVI2S)perspostaredatitraregistriGPeregistrispecialieviceversaCaratteristiche dell’ISA DLX (integer)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#14": "Registri del DLX (integer)R0=0R1R2R3R28R29R30R3132PCIARMARMDR32Registri GP*accessibilidirettamentedal codiceRegistri nonaccessibilidirettamentedal codice*\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#15": "DLX (integer): tipi di datoNelDLX(integer)sonodisponibilitretipididato:BYTE(8bit)HALF-WORD(16bit)WORD(32bit)•Idatididimensioneinferiorea32bit(quindia8o16bit)lettidallamemoriadebbonoessereestesia32bitduranteilcaricamentoneiregistri(semprea32bit)•Questaoperazionepuòessereeseguitamantenendoomenoilsegnodeldatolettodallamemoria07015031",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#16": "Estensione del segnoInmolticasiènecessarioèestenderelarappresentazionediundatocodificatoconnbit,inundatoconunarappresentazioneambit(conm>n).Peresempio,volendotrasferireunbyte(n=8)dallamemoriainunregistroa32bit(m=32)ènecessarioconoscerelamodalitàconlaqualeèrappresentatoildatoletto.Esempio:10110101(n=8)Assumendoildatosenzasegno(unsigned),l‘estensionea32bitavvieneaggiungeno24zeri:00000000000000000000000010110101oppure(0)24##10110101Assumendoildatoconsegno(signed),l’estesioneavvienereplicando24volteilbitdisegno11111111111111111111111110110101oppure(1)24##10110101",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#17": "Il set di istruzioni (integer) del DLX•Le principali istruzioni aritmetiche e logiche•Istruzioni logiche anche con op. immediato: AND, ANDI, OR, ORI, XOR, XORI•Istruzioni aritmetiche: ADD, ADDI, SUB, SUBI•Istruzioni di shift(a destra anche aritmetico): SLL1, SRL, SRA2•Istruzioni di SET CONDITION: Sx, con x= {EQ, NE, LT, GT, LE, GE} •Le principali istruzioni di trasferimento dati•Loadbyte signede unsigned(LB, LBU), loadhalfwordsignede unsigned(LH, LHU), loadword (LW)•Storebyte, storehalfword, storeword: SB, SH, SW•Copia un dato da un registro GP a un registro speciale e viceversa MOVS2Ie MOVI2S•Le principali istruzioni di trasferimento del controllo•Istruzioni di salto condizionato (PC+4 relative): BNEZ, BEQZ•Istruzioni di salto incondizionato J: assoluto (con reg.) e PC-relative•Istruzioni di chiamata a procedura Jumpand Link (JAL). L’indirizzo di ritorno viene automaticamente salvato in R31. JAL con registro e immediato  (PC-relative)•Istruzione di ritorno dalla procedura di servizio delle interruzioni: RFE1)Shiftlogicoasinistraeshiftaritmeticoasinistracoincidono(entrano0neibitmenosignificativi).PerquestaragioneNONesisteSLA.Fareattenzioneconshiftasinistra,nonpreservailsegnoepuògenerareoverflow2)Trascinandoadestradiunaposizioneunregistroeinserendoasinistrasempreilbitdelsegnosimantieneilsegnodeldatomentrelosidividesuccessivamenteper2",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#18": "Elencoistruzionidel DLX (integer)Data TransferLWRa,Imm16bit(Rb)LB Ra,Imm16bit(Rb)LBU Ra,Imm16bit(Rb)LH  Ra,Imm16bit(Rb)LHURa,Imm16bit(Rb)SW  Ra,Imm16bit(Rb)SH  Ra,Imm16bit(Rb)SB  Ra,Imm16bit(Rb)MOVS2IRa,Rs*MOVI2SRs*,RaSpecial registerRs* (IAR)Aritmetiche/logicheADD Ra,Rb,RcADDIRa,Rb,Imm16bitADDURa,Rb,RcADDUI Ra,Rb,Imm16bitSUB Ra,Rb,RcSUBIRa,Rb,Imm16bitSUBURa,Rb,RcSUBUIRa,Rb,Imm16bitSLL Ra,Rb,RcSLLI Ra,Rb,Imm16bitSRL Ra,Rb,RcSRLI Ra,Rb,Imm16bitSRA Ra,Rb,RcSRAI Ra,Rb,Imm16bitOR Ra,Rb,RcORIRa,Rb,Imm16bitXORRa,Rb,RcXORIRa,Rb,Imm16bitANDRa,Rb,RcANDIRa,Rb,Imm16bitLHI Ra,Imm16bitControlloSxRa,Rb,RcSxIRa,Rb,Imm16bitBEQZRa,Imm16bitBNEZ Ra,Imm16bitJImm26bitJRRaJALImm26bitJALRRaxpuò essere: LT,GT,LE,GE,EQ,NE\nRa{R0+,R1,..,R30,R31}Rb{R0,R1,..,R30,R31}Rc{R0,R1,..,R30,R31}+RanonpuòessereR0comeregistrodestinazionediistruzioniload,MOV2SI,aritmetico/logiche,LHIeSET∈∈∈\nPer le istruzioni aritmetiche: l’immediato a 16 bit è esteso senza segno se di tipo U (unsigned) altrimenti con segno.  Per istruzioni logiche, sempre estensione senza segno.  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#19": "DLX: formato delle istruzioni\n•Istruzionidiload,store,branch,JeJALconregistro,serconditionSxIeALUconoperandoimmediato.L’immediatoèa16bit•NelleoperazioniloadeALURS2/RdèRd.NellestoreRS2/RdèRS2.InentrambiicasiRS1perindirizzosorgente(loadostore)oregistrosorgente(operazioniALUconconoperandoimmediato)IOpCodeRS2/RdRS1Immediato di 16 bit\nJOpCodeImmediato/offset di 26 bit (PC relative)•Salti incondizionato con e senza ritorno (Je JAL) con immediatoROpCodeRS2RS1RdOpCodeext. (11 bit)•IstruzioniALUdeltipoRd¬Rs1opRs2oppuresetconditionSxtraregistri6 bit5 bit5 bit5 bit11 bit031•In alcuneistruzionidi tipoI (LOAD e ALU), RS2 rappresentailregistrodestinazioneRd•Alcuneistruzioni(e.g., J e JAL con registro) potrebberoesserecodificatecon piùdi un formatotraquellidisponibili",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#2": "Requisitidi un linguaggiomacchina/ISAOltreallapossibilitàdipoterrisolvereunqualsiasiproblema*,unrequisitofondamentalediunlinguaggiomacchina/ISAèquellodiminimizzareiltempodiesecuzionedelcodice*•SeCPImedioèilnumeromediodiclockperl’esecuzionediunaistruzione,l’obiettivoèquellodiminimizzareCPUTime=Nistruzioni*CPImedio*TCK•Lostessoproblema,puòesserequindirisoltoconCPUTimediversiinbasea:•Nistruzioni(RISC,richiedonoingenerepiùistruzioni)•CPImedio(RISC,tipicamenteistruzionipiùveloci)•TCK(Retilogichesemplicipotenzialmentepiùveloci)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#20": "Modalitàdi accessoallamemoria•OgniISAdisponediistruzioniperaccedereallamemoriainletturaescrittura•Normalmenteèpossibilestabilireladimensionedeldatochepuòesseretrasferito(BYTE,HALF-WORD,WORD,etc)•Idueprincipalimetodidiaccessoallamemoria(indirizzamento)sono:–Diretto(indirizzocablatonell’istruzione)–Indiretto(indirizzomodificabilearun-time)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#21": "Indirizzamentodiretto•Conquestamodalitàl’istruzionecontienealsuointernounvalore(cablato)chespecifical’indirizzodiaccessoallamemoriaLBR7,0800h-“LeggiunBYTE(8bit)all’indirizzo0800hememorizzalanelregistroR7”A0870800Ipotetica codifica dell’istruzione con 32 bit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#22": "Indirizzamentoindiretto•Conquestamodalitàl’indirizzodiaccessoallamemoriaèottenutosommandounvalorecostantepresentenell’istruzioneconilcontenutodiunregistro•Indirizzo=costante+registro•Ilregistroècablatonell’istruzionemailsuocontenutopuòcambiareatempodiesecuzioneLBR7,0800(R3)-“LeggiunBYTE(8bit)all’indirizzoR3+0800hememorizzalanelregistroR7”A3570800Ipotetica codifica dell’istruzione con 32 bit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#23": "Indirizzamentodirettovsindiretto1/2•Ladifferenzatraleduemodalitàdiindirizzamentoènotevole•Perrenderveneconto,poteteconsiderareuncasopiuttostocomune:“sommareglielementidiunarrayAdi8elementimemorizzatoapartiredall’indirizzo0800h”\n00800h10801h20802h30803h40804h50805h60806h70807h\nA[0]",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#24": "Indirizzamentodirettovsindiretto2/2Diretto(non usato):XOR  R8,R8,R8; R8=0LBU R7,0800hADD R8,R8,R7 ; R8=R8+R7LBU R7,0801hADD R8,R8,R7 ; R8=R8+R7LBU R7,0802hADD R8,R8,R7 ; R8=R8+R7LBU R7,0803hADD R8,R8,R7 ; R8=R8+R7LBU R7,0804hADD R8,R8,R7 ; R8=R8+R7LBU R7,0805hADD R8,R8,R7 ; R8=R8+R7LBU R7,0806hADD R8,R8,R7 ; R8=R8+R7LBU R7,0807hADD R8,R8,R7 ; R8=R8+R7Indiretto:XOR  R8,R8,R8; R8=0ADDI R9,R8,8; R9=8LOOP: SUBI R9,R9,1; R9=R9-1LBU R7,0800h(R9); legge BYTE ; a 0800+R9ADD R8,R8,R7; R8=R8+R7BNEZ R9,LOOP; se R9!=0; salta a LOOP•Il registro R9 è utilizzato in ogniiterazione per cambiare l’indirizzobase (0800h)•Pensate se l’array fosse di 1000000elementi...",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#25": "DLX: modalitàdi accessoallamemoria•IlDLXprevedeun’unicamodalitàdiindirizzamento:indiretto•L’indirizzo(a32bit)èsempreottenutosommandounregistroa32bitconunvaloreimmediatoa16bitestesoa32bitconsegno.•Esempio:LWR7,Imm16_bit(R8)•CaricainR7,lawordall’indirizzo(a32bit)ottenutosommandoR8ilvaloredell’immediatoestesoa32bitconsegno:R7ç32M[R8+Imm16_bit[15]16##Imm16_bit[15..0]]•Nell’eserciziodellepagineprecedentiabbiamosottointeso,persemplicità,chel’indirizzofossea16bit.Inrealtà,nelDLXl’indirizzoèsemprea32bit(lospaziodiindirizzamentoè4G)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#26": "Come sonomemorizzatiidatiin memoriain un sistemacon parallelismo> 8? •Consideriamounsistemaconbusdatia16bit•Comepossiamomemorizzareilvalorea16bit0468hapartiredall’indirizzo(chesupponiamoa20bit)00010h?•Esistonodueconvenzioni:04680468046800010h00011h00010h00011h880000Fh00012h0000Fh00012h16HL\nLittle Endian(e.g., Intel)Big Endian(e.g., Motorola)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#27": "Istruzioni Aritmetico Logiche (ALU)•Istruzioni a 3 operandi:–2 operandi “sorgente”–1 operando “destinazione”. •“destinazione”: sempre un registro (a 32 bit)•“sorgente”: registro, registro •“sorgente”: operando immediato(16 bit)Esempi: ADD R1,R2,R3; R1 çR2 + R3 formato RADDIR1,R2,3; R1 çR2 + 3 formato I; il valore (3) dell’immediato a 16 bit ; è esteso a 32 bit ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#28": "Istruzioni di Set ConditionQuesteistruzioniconfrontanoidueoperandisorgenteemettonoa“1”oppurea“0”l’operandodestinazioneinfunzionedelrisultatodelconfronto•“SET EQUAL” (SEQ, =) : settase uguale•“SET NOT EQUAL” (SNE, !=): settase diverso•“SET LESSER THAN” (SLT, <) : settase <•. . . Gli operandi possono anche essere unsigned:•“SET LESSER THAN UNSIGNED” (SLTU, <)Esempi SLT R1,R2,R3; R1 ç1 se R2<R3 altrimenti R1 ç0; formato RSLTIR1,R2,3; R1 ç1 se R2<3 altrimenti R1 ç0; formato I",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#29": "Istruzioni per il trasferimento dati •Sonoistruzionicheaccedonoallamemoria(loadestore):LB,LBU,SB,LH,LHU,SH,LW,SW•L’indirizzodell’operandoinmemoriaèlasommadelcontenutodiunregistroa32bitconun“offset”di16bit(Imm16bit)estesoconsegnoa32bit•L’istruzioneècodificatasecondoilformatoIEsempi:LWR1,40(R3);R1←32M[40+R3]LBR1,40(R3);R1←32(M[40+R3]7)24##M[40+R3]LBUR1,40(R3);R1←32(0)24##M[40+R3]",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#3": "Istruzionie risorseinterne a unaCPULeistruzionieseguibilidaunaCPU,codificateinbinario,sonoingeneremoltopiùsemplicidelleistruzionicheutilizzateneilinguaggiadaltolivello.Tipicheoperazionisono:-somme,sottrazioni,divisioni,moltiplicazioni,etc-lettureescrittureinmemoriaeperiferiche-confrontotraoperandi(“A>B?”)-salticondizionati(“saltase”)eincondizionati(“salta”)-...E’possibile,medianteleistruzioni,accederearisorseinternedellaCPUcomeregistriarchitetturalietalvoltaaregistridistato(e.g.,AeramaggiorediB?)LerisorsechesonoaccessibilialleistruzioniinlinguaggiomacchinasonodefinitedaiprogettistidallaCPUTuttavia,nontuttiiregistriinternisonoaccessibilialprogrammatore(senzachequestorappresentiunproblema)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#30": "Istruzioni per il trasferimento del controllo:salti incondizionati (con e senza ritorno)•“JUMP”: salto incondizionato•“JUMP AND LINK: salto incondizionato con ritornoEsempiJoffset; PC = PC + 4 + (offset[25])6## offset, tipo JJR R3; PC = R3, tipo RJAL offset; R31 = PC+4; PC = PC + 4 + (offset[25])6## offset, tipo JJALR R5; R31 = PC + 4, PC = R5JR R31; PC = R31; istruzione per tornare da una procedura ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#31": "BCONDRd,Imm16E’ possiibleverificare solo due condizioni (COND):•BEQZ“BEQUAL ZERO”: salta se registro è 0•BNEQZ“BRANCH NOT EQUAL ZERO”: salta se registro è ≠ 0EsempiBEQZR4,Imm16; se R4==0 PC = PC + 4 + Imm16[15]16## Imm16; altrimenti PC = PC + 4BNEZR4,Imm16; se R4!=0 PC = PC + 4 + Imm16[15]16## Imm16; altrimenti PC = PC + 4Conunaistruzioneditiposetseguitadaun’istruzionedibranchsirealizzalafunzionedicompareandbranch(confrontoesaltocondizionatodalrisultatodelconfronto)senzabisognodiflagdedicatiIstruzioni per il trasferimento del controllo: salti condizionati (Branch)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#32": "Come generare valori a 32 bitNelDLXèpresenteunaistruzione,LHI(“LoadHighImmediate”)checonsentedicrearerapidamentevaloria32bit(NONèunaistruzionediaccessoallamemoria!).LHI Rd,Imm16; Rd= Imm16 ## 0000h  InserisceinRdilvaloredell’immediatonei16bitpiùsignificativie0neirimanentibitTipicamente,LHIèutilizzatapergenerareindirizzia32bitpartendodaimmediatia16bit.QualipotrebberoesseredellealternativeallaLHI?Esempio LHI R1,8420; R1 = 8420 ## 0000h = 84200000h",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#33": "Esempio di codice assemblerDLX 1QualevaloreassumonoiregistriR3edR4alterminedell’esecuzionedelcodiceseguente?LHIR1,0xE000ADDUIR2,R0,0x0081SB0x0000(R1),R2LBUR3,0x0000(R1)LBR4,0x0000(R1)R3=?,R4=?",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#34": "EsercizioScrivereilcodiceDLXchesommaduewordmemorizzateapartiredallametàdellospaziodiindirizzamento(80000000h).LHIR4,8000h;R4=8000##0000hLWR5,0(R4);R5<-M[R4+0]LWR6,4(R4);R6<-M[R4+4]ADDR7,R5,R6;R7=R5+R6",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#35": "EsercizioProgettareunsistemabasatosulprocessoreDLXcon512MBdiEPROMnellapartebassadellospaziodiindirizzamento,1GBdiRAMapartiredall’indirizzo0x40000000e512MBdiRAMnellapartefinaledellospaziodiindirizzamento.Nelsistema,medianteopportuneistruzionisoftware,ènecessariopoter:-impostareallivellologico0o1unsegnaledenominatoSTARTUP,mappatoa0xC0000000einizialmentealvalore1-invertirelostatodiunLED,inizialmentespentoemappatoall’indirizzo0x90000000,prevedendoanchelapossibilitàdipoterneleggerelostato(ie,determinareseilLEDèaccesoospento)EPROM512 MBRAM 1 GBRAM512 MB\n0xC00000000x90000000\n0x1FFFFFFF\n0x40000000\n0x7FFFFFFFSTARTUPLED\n0xE0000000",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#36": "Struttura di una soluzioneRispostaaeventualidomandespecificheindicateneltestoIndicazionedeidispositiviedellememorieutilizzaticonrelativiindirizzidimappingreali(inizioefineinesadecimale)Scritturadeichip-selectdiciascundispositivocondecodificasemplificataProgettodieventualiretilogichenecessarieperrisolvereilproblema\nScritturadelcodiceinassemblerDLX,necessarioarisolvereilproblemaIndicazionedicomesonoconnessituttiidispostivi(inclusetuttelememorie)presentinellasouzioneaibusdisistemadelDLXCognomeNomeMatricolaDataTipoesame(CalcolatoriToLA)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#37": "Soluzione -chip selectCS_EPROM_512_3=CS_EPROM_512_2=CS_EPROM_512_1=CS_EPROM_512_0=CS_RAM_1_GB_L_3=CS_RAM_1_GB_L_2=CS_RAM_1_GB_L_1=CS_RAM_1_GB_L_0=CS_RAM_1_GB_H_3=CS_RAM_1_GB_H_2=CS_RAM_1_GB_H_1=CS_RAM_1_GB_H_0=CS_READ_LED=(0x90000000)CS_SWITCH_LED=(0x90000004)CS_READ_STARTUP=(0xC0000000)CS_WRITE_STARTUP=(0xC0000004)CS_RAM_512_3=CS_RAM_512_2=CS_RAM_512_1=CS_RAM_512_0=",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#38": "Soluzione –rete segnale STARTUPAll’avviodelsistemaSTARTUP=1",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#39": "Soluzione –rete segnale LEDAll’avviodelsistemaLED=0",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#4": "Registridi unaCPU•OgniCPUpossiedeuncertonumerodiregistriaccessibilialprogrammatore•Ilnumeroeladimensionedeiregistridipendonodall’ISA(equestohaimpattosullaretelogicarisultante)•Ovviamente,averemoltiregistrigeneralpurpose(GP)èvantaggioso(menoaccessiallalentamemoria)•Avereistruzionichepossonousaretutti,oquasi,iregistriGPsenzavincolièvantaggioso•LostessoISApuòessererealizzatoconretilogichecompletamentedifferenti(e.g.,InteleAMD)•Questeretihannoingenereprestazionidiverse(diversoCPUTimesebbeneabbianostessoNistruzioni)•NonsarebbestatomeglioavereunsoloISA?",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#40": "Soluzione –connessione memorie\n_3_2_1_0BA[  ..  ]MEMWRMEMRDCS_CS_CS_CS_\nBD[7..0]BD[15..8]BD[23..16]BD[31..24]\nA[  ..  ]RD WR CSRD WR CSRD WR CSRD WR CS",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#41": "Soluzione –codice assemblerDLX 1/2 LetturasegnaleSTARTUP\nImpostazionesegnaleSTARTUPalvalorelogico0",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#42": "Soluzione –codice assemblerDLX 2/2 LetturasegnaleLED\nInversionevaloredelsegnaleLED",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#43": "Simulatore DLXNell’ambitodialcunetestidilaureaèstatosviluppatounsimulatorediistruzioniDLXperscopididatticidisponibileaquestoindirizzo:http://dlx-simulator.disi.unibo.it/dlxAncorainfasedisperimentazionemapotrebbeessereunavalidaalternativaalsoftwareindicatonellepagineseguenti.Perchifosseinteressato,sebbenesiaancorainformamoltopreliminare,èpossibilesimulareancheistruzioniRISC-VSonograditesegnalazionidibachiesuggerimentipermigliorareisimulatoriinprossimetesiTesidilaureasvolteinquestocontesto:FedericoPomponii,“SviluppodiunsimulatoreDLXperscopididattici”,AA2019/20FabrizioMaccagnani,“ProgettodiunsimulatorediDLXperscopididattici”,AA2018/19AlessandroFoglia,“ProgettodiunsimulatorediRISC-Vperscopididattici”,AA2018/19",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#44": "AlcunenotesulsimulatoreDLXattuale-Negliimmediatinecessarioilprefisso0X(eg,0x8000)-Nellestoreladestinazioneasinistra(eg,SW0x800(R0),R18)-Altro?Esempio:sommaelementidiunarrayinit:XORR8,R8,R8;R8=0ADDIR9,R8,0x0008;R9=8LOOP:SUBIR9,R9,0x0001;R9=R9-1LBUR7,0x0800(R9);leggeunBYTEa00000800+R9ADDUR8,R8,R7;R8=R8+R7BNEZR9,LOOP;seR9!=0saltaaLOOP\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#45": "",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#46": "Esempio di codice assemblerDLX 2E’correttoilcodiceseguente?LHIR1,0x0000ADDIR2,R0,0x0081SH0x7FF1(R1),R2LHUR3,0x7FF1(R1)LHR4,0x7FF1(R1)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#47": "Esempio di codice assemblerDLX 3ScrivereilcodiceassemblerDLXperinserireinmemoria,apartiredall’indirizzoE0000800hl’arraydiwordindicatoinfigura.\n01234567\n0xE00008000xE00008040xE00008080xE000080C0xE00008100xE00008140xE00008180xE000081C0xE0000820\n32",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#48": "ADDR2,R0,R0;R2usatocomeindicedelcicloLHIR3,0xE000;R3=E0000000Loop:SWR2,0800(R3);scriveindiceinmemoriaADDIR2,R2,1;incrementaindicedelciclodi1ADDIR3,R3,4;incrementaindiceoffestdi4SNEIR4,R2,8;confrontaindiceR2con8BNEZR4,Loop;saltaseR4nonèzeroi)QualevaloreènecessariosostituireaLoopinBNEZ?i)Sipuòfaremeglio(ie,usaremenoistruzioni)?",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#49": "76543210\n0x000008000x000008040x000008080x0000080C0x000008100x000008140x000008180x0000081C0x00000820\n32Esempio di codice assemblerDLX 4Scrivereilcodiceassemblerperilcalcolodellasommadeiprimi8elementidiunvettorediWORDmemorizzatoapartiredall’indirizzo00000800h.Ilrisultatodell’elaborazionedeveesserememorizzatoall’indirizzoE0000200h.Σ\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#5": "IA: Intel X86 (CISC)\nIA: ARM (RISC)\nATMEL (RISC 8 bit)ArduinoUnoDesktopSmartphonee Tablet",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#50": "ADDR1,R0,R0;azzeraR1,accumulatoreADDIR2,R0,20h;R2=3210Loop:SUBIR2,R2,4h;R2=R2-410LWR3,0800(R2);leggewordinmemoriaADDR1,R1,R3;aggiornaaccumulatoreR1BNEZR2,Loop;saltaseR2nonèzeroLHIR7,0xE000;R7=E0000000SWR1,0200h(R7);memorizzaaccumulatoreinE0000200h",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#51": "Esercizio",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#6": "RISC-V (1/2)•IlprogettoRISC-Vmiraproprioaquesto:creareunISAunicoeopensource•Ovviamentel’obiettivononèquellodiuniformareleretilogichecheimplementanol’ISA•L’ISAbasedelprogettoRISC-VèmoltosimileaquelladelDLXchestudieremoeprogetteremoinquestocorso•Esistonospecificheperestenderel’ISAbasealfinedicontemplareparticolarifunzionalità(floating-point,SingleInstructionMutipleData(SIMD),32/64/128bit,etc)\nhttps://riscv.org/\nRISC-V: The Free and Open RISC Instruction Set Architecture",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#7": "RISC-V (2/2)\nhttps://www.slideshare.net/KrsteAsanovic/riscv-20160507patterson\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#8": "Codificabinariadelleistruzioni•LeistruzioniperessereeseguitedallaretelogicaCPUdebbonoesserecodificateinbinariosecondounformatonotoedocumentatodalproduttore(datasheet)•Lacodificabinariadeveconteneretutteleinformazioninecessarieall’UnitàdiControlloperpotereseguirel’istruzione•EsistonoCPUconcodificadelleistruzionialunghezza:-costante(e.g.,32bitcasoRISCDLXemoltialtri)-variabiledaistruzioneaistruzione(IntelX86)Esempio:LBR7,0800(R3)-“LeggiunBYTE(8bit)all’indirizzoR3+0800hetrasferiscinelregistroR7”A3570800Ipotetica codifica dell’istruzione con 32 bit. I bit non utilizzati per codificare R3, R7e 0800rappresentano il codice operativo (op code) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\03_Linguaggio_macchina.pdf#9": "Linguaggioassembler•Lacodificadelleistruzioniinlinguaggiomacchinaèpocointuitivapergliesseriumani•Nellinguaggio*assemblersicodificanoleinformazioniinunmodo(unpo’)piùintuitivoMacchina->Assembler014FA27Dh->ADDR1,R2,R3;R1=R2+R3Escludendolacaratteristicaappenaevidenziata,unaltrosignificativovantaggioèquellodipoterdefiniredellelabelutili(spesso)neisaltiLOOP:SUBR1,R1,R3......BNEZ(R1),LOOP;saltaaLOOPseR1!=0",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#0": "04 InterruzioniCalcolatori Elettronici TIngegneria Informatica\nStefano Mattoccia",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#1": "•Inunsistemaamicroprocessoreèdifondamentaleimportanzapotergestireeventichesiverificanoall’esterno(manonsolo)dellaCPU•Peresempio,determinareseèstatopremutountastosullatastiera,seilmouseèstatospostato,etc•Unastrategia,pocoefficiente,perraggiungerequestoscopoconsistenelcontrollareperiodicamentesetalieventisisonoverificati(polling)•Questopuòesserefattointerrogandodicontinuolaperifericachesidesideragestire•Ovviamente,conquestastrategia,laCPUspendemolticiclimacchinaperlaverifica(oleverifiche)•Unastrategiamoltopiùefficiente,basatasuunastrategia“push”,consistenell’usodiinterruptGestioneeventicon unaCPU: polling",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#10": "Interruzionimultiple e priorità\n•Inunsistemanelqualeèpresentepiùdiunasorgentediinterruzioneèfondamentalepoterassociareunlivellodiprioritàaciascunainterruzione•Sarebbeauspicabilepoterinterromperel’interrupthandlerinesecuzionesegiungeunarichiestadiinterruzionepiùprioritaria(annidamento)•Esempio:\nPROBLEMA_SISTEMA_FRENIPROBLEMA_SISTEMA_AUDIOINT?\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#11": "•AssumeremocheilDLXsiasensibileallivellodelsegnalediinterruptINTenonalsuofronte•L’indirizzodiritorno(PC+4)èsalvatoinIAR•Inseguitoall’arrivodiuninterrupt,l’istruzioneincorsoècompletataedèeseguitoilcodiceall’indirizzo00000000h•Ilritornodall’interrupthandler(PCçIAR)avvienemediantel’istruzioneRFE(ReturnFromException)•Ingenere,manonnelDLXbase,gliinterruptpossonoessereabilitatiodisabilitatimedianteistruzioni•Nell’ISADLX,ègestitounsoloindirizzodiritorno.Pertanto,ilDLXdisabilitaleinterruzionimentreeseguel’handlereleriabilitaautomaticamenteritornandodall’handler(RFE).Incasocontrario,nelDLX,servirebbeunostacksoftwareInterrupt nelDLX",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#12": "•Conannidamento(nesting)delleinterruzionisiintendelapossibilitàdipoteravviareuninterrupthandlerdurantel’esecuzionediunaltrohandler•QuestacaratteristicaèstandardnellamaggiorpartedelleCPUincommerciomanonèprevistadalDLXbase•Perpoterannidaregliinterruptsarebbenecessariounostacksoftware(utilizzandol’istruzioneMOVS2I)eaverelapossibilitàdiri-abilitaregliinterruptnell’handlermedianteopportuneistruzioni(ENI)nonprevistadall’ISAbase•Incasomultiplesorgentidiinterruzione,nasceilproblemadicomeassociareunascaladiprioritàalleinterruzioni•Atalfineesistonovariepolitiche:prioritàfissa,variabile,etc.Ovviamentelaprioritàècrucialenonsoloquandoèpossibileannidaregliinterrupt",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#13": "•Lerichiestediinterruptpossonoverificarsiinqualsiasimomento•E’perònecessariomantenerelaconsistenzadeidatiinmodocheilcodiceinesecuzionenonsiamodificatodall’arrivoomenodiinterruptediconseguenzadall’esecuzioneomenodegliinterrupthandler•Perquestaragioneènecessariofareinmodochel’interrupthandler(i.e.,ildriverdeldispositivo)noninterferiscaconilcodicedelprogramma(main)inesecuzione•Comefare?Salvandoeripristinandoiregistrimodificatidall’interrupthandlerall’internodellostessocodice(handler)•Nellapaginaseguenteèmostratol’effettodiunpessimointerrupthandlerchenonpreservairegistriInterrupt handler e consistenzadeidati",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#14": "1\n+\n2\n=\n33\na)b)c)\nd)e)\n1+2=33??Chi ha scrittoildriver/handler del nuovodispositivo, avràsalvatoe ripristinatolo statodeiregistri?Temodi no…",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#15": "Nelcasodiunasingolasorgentediinterruzione,ilcodicediuntipicointerrupthandlerpotrebbeaverelastrutturaseguente:00000000h;Istruzionichesalvanoiregistri;modificatidalleistruzioniseguenti;codicedirispostaallarichiesta;diinterruzione;istruzionidiripristinodeiregistri;modificatiinprecedenzaXXXXXXXXhRFE;ritornodall’interrupt(PCçIAR)Interrupt handlercon singolainterruzione",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#16": "Nelcasodimultiplesorgentidiinterruzione,ilcodicediuntipicointerrupthandlerpotrebbeaverelastrutturaseguente:00000000h;Istruzionichesalvanoiregistri;modificatidalleistruzioniseguenti;Identificazionedell’interruptpiù;prioritariotraquelliasseriti;ripristinaregistriesaltaalcodice;dell’interruptpiùprioritario;salvaregistrimodificatiinseguito;codicehandler_1XXXXXXXXh;ripristinaregistrieritorno(RFE);salvaregistrimodificatiinseguito;codicehandler_2YYYYYYYYh;ripristinaregistrieritorno(RFE)Interrupt handlercon multiple interruzione\nRFERFEPreambolo",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#17": "•Conlastrategiamostratanellapaginaprecedenteèilsoftware,interrogandoognisingolaperiferica,adoverdeterminarequalèl’interruptpiùprioritario•Atalfinesaràanchenecessariaunaopportunainfrastrutturahardware(itri-stateserviranno?)•Tuttavia,èpossibilevelocizzareesemplificareleretilogichedisupportoaquestocompitomediantel’utilizzodiundispositivoadhoc(PIC)•IlPICsioccupadigestiremultiplesorgentidiinterruzioneediforniredirettamenteallaCPU(surichiesta)qualèilcodice/indirizzodell’interruptpiùprioritariotraquelliasseritiinquelmomento•Tipicamente,inunPICèpossibiledisabilitarelesingolesorgentidiinterruzioneestabilireillivellodiprioritàdiciascunainaccordoavariepolitiche(prioritàfissa,variabile,etc)Programmable Interrupt Controller (PIC)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#18": "PICCSA[K-1..0]RDWRD[7..0]KBA[?..?]CS_PIC8BD[7..0]RDWRINT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0INTINTINT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0•LastrutturadiunipoteticoPICpotrebbeesserequellamostratainseguito•LevariesorgentidiinterruzioneINT[7..0]sonoinviatealPICchesioccupadiinviarelarichiestasull’unicopinINTdelDLX•Piùavantineprogetteremounomoltosempliceconfunzionalitàdibase(abilita/disabilitaINT_i)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#19": "INTPICCSA[K-1..0]RDWRD[7..0]INT_7INT_6INT_5INT_4INT_3INT_2INT_1INT_0INTCPU•IlPICinviailsegnalediINTefornisceallaCPU,surichiesta,ilcodicedell’interruptconprioritàpiùelevatatraquelliasseritiinquelmomento•PerchénelPICèpresenteancheilsegnaleWR?Perché dei timer?Come può essere realizzato un timer?\nCosa comunicano alla CPU le reti?",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#2": "main(){bool tasto_premuto=false;while(1){if (tasto_premuto==true)gestisci_evento();. . .}}void gestisci_evento(){. . .return;}Premuto?Premuto?Premuto?Premuto?\nLaCPUspendemoltotemponelcontrollare(polling)sel’eventosièverificato.Questastrategiarallental’esecuzionedelmainPocoefficiente….",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#20": "(i)(ii)INT\nΔxΔyΔwheelpressed_Lpressed_R•Inrealtàleinformazionisonoconvogliatesuuncanaleseriale(USB,PS/2)perridurreilnumerodiconnessioni/fili•Tuttavia,possiamopensareperlenostrefinalitàchel’interfacciamouse/CPUespongaisegnalidiunaportadiI/Ostandard(CS,RD,WR,D[7..0],indirizzi)\nInrealtàgliinterruptsonoemessiperiodicamente(e.g.,100Hz)esolosenecessario(uneventonelmouse)\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#21": "",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#22": "•InunaCPU(manonnelDLX)puòesserepresenteunulterioresegnale(ininput)denominatoNMI(NotMaskableInterrupt)•Atalesegnalesonocollegateunnumerolimitatodisorgentidiinterruzioniparticolarmentecritiche•Peresempio,l’outputdiunaretecherilevaesegnalaunaimminenteperditadialimentazioneelettrica•UnarichiestadiinterruptinviatasulpinNMInonpuòessereignorata(eventualiistruzionichedisabilitanogliinterruptnonagisconoperquestosegnale)einterrompel’esecuzionedialtrihandler•L’handlerassociatoalpinNMIèaprioritàmassimaedeveessereseguitonelminortempopossibileInterrupt non mascherabili(segnaleNMI)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#23": "•IlsegnaleNMIvausatoconcautelaesolopersegnalazionicriticheallaCPU•NelcasodelDLXutilizzeremosoloINT•Sefossedisponibile,perlagestionedelsegnaleNMIsarebbenecessarioinserireleistruzioninellaprimapartedel“preambolo”all’indirizzo00000000h,primadigestiregliinterruptchesonoinviatiattraversoINT",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#24": "ProgettareunsistemabasatosulprocessoreDLX,conun1GBdiEPROMaindirizzibassie512MBdiRAMaindirizzialti.Intalesistema,utilizzandounpulsante,deveesserepossibileaccendere/spegnereunledmedianteinterrupt.All’avvioilleddeveessereacceso.Sifaccial’ipotesicheR29eR30possanoessereusatisenzalanecessitàdiessereripristinati.Esercizio",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#25": "Alcune considerazioni sul reset asincrono\nFFDDQQ*A_SETA_RESRESETClockRESET_SYNCTuttavia,presentadeiproblemi:•E’semprenecessariounsegnalediclock•QuandoRESETvaa1,RESET_SYNCsiasserisce(ie,diventaattivo)alprimofrontediclockL’applicazionediunsegnaleasincronodireset,puòportareaproblemidimetastabilitànelmomentoincuitalesegnalevienepostoalvalore0(ie,quandosiescedalreset,assumendochetalesegnalesiaattivoalto).Leproblematichesonoanalogheaquelleevidenziateduranteilcampionamentodiunsegnalechenonrispettaitempidisetupehold.Unapossibilesoluzioneèlaseguente:",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#26": "FFDDQQ*A_SETA_RES0ClockRESET_SYNCRESETUnasoluzionecheeliminaidueproblemiprecedenti,echegarantisceun’uscitasincronadalreset,èlaseguente:\nClockRESETRESET_SYNCAttivazionenonsincronadelresetUscitasincronadalreset",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#3": "•UninterruptèuneventocheinterrompelaCPUduranteilregolareflussodiesecuzionedelcodice•L’interruptsegnalachesièverificatouneventochemeritaimmediata*attenzionedapartedellaCPU•SelaCPUèabilitata*ariceveretalesegnalazione,esegueautomaticamenteunaporzionedicodicedenominatainterrupthandleralfinedigestirel’evento•Glieventipossonoessererelativiafattoriesterni(e.g.,premutountasto)ointerni(e.g.,èstataeseguitaunadivisioneperzero,overflow,etc)•Quandodipendonodafattoriinternisiparladieccezioni(exceptions)•Inoltre,èpossibileinvocarel’handlermedianteopportuneistruzioni(e.g.,perinvocaresystemcall)Gestioneeventicon CPU: interrupt",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#4": "READYINTBA[31..2]BE3BE2BE0BE1BD[31..0]MEMRDMEMWRµPDLXCLOCKRESET\nREADYINTRESETBA[31..2]BE3BE2BE1BE0BD[31..0]RDWR\nInogniprocessore,èpresentealmenounsegnaledenominatoINTpergestireleinterruzioni.Inmolticasi,manonnelDLX,èpresenteancheunulterioresegnaledenominatoNMIpergestireinterruzionichenonpossonoessereignorate.Gestione interruzioni nel DLX30\n32NMI(NA nelDLX)NMI",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#5": "•Nelcasodiinterruptgeneratodall’esternolasituazioneèquesta:\n•Lapressionedeltastoinnesca*l’esecuzionedelcodicedell’interrupthandler(2)(1)(2); Interrupt hander. . . . . . . . . .. . . . .RFEINT\nLaCPUnormalmentesvolgeoperazioniutiliedèavvisatasoloquandosiverifical’evento(inquestocaso,lapressionedeltasto)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#6": "•Nelcasodiinterruptgeneratodall’esternolasituazione,dalpuntodivistasoftware,èquesta:main(){Istruzione1;Istruzione2;Istruzione3;Istruzione4;Istruzione5;Istruzione6;Istruzione7;Istruzione8;}\n(i); Interrupt handler ADD R1,R0,R0. . . . . . . . . .RFE(ii)(iii)•L’interruptpuòverificarsiinqualsiasimomento(i.e.,durantel’esecuzionediqualsiasiistruzione)enonèsincronizzatoconilclock•Assumeremosempreche,l’esecuzionedell’istruzionedurantelaqualesiverifical’interruptsiasempreportataatermineprimadieseguirel’handler\nL’is tr uzio n e4èportataatermineprimadieseguirel’interrupthandler",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#7": "•EsistonoCPUsensibiliallivellodelsegnalediinterrupt,altrealfrontedisalitaealtreaentrambelecose•NelcasodelDLXassumeremochelaCPUsiasensibileallivellodelsegnale(1sel’interruptèattivoe0incasocontrario)•Nelcasodeidispositivichegeneranointerrupt,assumeremocheessorimangaa1fintantochélacausachelohageneratononsiastatagestitadallaCPU•Pertanto,seunaperifericahauninterruptalivelloasserito,rimanetalefintantochél’interruptnonègestitodallaCPU(nonnecessariamentesubito*)•Inalcunicasi,nell’handlerpuòesserenecessarioeseguiredelleoperazionisoftwareperpoterportareallivellologico0ilsegnalediinterruptprovenientedall’esternodopoavergestitol’eventoSegnaledi interrupt: fronteo livello",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#8": "FFDDQ1A_RESINT_FRONTEINT_LIVELLOCS_RESET_INT\n•Comefareseildispositivochegeneral’interruptassumechelaCPUsiasensibileaifrontimentrelaCPUèsensibilesoloallivellodelsegnale?•E’necessarioeseguireunatrasformazionedafrontealivellodelsegnaleINT_FRONTE•Inuncasocomequesto,illivellologicodelsegnaleINT_LIVELLOdeveessereportatoazerodaunopportunocomandosoftware(CPU)cheasserisceilsegnaleCS_RESET_INTTrasformazioneda frontea livello",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\04_Interruzioni.pdf#9": "•C’èperòunproblema:escludendoNMI(discussodopo)ilDLXhaunsolosegnalediinterruptdenominatoINT.Comefacciamoagestire,cometipicamenteaccade,multiplesorgentidiinterrupt?•Siconvogliano(e.g.,medianteunORoaltrefunzioniinbaseallespecificheesigenze)tuttigliinterruptversol’unicosegnaleINTpresentenelDLX•Rimaneunaltroproblema:comedeterminarequale/qualiinterruptsonoasseritiinundeterminatoistante?•Atalpropositoè(tipicamente)necessariopoterdeterminarelostatodellerichiestediinterruptmedianteopportuneistruzionisoftware•Vedremocheesistonoanchedellereti,denominatePIC,chepossonoagevolarequestocompitoallaCPUGestionedi interruzionimultiple",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#0": "05 Periferiche di I/O con handshakeCalcolatori Elettronici TIngegneria Informatica\nStefano Mattoccia",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#1": "Porte di Input/Output (I/O)•InprecedenzaabbiamovistocomeprogettaredellesempliciperiferichediI/O,perscambiaredatitraCPUemondoesternomedianteunbuffer•Tuttavia,nonvieranessunagaranziasulcorrettoesitodeitrasferimenti•Infatti,cosaaccadese,mentrelaCPUscrivenellaportainoutput,undispositivoesternoleggedallamedesimaporta?Inoltre,cosaaccadeselaCPUleggeundatocheinrealtànonèmaistatoscrittodaundispositivoesterno?Comepuòsaperlo?Perquesto,itrasferimentisonointrinsecamenteespostiaerrori•Inpiù,lagestionedeltrasferimentieratotalmenteacaricodellaCPU(chepotrebbefarealtro)•LeportediI/Ononeranoingradodigenerareinterruptcontutteleproblematichechenederivano",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#10": "WROBFINT_OACKHandshake (OUTPUT): formed’onda\nNOTA: questo WRdeve essere “diretto”, dal processore, alla porta in OUTPUTOUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#11": "Unesempiodiunitàesternainoutputpotrebbeessererappresentatadaunastampantecheimprimesullacartaunacarattereallavolta.LaCPU,fornisce*idatiallastampanteattraversolaperifericadioutputquandoilsegnaleINT_Oèasserito(questoimplicacheOBFsia0)LastampanteleggeildatosoloquandoilsegnaleOBFèasserito(i.e.,quandolaportainoutputcomunicaallastampantecheunnuovodatoèstatoscrittodallaCPUnelbufferedèquindidisponibile)\nOUTPUTINT_OACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK\nLastampantedevecontenereunasempliceretelogicaingradodigestireilprotocollodihandshake",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#12": "ProgettareunaretelogicabasatasuFFDingradodigestirelecomunicazioniconduedispositiviesterni–unoininputmappatoaCS+0eunoinoutputmappatoaCS+1–utilizzandoilprotocollodihandshakeEsercizio\nParallelI/OBD[7..0]RDINT_ICSA0WRINT_0D_OUT[7..0]OBFACKD_IN[7..0]STBIBFA_RESETRDINT_ICSBA2WRINT_0D_OUT[7..0]OBFACKD_IN[7..0]STBIBFRESET\nBD[7..0]",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#13": "Progettodell\u0001interfacciaL’interfacciaparallelaèdotatadidueporte,ciascunaingradoditraferiredatia8bit:•PortainINPUTmappataall’indirizzoCS+0•PortainOUTPUTmappataall’indirizzoCS+1Alfinedirisolvereilproblema,risultautilepensarelaportadiI/Ocomecompostadadueporteindipendenti:unaportaininputeunaportainoutputInoltre,nellasoluzionesidesideraevitareclockgatingIlpuntodipartenzasonoleformed’ondadelprotocollodihandhsake,mostratenellepagineprecedenti",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#14": "STBIBFINT_IRDHandshake (INPUT)\nNOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUTINPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#15": "STBIBFINT_IRDHandshake (INPUT)\nNOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUT01230INPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#16": "STBIBFINT_IRDU0U1U2U300 0 010 0 011 0 011 1 011 1 101 1 100 1 100 0 100 0 010 0 011 0 011 1 011 1 1Handshake (INPUT): soluzionesenzaclock gating\n013715141280137151otrasferimento2otrasferimento3otrasferimentoOsservando le forme d\u0001onda, è possibile individuare unasoluzione senza clock gating\nDue trasferimenti, un ciclo completo ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#17": "IlsegnaleDEC(x)identificalaconfigurazionebinariaU3U2U1U0equivalenteaxinbase10.Pertanto,isegnaliIBFeINT_Irisultano:IBF=(DEC(1)+DEC(3)+DEC(7))+(DEC(14)+DEC(12)+DEC(8))INT_I=DEC(3)+DEC(12)Oppure,IBF=U0XORU3INT_I=U1XORU2CSèilchip-selectdellaperifericaininputFFDDQ0A_RESQ0*RESETSTBU0FFDDQ1A_RESQ1*RESETSTB*U1\nFFDDQ3A_RESQ3*RESETRD*U3Q3*Q310CS·A0*FFDDQ2A_RESQ2*RESETRDU2Q2*Q210CS·A0*",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#18": "373D[7..0]Q[7..0]OECCS·RD·A0*D_IN[7..0]BD[7..0]STBHandshake (INPUT): buffer di ingressocon 373 Ipotizzando di mappare la porta in INPUTall’indirizzoCS + 0e di voler utilizzare dei latch 373 come buffer.\nOvviamentesarebbepossibileunasoluzionedeltuttoequivalentecon374comemostratonellapaginasuccessiva",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#19": "374D[7..0]Q[7..0]OECS·RD·A0*D_IN[7..0]BD[7..0]STB*Handshake (INPUT): buffer di ingressocon 374 IpotizzandodimapparelaportainINPUTall’indirizzoCS+0edivolerutilizzaredeiFFD374comebuffer",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#2": "FFD(x8)D[7..0]Q[7..0]CS·RDDI[7..0]BD[7..0]WRITE*Unasempliceperifericaperleggeredatidall’esterno,senzautilizzareinterrupt,èlaseguente:CPU\nEsternoTuttavia,conquestasoluzione,sorgonodeglievidentiproblemi:•ComepuòsaperelaCPUcheèdisponibileunnuovodatoscrittodall’esternonellaporta?•Comesipuòsaperedall’esternochelaCPUhalettoildatoscrittoinprecedenzanellaporta?\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#20": "Esercizio: progettodellaportain outputProgettarelaperifericapergestireitrasferimentiinOutputmediantehandshakeapartiredalleformed\u0001ondamostratenelleslidesuccessive.OUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#21": "WROBFINT_OACKHandshake (OUTPUT)\nNOTA: questo WRdeve essere “diretto”, dal processore, alla porta in OUTPUT01230OUTPUTINT_OEXTUNITACKOBFD_OUT[7..0]WRBD[7..0]CSWRINTRBD[7..0]CSD[7..0]OBFACK",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#22": "Registridi statoe programmazioneSarebbeutileaggiungereallaperifericachegestisceinputeoutputconprotocollodihandshakeiseguentiregistri:•Registrodistato(letturasegnalidistatopergestioneapolling)indirizzoA1A0=10•Registrodiprogrammazione(enable/disablesingolainterfaccia,etc)indirizzoA1A0=11Ovviamente,serveunulteriorebit(A1)perindirizzaregliulterioridueregistriEsercizioComesipotrebbemodificareilprogettodellaportadiI/Oconhandshakeperaggiungerequestenuovefunzionalità?",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#23": "ProgettareunsistemabasatosulmicroprocessoreDLX,con1GBdiEPROMagliindirizzibassie2GBdiRAMagliindirizzialti.Nelsistemaèpresenteunaportaininput,giàprogettataedenominataINPUT_PORT,eunpulsantedenominatoP.Ilbyte(unsigned)lettodaINPUT_PORTdeveesserememorizzatoall’indirizzoFFFF0020hmentreilregistroR20deveessereincrementatodiuno,viasoftware,aognipressionediPeinizializzatoa0all’avviodelsistema.Inoltre,siassumache:1)IlpulsantePabbiaprioritàmaggiorediINPUT_PORT2)IlpulsantePnonpossaesserepremutoprimachesiaterminatalagestionediPdapartedell’interrupthandler.Atalfinesegnalare,conunLED,quandoilpulsantenondeveesserepremuto3)IregistridaR25aR30possonoessereutilizzatisenzalanecessitàdiessereripristinati4)IlregistroR20siamodificabilesolodall’handlerchegestisceilpulsanteEsercizio",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#3": "Unesempiocheevidenziaquestiproblemiriguardaloscambiodibeni/datitraunproduttoreeunconsumatore\nSeilproduttoreproduceuncaffècheèprelevatoprimadell’arrivodiunaltrotuttopotrebbeapparentementefunzionarecorrettamente(setupehold?)Tuttavia,comepuòsapereilproduttorecheilcaffèèstatoprelevato?Comepuòsapereilconsumatorecheèdisponibileunnuovocaffèpreparatodalproduttore?Perquesteragioni,sorgonoaltriproblemi...PC\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#4": "Unprimoproblemasiverificaseilconsumatoresmettediprelevarecaffèperchénonèpronto(e.g.,ilconsumatoreèaltelefono).Comepuòsaperloilproduttore?\nPC\nbla,bla,bla",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#5": "Ilproblemadualesiverificaseilproduttoresmettediprepararecaffèperchéimpegnatoafarealtro(e.g.,parlarealtelefono).Comepuòsaperloilconsumatore?\nbla,bla,bla\n•IdueproblemievidenziatipossonoessererisoltiinmodomoltosemplicericorrendoaqualcheformadisincronizzazionetraledueentitàPeC•Perquestoscopol’handshakeèunapprocciosemplice,efficienteeampiamenteutilizzatoPC\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#6": "Segnali del protocollo \u0002handshake\u0003: INPUT\n1.SeIBF=0,quandopossibile*UEpuòscrivereildatonelbufferd\u0001ingressodellaporta2.UE,portandoSTBa1,scriveildatonellaportachecontemporaneamenteasserisceIBF(InputBufferFull)3.QuandoUEportaSTBazero(scritturaterminata),l\u0001interfacciaattivaINT_I(InterruptRequest)4.Quandopossibile*,laCPUandràaleggereildatoscrittonellaportadaUE.Altermine,IBFandràazero(mentreINT_Ivaa0,dall’iniziodellalettura)INPUTUnitàEsterna(UE)InputRDINT_IBD[7..0]D_IN[7..0]STBIBFCSRDINTRBD[7..0]CSD[7..0]STBIBF",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#7": "STBIBFINT_IRDHandshake (INPUT): formed’ondaINPUTINT_IEXTUNITSTBIBFD_IN[7..0]RDBD[7..0]\nNOTA: questo RDdeve essere “diretto”, dal processore, alla porta in INPUTCSRDINTRBD[7..0]CSD[7..0]IBFSTB",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#8": "Unesempiodiunitàesternaininputpotrebbeessererappresentatadaunsensore(e.g.,ditemperatura)IlsensoreinviaidatiallaCPUattraversolaperifericadiinputquandounanuovamisuraèdisponibileeIBF=0.Alterminediogniscritturanellaportadapartedelsensoreditemperatura,ilsegnaleINT_IsiasserisceINPUTINT_ISTBIBFD_IN[7..0]RDBD[7..0]CSRDINTRBD[7..0]CSD[7..0]IBFSTB\nIlsensoredevecontenereunasempliceretelogicaingradodigestireilprotocollodihandshake",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\05_Handshake.pdf#9": "Segnali del protocollo \u0002handshake\u0003: OUTPUTOUTPUTUnità Esterna(UE)Output1.IlsegnaleINT_OasseritocomunicaallaCPUchelaportapuòaccettareunnuovodato2.InrispostoallarichiestadiinterruptlaCPUscrive,quandopossibile*,ildatosulbufferdellaporta1.L\u0001interfacciasegnalaaUEcheèdisponibileunnuovodatoattivandoOBF(OutputBufferFull)2.Quandopossibile*,UEleggeildatoscrittodallaCPUasserendoACK(acknowledge)WRINT_OBD[7..0]D_OUT[7..0]ACKOBFCSWRINTRBD[7..0]CSD[7..0]ACKOBF",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#0": "06 ProgrammableInterrupt Controller (PIC)Calcolatori Elettronici TIngegneria Informatica\nStefano Mattoccia",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#1": "•Abbiamogiàvistocheèpossibile,opzionalmente,utilizzareundispositivoad-hocperlagestionedimultiplesorgentiinterruzionidenominatoPIC•IlPICvelocizzaefacilitalafasedianalisiegestionedegliinterrupt•TipicamenteunPICconsentedi:•Abilitaredisabilitaresingoleinterruzioni•Fornireinformazionisulleinterruzioniasserite•Gestirelaprioritàdelleinterruzioni•Perleragionievidenziate,unPICèprogrammabilemediantel’utilizzodiopportuniregistriinterni•Sebbenesiasemprepossibileunagestioneinteramentesoftwaredelleinterruzioni,l’utilizzodiunPICpuòessereunavalidaalternativa•Perquesteragioni,progettiamounPICmoltosempliceGestionedelleinterruzionicon PIC",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#10": "EN_INT_0INT_0Diconseguenza,inogniistante,gliinterruptabilitatirisultanodalleuscitediquestarete:EN_INT_1INT_1EN_INT_2INT_2EN_INT_3INT_3RAW_ENABLED_INT_0RAW_ENABLED_INT_1RAW_ENABLED_INT_2RAW_ENABLED_INT_3Si ricorda che, come mostrato nello schema ai morsetti del PIC, risulta:INT_0= INT_OUT_PORT_0INT_1= INT_OUT_PORT_1INT_2= INT_IN_PORT_0INT_3= INT_IN_PORT_1Al pin di interrupt del DLX è pertanto inviato il segnale:INT_DLX= RAW_ENABLED_INT_0+RAW_ENABLED_INT_1+RAW_ENABLED_INT_2+RAW_ENABLED_INT_3",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#11": "Perevitareproblemidimetastabiitàèpossibilecampionarelostatodegliinterrupt,primadiprocedereallalorolettura,peresempioconquattroFFDchecampionanogliinterruptsulfrontedisalitadiMEMRD.RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_0SYNC_ENABLED_INT_0RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_1SYNC_ENABLED_INT_1RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_2SYNC_ENABLED_INT_2RESETFFDDQA_RESMEMRDRAW_ENABLED_INT_3SYNC_ENABLED_INT_3",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#12": "Alfinedileggerelostatodegliinterruptasseriti,traquellichesonostatiabilitati,siutilizzanodeibuffertri-statepilotatidalsegnaleCS_PIC_READ_INTscomesegue:CS_PIC_READ_INTsSYNC_ENABLED_INT_0CS_PIC_READ_INTsSYNC_ENABLED_INT_1CS_PIC_READ_INTsSYNC_ENABLED_INT_2CS_PIC_READ_INTsSYNC_ENABLED_INT_3CS_PIC_READ_INTs‘0000’ENABLED_INT[0]ENABLED_INT[1]ENABLED_INT[2]ENABLED_INT[3]ENABLED_INT[7..4]IsegnaliENABLED_INT[7..0]sonoconnessialbusdatiBD[7..0]44",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#13": "Lareteseguente,consentedileggereaCS_PIC_READ_CODEilcodicea16bit(perragionimostratedopo)dell’interruptpiùprioritario(BD[15..0])\nCS_PIC_READ_CODESYNC_ENABLED_INT_0·SYNC_ENABLED_INT_1*· SYNC_ENABLED_INT_2*·SYNC_ENABLED_INT_3* CS_PIC_READ_CODESYNC_ENABLED_INT_1·SYNC_ENABLED_INT_2*·SYNC_ENABLED_INT_3*CS_PIC_READ_CODESYNC_ENABLED_INT_2·SYNC_ENABLED_INT_3*CS_PIC_READ_CODESYNC_ENABLED_INT_3CS_PIC_READ_CODE‘00000000’\nCS_PIC_READ_CODE‘0000’INT_CODE[7..0]INT_CODE[8]INT_CODE[9]INT_CODE[10]INT_CODE[11]INT_CODE[15..12]NOTA: come richiesto dal testo del problema, si assegna il seguente ordine crescente di priorità:0) INT_0 (Minima) 1) INT_12) INT_23) INT_3 (Massima)4488",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#14": "Icodicidipriorità,a16bitpervelocizzarel’handler,associatiallequattrointerruzionielettiall’indirizzoCS_PIC_READ_CODE,risultano:0800hseèasseritoSYNC_ENABLED_INT_3(massimapriorità)0400hseèasseritoSYNC_ENABLED_INT_2enonSYNC_ENABLED_INT_30200h se è asseritoSYNC_ENABLED_INT_1e non SYNC_ENABLED_INT_2oSYNC_ENABLED_INT_30100h se è asserito SYNC_ENABLED_INT_0e nessun altro segnaleIl codice per abilitare le interruzioni dalle 4 porte risulta:LHI R25,8000h; R25 = 80000000hADDI R26,R0,000Fh; R26 = 0 + 0000000FSBR26,(R25)04h; scrive il byte 0Fh contenuto in R26; all’indirizzo CS_PIC_SET_INTs(80000004h)Il codice per leggere quali sono le interruzioni asserite:LHI R25,8000h; R25 = 80000000hLBUR26,(R25)08h; legge in R26 gli interrupt asseriti, tra quelli; abilitati, all’indirizzo CS_PIC_READ_INTs; (80000008h)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#15": "Il codice dell’interrupt handlerè il seguente:00000000: LHI R25,8000h; prepara indirizzo 80000000h00000004: LHU R26,(R25)0Ch; lettura del codice di priorità a 16 bit; all’indirizzo CS_PIC_READ_CODE00000008: LHIR27,FFFF; prepara in R27 l’indirizzo per : operazioni comuni successive al salto 0000000C: JRR26; salta all’indirizzo presente in R26; checorrisponde al codice di interrupt ; più prioritario letto mediante LHU00000100: LBU R28,(R27)10h; legge in memoria un byte a FFFF0010h00000104: SB R28,(R25)2h; scrive quanto letto in OUTPUT_PORT_000000108: RFE; (80000002h) e ritorna dall’interrupt00000200: LBU R28,(R27)20h; legge in memoria un byte a FFFF0020h00000204: SB R28,(R25)3h; scrive quanto letto in OUTPUT_PORT_100000208: RFE; (80000003h) e ritorna dall’interrupt00000400: LBU R28,(R25)0; legge da INPUT_PORT_0(80000000h)00000404: SB R28,(R27)40h; scrive byte in memoria a FFFF0040h  00000408: RFE; ritorna dall’interrupt00000800: LBU R28,(R25)1; legge da INPUT_PORT_1(80000001h)00000804: SB R28,(R27)80h; scrive byte in memoria a FFFF0080h  00000808: RFE; ritorna dall’interrupt",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#16": "RAM_3RAM_2RAM_1RAM_0BA[28..2]Interfacciamento RAMMEMWRMEMRDCS_RAM_0CS_RAM_1CS_RAM_2CS_RAM_3\nBD[7..0]BD[15..8]BD[23..16]BD[31..24]\nA[26..0]RD WR CSRD WR CSRD WR CSRD WR CS",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#17": "Interfacciamento EPROM\nBD[7..0]BD[15..8]BD[23..16]BD[31..24]EPROM_3EPROM_2EPROM_1EPROM_0BA[29..2]MEMRDCS_EPROM_0CS_EPROM_1CS_EPROM_2CS_EPROM_3\nA[27..0]RD  CSRD  CSRD  CSRD  CS",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#2": "InunsistemabasatosulDLX,con1GBdiEPROMmappatanegliindirizzibassie512MBdiRAMmappatanegliindirizzialti,sonopresentiegiàprogettate2portea8bitinINPUT(IN_1eIN_0)e2portea8bitinOUTPUT(OUT_1eOUT_0)basatesulprotocollodihandshake.ProgettareunsemplicePICalfinediassegnareleseguentiprioritàstaticheallequattrointerruzioni:IN_1(massimapriorità),IN_0,OUT_1eOUT_0(minimapriorità).IlPICdovràinoltreconsentiredi:a)disabilitare/abilitareselettivamente,medianteparoledicontrollo,ciascunainterruzionegeneratadalle4perifericheb)fornireleinterruzioniasserite(traquelleabilitate)c)fornireuncodicecheindicaqualèl’interruzionepiùprioritaria(traquelleabilitate)inundeterminatoistanteUtilizzandolaretelogicaprogettatagestirelequattrointerruzioniinmodochedurantel’esecuzionedell’interrupthandlersiaeseguito,nelmodopiùrapidopossibile,soloiltrasferimentoattivopiùprioritarioinquelmomento.Eventualialtrerichiesteditrasferimentoattivesarannogestitedurantesuccessiveesecuzionidell’interrupthandler.IdatilettidalleporteinINPUTdovrannoesserescrittiaFFFF0080(IN_1)eFFFF0040(IN_0)mentreidatidascriverenelleporteinOUTPUTdovrannoesserelettidaFFFF0020(OUT_1)eFFFF0010(OUT_0).All’avviodelsistemailPICdovràautomaticamentedisabilitaretuttelerichiestediinterruzioneprovenientidallequattroporte.-ScrivereilcodicecheabilitatutteleinterruzioninelPICeilcodicecheconsentedileggerelostatodegliinterrupt-Scrivereilcodiceottimizzatodell’interrupthandler(iregistridaR25aR29possonoessereutilizzatisenzalanecessitàdidoverliripristinare).Progettodi un semplicePIC",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#3": "PICProgrammableInterruptControllerA_RESETINT_0 (-)INT_1INT_2INT_3 (+)CS_PIC_SET_INTs\nCS_PIC_READ_INTsCS_PIC_READ_INTs_CODED[3..0]INT_TO_DLXENABLED_INT[7..0]INT_CODE[15..0]4816BD[7..0]BD[15..0]BD[3..0]INT(to DLX)CS_PIC_SET_INTs\nCS_PIC_READ_INTsCS_PIC_READ_CODEINT_OUT_PORT_0INT_OUT_PORT_1INT_IN_PORT_0INT_IN_PORT_1RESETIlPIC(ProgrammableInterruptController),ingradodigestire4interruzioni,puòessereschematizzatonelmodoseguente:\nRDWRMEMRDMEMWR",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#4": "NelPIC,lamassimaprioritàèassegnataaINT_3,quellaminimaaINT_0.Leprioritàsonostatiche,comeprevistodaltesto.IsegnalidiingressodelPICINT_3,INT_2,INT_1eINT_0sonoconnessiai4interruptdelleperifericheinmododasoddisfareivincolisullaprioritàprevistidaltestodelproblema.ScrivendoaCS_PIC_SET_INTs,idatipresentisuipinD[3..0]consentonodiabilitare/disabilitareisingoliinterrupt.Gliinterruptasseritidalleperiferiche,traquelliabilitati,possonoessereletti,aCS_PIC_READ_INTs,attraversoisegnaliENABLED_INT[7..0].Essendoprevistisolo4interrupt,4degli8bitsonocablatia0(i4bitpiùsignificativi).Ilcodicechecorrispondeall’interruptpiùprioritario,traquelliabilitati,potràessereletto,aCS_PIC_READ_CODE,attraversoisegnaliINT_CODE[15..0].Diquestiultimi16segnali,12sarannosemprecablatia0perragionichiariteinseguito.",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#5": "Dispositivi e segnali presenti nel sistemaMemorie:RAM_512_MBmappata da E0000000h:FFFFFFFFh, 4 banchi da 128 MBEPROM_1_GB mappata da 00000000h:3FFFFFFFh, 4 banchi da 256 MBPorte di input, output e altri chip-selecte/o segnali:CS_INPUT_PORT_0mappato a 80000000hCS_INPUT_PORT_1mappato a 80000001hCS_OUTPUT_PORT_0mappato a 80000002hCS_OUTPUT_PORT_1mappato a 80000003hCS_PIC_SET_INTsmappato a 80000004hCS_PIC_READ_INTsmappato a 80000008hCS_PIC_READ_CODEmappato a 8000000Ch",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#6": "Segnali di decodifica di memorie, periferiche e segnali:CS_RAM_0 = BA31·BA30·BE0CS_RAM_1= BA31·BA30·BE1CS_RAM_2= BA31·BA30·BE2CS_RAM_3= BA31·BA30·BE3CS_INPUT_PORT_0= BA31·BA30*·BA3*·BA2*·BE0·IBF_0mappato a 80000000hCS_INPUT_PORT_1= BA31·BA30*·BA3*·BA2*·BE1·IBF_1mappato a 80000001h CS_OUTPUT_PORT_0= BA31·BA30*·BA3*·BA2*·BE2·OBF_0*mappato a 80000002h CS_OUTPUT_PORT_1= BA31·BA30*·BA3*·BA2*·BE3·OBF_1*mappato a80000003hCS_PIC_SET_INTs= BA31·BA30*·BA3*·BA2mappato a 80000004hCS_PIC_READ_INTs= BA31·BA30*·BA3·BA2*·MEMRDmappato a 80000008hCS_PIC_READ_CODE= BA31·BA30*·BA3·BA2·MEMRDmappato a 8000000ChCS_EPROM_0 = BA31*·BE0 CS_EPROM_1= BA31*·BE1CS_EPROM_2 = BA31*·BE2CS_EPROM_3 = BA31*·BE3",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#7": "INPUTPORT_0D[7..0]RDINT_INPUTCSDATA_IN[7..0]STBIBFCS_INPUT_PORT_0MEMRDUNITA’ESTERNA#0INT_IN_PORT_0BD[7..0]IBF_0Nelsistemasonopresentidueporteininput,collegateaibusdatiBD[7..0](INPUT_PORT_0)eBD[15..8](INPUT_PORT_1)\nINPUTPORT_1D[7..0]RDINT_INPUTCSDATA_IN[7..0]STBIBFCS_INPUT_PORT_1MEMRDUNITA’ESTERNA#1INT_IN_PORT_1BD[15..8]IBF_1STB_1STB_0A_RESETRESET\nA_RESETRESET",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#8": "OUTPUTPORT_0D[7..0]WRINT_OUTPUTCSDATA_OUT[7..0]ACKOBFA_RESETCS_OUTPUT_PORT_0MEMWRRESETUNITA’ESTERNA#2INT_OUT_PORT_0     BD[23..16]NelsistemasonopresentianchedueporteinoutputcollegateaibusdatiBD[23..16](OUTPUT_PORT_0)eBD[31..24](OUTPUT_PORT_1)\nOUTPUTPORT_1D[7..0]WRINT_OUTPUTCSDATA_OUT[7..0]ACKOBFCS_OUTPUT_PORT_1MEMWRUNITA’ESTERNA#3INT_OUT_PORT_1     BD[31..24]ACK_1OBF_1ACK_0OBF_0\nA_RESETRESET",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\06_PIC.pdf#9": "RESETFFDDQA_RES10MEMWR*D0EN_INT_0AlfinediabilitareedisabilitareselettivamentegliinterruptsipossonoutilizzarequattroFFD.IquattrobitD[3..0]sonoconnessiaisegnaliBD[3..0]delbusdatieutilizzatipercondizionareognisingolainterruzionemedianteisegnaliEN_INT_0,EN_INT_1,EN_INT_2eEN_INT_3generatidalleretiseguenti:CS_PIC_SET_INTsEN_INT_0RESETFFDDQA_RES10MEMWR*D1EN_INT_1CS_PIC_SET_INTsEN_INT_1RESETFFDDQA_RES10MEMWR*D2EN_INT_2CS_PIC_SET_INTsEN_INT_2RESETFFDDQA_RES10MEMWR*D3EN_INT_3CS_PIC_SET_INTsEN_INT_3",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#0": "DLX: implementazione sequenziale  Calcolatori Elettronici T Ingegneria Informatica \n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#1": "Datapath e Unità di Controllo  • La struttura di una CPU, come tutte le reti logiche sincrone che  elaborano dati, può essere strutturata in due blocchi: Unità di Controllo e Datapath  • La CPU, per funzionare, ha bisogno della memoria esterna su cui risiedono il programma e i dati \nreset interrupt ready \nCPU istruzioni Dati (in)  indirizzi \nDati (out) U.d.C. Data Path clock memoria Rete logica CPU ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#10": "Estrazione “automatica” dei registri durante la fase di decode di una istruzione (qualsiasi)  I Codice  operativo  RS2/Rd RS1 Operando immediato di 16 bit J Codice  operativo  Offset di 26 bit (PC relative) R Codice  operativo  RS2 RS1 Rd Estensione al Cod. op (11 bit) 0 31 < A B \nQuesti 5 + 5 bit  sono utilizzati per estrarre, preventivamente e ancora prima di conoscere che tipo  di istruzione che è stata letta dalla memoria, dal Register File due registri in A e B. Nel caso di  istruzione J non ci sono registri coinvolti e quindi saranno estratti bit corrispondenti all’offset. Nel  caso di istruzione I, in B potrebbe finire il valore del registro destinazione (e.g. in una LD o  operazione ALU (tipo I)). Infine: i 5 + 5 bit rappresentano gli indici (o presunti tali) ma non il valore dei due registri che è  contenuto nel Register File. ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#11": "Gli stati della fase di fetch  • In questa fase si deve verificare se è presente un interrupt (evento esterno asincrono che la CPU deve “servire” con apposito software); • se l’interrupt è presente e può essere servito (IEN = true) si esegue implicitamente l’istruzione di chiamata a procedura all’indirizzo 0, e si salva l’indirizzo di ritorno nell’apposito registro IAR; • se l’interrupt non è presente o le interruzioni non sono abilitate, si va a leggere in memoria la prossima istruzione da eseguire (il cui indirizzo è in PC) MAR ← PC Dall’ultimo stato  dell’istruzione precedente  IAR:  Interrupt  Address  Register  IAR ← PC PC ← 0 IEN ← 0 IEN:  Interrupt  Enable  Flag  (int and IEN) = 1 (int and IEN) = 0 IR ← M(MAR) Alla fase di decodifica Ready = 1 Ready = 0 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#12": "Si modifica il  DATAPATH in  maniera da poter  indirizzare  la memoria dal PC.  Meno stati ma maggiore complessità  Data transfer ALU Set Jump Branch Ready ? INSTRUCTION FETCH INSTRUCTION  DECODE* Tutte le istruzioni impiegano un clock in meno per essere eseguite !  Ma potenzialmente aggiore lentezza  -> minore freq. clock Il diagramma  degli  stati del  controller  PC <- PC +4  A <- RS1 B <- RS2  IR <- M [PC] ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#13": "Ready ? IR <- M [PC] \n MAR <- A + (IR15)16 ## IR15..0 LOAD MDR <- M[MAR]  LB Ready ? C <- (MDR7)24 ## MDR7..0 RD <- C   PC <- PC +4  A <- RS1  B <- RS2  Controllo per  l’istruzione LB  (LOAD BYTE) ALU ALU Parte comune \nRS2 è da intendersi come registro di destinazione (A) = (RS1) Estensione segno ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#14": "Estensione del segno   (IR15)16 ## IR15..0 0    15      31 IR \n31 30…………17  16 BUS S1 o S0 Da UdC \n15-0 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#15": "MDR <- M[MAR]\nMDR <- B.C <- MDRRD <- C M[MAR] <-MDRINIT STORE \nLB LBU LH LHU LW Controllo per  le istruzioni di  DATA  TRANSFER  LB  LBU LH LHU LW STORE  Byte -> SB Half Word –> SH Word -> SW  C <-(MDR7)24 ## MDR7..0C <- (0)24 ## MDR7..0C <- (MDR15)16 ## MDR15..0 C <-(0)16 ## MDR15..0MAR <- A + (IR15)16 ## IR15..0 LOAD \nMancano nell’esempio  SH e SB (sempre unsigned)  che corrispondono a attivazione degli specifici WE delle memorie e “traslatori” dei bytes del registro MDR.  Come si realizzerebbero ?  NB: in lettura la parte meno  significativa del dato viene letta  sempre allineata al registro MDR per permettere il filling SW Il contenuto di A come unsigned Ready ? \nReady ? ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#16": "17  17  Trasferimenti BYTE, HW  •  I trasferimenti di bytes sono SEMPRE considerati allineati •  I trasferimenti di HW debbono avvenire a indirizzi multipli di 2 •  I trasferimenti di Word debbono sempre avvenire a indirizzi multipli di 4 •  In caso di disallineamento: fault •  Nel caso di store di dati di dimensione inferiore alla word NON si ha estensione del segno •  La lettura/scrittura di bytes e HW (a causa del reciproco disallineamento fra i registri e la memoria) implica che fra i registri e la memoria siano interposti dei mux/demux (realizzati con tristate) Registro MDR \nMemoria Come sono attivati i WE delle memorie ? Progettare la rete  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#17": "Trasferimenti BYTE, HW  MDR \nMemoria 31 0 Mux Demux I MUX 23-16 e 31-24 hanno come ingresso anche il bit 7 del byte 7-0 della memoria (LB) e il bit 15 del byte 15-8 della memoria (LH)  Ad esempio in una LB il MUX 7-0 si collega direttamente alla memoria mentre i MUX 15-8, 23-16 e 31-24 si collegano al bit 7 del MUX 7-0 proveniente dalla memoria.  In una SH a indirizzo multiplo di 2 e non di 4  il DEMUX 7-0  dal MDR si collega alla memoria 23-16 e il DEMUX 15-8 alla memoria 31-24. Gli altri due bytes della memoria rimangono invariati Mux Demux “0” Bit più signif. byte precedenti Solo in lettura Trasferimento  “unsigned” 24 23 16 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#18": "C <- A + TempC <- A xor TempC <- A - Temp C <- A and TempC <- A or TempINIT RD <- CRegistro (formato R) Immediato (formato I) \nADD AND SUB XOR OR   Temp <- BTemp <- (IR15)16 ## IR15..0Esempi di istruzioni  ALU  Duplicando i percorsi si potrebbe risparmiare il passaggio in TEMP  Lo stesso schema si può usare per gli shift etc.  Il contenuto dei registri come signed se op aritmetica ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#19": " RD <- C A = Temp\nC <- 1SEQ SLT SGE SNE SGT SLE YES NO  Il risultato del test è un input per il controller ! Registro (formato R) Immediato (formato I) Controllo per  le istruzioni  di SET  (confronto) ex. SLT R1,R2,R3  \nINIT Duplicando i percorsi si potrebbe risparmiare il passaggio in TEMP   Temp<- BTemp <- (IR15)16 ## IR15..0 A < Temp A >= Temp A <= Temp A > Temp A! = TempC <- 0I micropassi sono eseguiti  in ALU ma il risultato  NON è memorizzato in un registro: i flag sono utilizzati dalla ALU per impostare (almeno) il bit 0 del registro C  Il contenuto dei registri come signed ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#2": "•  Datapath: contiene tutte le unità di elaborazione ed  i registri necessari per l’esecuzione delle istruzioni  della CPU. Ogni istruzione appartenente all’ISA è  eseguita mediante una successione di operazioni  elementari, dette micro-operazioni •  Micro-operazione: operazione eseguita all’interno  del DATAPATH in un ciclo di clock ( e s e m p i :  trasferimento di un dato da un registro ad un altro  registro, elaborazione ALU) •  Unità di Controllo: è una RSS che in ogni ciclo di  clock invia un ben preciso insieme di segnali di  controllo al DATAPATH al fine di specificare  l’esecuzione di una determinata micro-operazione  Datapath e Unità di Controllo  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#20": "INIT  C <- PCJALR JAL JMP JR JALR \nJALR JR JAL \nJMP JAL JALR  JAL Controllo per  le istruzioni  di JUMP  (IR15)16 ## IR15..0  C <- PC\nPC <-  PC + (IR25)6 ## IR25..0 PC <- A R31 <- CPer il salvataggio in R31 \nIstruzione  formato I  Istruzione  formato J  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#21": "INIT A = 0 BRANCH \nYES YES NO NO BEQZ BNEZ Controllo per  le istruzioni  di BRANCH  A! = 0 PC <-  PC + (IR15)16 ## IR15..0 Ex. BNEQZ R5, 100 Il controllo se 0 (o !=0) è fatto sull’intero registro A (a 32 bit) e non solo sul bit meno significativo ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#22": "Numero di clock necessari per eseguire le istruzioni  Istruzione Cicli Wait Totale Load 6 2 8 Store 5 2 7 ALU 5 1 6 Set 6 1 7 Jump 3 1 4 Jump and link 5 1 6 Branch (taken) 4 1 5 Branch (not taken) 3 1 4 CPICPIN numero totale di istruzioni iin=i = 1 ∑(*)Esempio su DLX  LOAD: 21%, STORE: 12%, ALU: 37%, SET: 6%, JUMP: 2% BRANCH (taken): 12%, BRANCH (not-taken): 11%    CPI = 6.3 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#23": "Controllo cablato (“hardwired”) Segnali di  controllo \nINSTRUCTION REGISTER (IR) 40 Opcode +  OpCode Extension   6 Datapath Stato presente Rete combinatoria che  genera uscite e stato futuro Int e ready 2 6+11 3 Stato futuro 228 righe Rs1, Rs2, Rd - Indici di Rs1, Rs2 e Rd provengono da IR - IR25..0 sono portati ai bus S1 ed S2 del data path attraverso due buffer tristate IR25..0 U.d.C. \n32 bit dalla  memoria - U.d.C. genera anche i segnali di comando per la memoria (MEMRD e  MEMWR) Flag ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#24": "I passi dell’esecuzione delle istruzioni  Nel DLX l’esecuzione di tutte le istruzioni può essere scomposta in 5 passi, ciascuno eseguito in uno o più cicli di clock.   Tali passi sono detti:  1) FETCH:   l’istruzione viene prelevata dalla memoria e posta in IR.  2) DECODE: l’istruzione in IR viene decodificata e vengono prelevati gli   operandi sorgente dal Register File.   3) EXECUTE: elaborazione aritmetica o logica mediante la ALU.   4) MEMORY: accesso alla memoria e, nel caso di BRANCH aggiornamento   del PC (“branch completion”).   5) WRITE-BACK:   scrittura sul Register File. ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#25": "Le micro-operazioni eseguite  in ciascun passo  1) FETCH MAR   ß PC ;   ß  M[MAR]; 2) DECODE A  ß RS1, B  ß RS2,  PC  ß PC+4 IR   ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#26": "Le micro-operazioni eseguite  in ciascun passo  MEMORIA: MDR   ß   B;        ALU:   BRANCH: 3) EXECUTE MAR      A + (IR15)16 ## IR15..0 ; ß C  <- A op B (oppure A op (IR15)16 ## IR15..0) ; Temp       PC + (IR15)16 ## IR15..0) ; (utilizza ALU, S1, S2, dest: qui non si sa       ancora se si deve saltare) ß (utilizzano ALU, S1, S2, dest)  C <-  sign( A op B (oppure A op (IR15)16 ## IR15..0));  se SCn (NB: serve nelle Store  ove RD=RS2 operazione non significativa nelle LOAD)  J e JAL  Temp       PC + (IR25)6 ## IR25..0) ;  ß JR e JALR Temp       A;  ß ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#27": "Le micro-operazioni eseguite  in ciascun passo  4) MEMORY MDR   ß M[MAR];  (LOAD) ß  MDR;    (STORE)  BRANCH: M[MAR]  If (Cond)      PC       Temp; ß Memoria: \n[A] è il registro che condiziona il salto (Cond) ; JAL e JALR: C       PC; ß ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#28": "5) WRITE-BACK RD  ß C ; C ß MDR; (se è una LOAD – due micropassi)) Le micro-operazioni eseguite  in ciascun passo  \nPC       Temp; ß  istruzioni J, JR, JAL, JALR  istruzioni diverse da J, JR, JAL, JALR RD  ß C ; ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#3": "Register file C A B Struttura del DLX (esecuzione sequenziale)  \nTEMP IAR PC S1 S2 dest alu \nCPU Memoria dati in scrittura dati/istruzioni in lettura Indirizzi Instruction register C O N T R O L U N I T \nfetch MDR MAR execute Parallelismo dell’architettura: 32 bit (bus, alu e registri hanno parallelismo 32) I segnali di controllo non sono riportati !  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#4": "I registri del DLX (tutti a 32 bit)  • Register f i l e: 32 General Purpose Registers R 0 … . R 3 1  con  R0=0 • IAR: Interrupt Address Register –  D e p o s i t o  dell’indirizzo di ritorno in caso di interruzione • PC: Program Counter • MAR: Memory Address Register –  C o n t i e n e  l’indirizzo  del dato da scrivere o leggere in memoria • IR: Instruction Register –  C o n t i e n e  l’istruzione  attualmente in esecuzione • TEMP: Temporary Register –  R e g i s t r o  d i  d e p o s i t o  temporaneo di risultati  • MDR: Memory Data Register –  R e g i s t r o  d i  t r a n s i t o  temporaneo dei dati da e per la memoria • A e B: Registri di uscita dal Register File A parte il Register File questi registri NON sono accessibili  al programmatore. In alcuni casi istruzioni speciali per  accedere ad alcuni (e.g., IAR) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#5": "Funzioni della ALU       Dest (uscite) – 4 bit di comando  S1 + S2 S1 – S2 S1 and S2 S1 or S2 S1 exor S2 Shift S1 a sinistra di S2 posizioni Shift S1 a destra di S2 posizioni Shfit S1 aritmetico a destra di S2 posizioni S1 S2 0 1   Flag di uscita  Zero Segno negativo Carry \n• La ALU è una rete PURAMENTE combinatoria • Non esiste nel DLX un registro di flag ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#6": "Trasferimento dati sul datapath • I bus S1 ed S2 sono multiplexati (tri-state) con parallelismo 32 bit. • I registri campionano sul fronte positivo del clock, hanno due porte di uscita O1 e O2 per i due bus (o i registri A e B) e dispongono di tre ingressi di controllo:  – un ingresso di Write Enable (WE*)  ed  uno di Output Enable per ogni porta di uscita, una per ogni bus S1 e S2 (OE1* e OE2*). • Al fine di valutare la massima frequenza a cui è possibile far funzionare il datapath è importante conoscere le seguenti temporizzazioni: – TC (max) : ritardo max tra il fronte positivo del clock e l’istante in cui i  segnali di controllo generati dall’unità di controllo sono validi; – TOE (max): ritardo max tra l’arrivo del segnale OE e l’istante in cui i dati del registro sono disponibili sul bus; – TALU (max): ritardo massimo introdotto dalla ALU; – TSU (min)  : tempo di set-up minimo dei registri (requisito minimo per il corretto campionamento da parte dei registri).  • La massima frequenza di funzionamento del data path si calcola come segue:      fCK(max) = 1/TCK TCK  > TC (max) + TOE (max) + TALU (max) + TSU (min) ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#7": "Esempio : esecuzione della microistruzione  Rin ← Rout  S2 \nalu WE*  OE1* OE2* WE* OE1* OE2* S1 Rout Rin dest clock O2 O1 O2 O1 I I i1 i2 u = i2 WERin* OE2Rout* I segnali in blu (segnali di controllo) provengono dall’Unità di Controllo \nI segnali di controllo in grassetto sono attivi nel ciclo di clock in cui il micro-step Rin ← Rout viene eseguito  (e.g. TEMP) (e.g. MAR) Clock sempre collegato:  write enable !  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#8": "Il progetto dell’Unità di Controllo  • Una volta definito il Set di Istruzioni e progettato il DATAPATH, il passo successivo del progetto di una CPU è il progetto dell’Unità di Controllo  (CONTROLLER). • Il CONTROLLER è una RSS: il suo funzionamento può essere specificato tramite un diagramma degli stati.  •  Il CONTROLLER (come tutte le RSS) permane in un determinato stato per un ciclo di clock e transita (può transitare) da uno stato all’altro in corrispondenza degli istanti di sincronismo (fronti del clock).  •  Ad ogni stato corrisponde quindi un ciclo di clock.  Le micro-operazioni che devono essere eseguite in quel ciclo di clock sono specificate (in linguaggio RTL) nel diagramma degli stati che descrive il funzionamento del CONTROLLER all’interno degli stati. •  A partire dalla descrizione RTL si sintetizzano poi i segnali di controllo che  devono essere inviati al DATAPATH per eseguire le operazioni elementari  associate ad ogni stato.   ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\07_DLX_sequenziale.pdf#9": "Il diagramma  degli  stati del  controller  Data transfer ALU Set Jump Branch Ready ?  IR <- M [MAR] INSTRUCTION  FETCH INSTRUCTION  DECODE* MAR <- PC  \n PC<- PC+4 A <- RS1 B <- RS2 Oltre a decodificare l’istruzione si prelevano  gli operandi sorgente dal RF (anche se non utilizzati !) e si incrementa il PC.  Qui non si sa ancora quale sia l’istruzione ma il trasferimento ai registri è fatto  comunque !! N.B. I primi tre stadi sono comuni a tutte  le istruzioni  ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#0": "ISA DLX: implementazione pipelinedCalcolatori Elettronici TIngegneria Informatica\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#1": "Principio del PipeliningIl pipeliningè oggi la principale tecnica di base impiegata per rendere \u0002veloce\u0003una CPU . L\u0001idea alla base del pipeliningè generale, e trova applicazione in molteplici settori dell\u0001industria (linee di produzione, oleodotti …)Un sistema, S, deve eseguire Nvolte un\u0001attività A: A1 , A2 , A3…ANSR1 , R2 , R3…RNLatency: tempo che intercorre fra l\u0001inizio ed il completamentodell\u0001attività A(TA).Throughput: frequenza con cui vengono  completate le attività.",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#10": "Requisiti per l’implementazione in pipeline•Ogni stadio deve essere attivo in ogni ciclo di clock. •E\u0001necessario incrementare il PC in IF (invece che in ID).•E\u0001necessario introdurre un ADDER (PC <--PC+4 –PC <-PC+1) nello stadio IF.•Sono necessari due MDR (che chiameremo LMDR e SMDR) per gestire il caso di una LOAD seguita immediatamente da una STORE (WB-MEM sovrapposti –sovrapposizione di due dati in attesa di essere scritti, uno in memoria e l’altro nel RF). •In ogni ciclo di clock devono poter essere eseguiti 2 accessi alla memoria (IF, MEM): InstructionMemory (IM) e Data Memory (DM) ->  Architettura ‘Harvard’•Il clock della CPU è determinato dallo stadio più lento: IM, DM devono essere delle memorie cache(on-chip) •I Pipeline Registerstrasportano sia dati sia informazioni di controllo (l’unità di controllo è ‘distribuita’  fra gli stadi della pipeline)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#11": "GerarchiadellamemoriaL0 (registri CPU)L1L2L3Memoria (DDR)\nDiscoCosto/ByteTempo di accessoH\nLL\nHCPU ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#12": "13MemoriecacheCPUCacheMemoria (DDR)Una(opiùlivelli)memoriavelocemadiridottedimensioni,iecache,ingradodisfruttareilprincipiodilocalitàfannoapparirela(lenta)memoriaDDRmoltopiùveloce",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#13": "14\nArea di silicio occupata da cache L1,L2,L3 in un Intel Core i5Fonte: https://thecodeartist.blogspot.com/2011/12/why-readmostly-does-not-work-as-it.html",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#14": "IFIDEXMEMWBDatapath in Pipeline del DLX\nADD4MUX\nDATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBEstensionedel segnoNumero reg. dest.nel caso di LOADe ALU instr.JL (il PC in   R31)JLRPer il calcolo del nuovo PC nei salti\nPer le operazioni con immediatiRDDRS1RS2\nNumero del registro di destinazioneDatiPCIn realtà è un contatore programmabile  visto che i due bit meno significativi sono a 0se saltoContiene anche i circuiti di swapPer SCn(anche <0 e >0)[agisce sull\u0001uscita]\n=0?per BranchDurante JMP e BRANCH taken in IF/ID entra PC… Pazienza, sarà eliminata l’istruzione mediante NOP",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#15": "Stadiodi Fetch con contatore1/2\nCounter 30 bitENU[29..0]ClockSTALL*LDJUMPPC[31..2]I[29..0]JUMP_ADDRESS[31..2]\nSempre con riferimento allo stesso schema del DLX. Il segnale JUMPcodifica se il DLX deve saltare alla destinazione specificata daJUMP_ADDRESS[31.2]. Entrambi i segnali sono inviati dallo stadio MEM.Il segnale STALL, è generato dalla Unità di Controllo quando lostadio di IF deve essere bloccato. PC (to memory)ConriferimentoalprimoschemadelDLXpipelinedstudiatoduranteilcorso(maconsiderazionianaloghesiapplicanoallealtreversionidelDLX),lareteseguenteconsentedisostituireloschemabasatosuregistroemultiplexerconuncontatorea30bit(iduebitmenosignificatividell’indirizzosonosuperfluiperchéilDLXesegueilfetchsempreaindirizziallineati).PC +1 (to IF/ID)Come?",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#16": "REGISTER30 bitStadio di Fetch con contatore 2/2Un’osservazione: come possiamo generare PC + 1 per lo stadio IF/ID(quando viene eseguito il fetch a PC è necessario fare entrare nellapipeline (stadio IF/ID) PC +1 ?\nCKD[29..0]OUT[29..0]+1PC +1 (to IF/ID)\nPC  (to memory)Stato presenteStato futuro\nPC[31..2]",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#17": "Sezione IDIRRFSERDDRS1RS2IF/IDID/EX\nIR25-21IR20-16\nNumero registro destinaz.(dallo stadio WB) Dati (dallo stadio WB)(31-16) Immed./Branch(31-26)  JumpIR15IR25LBSWIR31-26 (Codop)IR15-0    (Offset/Immediato/Branch/Load -Reg. dest.)IR25-16   (J; JL))\nPC31-0    (JAL)PCAB26 (J e JL)\n61632323232\n32Info che viaggiacon l\u0001istruzioneIR10-00 (ExtCO)DEC\nEstensione segno",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#18": "Datapath in Pipeline del DLX ADD4MUX\nDMALUMUXMUXIMRFSEPCDEC\nMUXIF/IDID/EXEX/MEMMEM/WBIR1ABIR2PC2CONDX\nX: ALUOUPUT/DMAR/BTASMDRYLMDR\nY: ALUOUPUT1IFIDEX MEMWBPC1PC3PC4IndirizzoDatiIR3IR4n.  registro di destinazionePer SCn(anche <0 e >0)[agisce sull\u0001uscita]\n=0?=0?per BranchJLJLR(il PC in R31)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#19": "Esecuzione in pipeline di istruzione \u0002ALU\u0003\nX : \u0002ALUOUTPUT\u0003(in EX/MEM),  Y : \u0002ALUOUTPUT1\u0003NB in questa come nelle altre istruzioni RD (RS2) è trasferita fino allo stadio WBIFIDEXMEMY <-X (\u0002parcheggio\u0003in attesa di WB)WBRD <-YIR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4 A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;X <-A op BoppureX <-A op (IR215)16##IR215..0[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3]N.B. al passare degli stadi IRperde i bit che non servono più in tutte le istruzioni. Da uno stadio al successivo vengono mantenuti i bit che servono qualunque sia l\u0001istruzione",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#2": "Motore: 2000 ccTipo:BenzinaColore:Rosso\n",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#20": "Esecuzione in pipeline di istruzione \u0001MEM\u0002IFIDEXMEMLMDR <-M[MAR]  (LOAD)oppureM[MAR] <-SMDR  (STORE)WBRD <-LMDR   (LOAD)  [ext. Segno]IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4 A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;MAR <-A op (IR215)16##IR215..0SMDR <-B[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2[IR4  <.-IR3]",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#21": "Esecuzione in pipeline di istruzione \u0001BRANCH \u0002\nX : \u0001BTA (BRANCH TARGET ADDRESS)\u0002IFIDEXMEMif (Cond) PC <-XWB(NOP)IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;X <-PC2 op (IR15)16##IR15..0Cond <-A op 0[PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3Il test avviene sul valore del registro",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#22": "Esecuzione in pipeline di un\u0001istruzione \u0002JR\u0003IDMEMWBIFIDEXMEMPC <-XWB(NOP)IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-PC1; IR2<-IR1ID/EX <-Decodifica istruzione;;X <-A [PC4 <-PC3][PC3 <-PC2]La decod.ifica  attraversa  tutti gli stadi[IR3  <.-IR2][IR4  <.-IR3]\nCome sarebbe la sequenza degli stati per una J ?",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#23": "Esecuzione in pipeline di istruzione \u0001JL  o JLR\u0002IDIFIDEXMEMPC <-X ; PC4<-PC3WBR31 <-PC4IR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-P1; IR2<-IR1ID/EX <-Decodifica  istruzione;PC3 <-PC2X <-A (Se JLR)     X <-PC2 + (IR25)6##IR25..0(Se JL)\nNB: La scrittura in R31 NON può essere anticipata perché potrebbe sovrapporsi ad altra scrittura di registro Decod. in tutti gli stadi[IR4 <-IR3][IR3  <.-IR2]\nEvidenziati perché in questo caso utilizzati",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#24": "25Qual sarebbe la sequenza nel caso di SCN  (ex SLT R1,R2,R3) ?IDIFIDEXMEMWBIR <-M[PC] ; PC <-PC + 4 ; PC1 <-PC + 4A <-RS1; B <-RS2; PC2 <-P1; IR2<-IR1ID/EX <-Decodifica  istruzione;???",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#25": "Alee nelle Pipeline•AleeStrutturali-Unarisorsaècondivisafraduestadidellapipeline:leistruzionichesitrovanocorrentementeintalistadinonpossonoessereeseguitesimultaneamente.•AleediDato–Sonodovuteadipendenzefraleistruzioni.Adesempiounaistruzionecheleggeunregistroscrittodaun\u0001istruzioneprecedente(RAW).•AleediControllo–Leistruzionicheseguonounbranchdipendonodalrisultatodelbranch(taken/nottaken).Siverificaunasituazionedi\u0002Alea\u0003(\u0002Hazard\u0003)quandoinundeterminatociclodiclockun\u0001istruzionepresenteinunostadiodellapipelinenonpuòessereeseguitainquelclock.\nL\u0001istruzionechenonpuòessereeseguitavienebloccata(\u0002stallodellapipeline\u0003),insiemeatuttequellechelaseguono,mentreleistruzionichelaprecedonoavanzanonormalmente(cosìdarimuoverelacausadell\u0001alea).",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#26": "Clk 6Clk 7Clk 8Alee e Stalli\nIDIFIDEXMEMWBIi-3Ii-2Ii-1IiIDEXMEMIDEXIDIFIFIFIFIi+1Clk 1Clk 2Clk 3Clk 4Clk 5WBClk 9Clk 10Clk 11Clk 12WBWBT5=  8 * CLK = (5 + 3) * CLKT5= 5 * (1 + 3/5 ) * CLKCPI  idealeStalli per istruzioneTN= N *  1  * CLKTN= N *  (1 + S) * CLKCPI  effettivoSSSSSIFSMEMWBStallo: blocco del clock dello stadio e di tutti quelli precedentie propagazione progressiva agli stadi successiviEffetto–adesempio-diunaaleadidato:sel\u0001istruzioneIinecessitadiundatoprodottodallaistruzioneIi-1deveaspettarefinoalWBdellaIi-1",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#27": "IFIDEXMEMWBStalli nel salto (1/3)\nADD4MUX\nDATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2\nDatiPCse salto\n=0?NOPNOPNOPNOP forzate per salto\nAl primo fronte positivo del clock successivoal campionamento della  verifica della condizione di salto sono inserite 3 NOP al posto dei codici operativi provenienti dalla memoria",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#28": "IFIDEXMEMWBStalli nel salto (2/3)\nADD4MUX\nDATAMEMALUMUXMUX=0?INSTRMEMRFSEPCDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2\nDatiPCse salto\n=0?NOPNOPNOP forzate per salto\nAl primo fronte positivo del clock successivoalla verifica della condizione di salto sono inserite 2 NOP al posto dei codici operativi provenienti dalla memoriaNB In questo caso la condizione di salto e il nuovo PC sono presentatial MUX nello stesso periodo di produzione  della condizione",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#29": "IFIDEXMEMWBStalli nel salto (3/3)ADD4\nDATAMEMALUMUXMUX=0?INSTRMEMRFSEDECMUXIF/IDID/EXEX/MEMMEM/WBRDDRS1RS2\nDatiPCse salto\n=0?NOPNOP per salto\nAl primo fronte positivo del clock successivoalla produzione della verifica della condizione di salto e inserita una NOP al posto del codice operativo proveniente dalla stadio IF/IDNB In questo caso la condizione di salto e il nuovo PC agisconosul MUX nello stesso periodo di produzione  della condizione\nPCMUX",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#3": "Motore: 2000 ccTipo:BenzinaColore:Rosso\nMotore: 2000 ccTipo:BenzinaColore:Rosso\nMotore: 2000 ccTipo:BenzinaColore:Rosso\nMotore: 2000 ccTipo:BenzinaColore:Rosso\nMotore: 2000 ccTipo:BenzinaColore:Rosso\nt",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#30": "ForwardingADD  R3, R1, R4Clk 6Clk 7Clk 8MEMWBIFIDEXMEMWBIDEXMEMIDEXIDIFIFIFIFClk 1Clk 2Clk 3Clk 4Clk 5WBEXMEMIDEXClk 9MEMWBWBIDIDIDIl forwardingconsente di eliminare quasi tutte le alee di tipo RAW dellapipeline del DLX senza stallarela pipeline. (NB: nel DLX si alteranoi registri  soloin WB)SUB  R7, R3, R5 aleaOR  R1, R3, R5 aleaLW  R6, 100 (R3) aleaAND R9, R5, R3  no aleaAnche qui il dato non è ancora in RF per essere estratto in ID !",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#31": "Implementazione del ForwardingFU\nEX/MEMMUXMEM/WBALUMUXID/EXMUXMUXRS1/RS2CODOPRD2/CodOpRD1 (registro di destinazione/CodOpConfronto fraRS1, RS2 e RD1, RD2 e i cod. Op.RFMUX\nSpesso realizzato all\u0001interno del RFOppure SPLIT-CYCLE(v. dopo)scrittura prima di lettura\nPermette di \u0002anticipare\u0003il registro su ID/EXControllo MUX: codice operativo IF/ID e confronto RD con RS1 e RS2 IF/IDFU –> Forwarding Unit",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#32": "33Split-cycleT\nIn questo semiperiodo si scriveil registroIn questo semiperiodo si leggeil registro",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#33": "34Alea di dato dovuta alle istruzioni di LOAD\nN.B.ildatorichiestodallaADDèpresentesoloallafinediMEM.L\u0001aleanonpuòessereeliminataconilforwarding(amenodinonaprireunaulteriorediingressoaimuxdellaALUdallamemoria–ritardi!)ADD  R4,R1,R7 SUB  R5,R1,R8AND  R6,R1,R7LW    R1,32(R6)MEMWBIFIDEXMEMIFIDEXIFIDIFIDEX\nLW     R1,32(R6)ADD  R4,R1,R7 SUB  R5,R1,R8AND  R6,R1,R7IFIDEXMEMWBIFIDSEXMEMIFSIDEXSIFIDE\u0001necessario stallare lapipelineDi fatto non viene generato il clock. Il blocco di un  clock si propaga lungo  la pipeline uno stadio alla volta. Dalla fine di questo stadio in poi normale forwarding",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#34": "Delayed loadIn diverse CPU RISC l\u0001alea associata alla LOAD non è gestita in HW stallando la pipeline ma è gestita via SW dal compilatore (delayed load): Istruzione LOADdelay slotIstruzione SuccessivaIl compilatore cercadi riempire il delay-slotcon un\u0001istruzione \u0002utile\u0003(caso peggiore: NOP).LW     R1,32(R6)LW     R3,10 (R4)ADD   R5,R1,R3LW     R6, 20 (R7)LW     R8, 40(R9)LW     R1,32(R6)LW     R3,10 (R4)ADD   R5,R1,R3LW     R6, 20 (R7)LW     R8, 40(R9)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#35": "36Alee di Controllo\nBEQZ R4, 200PCBEQZ R4, 200PC+4SUB  R7, R3, R5PC+8OR   R1, R3, R5PC+12LW   R6, 100 (R8)PC+4+200AND R9, R5, R3(BTA)Next InstructionAddressR4 = 0 :    Branch Target Address(taken)R4 ¹0 :   PC+4(not taken)Clk 6Clk 7Clk 8IFIDEXMEMWBIDIDClk 1Clk 2Clk 3Clk 4Clk 5MEMWBEXMEMEXIFIFWBIDIDIDIFEXWBIDMEMFetch connuovo PCNuovo valore PC calcolato (Aluout)SUB R7, R3, R5OR R1, R3, R5LW R6, 100 (R8)Nuovo valore in PC (un clock dopo)  \nIDIFEXWBIDMEM",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#36": "ADD4\nIMRFSEPCDECInstruction FetchInstruction DecodeExecuteMemoryWriteBack\nIF/IDID/EXALUMUXEX/MEMMUXMUXDatapath in Pipeline del DLX  (caso 1/3) -(Branch o JMP)BEQZ R4, 200\nMUXDMMEM/WBNel momento in cui il nuovo PC agisce sulla IM treistruzioni hanno eseguito i primi trestadi (fino a EXincluso)=0?=0?",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#37": "Gestione delle Alee di ControlloBEQZ R4,200Clk 6Clk 7Clk 8IFIDEXMEMWBClk 1Clk 2Clk 3Clk 4Clk 5SSIFSFetch at new PC•Always Stall (blocco di tre clock che si propaga)\nHyp.:  Freq.Branch = 25 %CPI = (1 + S) = ( 1 + 3 * 0.25) = 1.75•Predict Not TakenIFIDEXMEMWBIDIDIDBEQZ R4, 200SUB R7, R3, R5OR R1, R3, R5LW R6, 100 (R8)Clk 6Clk 7Clk 8Clk 1Clk 2Clk 3Clk 4Clk 5MEMWBEXMEMEXIFIFIFWBEXWBIDIDIDMEMBranch CompletionFlush:diventanoNOPNOP           NOP           NOP           IF–maquil\u0001istruzioneprecedentenonancoradecodificataSIFIFIDSSituazione realeIF ripetuto PC <-PC -4Qui il nuovo valoreè campionato dal PC\nNessun danno: nessuna istruzione ha effettuato WB !",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#38": "Delayed branchSimilmentealcasodellaLOAD,indiverseCPUditipoRISCl\u0001aleaassociataalleistruzionidiBRANCHègestitaviaSWdalcompilatore(delayedbranch):Istruzione BRANCHdelay slotIstruzione SuccessivaIl compilatore cercadi riempire i delay-slotcon istruzioni \u0002utili\u0003(caso peggiore: NOP).delay slotdelay slot",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#39": "Delayed branch/jumpAdd  R5, R4, R3Sub   R6, R5, R2Or     R14, R6, R21Sne   R1, R8, R9; condizione di branchBr     R1, +100Sne   R1, R8, R9; condizione di branchBr     R1, +100Add  R5, R4, R3Sub   R6, R5, R2Or     R14, R6, R21CompilatoOriginale\nEseguite inentrambi i casiOvviamente in questo gruppo  non debbono esserci salti !!!!Al posto di una o più istruzioni \u0001posposte\u0002il compilatore mette delle NOP in caso non riesca a trovarne di adatte",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#4": "•Latenza: 5 fasi(clock)•Throughput: a regime, dopo5 fasi(clock), un’automobileper fase(clock)",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#40": "Gestione delle Alee di Controllo con BTBDynamic Prediction: Branch Target Buffer -> nessuno stallo (quasi)T/NTTAGSPredicted PCPC=HIT:  Fetch a PC  predettoMISS: Fetch a  PC + 4Predizione Corretta :    0 stalli Predizione Errata :       da 1 a 3 stalli  (fetch corretto in  ID o EX   v. precedentemente)N.B.  Qui il branch è individuato durante il periodo del clock IF che carica IR1 in IF/ID",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#41": "Buffer di predizione: caso più semplice un bit che  indica cosa è successo l'ultima volta.\nIn presenza di preponderanza di un caso quando si verifica il caso opposto si hannodueerrorisuccessivi.Loop1Loop2Quando esce da loop2 sbaglia (predetto takenma in realtà untaken) ma sbagli ancora quando predice untakenrientrando nuovamente in loop2 a causa di  loop1 ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#42": "Normalmente duebits.TAKENTAKEN\nUNTAKENUNTAKENTAKENUNTAKENTAKENUNTAKENTAKENTAKEN\nUNTAKENUNTAKEN",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#43": "Esempio, molto frequente, di loop annidato:for (i=0; i<5000; i++)for (j=0; j<1000; j++}{x[i,j] = i*j + i + j;...... }",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#5": "Principio del Pipelining1) Sistema Sequenziale A2A3tANA1TALatency(tempo di esecuzione di una istruzione)= TAThroughput=1TA2) Sistema in Pipeline\nSAP1P2P3P4tS1S2S3S4Si: pipeline stage",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#6": "Principio del PipeliningP1TPP2P1A2P2P3P1A3tA1\nSS1S2S3S4P4P3P2P1A4P4P3P4P2P3P4AnLatency(2)= 4 *TP = TAThroughput(2)@1TP4TA==4 * Throughput(1)TP : pipeline cycle ",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#7": "Pipeliningin una CPU (DLX)Attività:    A1 , A2 , A3…ANIstruzioni:    I1 , I2 , I3…INIEXIDtMEMWBIF\nCPI=1 (idealmente !)IF/IDID/EXEX/MEMMEM/WBCPU (datapath)IFIDEXMEMWBPipeline CycleClock CycleRitardo dello stadio piùlentoRegistri(Pipeline)Registers)ReticombinatorieN.B. architettura TOTALMENTEdiversa !!!!!",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#8": "Pipeline del DLXInstr iInstr i+1Instr i+2Instr i+3Instr i+4IFIDEXMEMWB\nTclk=  Td  +  TP+  TsuClock CycleCPI (ideale)  = 1\nOverhead introdotto dai Pipeline Registers:Ritardo registroa monteSet-up registro a valleRitardo stadio combinatorio più lentoIFIDEXMEMWBIFIDEXMEMWBIFIDEXMEMWBIFIDEXMEMWBt",
    "data_test\\rootfolder\\università\\CalcolatoriElettronici\\08_DLX_pipelined.pdf#9": "DDRCTp",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#0": "Machine Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nDeep Learning: Introduzione\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#1": "Sommario\nInformazioni sul corso  \nProgramma, testi consigliati, precondizioni  \nSoftware tools  \nCos'è il deep learning  \nRepresentation learning  \nAutoencoders  \nFactors of variation  \nApprocci di IA ed evoluzione delle architetture  \nCurse dimensionality  \nLocal constancy & smoothness regularization  \nLibreria D2L",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#10": "Google Colaboratory (o Colab)  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#11": "Google Colaboratory (o Colab)  \nGPUs includes Tesla \n P100\n  (used in Colab), Tesla \n V100\n  (equipped in \nAmazon EC2 P3 instance), and Tesla \n T4\n (equipped in Amazon EC2 \nG4 instance). \n TPUs\n  are tensor processing units developed by Google \nto accelerate operations on a Tensor\n ﬂ\now Graph. Each TPU packs up \nto 180 tera\n ﬂ\nops of \n ﬂ\noating-point performance and 64 GB of high-\nbandwidth memory onto a single board.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#12": "Cos'è il Deep Learning\nIl \nmachine learning\n  riguarda tecnologie capaci di acquisire conoscenza \nrelativamente all'ambiente di interesse allo scopo di risolvere problemi in \nmodo automatizzato, cioè senza l'intervento dell'utente.  \nPer problemi complessi occorre rappresentare la conoscenza come \nconcetti su vari livelli di astrazione, creando dipendenze tra gli stessi, in \nmodo simile a come avviene nella mente umana.  \nDa queste strutture deriva il termine \n deep learning\n . \nStoricamente i computer sono stati impiegati per rappresentare conoscenza \nformale (es. regole per giocare a scacchi) su cui implementare meccanismi \ndi \nreasoning\n  (es. regole logiche) mentre è stato più dif\n ﬁ\ncile rappresentare la \nconoscenza informale.  \nEsempio: Cyc inference engine e \"Fred shaving in the morning\"\n13",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#13": "Representation learning (1)\nSuccessivamente sono state introdotte tecniche di machine learning per \nacquisire la conoscenza (\n know-how\n ) estraendo \n patterns\n  dai dati in modo \nautomatico, es. logistic regression e naive Bayes.  \nLe prestazioni di tali approcci dipendono dalla scelta con cui i dati sono \nrappresentati. È importanti scegliere le informazioni più rilevanti (\n features\n ) \nper il task che si intende risolvere (approccio \n hand-designed\n ). \nLXI + XCIX = ?  \nPer alcuni task de\n ﬁ\nnire una rappresentazione dei task è arduo.  \nEs. identi\n ﬁ\ncare un auto potrebbe ridursi al task di riconoscere le ruote; \ncome puoi farlo a partire da una rappresentazione a pixel?  \nA differenza del hand-designed, il \n representation learning\n  introduce un \nsotto-task nel processo di ML che mira a riconoscere le feature più rilevanti \nin modo automatico. \n14",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#14": "Representation learning (2)\nIdenti\n ﬁ\ncare le features in modo automatico garantisce vantaggi:  \nL'approccio hand-designed è lungo e richiede risorse  \nSi può facilmente adattare l'addestramento a nuovi tasks\n15",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#15": "Autoencoders\nGli \nautoencoders\n  sono composti da un \n encoder\n  e un \n decoder\n . Il primo \nconverte l'input in una rappresentazione compatta, cioè con \ndimensionalità ridotta,, il decoder mira a ricostruire l'input originale da tale \nrappresentazione.  \nL'addestramento degli autoencoders crea uno \n spazio \n che mira a \nrappresentare solo le features salienti necessarie per identi\n ﬁ\ncare una certa \nistanza, tralasciando informazioni non utili.  \nNel corso vedremo diversi tipi di autoencoders. Le \n Generative Adversarial \nNetwork (GAN)\n  impiegano tali tecnologie.\n16",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#16": "Factors of variation\nLe features identi\n ﬁ\ncate con un approccio hand-designed, oppure \nriconosciute in modo automatico durante il learning, devono saper \ndistinguere i \n fattori di variazione\n . \nSono spesso considerati degli elementi astratti (non misurabili) che \nin\nﬂ\nuenzano il modo in cui le istanze vengono viste dagli approcci di ML. \nSe identi\n ﬁ\ncati ci permettono di capire meglio la grande variabilità di \nistanze in certi domini.  \nAd esempio, età, sesso, un certo accento possono in\n ﬂ\nuenzare le parole \npronunciate da una certa persona in un task di speech-recognition. \nOsservando un automobile, la posizione, il colore, l'angolo di incidenza \ndei raggi solari sono altri tipici fattori per l'analisi di una immagine.  \nSe riusciamo a riconoscerli e ignorarli durante il processamento saremmo \nin grado di sempli\n ﬁ\ncare molti task di ML.\n17",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#17": "Esercizio\nProva a identi\n ﬁ\ncare un ulteriore task adatto ad un approccio di ML, ed \nelenca qualche fattore di variazione. \n18",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#18": "Deep Learning\nIl Deep learning segue un approccio di \n representation learning\n , dove certe \nrappresentazioni sono espresse mediante altre più semplici, es., l'immagine \ndi un uomo viene composta da angoli e contorni, che a sua volta sono \nrappresentati con piccoli segmenti.  \nUn esempio di una architettura Deep, il \n multilayer perception:\n19\nImmagine tratta da Zeiler and Fergus (2014).",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#19": "Schema sempli\n ﬁ\ncato approcci di IA\nI box scuri includono fasi esplicite di apprendimento.\n20\n",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#2": "Il corso\nL'obiettivo del \n corso di Deep Learning (DL)\n  di 6 CFU è fornire competenze \navanzate e speci\n ﬁ\nche nell'ambito delle architetture di reti neurali Deep.  \nIl corso è strutturato in una parte teorica e \n metodologica\n  sui concetti \nfondamentali, e da una \n attività di programmazione \n in cui tali concetti sono \napplicati nella risoluzione di problemi mediante recenti framework di \nsviluppo (Keras & PyTorch).  \nAl termine del corso lo studente sarà in grado di:  \naddestrare e ottimizzare in maniera adeguata reti neurali Deep;  \nsaper distinguere tra diverse soluzioni, e saper selezionare e \npersonalizzare le architetture di reti più ef\n ﬁ\ncaci da utilizzare in ambiti \napplicativi reali, supervised, unsupervised o seguendo un approccio \nbasato su un apprendimento per rinforzo.  \nIl corso prevede lo svolgimento di progetti.\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#20": "Evoluzione delle architetture\nOgni 2,4 anni il numero di neuroni nascosti è all'incirca raddoppiato.\n21\n",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#21": "I.A. & Big Data: il contesto attuale\n2222\n\u0000\n\u0000\u0000Large amount of \nHuman -generated content\nPosizione GPS, “mi piace”, precedenti \nacquisiti, immagini sui social.\nInfrastructures\nCloud computing, GPU -enabled \ninfrastructure\nEU GDPR \npersonal information as \neconomic assetAI-enabled frameworks\nRecommender systems, Speech and Text \nprocessing, Video and Image analysis\nOligopoly on data\nPoche imprese possiedono \ngrandi quantità di dati sull’utente.\nAI-based interpretation of content\nby natural language processing, personality \ntraits, object recognition, etc.AI & Big Data\nLa distribuzione traintelligenza artificiale , e-commerce e abitudini di consumo -12 aprile 2018 Fabio Gasparetti",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#22": "Curse of dimensionality\nNei corsi di I.A. e M.L. sono stati descritti numerosi algoritmi che si \nadattano facilmente i vari task. Ma solo pochi riescono ad affrontare \nproblemi centrali come riconoscere il parlato od oggetti arbitrari.  \nTali task causano il cosiddetto \n curse of dimensionality\n : il numero di \npotenziali con\n ﬁ\ngurazioni di variabili di ingresso cresce in modo \nesponenziali col numero di variabili considerate.  \nNe segue: istanze di training << # potenziali con\n ﬁ\ngurazioni \n23\nIncrementando il numero di dimensioni (da 1d a 3d) il \nnumero di regioni di interesse (box colorati) incrementa, \ne abbiamo necessità di un numero elevato di istanze per \ncaratterizzarne ognuna.",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#23": "Local constancy & Smoothness regularization\nImponiamo che la distribuzione di probabilità a priori, che in\n ﬂ\nuenza i \nparametri ma anche la funzione che stiamo cercando di stimare, sia \nsmoothness prior\n  o \nlocal constancy prior\n . \nSotto questa assunzione, se l'output di una funzione è OK per una certa \nistanza \n x\n, allora l'output è buono anche per istanze vicine ad \n x\n: \nEsempio\n : algoritmo di \n k\n-nearest neighbors.  \nPer dimensionalità elevate, una funzione smooth potrebbe cambiare (in \nmodo smooth) in modo diverso a seconda della dimensione. Occorrono \nmolte istanze di training per caratterizzarle.  \nIl deep learning introduce dipendenze tra le regioni di interesse (cioè nelle \ndistribuzioni dei dati) per ridurre il numero di istanze necessarie. \n24\n",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#24": "La libreria D2L\nDurante il corso faremo uso di una libreria Python di supporto chiamata \nD2L.ai  \nLa libreria d2l mette a disposizione alcune funzionalità per rendere il \ncodice più interpretabile e compatto.  \nVediamone alcuni esempi di impiego:  \n01-d2l_3.2.ipynb  \n02-d2l_regressione_3.3.ipynb\n25",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#3": "Il programma\n4\n",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#4": "Testi consigliati e altri riferimenti\n• I. Goodfellow, Y. Bengio, and A. Courville, \"Deep Learning\", MIT Press, \n2016.  \n• A. Zhang, Z. C. Lipton, M. Li, and A. J. Smola, \"Dive into Deep Learning\", \n2020 (free online).  \n• A. Geron, “Hands-on Machine Learning with Scikit-Learn, Keras, and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems”, \nO'Reilly Media, Inc, USA, 2019.  \n• M. Nielsen, \"Neural Networks and Deep Learning\", 2019 (free online).  \nAltri riferimenti a codice, tutorial, e altre fonti saranno dati durante il corso.\n5",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#5": "Precondizioni\nLe seguenti lezioni del corso di Machine Learning sono requisiti per il \ncorso di DL:  \nIntroduzione alla Regressione  \nLa Valutazione nella Regressione  \nOver\n ﬁ\ntting, Cross Validation  \nIntroduzione alle Reti Neurali Arti\n ﬁ\nciali (es. algoritmo di \nbackpropagation)  \nSebbene alcuni dei concetti saranno ripresi per introdurre i formalismi \nnecessari al resto del corso.\n6",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#6": "Software Tools\nDocker  \nhttps://www.docker.com/community-edition#/download  \nJupyter Notebook Scienti\n ﬁ\nc Python Stack + Tensor\n ﬂ\now + Tensorboard  \nhttps://github.com/lspvic/jupyter_tensorboard  \ndocker pull lspvic/tensorboard-noteboo\n k\ndocker run -it --rm -p 8888:8888 lspvic/tensorboard-noteboo\n k\nDocker Engine Utility for NVIDIA GPUs  \nhttps://github.com/NVIDIA/nvidia-docker   \nAnaconda + Tensor\n ﬂ\now \nhttps://docs.anaconda.com/anaconda/user-guide/tasks/tensor\n ﬂ\now/ \n",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#7": "Jupiter\nhttps://jupyter.readthedocs.io/en/latest/  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#8": "Google Colaboratory (o Colab)  \nServizio di calcolo online basato su Nvidia Tesla T4 GPUs  \n12 GB of RAM  \nﬁ\nno a 12 ore di seguito  \nSupporto multi-ambiente: TensorFlow, Keras, PyTorch, e OpenCV.  \nMolti dataset disponibili nell'ambiente  \nhttps://www.tensor\n ﬂ\now.org/datasets/catalog/overview   \nInterfaccia Jupyter ben nota.  \nDefault: Runtime Python 3 e nessun acceleratore hardware.  \nMenu Runtime -> Change runtime type  \nPossibilità di trasferire l’esecuzione in locale (per elaborazioni molto \nlunghe)  \nhttps://research.google.com/colaboratory/local-runtimes.html  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\01-Introduzione-sbloccato.pdf#9": "Google Colaboratory (o Colab)  \nAcceleratore: GPU\n",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nMultilayer Perceptrons, One-hot encoding e Softmax\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#1": "Sommario\nMonotonicità  \nMLP e Hidden layers  \nNon linearità  \nFunzioni di attivazione  \nDatasets  \nMLP e Tensor\n ﬂ\now \nDa regressione lineare a classi\n ﬁ\ncazione  \nFunziona softmax  \nOne-hot encoding e misure di distanza",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#10": "Alcuni toy datasets \nElenchiamo alcuni dataset che vengono spesso impiegati negli approcci di \nML e DL:  \nMNIST  \nnotMNIST  \nfashion-MNIST  \nDataset più complessi saranno introdotti più avanti. \n11",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#11": "Dataset MNIST\nComposto da cifre numeriche, usato per addestrare sistemi OCR.  \n\"If it doesn't work on MNIST, it won't work at all”; \"Well, if it does work on \nMNIST, it may still fail on others.\"  \nContiene 60K immagini di addestramento e 10K di training.  \n1998: un linear classi\n ﬁ\ner ha ottenuto 7.6% di errore rate.  \n2012: per mezzo di una architettura DL (convolutional neural networks) si è \narrivati al 0.23%.  \nOgni immagine è rappresentata in scala di grigi (256 livelli). Le cifre sono \ncentrate in un box 28x28 pixel: abbiamo 784 valori in [0-255] per rappresentare \nuna cifra.  \nhttp://yann.lecun.com/exdb/mnist/  \nhttps://www.kaggle.com/c/digit-recognizer/data   \nImplementazione online JS (ott’17) \n http://myselph.de/neuralNet.html\n12",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#12": "Dataset MNIST: train.csv e test.csv\nIl \nﬁ\nle train.csv contiene una matrice con 785 colonne. La prima colonna è il \nlabel\n della cifra (es. 3) e le restanti colonne sono la rappresentazione \nsequenziale dell’immagine:  \nIl \nﬁ\nle test.csv ha la stessa rappresentazione senza la prima colonna.  \nEsempio di immagini:\n13\n",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#13": "Dataset MNIST - svantaggi\nTroppo semplice: algoritmi classici di ML raggiungono i 97% di precisione, \narchitetture DL il 99.7%  \nSi rischia di ideare nuove architetture adatte solo per questo dataset e \ndif\nﬁ\ncilmente adattabili in altri contesti.  \nMolto diverso dai task studiati attualmente nell’ambito del DL.\n14",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#14": "Dataset notMNIST\nSimile a MNIST: contiene 10 labels (lettere da A a J), ma ogni lettera nel \ndataset ha un font molto diverso dalle altre, es.:  \nhttp://yaroslavvb.blogspot.\n ﬁ\n/2011/09/notmnist-dataset.html   \nDownload \n http://yaroslavvb.com/upload/notMNIST/  \nnotMNIST_large.tar.gz -> training e validazione  \nnotMNIST_small.tar.gz -> test \n15\n",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#15": "Dataset fashion-MNIST\nFornito da Zalando: 10 classi che fanno riferimento a generi di vestiario (es. \nsandali, t-shirt, borse, etc).  \nContiene 60K immagini di addestramento e 10K di training.  \nOgni immagine è rappresentata in scala di grigi di 28x28 pixel  \nhttps://github.com/zalandoresearch/fashion-mnist   \nSide-by-side accuracy MNIST vs fashion MNIST:  \nhttp://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#\n16\n",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#16": "Altri dataset popolari sulle immagini\nCIFAR-10 (e 100)\n : 60K 32x32 colour images in 10 classes.  \nImageNet\n : 1,5 milioni di immagini organizzate etichettate su WordNet. In \nmedia 1K immagini per concetto.  \nILSVRC2012 task 1\n : 10 milioni di immagini e +1K classi.  \nOpen Image\n : 9 milioni di URLs di immagini annotate con bounding boxes e \nmigliaia di classi.  \nVisualQA\n : open-ended questions su 265K immagini. In media 5.4 questions \nper immagini con 10 ground truth answers per question.  \nThe Street View House Numbers\n : 600K immagini di numeri civici.  \nRisultati sperimentali ottenuti per varie architetture  \nhttp://rodrigob.github.io/are_we_there_yet/build/#datasets  \n17",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#17": "MLP e Tensor\n ﬂ\now\nProviamo a costruire una MLP con Tensor\n ﬂ\now (Keras).  \nCoalb 04-mlp_5.2.1.ipynb\n18",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#18": "Da regressione lineare a classi\n ﬁ\ncazione\nNei problemi di regressione rispondiamo a domande del tipo \"\n Quale \nquantità o valore?\n \". Ma molti problemi mirano a trovare una classe di \nappartenenza,  \nes. è una email di spam? è più probabile che un utente si iscriva ad un \nabbonamento oppure no?  \nCi può interessare la classe più verosimile (\n hard assignements\n ), oppure la \ndistribuzione di probabilità sulle classi possibili (\n soft assignements\n ), o siamo \nin presenza di più classi di appartenenza (\n multi-label classi\n ﬁ\ncation\n ). \nIn caso di più valori in output (es. un layer di output con più nodi), ogni \nvalore può essere interpretato come \n il grado di appartenenza dell'istanza in \ningresso ad una certa classe\n . La loss misura il discostamento tra classe attesa \ne valori prodotti dal modello. \n19",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#19": "Classi\n ﬁ\ncazione binaria\nSi ha interesse ad associare una istanza in input ad un valore in y\n ∈\n{0,1} \nSe usiamo un modello di regressione, estraiamo dall'istanza x features \nnumeriche e le combinano linearmente. Il risultato dipende dalle somme \ndei valori di input e dei parametri del modello.  \nAl risultato del modello applichiamo la funzione \n logistic\n , che restituisce un \nvalore in [0,1]. La funzione è facilmente differenziabile.  \nInterpretiamo tale valore come la probabilità di appartenenza ad una delle \ndue classi.  \nSi ottiene una \n logistic regression\n . \nVogliamo generallizzare la logistic regression al caso K classi, con K>2\n20!\"=\targmax!*(!|-)",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#2": "Motivazioni\nTale dispensa richiama in modo sommario molti concetti trattati nel corso di \nML con particolare attenzione ai concetti che interessano maggiormente lo \nsviluppo di architetture DL (architetture MLP).  \nSi rimanda al materiale del corso di ML per i dettagli\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#20": "Esempio  \nSupponiamo di avere 3 classi e l’output della combinazione lineare sia:  \nSebbene la classe più probabile sia associata all’indice 1, i valori non sono \ndirettamente interpretabili come distribuzioni di probabilità, infatti:  \nI valori non sono in in [0,1]  \nLa somma non è pari 1\n21y=2.0\n1.0\n0.1⎡\n⎣⎢\n⎢\n⎢⎤\n⎦⎥\n⎥\n⎥",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#21": "La funzione Softmax\nLa funzione \n softmax\n  prende in input un vettore in \n ℝ\nT\n e dà in output un \nvettore \n ℝ\nT  \nnell'intervallo (0,1] la cui somma è pari a 1. È de\n ﬁ\nnita: \nL'output può essere interpretato come distribuzione di probabilità su K \nclassi, a differenza di altri modelli (es. classi\n ﬁ\ncatore SVM).\n22S(yi)=eyi\neyj\njK\n∑",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#22": "Layer softmax nelle reti neurali\nLa funzione softmax è tipicamente applicata all’output di un layer fully-\nconnected, creando un nuovo layer chiamato \n softmax\n . \nIl seguente esempio rappresenta un singolo layer, con funzione di attivazione \nsoftmax su T classi.  \nNota\n : la funzione softmax introduce non linearità.\n23\ny s(y)",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#23": "Softmax in Keras\nIn Keras è semplice implementare il modello precedente con il parametro \nactivation\n  di layer Dense:  \n24\n",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#24": "One-hot encoding\nNel ML le rappresentazioni dell’input e output sono sottoinsiemi dei \ndomini \n ℕ\n e \nℝ\n. Tali insieme introducono implicitamente ordinamenti.  \nEs. se abbiamo 3 categorie (es. rosso=1, bianco=2 e nero=3) e gli \nassegniamo 3 numeri, introduciamo una relazione di ordinamento che \nnon esiste nei dati.  \nDurante l’addestramento tali relazioni possono essere considerate \npotenziali features, e di conseguenza apprese dall'algoritmo  \nEs. Le due istanze Rosso-Nero possono considerarsi più distanti rispetto \na Rosso-Bianco  \nLa rappresentazione \n one-hot\n  caratterizza ogni istanza con una \ncon\nﬁ\ngurazione univoca, costituita da una sequenza binaria di zero, tranne \nun solo elemento pari a 1.\n25",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#25": "One-hot encoding in Python\nColab 05_onehot.ipynb\n26",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#26": "Loss e one-hot encoding\nSe la \n softmax\n  genera una distribuzione di probabilità su K possibili, la \ncodi\nﬁ\nca one-hot genera una distribuzione che \"concentra\" tutta la densità di \nprobabilità sulle classi corrette, es.:  \n[0, …, 0, 1, 0 …, 0].  \nPer addestrare il modello occorre de\n ﬁ\nnire una misura di loss che tenga conto \ndella distanza tra le due distribuzioni.\n27",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#27": "Misura di Distanza: cross entropy\nPer confrontare due generici vettori \n p\n e \nq\n che rappresentano distribuzioni di \nprobabilità si impiega la misura \n cross entropy\n : \nDove \n x\n si estende su tutte i valori potenziali della variabile causale su cui \nsono de\n ﬁ\nnite le probabilità, cioè le classi in output.  \nAttenzione: la funzione H non è simmetrica:  \nSe uno dei parametri (\n p\n o \nq\n) è codi\n ﬁ\ncato one-hot, in che posizione conviene \naverlo?\n28H(p,q)≠H(q,p)H(p,q)=−p\nx∑ (x)⋅log\tq(x)",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#28": "Misura di Distanza: cross entropy\nNella fase di addestramento un parametro della cross entropy è l’output \ndella funzione softmax s(y), mentre il secondo è la codi\n ﬁ\nca one-hot che \nindica una o più classi di appartenenza.  \nSupponiamo di usare la codi\n ﬁ\nca one-hot per il calcolo dei logaritmi:  \nAnche il layer softmax può generare valori 0, ma è un problema raro e \nfacilmente risolvibile (es. aggiungendo un \n ε\n).\n29D(s(y),ˆy)=−s(y1)⋅log\t1.0+s(y2)⋅log\t0+s(y3)⋅log\t0 ( ) ˆy=1.0\n0.0\n0.0⎡\n⎣⎢\n⎢\n⎢⎤\n⎦⎥\n⎥\n⎥",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#29": "Multinomial logistic classi\n ﬁ\ncation\n30x=2.0\n0.7\n1.5\n...\n8.0⎡\n⎣⎢\n⎢\n⎢\n⎢\n⎢\n⎢⎤\n⎦⎥\n⎥\n⎥\n⎥\n⎥\n⎥S(y)=0.659\n0.242\n0.099⎡\n⎣⎢\n⎢\n⎢⎤\n⎦⎥\n⎥\n⎥y=2.0\n1.0\n0.1⎡\n⎣⎢\n⎢\n⎢⎤\n⎦⎥\n⎥\n⎥ˆy=1.0\n0.0\n0.0⎡\n⎣⎢\n⎢\n⎢⎤\n⎦⎥\n⎥\n⎥D(ˆy,S(y))Input\nLinear model Softmax Onehot rep.\nCross entropy distanceLabels",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#3": "Monotonicità\nLe architetture lineare impongono l'assunzione di \n monotonicità\n : \nl'incremento di una feature generare un incremento/decremento nel valore \nin output del modello, a seconda del valore dei pesi (o parametri).  \nPer certi task è verosimile, sebbene non sempre vero, ad esempio:  \nTask: \"\n un individuo sarà regolare con le rate del mutuo?\n \". Se il salario \npassa da 0K a 50K la probabilità che ripaghi il mutuo sarà molto diversa; \nmentre se il salario passa da 1M a 1,05M la probabilità non cambierà \nmolto.  \nTask: \"\n predire se un individuo è malato in base alla temperatura\n \".  \nT << 37 o T >> 37 indica una possibile patologia.  \nCome pensi si può risolvere il problema impiegando un algoritmo di \nregressione lineare?\n4",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#30": "Esercizio\nSupponiamo di avere 3 istanze di addestramento che consistono in varie \nfeatures (es. sex, age, etc) e vogliamo predire se un elettore voterà \ndemocratico o repubblicano con una rete neurale.  \nAvendo due reti che producono in output i seguenti valori:  \nCalcola l’errore impiegando: (1) cross entropy, (2) mean squared error, (3) \naccuratezza (binaria).\n31\n#1\n#2",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#31": "Confronto tra misure di loss\nCross entropy  \n#1: -(ln(0.4) + ln(0.4) + ln(0.1)) / 3 = 1.38  \n#2: -(ln(0.7) + ln(0.7) + ln(0.3)) / 3 = 0.64 (smaller)  \nMean squared error  \n#1: [(0.3 - 0)^2 + (0.3 - 0)^2 + (0.4 - 1)^2 + …] / 3  \n(0.54 + 0.54 + 1.34) / 3 = 0.81  \n#2: (0.14 + 0.14 + 0.74) / 3 = 0.34 (smaller)  \nAccuratezza (binaria)  \nEntrambi: classi\n ﬁ\ncation error 1/3 = 0.33, accuracy 2/3 = 0.67  \nNota\n : le implementazione delle misure discusse sono in \n sklearn.metrics  \n32",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#32": "Confronto tra misure di loss\nCross entropy  \n#1: 1.38  \n#2: 0.64 (migliore)  \nMean squared error  \n#1: 0.81  \n#2: 0.34 (migliore)  \nAccuratezza (binaria)  \nEntrambi: 0.67  \nRispetto alla cross entropy, MSE da molta importanza agli output sbagliati, \nma allo stesso tempo, se la rete si avvicina ai risultati corretti, i gradienti \ndiventano assai bassi, rallentando notevolmente la convergenza.\n33\n#1\n#2",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#4": "Monotonicità\nPer un task \"\n l'immagine contiene un cane\n ?\", come possiamo creare una \nrelazione tra un certo pixel è una classe in output?  \nL'assunzione di linearità ci impone un vincolo tra:  \nluminosità del pixel <-> classe di appartenenza;  \nignorando però il contesto (altri pixel) e la complesse relazioni tra essi che \nportano a rappresentare visivamente un oggetto.  \nInvece di de\n ﬁ\nnire una rappresentazione adeguata, impieghiamo reti neurali \nmultistrato\n , dove gli \n hidden layer\n  si occupano di riconoscere una \nrappresentazione adeguata dei dati in input, che viene impiegata da un \npredittore lineare per generare l'output. \n5",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#5": "Hidden layers e MLP\nL'approccio più semplice per aggiungere strati nascosti è \n impilarli\n  (stack) uno \ndopo l'altro, ottenendo L layers.  \nInterpretiamo gli L layer, tranne l'ultimo, come l'insieme di nodi impiegati \nper la rappresentazione, e l'ultimo come predittore lineare.  \nOtteniamo una architettura \n Multilayer perceptron (MLP)\n  fully connected.\n6\n",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#6": "Da lineare a non lineare\nIndichiamo con \n  un \nminibatch\n  (una sottoinsieme del dataset di \ntraining) di \n n\n istanze dove ogni istanza ha \n d\n features.  \nPer un hidden layer con \n h\n unità, indichiamo con \n  il relativo \noutput. Avendo layer fully connected, abbiamo come parametri:  \ni pesi \n   e i  bias \n  . \nIl layer di output avrà parametri:   \n    e    \nL'output è ricavato nel seguente modo:  \n \n \nSecondo te, combinando più funzioni af\n ﬁ\nni, siamo riusciti a introdurre non \nlinearità nel modello?\nX\n∈\nℝ\nn\n×\nd\nH\n∈\nℝ\nn\n×\nh\nW\n(\n1\n)\n∈\nℝ\nd\n×\nh\nb\n(\n1\n)\n∈\nℝ\n1\n×\nh\nW\n(\n2\n)\n∈\nℝ\nh\n×\nq\nb\n(\n2\n)\n∈\nℝ\n1\n×\nq\nH\n=\nX\nW\n(\n1\n)\n+\nb\n(\n1\n)\nO\n=\nH\nW\n(\n2\n)\n+\nb\n(\n2\n)\n7",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#7": "Da lineare a non lineare\nCombinando le equazioni viste in precedenza otteniamo un modello \nequivalente ad un singolo layer:  \n \nLa non linearità viene espressa mediante funzioni di attivazione \n  non \nlineari (es. ReLU) impiegate all'interno delle unità nascoste, a valle della \ntrasformazione af\n ﬁ\nne. \nFacendo \n stacking\n  di più hidden layer con funzioni non lineari, es:  \n \n \nsi ottengono architetture \n deep\n , che approssimano funzioni più complesse.\nO\n=\n(\nX\nW\n(\n1\n)\n+\nb\n(\n1\n)\n)\nW\n(\n2\n)\n+\nb\n(\n2\n)\n=\nX\nW\n(\n1\n)\nW\n(\n2\n)\n+\nb\n(\n1\n)\nW\n(\n2\n)\n+\nb\n(\n2\n)\n=\nX\nW\n+\nb\nσ\nH\n(\n1\n)\n=\nσ\n1\n(\nX\nW\n(\n1\n)\n+\nb\n(\n1\n)\n)\nH\n(\n2\n)\n=\nσ\n2\n(\nH\n(\n1\n)\nW\n(\n2\n)\n+\nb\n(\n2\n)\n)\n8",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#8": "Universal approximators\nCi si può chiedere quanta capacità rappresentativa (i.e. quanto è \n potente\n ) è \nespressa da una rete neurale.  \nAlcuni risultati suggeriscono che \n per\nﬁ\nno con un solo hidden layer\n  è possibile \napprossimare qualsiasi funzione con un numero adeguato di unità.  \nUna rete neurale deep può essere pensata come un programma in C,  \ncioè puoi risolvere qualsiasi problema software, ma i programmi possono \nraggiungere complessità molto elevate.  \nVedremo architetture di reti deep possono risolvere gli stessi task in modo \nmolto più ef\n ﬁ\nciente. \n9",
    "data_test\\rootfolder\\università\\DeepLearning\\02-MLP_onehot_softmax-sbloccato.pdf#9": "Funzioni di attivazione\nNe esistono molte, ad esempio:  \nFunzione Sigmoide  \nTangente iperbolica (tanh)  \nRelu \nLeaky Relu  \nSwish  \nRelu parametrizzato  \nELU \nSoftplus e Softsign  \nSelu \nGelu  \nDurante il corso discuteremo pro e contro delle principali.  \nColab 03-funzioni_di_attivazione_5.1.2\n10",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nKayers e moduli in Keras\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#1": "Sommario\nModuli e Keras  \nSequential  \nModuli custom  \nGestione dei parametri: lettura, condivisione, inizializzazione  \nInizializzazione lazy  \nLayer custom  \nI/O \nGPU e Keras",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#10": "Gestione dei parametri: accesso\nIl loop di addestramento mira a trovare i parametri che minimizzano la funzione di \nloss. Le architetture più classiche hanno implementazioni che si occupano \ninteramente della gestione dei parametri. In altri casi è necessario accedervi \ndurante l'esecuzione (es. debugging, riuso dei parametri in parti diverse del \nmodello).  \nVediamo come accedere ai parametri. Costruiamo un semplice modello:  \nimport \ntensorflow  \nas \ntf \nnet = tf.keras.models.Sequential([  \n    tf.keras.layers.Flatten(),  \n    tf.keras.layers.Dense(\n 4\n, activation=tf.nn.relu),  \n    tf.keras.layers.Dense(\n 1\n), \n]) \nX = tf.random.uniform((\n 2\n, \n4\n)) \nnet(X).shape  \nI layer nel modello sono memorizzati mediante liste. I parametri sono facilmente \naccedibili:  \nnet.layers[\n 2\n].weights       # secondo layer: 4 pesi e 1 bias  \n[<tf.Variable \n 'dense_1/kernel:0'\n  shape=(\n 4\n, \n1\n) dtype=float32, numpy=  \n array([[-\n 0.6941955\n  ], \n        [-\n 0.9906301\n  ], \n        [-\n 0.13128954\n ], \n        [ \n 0.22367525\n ]], dtype=float32)>,  \n <tf.Variable \n 'dense_1/bias:0'\n  shape=(\n 1\n,) dtype=float32, numpy=array([\n 0.\n], dtype=float32)>]  \n11",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#11": "Gestione dei parametri: lettura\nIn Keras i parametri sono salvati in particolari classi. Per ottenere il valore \nbisogna convertire le classi in tensori, ad esempio, per ottenere il bias dal \nsecondo layer della rete:  \ntype\n(net.layers[\n 2\n].weights[\n 1\n]), tf.convert_to_tensor(net.layers[\n 2\n].weights[\n 1\n]) \n(tensorflow.python.ops.resource_variable_ops.ResourceVariable,  \n <tf.Tensor: shape=(\n 1\n,), dtype=float32, numpy=array([\n 0.\n], dtype=float32)>)  \nMentre per ottenere tutti i parametri:  \nnet.get_weights()  \n[array([[-\n 0.20149094\n ,  \n0.69364685\n , -\n0.12403131\n ,  \n0.81778544\n ], \n        [ \n 0.3347332\n  ,  \n0.43645364\n ,  \n0.18376476\n , -\n0.5020199\n  ], \n        [-\n 0.7681664\n  , -\n0.14477473\n , -\n0.6313741\n  ,  \n0.8246415\n  ], \n        [-\n 0.8074637\n  , -\n0.20050609\n ,  \n0.4308104\n  ,  \n0.69257575\n ]], \n       dtype=float32),  \n array([\n 0.\n, \n0.\n, \n0.\n, \n0.\n], dtype=float32),  \n array([[-\n 0.6941955\n  ], \n        [-\n 0.9906301\n  ], \n        [-\n 0.13128954\n ], \n        [ \n 0.22367525\n ]], dtype=float32),  \n array([\n 0.\n], dtype=float32)]  \n12",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#12": "Condivisione dei parametri\nIn alcune architetture è conveniente condividere i parametri in layer distinti, \nin modo che la modi\n ﬁ\nca dei parametri di un layer si ri\n ﬂ\netta sull'altro.  \nshared = tf.keras.layers.Dense(\n 4\n, activation=tf.nn.relu)  \nnet = tf.keras.models.Sequential([  \n    tf.keras.layers.Flatten(),  \n    shared,  \n    shared,  \n    tf.keras.layers.Dense(\n 1\n), \n]) \nnet(X) \nIn questo caso, i gradienti del secondo e terzo layer sono sommati.\n13",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#13": "Inizializzazione dei parametri\nAll'interno del modulo Python \n keras.initializers\n  sono contenute le \nimplementazioni di vari tipi di inizializzazione dei parametri. Tali approcci \ndipendono solitamente dall'input e dell'output e i valori dei bias sono \nimpostati a zero.  \nPer default, l'inizializziazione dei parametri è basata su una distribuzione \nuniforme (\n glorot initializer\n ) nell'intervallo [-k,k], dove k = sqrt(6/(\n ﬁ\nn_in + \nfan_out)).  \nimport \ntensorflow  \nas \ntf \nnet = tf.keras.models.Sequential([  \n    tf.keras.layers.Flatten(),  \n    tf.keras.layers.Dense(\n 4\n, activation=tf.nn.relu),  \n    tf.keras.layers.Dense(\n 1\n), \n]) \nX = tf.random.uniform((\n 2\n, \n4\n)) \nnet(X).shape  \nVedi: \n https://keras.io/api/layers/initializers/  \n14",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#14": "Inizializzazione dei parametri\nNell'esempio si impiega una inizializzazione basata su una distribuzione \ngaussiana con deviazione standard 0.01.  \nnet = tf.keras.models.Sequential([  \n    tf.keras.layers.Flatten(),  \n    tf.keras.layers.Dense(  \n        \n 4\n, activation=tf.nn.relu,  \n        kernel_initializer=tf.random_normal_initializer(mean=\n 0\n, stddev=\n 0.01\n), \n        bias_initializer=tf.zeros_initializer()),  \n    tf.keras.layers.Dense(\n 1\n)]) \nnet(X) \nnet.weights[\n 0\n], net.weights[\n 1\n] \n(<tf.Variable \n 'dense_2/kernel:0'\n  shape=(\n 4\n, \n4\n) dtype=float32, numpy=  \n array([[-\n 0.00021173\n ,  \n0.00316905\n , -\n0.00598176\n ,  \n0.00144992\n ], \n        [-\n 0.00882782\n ,  \n0.01484077\n , -\n0.00652608\n , -\n0.00581241\n ], \n        [ \n 0.00398763\n , -\n0.01069997\n , -\n0.01145216\n , -\n0.00430671\n ], \n        [ \n 0.00342147\n , -\n0.01215916\n ,  \n0.01345742\n ,  \n0.01632656\n ]], \n       dtype=float32)>,  \n <tf.Variable \n 'dense_2/bias:0'\n  shape=(\n 4\n,) dtype=float32, numpy=array([\n 0.\n, \n0.\n, \n0.\n, \n0.\n], dtype=float32)>)  \nInvece per una inizializzazione con valori costanti:  \n    tf.keras.layers.Dense(  \n        \n 4\n, activation=tf.nn.relu,  \n        kernel_initializer=tf.keras.initializers.Constant(\n 1\n), \n        bias_initializer=tf.zeros_initializer()),  \nNota\n : è possibile impiegare inizializzazioni distinte per ogni layer.\n15",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#15": "Inizializzazione dei parametri - custom\nPer una inizializzazione custom dei parametri bisogna creare una classe a \npartire dalla classe Initializer, e de\n ﬁ\nnire la funzione __call__() che restituisce \nil tensore in base alle dimensioni passate come parametro, es:  \nclass \nMyInit\n(tf.keras.initializers.Initializer):  \n    \n def \n__call__\n (\nself\n, shape, dtype=\n None\n): \n        data=tf.random.uniform(shape, -\n 10\n, \n10\n, dtype=dtype)  \n        factor=(tf.abs(data) >= \n 5\n) \n        factor=tf.cast(factor, tf.float32)  \n        \n return\n data * factor  \nnet = tf.keras.models.Sequential([  \n    tf.keras.layers.Flatten(),  \n    tf.keras.layers.Dense(  \n        \n 4\n, \n        activation=tf.nn.relu,  \n        kernel_initializer=MyInit()),  \n    tf.keras.layers.Dense(\n 1\n), \n]) \nnet(X) \nprint\n(net.layers[\n 1\n].weights[\n 0\n]) \n<tf.Variable \n 'dense_8/kernel:0'\n  shape=(\n 4\n, \n4\n) dtype=float32, numpy=  \narray([[-\n 0.\n       , -\n 6.526873\n  ,  \n8.615063\n  ,  \n5.7617836\n ], \n       [ \n 0.\n       ,  \n 0.\n       ,  \n 6.0559807\n , -\n0.\n       ],  \n       [-\n 6.7486644\n ,  \n8.665197\n  ,  \n0.\n       , -\n 7.035637\n  ], \n       [-\n 0.\n       , -\n 0.\n       , -\n 7.608464\n  ,  \n0.\n       ]], dtype=float32)>  \n16",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#16": "Inizializzazione dei parametri - custom (2)\nIn alternativa si possono impostare i parametri direttamente:  \nnet.layers[\n 1\n].weights[\n 0\n][:].assign(net.layers[\n 1\n].weights[\n 0\n] + \n1\n) \nnet.layers[\n 1\n].weights[\n 0\n][\n0\n, \n0\n].assign(\n 42\n) \nnet.layers[\n 1\n].weights[\n 0\n] # stampa  \n<tf.Variable \n 'dense_8/kernel:0'\n  shape=(\n 4\n, \n4\n) dtype=float32, numpy=  \narray([[\n 42.\n       , -\n 5.526873\n  ,  \n9.615063\n  ,  \n6.7617836\n ], \n       [ \n 1.\n       ,  \n 1.\n       ,  \n 7.0559807\n ,  \n1.\n       ],  \n       [-\n 5.7486644\n ,  \n9.665197\n  ,  \n1.\n       , -\n 6.035637\n  ], \n       [ \n 1.\n       ,  \n 1.\n       , -\n 6.608464\n  ,  \n1.\n       ]], dtype=float32)>  \nNell'esempio aggiorno i pesi del primo layer (+1) e imposto uno speci\n ﬁ\nco \npeso al valore 42.\n17",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#17": "Inizializzazione lazy\nNel codice visto, il risultato di alcune istruzioni dipende da iperparametri \nquali la dimensione dei layer (es. inizializzazione dei parametri, inserire un \nlayer senza indicarne il numero di nodi), sebbene tali iperparametri non \nsono esplicitamente indicati.  \nCon la inizializzazione differita (o lazy) è possibile de\n ﬁ\nnire una architettura \nin modo più possibile parametrico, in modo da speci\n ﬁ\ncare solo gli \niperparametri essenziali e derivare gli altri in modo automatico.  \nIn questo esempio manca la dimensione del layer di input, perciò Keras non \npuò de\n ﬁ\nnire completamente gli iperparametri:  \nimport \ntensorflow  \nas \ntf \nnet = tf.keras.models.Sequential([  \n    tf.keras.layers.Dense(\n 256\n, activation=tf.nn.relu),  \n    tf.keras.layers.Dense(\n 10\n), \n]) \n[net.layers[i].get_weights() \n for\n i \nin \nrange\n(\nlen\n(net.layers))]  \n[[], []]  \n...\n18",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#18": "Inizializzazione lazy (2)\nSe proviamo a de\n ﬁ\nnire le dimensioni di un certo input, Keras può \ncompletare l'inizializzazione, ad esempio:  \nX = tf.random.uniform((\n 2\n, \n20\n)) \nnet(X) \n[w.shape \n for\n w \nin\n net.get_weights()]  \n[(\n20\n, \n256\n), (\n256\n,), (\n256\n, \n10\n), (\n10\n,)]\n19",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#19": "Layer custom\nPossiamo de\n ﬁ\nnire layer anche senza parametri da sottoporre ad \naddestramento. Nell'esempio implementiamo una sorta di normalizzazione \nsottraendo la media dai valori in input. Tale operazioni vanno inserite nella \nfunzione call().  \nimport \ntensorflow  \nas \ntf \nfrom \nd2l \nimport\n tensorflow \n as\n d2l \nclass \nCenteredLayer\n (tf.keras.Model):  \n    \n def \n__init__\n (\nself\n): \n        \n super\n().\n__init__\n () \n    \n def \ncall\n(\nself\n, inputs):  \n        \n return\n inputs - tf.reduce_mean(inputs)  \nlayer = CenteredLayer()  \nlayer(tf.constant([\n 1.0\n, \n2\n, \n3\n, \n4\n, \n5\n])) \n<tf.Tensor: shape=(\n 5\n,), dtype=float32, numpy=array([-\n 2.\n, -\n1.\n,  \n0.\n,  \n1.\n,  \n2.\n], dtype=float32)>  \nImpieghiamo il layer custom nel nostro modello, e veri\n ﬁ\nchiamo che con dait \nrandom otteniamo un valore medio in output quasi 0:  \nnet = tf.keras.Sequential([tf.keras.layers.Dense(\n 128\n), CenteredLayer()])  \nY = net(tf.random.uniform((\n 4\n, \n8\n))) \ntf.reduce_mean(Y)  \n<tf.Tensor: shape=(), dtype=float32, numpy=\n 9.313226e-10\n >\n20",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#2": "Deep networks e moduli\nAbbiamo visto come una MLP sia composta da uno o più layer, ognuno \ncomposto da uno o più nodi che costituiscono l'unità elementare di \nelaborazione.  \nAlcuni risultati ci suggeriscono che questo sia un modello suf\n ﬁ\ncientemente \ngenerale per simulare un dominio molto vasto funzioni. Ma risultati \nsperimentali hanno dimostrato che modelli intermedi, più grandi del singolo \nneurone, ma più piccoli dell'intero modello computazionale siano più adatti \nper costruire architetture deep.  \nEsempio\n : l'architettura \n ResNet-152\n  (Residual NN) sviluppata nell'ambito \ndella computer vision è una delle prime architetture con 100ia di layers. \nLa rete è costituita da schemi di nodi e connessioni (\n moduli\n ) che si \nripetono. Particolari tecniche (\n skip connections\n ) sono impiegate per \nrisolvere il vanishing problem.  \nUn modulo può essere un layer, più layers, o l'intero modello; e generalizza \nun elemento computazionale che può essere ripetuto, o riutilizzato in diverse \narchitetture.\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#20": "Layer custom con parametri\nNell'esempio ricreiamo un layer fully connected con una classe custom. \nNella funzione \n __init__\n () creiamo i parametri che non dipendono dalla \ndimensione dell'input, mentre in \n build\n () de\nﬁ\nniamo quelli che dipendono, \ncon eventuale inizializzazione. La funzione \n build\n () viene invocata \nautomaticamente prima di call().  \nLa funzione \n add_weight\n () automatizza la creazione dei parametri da \nsottoporre ad addestramento.  \nclass \nMyDense\n(tf.keras.Model):  \n    \n def \n__init__\n (\nself\n, units):  \n        \n super\n().\n__init__\n () \n        # il secondo parametro indica la dimensione dell'input  \n        \n self\n.units = units  \n    # il secondo parametro indica la dimensione dell'input  \n    \n def \nbuild\n(\nself\n, X_shape):  \n        \n self\n.weight = \n self\n.add_weight(name=\n 'weight'\n , \n            shape=[X_shape[-\n 1\n], \nself\n.units],  \n            initializer=tf.random_normal_initializer())  \n        \n self\n.bias = \n self\n.add_weight(  \n            name=\n 'bias'\n, shape=[\n self\n.units],  \n            initializer=tf.zeros_initializer())  \n    \n def \ncall\n(\nself\n, X): \n        linear = tf.matmul(X, \n self\n.weight) + \n self\n.bias \n        \n return\n tf.nn.relu(linear)  \n# vedi anche https://www.tensorflow.org/guide/keras/custom_layers_and_models\n21",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#21": "Layer con parametri\nNell'esempio ricreiamo un layer fully connected con una classe custom. \nNella funzione \n __init__\n () creiamo i parametri che non dipendono dalla \ndimensione dell'input, mentre in \n build\n () de\nﬁ\nniamo quelli che dipendono, \ncon eventuale inizializzazione. La funzione \n build\n () viene invocata \nautomaticamente prima di call().  \nLa funzione \n add_weight\n () automatizza la creazione dei parametri da \nsottoporre ad addestramento.  \nclass \nMyDense\n(tf.keras.Model):  \n    \n def \n__init__\n (\nself\n, units):  \n        \n super\n().\n__init__\n () \n        # il secondo parametro indica la dimensione dell'input  \n        \n self\n.units = units  \n    # il secondo parametro indica la dimensione dell'input  \n    \n def \nbuild\n(\nself\n, X_shape):  \n        \n self\n.weight = \n self\n.add_weight(name=\n 'weight'\n , \n            shape=[X_shape[-\n 1\n], \nself\n.units],  \n            initializer=tf.random_normal_initializer())  \n        \n self\n.bias = \n self\n.add_weight(  \n            name=\n 'bias'\n, shape=[\n self\n.units],  \n            initializer=tf.zeros_initializer())  \n    \n def \ncall\n(\nself\n, X): \n        linear = tf.matmul(X, \n self\n.weight) + \n self\n.bias \n        \n return\n tf.nn.relu(linear)  \n# vedi anche https://www.tensorflow.org/guide/keras/custom_layers_and_models\n22",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#22": "I/O su \n ﬁ\nle - tensori\nGli addestramenti di reti deep possono essere molto lunghe. È necessario \nsalvare i risultati parziale e \n ﬁ\nnali su \n ﬁ\nle in modo da poterli recuperare \nfacilmente.  \nAd esempio, per salvare e recuperare i tensori:  \nimport \nnumpy \nas \nnp \nimport \ntensorflow  \nas \ntf \n# salvataggio  \nx = tf.range(\n 4\n) \nnp.save(\n 'x-file.npy'\n , x) \n# recupero  \nx2 = np.load(\n 'x-file.npy'\n , allow_pickle=\n True\n) \n# salvataggio di più sensori  \ny = tf.zeros(\n 4\n) \nnp.save(\n 'xy-files.npy'\n , [x, y])  \nx2, y2 = np.load(\n 'xy-files.npy'\n , allow_pickle=\n True\n) \n# o salvare dizionari stringa-tensore  \nmydict = {\n 'x'\n: x, \n'y'\n: y} \nnp.save(\n 'mydict.npy'\n , mydict)  \nmydict2 = np.load(\n 'mydict.npy'\n , allow_pickle=\n True\n) \n23",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#23": "I/O su \n ﬁ\nle - modelli\nPer i modelli, occorre distinguere architettura e parametri. Per la prima, ci si \nbasa sul codice che si usa per crearla, perciò senza salvataggio su \n ﬁ\nle. \nMentre per i parametri si sfruttano le funzionalità di Keras.  \nAd esempio, de\n ﬁ\nniamo una architettura, salviamo i parametri e ricostruiamo \nla rete con il recupero dei parametri:  \nclass \nMLP\n(tf.keras.Model):  \n    \n def \n__init__\n (\nself\n): \n        \n super\n().\n__init__\n () \n        \n self\n.flatten = tf.keras.layers.Flatten()  \n        \n self\n.hidden = tf.keras.layers.Dense(units=\n 256\n, activation=tf.nn.relu)  \n        \n self\n.out = tf.keras.layers.Dense(units=\n 10\n) \n    \n def \ncall\n(\nself\n, inputs):  \n        x = \n self\n.flatten(inputs)  \n        x = \n self\n.hidden(x)  \n        \n return \nself\n.out(x) \nnet = MLP()  \nX = tf.random.uniform((\n 2\n, \n20\n)) \nY = net(X)  \nnet.save_weights(\n 'mlp.params'\n ) \n...  \nclone = MLP()  \nclone.load_weights(\n 'mlp.params'\n )\n24",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#24": "GPU e Keras\nPer default i tensori sono creati in memoria e le computazioni sono sulla \nCPU. Ma possiamo comunque controllare l'elaborazione:  \nimport \ntensorflow  \nas \ntf \nfrom \nd2l \nimport\n tensorflow \n as\n d2l \ndef \ncpu\n():   \n    \n return\n tf.device(\n '/CPU:0'\n ) \ndef \ngpu\n(i=\n0\n):   \n    \n return\n tf.device(\n f'/GPU:\n{\ni\n}\n'\n) \ncpu(), gpu(), gpu(\n 1\n) \n(<tensorflow.python.eager.context._EagerDeviceContext at \n 0x7fafa2b271c0\n >, \n <tensorflow.python.eager.context._EagerDeviceContext at \n 0x7fafa257a100\n >, \n [<tensorflow.python.eager.context._EagerDeviceContext at \n 0x7fafa253ad00\n >, \n  <tensorflow.python.eager.context._EagerDeviceContext at \n 0x7fafa253ab40\n >]) \ndef \nnum_gpus\n ():   \n    \n return \nlen\n(tf.config.experimental.list_physical_devices(\n 'GPU'\n)) \ndef \ntry_gpu\n(i=\n0\n):   \n    \n# restituisce gpu(i) se esiste, altrimenti cpu()  \n    \n if\n num_gpus() >= i + \n 1\n: \n        \n return\n gpu(i) \n    \n return\n cpu() \ndef \ntry_all_gpus\n ():   \n    # \nNumero di GPU disponibili, o CPU se le GPU non ci sono  \n    \n return\n [gpu(i) \n for\n i \nin \nrange\n(num_gpus())]  \ntry_gpu(), try_gpu(\n 10\n), try_all_gpus()\n25",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#25": "GPU e Keras (2)\n# su quale device è allocato il tensore  \n# Nota: è fondamentale avere tutti i parametri di una operazione sullo stesso device  \nx = tf.constant([\n 1\n, \n2\n, \n3\n]) \nx.device  \n'/job:localhost/replica:0/task:0/device:GPU:0'  \n# alloca un tensore su una GPU  \nwith\n try_gpu():  \n    X = tf.ones((\n 2\n, \n3\n)) \n<tf.Tensor: shape=(\n 2\n, \n3\n), dtype=float32, numpy=  \narray([[\n 1.\n, \n1.\n, \n1.\n], \n       [\n 1.\n, \n1.\n, \n1.\n]], dtype=float32)>  \n# alloca un tensore sulla seconda GPU  \nwith\n try_gpu(\n 1\n): \n    Y = tf.random.uniform((\n 2\n, \n3\n)) \n<tf.Tensor: shape=(\n 2\n, \n3\n), dtype=float32, numpy=  \narray([[\n 0.44844735\n , \n0.7493162\n  , \n0.5692874\n  ], \n       [\n 0.10097635\n , \n0.81023645\n , \n0.5274769\n  ]], dtype=float32)>  \n# per calcolare X + Y, dobbiamo averli sullo stesso device  \n# spostiamo X sulla stessa GPU di Y  \nwith\n try_gpu(\n 1\n): \n    Z = X  \nprint\n(X) \nprint\n(Z) \ntf.Tensor(  \n[[\n1. \n1. \n1.\n] \n [\n1. \n1. \n1.\n]], shape=(\n 2\n, \n3\n), dtype=float32)  \ntf.Tensor(  \n[[\n1. \n1. \n1.\n] \n [\n1. \n1. \n1.\n]], shape=(\n 2\n, \n3\n), dtype=float32)  \n# ora possiamo calcolarlo  \nY + Z\n26",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#26": "GPU e Keras (3)\nÈ possibile indicare a Keras di impiegare le GPU disponibili per \nl'elaborazione di un certo modello:  \nstrategy = tf.distribute.MirroredStrategy()  \nwith\n strategy.scope():  \n    net = tf.keras.models.Sequential([  \n        tf.keras.layers.Dense(\n 1\n)]) \nINFO:tensorflow:Using MirroredStrategy \n with\n devices (\n '/job:localhost/replica:0/task:0/device:GPU:0'\n , \n'/\njob:localhost/replica:0/task:0/device:GPU:1'\n ) \nnet(X) \n<tf.Tensor: shape=(\n 2\n, \n1\n), dtype=float32, numpy=  \narray([[-\n 1.1522729\n ], \n       [-\n 1.1522729\n ]], dtype=float32)>  \n# vediamo la conferma cheanche i parametri sono memorizzati nello stesso device  \nnet.layers[\n 0\n].weights[\n 0\n].device, net.layers[\n 0\n].weights[\n 1\n].device  \n(\n'/job:localhost/replica:0/task:0/device:GPU:0'\n , \n \n'/job:localhost/replica:0/task:0/device:GPU:0')\n27",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#3": "Moduli in Keras\nUn modulo è rappresentato da una classe Python che implementa la forward \npropagation, memorizza i parametri, e fornisca la backpropagation. \nQuest'ultimo aspetto può essere delegato alla tecnica autodiff, senza perciò \nde\nﬁ\nnire manualmente i singoli gradienti.  \nAd esempio il seguente codice genera due layer: il primo con 256 nodi \n fully \nconnected\n  (o \ndenso\n ) ed uno di output con 10 nodi.  \nimport \ntensorflow  \nas \ntf \nnet = tf.keras.models.Sequential([  \n    tf.keras.layers.Dense(\n 256\n, activation=tf.nn.relu),  \n    tf.keras.layers.Dense(\n 10\n), \n]) \nX = tf.random.uniform((\n 2\n, \n20\n)) \nnet(X).shape  \nIl modello è costruito istanziando la classe \n Sequential\n  e passandogli i singoli \nlayer come parametri. Sia \n Sequential\n  che \n Dense\n  sono istanze di \n keras.Model\n .  \n4",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#4": "Sequential in Keras\nSequential crea una lista ordinata di layer.  \nLa procedura di forward propagation è de\n ﬁ\nnita implicitamente: l'output di \nun layer corrisponde all'input del secondo.  \nNell'esempio si invoca net(X), che corrisponde alla funzione net.call(X), per \nottenere l'output dal modello appena creato.\n5",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#5": "Moduli custom\nPer creare nuovi moduli occorre tener presente come vengono impiegati \ndurante l'esecuzione:  \n1.\nI dati di input vengono mandati in input alla forward propagation  \n2.\nLa funzione di propagazione restituisce i valori in output  \n3.\nSi calcolano i gradienti dell'output rispetto agli input per mezzo del \nmetodo di backpropagation. Uno step solitamente gestito in automatico  \n4.\nMemorizzare i parametri ottenuti necessari per la successiva forward \npropagation\n6",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#6": "Moduli custom\nAd esempio, la rete precedente (un layer da 256 nodi seguito da un layer di \n10 nodi) si codi\n ﬁ\nca nel seguente modo:  \nclass \nMLP\n(tf.keras.Model):  \n    \n def \n__init__\n (\nself\n): \n        \n # Sempre necessario richiamare il costruttore della superclass  \n        \n super\n().\n__init__\n () \n        \n self\n.hidden = tf.keras.layers.Dense(units=\n 256\n, activation=tf.nn.relu)  \n        \n self\n.out = tf.keras.layers.Dense(units=\n 10\n) \n    \n# forward propagation  \n    \n def \ncall\n(\nself\n, X): \n        \n return \nself\n.out(\nself\n.hidden((X)))  \nde\nﬁ\nnendo il costruttore e la funzione che si occupa della forward \npropagation.  \nIl metodo call permette di creare layer che richiedono particolari \nelaborazioni (es. controllare il \n ﬂ\nusso di esecuzione durante la forward \npropagation) che non corrispondono a quelle prede\n ﬁ\nnite in Keras.\n7",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#7": "Moduli custom - esempio\nDurante l'elaborazione possiamo aver bisogno di accedere a costanti, cioè valori \nche non sono associati a parametri da stimare durante l'apprendimento, perciò \nnon soggetti a back propagation.  \nNell'esempio, istanziamo i parametri in modo casuale, e rimarranno costanti \ndurante il training. Restituiamo la somma dei valori in output.  \nL'esempio è di scarsa utilità ma dimostra le potenzialità dei moduli custom.  \nclass \nFixedHiddenMLP\n (tf.keras.Model):  \n    \n def \n__init__\n (\nself\n): \n        \n super\n().\n__init__\n () \n        \n self\n.flatten = tf.keras.layers.Flatten()  \n       \nself\n.rand_weight = tf.constant(tf.random.uniform((\n 20\n, \n20\n))) \n        \n self\n.dense = tf.keras.layers.Dense(\n 20\n, activation=tf.nn.relu)  \n    \n def \ncall\n(\nself\n, inputs):  \n        X = \n self\n.flatten(inputs)  \n        \n # Usiamo i parametri costanti per generare l'output  \n        X = tf.nn.relu(tf.matmul(X, \n self\n.rand_weight) + \n 1\n)        \n        X = \n self\n.dense(X)  \n        \n # Control flow: simil l1 regularization  \n        \n while\n tf.reduce_sum(tf.math.abs(X)) > \n 1\n: \n            X /= \n 2 \n        \n # reduce_sum() calcola la somma dei valori per una certa dimensione del tensore  \n        \n # senza secondo parametro la somma è operata su tutte le dimensioni del tensore  \n        \n return\n tf.reduce_sum(X)  \nnet = FixedHiddenMLP()  \nnet(X) \n<tf.Tensor: shape=(), dtype=float32, numpy=\n 0.88945085\n >\n8",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#8": "Moduli custom - esempio\nNell'esempio de\n ﬁ\nnisco un altro modello (NestMLP) e successivamente un \nnuovo modello che include il primo come layer:  \nclass \nNestMLP\n(tf.keras.Model):  \n    \n def \n__init__\n (\nself\n): \n        \n super\n().\n__init__\n () \n        \n self\n.net = tf.keras.Sequential()  \n        \n self\n.net.add(tf.keras.layers.Dense(\n 64\n, activation=tf.nn.relu))  \n        \n self\n.net.add(tf.keras.layers.Dense(\n 32\n, activation=tf.nn.relu))  \n        \n self\n.dense = tf.keras.layers.Dense(\n 16\n, activation=tf.nn.relu)  \n    \n def \ncall\n(\nself\n, inputs):  \n        \n return \nself\n.dense(\nself\n.net(inputs))  \nchimera = tf.keras.Sequential()  \nchimera.add(NestMLP())  \nchimera.add(tf.keras.layers.Dense(\n 20\n)) \nchimera.add(FixedHiddenMLP())  \nchimera(X)\n9",
    "data_test\\rootfolder\\università\\DeepLearning\\03-Layers_moduli_keras-sbloccato.pdf#9": "Esercizio\nImplementare un modulo che prende l'output di due moduli (es. \n net1\n e \nnet2\n) e restituisce un output concatenato durante la forward propagation.\n10",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nConvolutional Neural Networks (CNN) - parte 1\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#1": "Sommario\nIntroduzione  \nArchitettura Visual cortex  \nMLP fully connected e limiti  \nInvarianza (spaziale) e principio di località  \nConvolutional layer e canali",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#10": "MLP - fully connected\nLe reti MLP sono comunque ef\n ﬁ\ncaci in molti contesti, ad esempio:  \nIn presenza di dati in formato \n tebellare\n , dove non assumiamo a priori \nuna struttura che mette in correlazione le features per ogni istanza, \nsebbene possano esserci potenziali correlazioni e dipendenze.  \nDati da cui si possono estrarre un numero di features non elevatissimo \n(<<1000), che perciò necessitano di un numero di parametri da stimare \nlimitato.\n11",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#11": "Invarianza (spaziale) #1\n12\nNella identi\n ﬁ\ncazione delle targhe, per addestrare una MLP dobbiamo \ncostruire un training set con molte istanze, in modo da :  \navere lo stesso oggetto che compare in varie posizioni, angolazioni e \ndimensioni.  \noggetto visualizzato parzialmente (es. sul bordo).  \ncasi di overlap tra oggetti etc.",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#12": "Invarianza (spaziale) #2\nNel task \"Where's Waldo?\" non siamo interessati alla posizione, ma solo \nalla presenza o meno di una certa istanza.  \nIl modello dovrebbe tentare di analizzare piccole zone dell'immagine e \nconfrontarle con il pattern \"Waldo\".\n13\n",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#13": "Proprietà locali\n14Per riconoscere certe caratteristiche speci ﬁche analizziamo informazioni \"locali\" o ravvicinate, cioè con una \ndistanza relativa limitata . Non c'è bisogno di considerare l'intera immagine iniziale.  \nUn output associato ad una certa feature (es. occhio o naso) è associato solo un certo numero di pixel in input.  ",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#14": "MLP: Proprietà desiderate\n15\nNei primi layer la rete dovrebbe comportarsi in modo simile \nindipendentemente dalla posizione di una certa regione di interesse \n(\ntranslation invariance\n  o \ntranslation equivariance\n ). \nNei primi layer l'analisi deve essere limitata a piccole regioni \ndell'immagine in input, e non sull'intera immagine (\n principio di località\n ).  \nNei successivi layer, tali analisi considerano regioni più vaste, combinando \nl'output delle analisi precedenti, \n ﬁ\nno ad arrivare all'intera immagine.",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#15": "Esempio MLP e immagini\n16\nSupponiamo di avere una MLP con uno strato nascosto \n H\n. L'input \n X\n è 2d, ed è \nrappresentato da un tensore, anch'esso 2d. Supponiamo per ora che \n H\n abbia la \nstessa struttura di \n X\n. \nIndichiamo con [\n X\n]\ni,j\n e [\nH\n]\ni,j\n il pixel nella posizione <i,j> e il corrispettivo nodo nel \nlayer nascosto.  \nIndichiamo con \n W\n e \nU\n pesi e bias della rete. Poiché ogni nodo di \n H\n riceve input \nda tutti i pixel in input, usiamo matrici-tensori di ordine 4.  \nDove [\n V\n]\ni,j,a,b\n := [\nH\n]\ni,j,i+a,j+b \n , \nperciò introduciamo un semplice cambio notazione. \nGli indici \n a\n e \nb\n sono offset rispetto a <i,j> e scorrono l'intera immagine in input, \nperciò possono assumere valori negativi.  \nNumero di parametri: per immagini 1000x1000 abbiamo 10\n12\n parametri, infatti \nogni nodo in \n H\n deve essere connesso con tutti i nodi del layer precedente.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#16": "Invarianza spaziale nella pratica\n17\nTale proprietà impone che, se abbiamo uno \n shift\n nell'input \n X\n, anche la \nrappresentazione \n H\n deve subire lo stesso \n shift\n, in modo da mantenere lo \nstesso output. Ma questo è possibile solo se \n U \ne \nV\n non dipendono da \n <i,j>\n, \ncioè [\n V\n]\ni,j,a,b\n := [\nV\n]\na,b  \ne \nU\n è una costante.  \nRappresenta l'operatore di \n convoluzione\n . Il pixel <i+a,j+b>, vicino alla \nlocation <i,j>, è pesato con il coef\n ﬁ\nciente [\n V\n]\na,b\n per ottenere l'output [\n H\n]\ni,j\n. \n[\nV\n]\na,b  \nrichiede meno coef\n ﬁ\ncienti poiché è indipendente dalla location. I \nparametri passano da 10\n12\n a 4·10\n6\n, con \n a\n e \nb\n in (-1000,1000).\n",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#17": "Principio di località nella pratica\n18\nLimitiamo l'analisi per determinare [\n H\n]\ni,j\n a una zona \n Δ\n×\nΔ\n, con \nΔ\n<<1000 \n(es. \nΔ\n=10), perciò evitando di considerare l'intera immagine:  \nI parametri si riducono ulteriormente da 4·10\n6\n a 4·\nΔ\n2\n, sebbene il layer \nnascosto mantenga la dimensione iniziale, e perciò la quantità di \ninformazione originale.  \nLa regione \n Δ\n×\nΔ\n che genera le attivazioni nel successivo strato è chiamata \nLocal receptive \n ﬁ\neld (LRF)\n .\n",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#18": "CNN - Convolutional layer e LRF\n19\nnodo\ninput per il successivo hidden layer\n25x2521x21\nEsempio di input:  \nimmagine 25x25 pixe l\nin bianco e neroOutput dopo il primo  \nlayer convolutivo .local receptive ﬁeldOgni nodo è attivato in base \nall'input determinato  \nda una certa posizione del \nLRF  che scorre lungo l'input.input\nConvolutional layer\nnotiamo la riduzione della  \ndimensione rispetto all'inputmatrice delle attivazioni\nelaborazione",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#19": "Convolutional neural networks\n20\nIl layer \n H\n che abbiamo introdotto prende il nome di \n convolutional layer,\n  e \nle rete basate su tale layer \n Convolutional neural networks\n  (CNNs).  \nV\n è comunemente chiamato \n convolution kernel\n  o \nﬁ\nltro\n. \nPer rappresentare features più complesse e ad alto livello, si impiegano più \nlayer convolutivi alternati a non linearità.",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#2": "Introduzione\nAlcune so\n ﬁ\nsticate \n architetture ML\n  sono riuscite a ottenere \n performance superiori a \nquelle umane\n  (es. il gioco degli scacchi con IBM Deep Blue). Ma solo intorno al \n2000\n  si sono ottenute\n  buone performance per  \ntask apparentemente più semplici\n , \ncome:  \n•\nRiconoscere un giocattolo in una immagine  \n•\nSpeech recognition - riconoscimento vocale  \nPer noi sono task semplici perché l'evoluzione ha portato il cervello a costruire \nstrutture con funzioni speci\n ﬁ\nche.  \nQuando le informazioni arrivano alle parti deputate al ragionamento ad alto \nlivello, sono già arricchite di features ad alto livello elaborate da queste strutture.  \n•\nSebbene siamo coscienti che esiste un giocattolo, non sappiamo spiegare quale \nprocesso abbiamo seguito per identi\n ﬁ\ncarlo.  \n•\nLe architetture \n Convolutional Neural Networks (CNN)\n  sono state sviluppate negli \nanni '80 in base agli studi della zona della corteccia deputata al riconoscimento \nvisivo. Nelle ultime 2 decadi si sono diffuse grazie alla presenza di \n GPU\n .\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#20": "Channels (canali)\n21\nLe immagini a colori hanno 3 canali RGB, perciò, ai due assi principali che \nidenti\n ﬁ\ncano le relazioni spaziali, ne aggiungiamo un terzo ottenendo \ntensori 3d [\n X\n]\ni,j,k\n con \n ﬁ\nltri del tipo [\n V\n]\na,b,c\n . \nMuovendoci in profondità, possiamo creare una terza dimensione per ogni \nstrato hidden. In pratica si ha uno \n stack\n  di griglie, chiamato \n feature maps\n , \ndove ogni griglia è creata con un \n ﬁ\nltro distinto. Il numero di griglie \ncorrisponde ai canali per quello strato.  \nGeneralizzando, supponendo di avere più canali in input (\n c\n) e più canali \nnell'hidden layer (\n d\n), si ha:  \nIl successivo layer userà i \n d\n canali dell'hidden layer che diverranno i \n c \ncanali di input.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#21": "Esercizio\n22\nImpiega il dataset di cifre MNIST e crea una rete convolutiva per la \nclassi\n ﬁ\ncazione.  \nColab \n 07-lenet.ipynb \n",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#3": "L'architettura della Visual cortex\nNegli anni '60 \n Hubel e Wiesel\n  hanno dimostrato che  \n•\nmolti neuroni nella parte di corteccia deputata al riconoscimento di \nimmagini possiedono un piccolo \n Local receptive \n ﬁ\neld (LRF)\n , cioè possono \nreagire agli stimoli situati in regioni limitate del campo visuale.  \n•\nsebbene condividano il LRF, \n alcuni neuroni si attivano \n solo\n in presenza di \nlinee orizzontali\n , \naltri \nsolo \ncon quelle \n verticali\n . \n•\nalcuni neuroni hanno LRF più estesi\n  e \nsi attivano in presenza di certe \ncon\nﬁ\ngurazioni di più caratteristiche a basso livello\n .  \n•\nsi può desumere che l'attivazione di neuroni ad alto livello é basata \nsull'output di neuroni a basso-livello che sono ritenuti \"vicini\".  \nAumentando la complessità, ripetendo più volte in cascata i passi riportati, \npossiamo riconoscere \n patterns visuali \n anche molto \n complessi.  \nNota\n : il resto della lezione suppone di considerare \n immagini\n  come istanze di \ninput, ma le tecnologie introdotte possono essere usate anche per altri input.\n4",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#4": "L'architettura della Visual cortex\n5\nSecondo te è una MLP?Ad ogni livello saliamo di astrazione  \nnei pattern individuati\nLocal receptive ﬁelds",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#5": "L'architettura della Visual cortex\n6\nÈ simile a una MLP ,  \nma ogni nodo e connesso solo  \na un piccolo insieme di neuroni viciniAd ogni livello saliamo di astrazione  \nnei pattern individuati\nLocal receptive ﬁelds",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#6": "MLP - fully connected\nPerché non usiamo una NN MLP per riconoscere gli oggetti?\n7",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#7": "MLP - fully connected\nPerché non usiamo una NN MLP per riconoscere gli oggetti?  \n1.\nA causa dell'\n elevato numero di parametri da stimare  \n•\nSupponiamo di avere in input una piccola immagine di 100x100 pixel  \n•\nCreiamo un primo layer di appena 1000 nodi, che perciò \n ﬁ\nltra \nnotevolmente le informazioni passata ai successivi layer.  \n•\nPer questo primo strato abbiamo già \n 10 milioni di parametri da stimare\n .\n8",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#8": "MLP - fully connected\nPerché non usiamo una NN MLP per riconoscere gli oggetti?  \n1.\nA causa dell'\n elevato numero di parametri da stimare  \n•\nSupponiamo di avere in input una piccola immagine di 100x100 pixel  \n•\nCreiamo un primo layer di appena 1000 nodi, che perciò \n ﬁ\nltra \nnotevolmente le informazioni passata ai successivi layer.  \n•\nPer questo primo strato abbiamo già \n 10 milioni di parametri \n da stimare.  \n2.\nSupponiamo che \n certi nodi \n del primo strato \n si specializzino su un certo \ntask\n, es. riconoscere linee orizzontali.  \n•\nI neuroni specializzati sono attivati se il pattern da identi\n ﬁ\ncare è \nlocalizzato in una certa zona.  \n•\nMa vorremmo poter identi\n ﬁ\ncare lo stesso pattern indipendentemente da \ndove compare.\n9",
    "data_test\\rootfolder\\università\\DeepLearning\\04-CNN parte 1-sbloccato.pdf#9": "MLP - fully connected\nPerché non usiamo una NN MLP per riconoscere gli oggetti?  \n3. Le reti \n MLP \nnon riescono a codi\n ﬁ\ncare esplicitamente l'organizzazione \nspaziale delle features\n . \n•\nNel Visual cortex i neuroni degli strati più vicini all'input identi\n ﬁ\ncano \nfeatures analizzando piccole aree dell'immagine.  \n•\nI neuroni \"ad alto livello\" combinano tali features per identi\n ﬁ\ncare features \nspazialmente più estese.\n10",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nConvolutional Neural Networks (CNN)  \n2a parte\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#1": "Sommario\nConvolutional Neural network  \n•\nConvolutional layer  \n•\nLocal receptive \n ﬁ\neld \n•\nStride e Padding  \n•\nFilters e Feature Maps  \n•\nPooling Layer  \nArchitettura LeNet-5",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#10": "CNN - Stride\n11•La distanza s tra due LRF  adiacenti è chiamata stride . \n•Finora abbiamo visto stride di 1 pixel, ma la LRF  può scorrere di più pixel . \n•Le CNN spesso impiegano kernels di dimensione 1,3,5 o 7. Questo rende più facile mantenere \nla dimensionalità con padding (vedi di seguito) che consistono nello stesso numero di righe in \ncima e in fondo, e colonne a sinistra e a destra dell'immagine. \nOutput layer precedenteLayer convoluzionale\n<------ padding ------>\n<------ padding ------>\nLRF di 3x3  \nStride = 2",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#11": "CNN: Padding\n12•Supponendo stride > 1 , può accadere che il convolutional layer (comunque ridotto di fw-1 e \nfh-1 a causa del LRF ) non abbia le stesse dimensioni del layer precedente poiché la LRF non \npuò scorrere l'intera instanza in input.  \n•Il padding  aggiunge dimensioni  ai dati in input. Normalmente i dati inseriti sono valori nulli \n(0-padding ). Si hanno i seguenti vantaggi :\n•Permettere alla LRF  di scorrere per intero l'immagine in input senza ignorarne delle parti .\n•Un LRF potrebbe \"imparare\" a riconosce una certa feature  quando è centrata \nnell'immagine. Se la feature è posizionata molto vicino al bordo , senza padding potrebbe \nessere ignorata.\n0-padding\n✓LRF\nOutput layer precedente senza padding Output layer precedente con padding",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#12": "CNN: Riduzione dimensionalità e Stride\n13Output layer precedente•La presenza di stride > 1  altera gli indici iniziali e ﬁnali che identi ﬁcato il LRF associato ad \nun certo nodo.  \n•L'attivazione di un nodo nella posizione (i, j) di un certo layer è determinato dagli output dei \nnodi nel layer precedente posizionati nella righe da i × s h  a  i × s h + f h - 1, e nelle colonne da  \nj × s w  a  j × s w + f w - 1.\n•Per s pari a 1, si torna alla formulazione già vista .\n•Stride > 1 riducono la dimensione  del layer convoluzionale a scapito della precisione .\nLayer convoluzionale\n<------ padding ------>\n<------ padding ------>stride verticale\nstride orizzontaleLRF di 3x3  \nStride = 2",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#13": "CNN: Filters\n14Filters•Supponiamo di poter rappresentare gra ﬁcamente i pesi associati a un certo nodo , usati per \nil calcolo della sua attivazione. Tali pesi prendono il nome di ﬁlters  o convolution kernels  \n(o kernels )\n•Ad esempio, una LRF  77 corrisponderà ad un ﬁltro con medesime dimensioni. ×\nNell'esempio ci sono due ﬁltri Vertical ﬁlter e Horizontal ﬁlter entrambi con matrice tutta di 0, \ntranne una colonna di 1 e una riga di 1, rispettivamente.\nInput",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#14": "Esempi di \n ﬁ\nltri e attivazioni (1)\n15Esempio di input  \nimmagine 25x25 pixel\nOutput dopo il primo  \nlayer convolutivo .\nImmagine in input\nImmagine in inputOutput\nOutputFiltro\nFiltroAttivazioni\nAttivazioni",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#15": "Esempi di \n ﬁ\nltri e attivazioni (2)\nhttp://brohrer.github.io/how_convolutional_neural_networks_work.html\n1-1-1\n-11-1\n-1-11\n0.33 -0.11 0.55 0.33 0.11 -0.11 0.77\n-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11\n0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11\n0.33 0.33 -0.33 0.55 -0.33 0.33 0.33\n0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55\n-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11\n0.77 -0.11 0.11 0.33 0.55 -0.11 0.33-1-1-1-1-1-1-1-1-1\n-11-1-1-1-1-11-1\n-1-11-1-1-11-1-1\n-1-1-11-11-1-1-1\n-1-1-1-11-1-1-1-1\n-1-1-11-11-1-1-1\n-1-11-1-1-11-1-1\n-11-1-1-1-1-11-1\n-1-1-1-1-1-1-1-1-1=0.77 -0.11 0.11 0.33 0.55 -0.11 0.33\n-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11\n0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55\n0.33 0.33 -0.33 0.55 -0.33 0.33 0.33\n0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11\n-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11\n0.33 -0.11 0.55 0.33 0.11 -0.11 0.77\n-1-11\n-11-1\n1-1-11-11\n-11-1\n1-110.33 -0.55 0.11 -0.11 0.11 -0.55 0.33\n-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55\n0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11\n-0.11 0.33 -0.77 1.00 -0.77 0.33 -0.11\n0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11\n-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55\n0.33 -0.55 0.11 -0.11 0.11 -0.55 0.33=\n=-1-1-1-1-1-1-1-1-1\n-11-1-1-1-1-11-1\n-1-11-1-1-11-1-1\n-1-1-11-11-1-1-1\n-1-1-1-11-1-1-1-1\n-1-1-11-11-1-1-1\n-1-11-1-1-11-1-1\n-11-1-1-1-1-11-1\n-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1\n-11-1-1-1-1-11-1\n-1-11-1-1-11-1-1\n-1-1-11-11-1-1-1\n-1-1-1-11-1-1-1-1\n-1-1-11-11-1-1-1\n-1-11-1-1-11-1-1\n-11-1-1-1-1-11-1\n-1-1-1-1-1-1-1-1-1ﬁltroattivazioni\nﬁltro\nﬁltro",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#16": "CNN: Feature Maps\n17Filters•Le LRF  scorrono sulla immagine in input. Supponiamo di mantenere costante i valori del \nﬁltro usato per il calcolo dell'attivazione . Tale approccio prende il nome di shared weights . \n•L'insieme delle attivazioni ottenute (output) con lo stesso ﬁltro viene chiamato feature map \npoiché rappresenta le features apprese nella dimensione spaziale. Esse possono essere \nvisualizzate come una immagine.\nNell'esempio si nota che il Vertical ﬁlter crea una feature map  dove le zone dell'input simili a una \nlinea verticale  sono più evidenziate  (cioè più attivazione), mentre le zone  meno simili saranno \npiù scure e sfocate . Discorso duale per il ﬁltro Horizontal ﬁlter.Feature maps\nInput",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#17": "CNN: Stacking feature maps\nIn \nogni layer\n  possiamo avere \n più \nﬁ\nltri con le medesime dimensioni\n . Ogni \nﬁ\nltro produrrà una diversa feature map. Ogni layer sarà così costituito da \nuna sequenza di matrici di attivazioni, perciò una \n struttura 3d\n . \nDurante il \n forward propagation\n  è fondamentale che i \n ﬁ\nltri, cioè i parametri \npesi\n e \nbias\n che costituiscono il layer convoluzionale, rimangano costanti, \nsebbene il valore delle attivazioni, ovvero la \n feature map\n , cambiano in base \nalla posizione del \n LRF\n. Questo permette di:  \n•\nAvere un numero molto minore di parametri da stimare rispetto a un layer \nMLP.  \n•\nDurante la backpropagation, adattare ogni \n ﬁ\nltro ad una particolare \ncaratteristica saliente.  \n•\nLa possibilità di usare lo stesso \n ﬁ\nltro in diverse zone dell'immagine garantisce la \ntranslational simmetry\n , cioè possiamo riconoscere la caratteristica in diverse \nposizioni. Una rete Fully connected (\n FC\n) potrebbe riconoscere una caratteristica \nin una posizione stimando certi parametri, ma non sarebbe in grado di \nriutilizzarli in altre posizioni.\n18",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#18": "Canali multipli in input\nAbbiamo già visto l'operatore di convoluzione in presenza di più canali.  \nSe in ingresso abbiamo più canali, es. RGB, \n c\ni\n > 1, allora il \n ﬁ\nltro \nrappresentato dal tensore \n k\nh\n × \nk\nw\n dovrà essere ripetuto per ogni canale. Se \nconcateniamo i tensori abbiamo un tensore \n c\ni \n× k\nh\n × \nk\nw\n. \nIl risultato sarà un tensore 2d poiché il risultato delle singole convoluzioni \nsarà sommato nella dimensione dei canali.  \nAd esempio, considerando 2 canali in input:\n19\n",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#19": "Canali multipli in output\nNelle CNN tradizionalmente il numero di canali aumentano con il numero \ndi layer processati, generalmente riducendo allo stesso tempo la risoluzione \nspaziale degli input.  \nIdealmente ogni canale rappresenterà un different set di features, ma in \nrealtà le features possono essere \n sparse\n  su più canali.  \nPer avere un output multicanale, creiamo più tensori \n c\ni \n× k\nh\n × \nk\nw \n, ognuno \nper singolo canale in output. Se li concateniamo otteniamo un kernel  \nc\no \n× c\ni \n× k\nh\n × \nk\nw\n .\n20",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#2": "CNN - Struttura gerarchica\n3Input layer:  \nÈ un layer costituito da unità  \na cui viene associato il valore  \ndei singoli pixel dell'immagine.  \nNon c'è reale elaborazione.Primo convolutional layer\nSecondo convolutional layerData una instanza in input, nodi vicini nel convolutional layer layer saranno attivati in base \nalle features estratte da una certa zona dell'input. Astrazione delle features\nNota : Nelle tradizionali MLP , input bidimensionali [N, M] (es. immagini in bianco e nero) sono \ncomunemente ridimensionati a vettori , ovvero matrici di dimensioni [NxM, 1].  \nNelle CNN  tale ridimensionamento è controproducente  poiché si perderebbe l'informazione relativa alla \nvicinanza delle features in input. Struttura gerarchica\n Nell' input layer  le features  \ncorrispondono ai singoli pixel",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#20": "CNN: Feature Maps e Canali\n21...Input\nConvolutional layer 2\nConvolutional layer 1\nUna immagine a colori con 3 matrici \nassociate ai canali RGB, cioè 3 \ncanali.Possiamo de ﬁnire un certo numero di \nﬁltri (es. 12) per riconoscere diverse \ncaratteristiche salienti dell'immagine \niniziale. I ﬁltri analizzano \ncontemporaneamente 3 canali RGB, \nperciò i ﬁltri saranno de ﬁniti con \nmatrici a 3 dimensioni. Un ﬁltro \napplicato all'immagine in input \nproduce un singolo convolutional layer.I successivi layer convoluzionali \nanalizzato le attivazioni di più ﬁltri \ncontemporaneamente. I ﬁltri di questo \nlayer riconosceranno caratteristiche \npiù astratte.depth = 3 depth = 12 depth = 7",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#21": "TensorFlow: Padding\nTensorFlow fornisce il parametro \n padding\n  che può assumere due valori:  \n•\n\"\nVALID\n \" nel caso in cui si voglia ignorare il padding  \n•\n\"\nSAME\n \" per aggiungere automaticamente righe e colonne composte da \nvalori 0 in modo bilanciato per garantire che il LRF scorra l'intera matrice \nin input.\n2201234567891011121300 12345678910111213\nsenza padding ('VALID' ) con padding ('SAME' )ignorati\nstride=5padding P=+3",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#22": "Stride, padding e Keras\nLe dimensioni del kernel e i restanti iperparametri sono de\n ﬁ\nniti via \ncostruttore del modello Conv2D:  \n# numero di kernels pari a 1  \nconv2d = tf.keras.layers.Conv2D(\n 1\n, kernel_size=\n 3\n, padding=\n 'same'\n, strides=\n 2\n) \nconv2d = tf.keras.layers.Conv2D(\n 1\n, kernel_size=(\n 3\n,\n5\n), padding=\n 'valid'\n, strides=(\n 3\n, \n4\n)) ",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#23": "Tuning delle CNN\nRispetto a una MLP abbiamo \n molti più iperparametri da stimare\n : \nNumero di \n ﬁ\nltri per layer (o \n depth\n ) \nDimensione del LRF  \nStride e padding  \nInvece di usare tecniche automatiche per il tuning,\n  ci si ispira ad \narchitetture già studiate \n in letteratura per avere una con\n ﬁ\ngurazione \nverosimilmente già ottimizzata.\n24",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#24": "Risorse di memoria: considerazioni\nLa backpropagation richiede di memorizzare tutti i valor intermedi calcolati \ndurante la forward propagation\n . \n•\nAd esempio, \n convolutional layer \n con \nﬁ\nltri 5\n 5 e con 200 feature maps di \ndimensione 150\n 100 con stride 1 e padding SAME: se in input abbiamo \nimmagini RGB 150\n 100, il numero di \n parametri\n  è (5\n 5\n3+1)\n 200 = \n 15.200  \n•\nNella \n MLP\n, un layer 150\n 100 completamente connesso col layer in input \nrichiederebbe 150\n 100\n 150\n 100\n 3 = \n67.5M di parametri\n . \n•\nOgnuna delle 200 mappe contiene 150\n 100 nodi, ed ogni nodo ricava \nl'attivazione valutando 5\n 5\n3 input, che corrispondono a \n 225 milioni di \nmoltiplicazioni\n  in virgola mobile.  \n•\nCon \nﬂ\noat di \n 32bit\n  il layer di output impiega 200\n 150\n 100\n 32 = \n 11.5Mb \ncirca\n  per ogni istanza. Per 100 istanze il layer occuperebbe più di un \n 1Gb\n. \nIn produzione, le attivazioni di un layer possono essere dimenticate appena i \ncalcoli sul layer successivo sono terminati, richiedendo molta meno memoria \n(cioè al massimo quella di 2 layer contemporaneamente). \n×\n×\n×\n ×\n×\n ×\n×\n×\n ×\n ×\n ×\n×\n×\n×\n×\n ×\n ×\n25",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#25": "Pooling layer\nRipetendo i layer convolutivi, ad ogni layer il \n receptive \n ﬁ\neld\n sarà \n sensibile  \nad una parte sempre maggiore in riferimento all'immagine iniziale. Perciò \ngli ultimi nodi della rete saranno attivati in base all'intera informazione \npresente nell'immagine iniziale.  \nSpesso l'informazione spaziale esatta delle features riconosciute non è \nimportante, soprattutto se ci interessa l'invarianza ad eventuali translazione \ndell'input.  \nI pooling layer sono utili per:  \nmitigare la sensitività\n  dei layer convolutivi rispetto alle posizioni delle \nfeatures  \nridurre la dimensionalità dell'input da elaborare\n .\n26",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#26": "Pooling layer (1)\nI \nlayer di pooling \n ha lo scopo di \n ridurre il numero di parametri \n operando un \ncampionamento\n  (o \ndown-sampling\n ) dei dati. I vantaggi sono i seguenti:  \n•\nMeno complessità computazione  \n•\nMeno risorse di memoria  \n•\nMeno parametri (e ridurre l'over\n ﬁ\ntting come effetto collaterale)  \nCome nel convolutional layer, \n ogni nodo è connesso con un numero limitato di \nnodi del layer precedente \n posizionati in un certo LRF.  \n•\nOccorre de\n ﬁ\nnire dimensione, stride e padding  \nIl \npooling layer non ha parametri.\n  Opera semplicemente una \"\n aggregazione\n \" dei \nvalori associati ai nodi, ad esempio calcolando \n media\n  o \nvalore massimo\n . \nSpesso il calcolo è fatto per ogni canale in input, cioè su un singolo strato alla volta \nrispetto all'intera profondità del layer precedente (es. sul canale R, G e B \nseparatamente).  \n•\nLa profondità (numero di layer) in uscita corrisponderà a quella che si ha in \ningresso. \n27",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#27": "Pooling layer (2)\nNon ha parametri da inferire\n , ma solo iperparametri, cioè dimensione del \nﬁ\neld (\npooling size\n ), il \npooling stride\n , e tipo di aggregazione.  \n•\nSpesso pooling size e stride corrispondono.  \nIn molti scenari \n non è fondamentale la posizione esatta di una certa \ncaratteristica\n , ma il fatto che esista in una certa zona, o che sia identi\n ﬁ\ncata \nuna certa sequenza (o pattern) di features senza considerare esattamente le \nrispettive distanze reciproche.  \n•\nAd esempio, nella face detection ho interesse a riconoscere due occhi \nvicini, ma non mi interessa la distanza esatta.  \nEsistono \n due tipi principali di aggregazione\n : \n•\nmax-pooling:  \nun nodo assume l’attivazione massima tra i valori presenti \nnel \nﬁ\neld considerato.  \n•\naverage pooling:\n  considero il valor medio nel \n ﬁ\neld.\n28",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#28": "Esempio: Pooling layer\nNell'esempio il pooling kernel è di 2\n 2, lo stride pari a 2, padding VALID e \naggregazione max.  \n•\nIl layer di output contiene il 75% in meno dei valori del layer precedente.\n×\n29\nA causa del padding VALID  \nil valore di alcuni nodi sarà ignorato.\nSe in input abbiamo un canale con un layer NN,  fpo è il pooling size , spo il pooling stride ,  \n \nuna dimensione del layer di output è:  ×\nN−fpo\nspo+1",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#29": "CNN: Convolutional layer e dimensione output\nLa dimensione dell'output di un \n convolutional layer\n  si ricava a \npartire dalla dimensione dell'input e dal valore degli iperparametri.  \nSe per semplicità assumiamo input \n N\nN\n, e la dimensione del \n LRF \n \nf\nh\n = f\n w\n = \nf\n, lo stride \n s,\n e le righe (o colonne) \n p\n aggiunte come \npadding, allora una delle due dimensione del layer di output è la \nseguente:  \n \nLa dimensione in output perciò corrisponde a \n O\nO.\n×\nO\n=\nN\n−\nf\n+\np\ns\n+\n1\n×",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#3": "CNN - Esempio di attivazione di un nodo \nL'attivazione di un nodo in un layer convoluzionale si ottiene \nanalizzando l’output dal layer precedente per mezzo del \n LRF\n. \nEsempio: la funzione d’attivazione (\n σ\n) per il nodo <\n l\n,\nk\n> si valuta \nconsiderando il bias \n b\n e la matrice \n W\n di dimensione \n f\nh  \nf\nw \nassociati al \nLRF, in questo caso pari a 3\n 3. \n \nW\n e \nb\n sono i parametri da determinare.  \ni\n e \nj\n sono gli offset riferiti al \n LRF\n. \nSe la \n ﬁ\nnestra scorre un passo alla volta allora \n l\n e \nk\n fanno riferimento \nall’origine della \n ﬁ\nnestra del \n LRF\n.\n×\n×\nσ\n(\nb\n+\n2\n∑\ni\n=\n0\n2\n∑\nj\n=\n0\nw\ni\n,\nj\n⋅\nx\ni\n+\nl\n,\nj\n+\nk\n)\nijlk\nLRF",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#30": "AlexNet\n  (2012) è una delle prime architetture di reti neurali che combina CNN e \nGPU nell'ambito della classi\n ﬁ\ncazione degli oggetti.\nEsempio: calcolo parametri AlexNetoutput depth = 96input depth = 3\nRicordiamoci  che il local receptive ﬁeld  \nha una profondità pari a quella dell’inputEsempi di calcolo dei parametri nel primo layer \nhidden:  \n•Dim. immagine in Input = 227 227 3 \n•Dim. LRF = 11 11 \n•Stride = 4; padding VALID  \n•Numero ﬁltri (o depth) = 96  \n•L’output per ogni ﬁltro avrà dimensione di lato \n(227-11)/4 + 1 = 55. Cioè 55 55 per ﬁltro. \n•Considerando la profondità si ha: 55x55x96 \n=290.400 nodi.  \n•L'attivazione di un nodo si ricava considerando \n11x11x3 nodi del layer precedente.  \n•In una MLP si avrebbero 105.415.200 parametri.  \n•Per la proprietà degli shared weights, nella CNN il \nnumero di parametri sarà 11x11x3x96 + 96 = \n34.944.  × ×\n×\n×\nfeature mapscomputazione",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#31": "Architettura LeNet-5 per OCR\nLeNet-5\n  (1989) è una delle prime architetture CNN.  \n•\nE' stata ideata per fare OCR garantendo un errore <1% su MNIST.  \nCombina layers \n CNN\n  con una rete tradizionale \n MLP\n a valle.  \n•\nLo scopo è di impiegare le caratteristiche salienti identi\n ﬁ\ncate dalle CNN \nper fare classi\n ﬁ\ncazione per mezzo della MLP.  \n•\nUna rete interamente \n MLP fully connected avrebbe richiesto molti più \nparametri\n  per ottenere le stesse prestazioni.",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#32": "Demo LeNet-5\nda http://yann.lecun.com/exdb/lenet/  ",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#33": "Architettura LeNet-5\nconvolutional layer#1 conv. laye r\nfeature maps:  \n28x28, depth 6#3 conv. layer  \nfeature maps:  \n10x10, depth 16\navg.  \npoolingconv. layeravg.  \npooling#2 pooling laye r\nfeature maps:  \n14x14, depth 6#4 pooling laye r\nfeature maps:  \n5x5, depth 16\nconv. layer#6 fully connected layer  \nnodi 84#5 conv. layer  \nfeature maps:  \n1x1, depth 120\nImmagini  \n32x32x1 (gray scale)LRF\nL'output dell'ultimo \nconvolution layer è \nconvertito in un vettore \n120x1, adatto come input di \nun fully connected layer.\nLa ReLU non era ancora \nstata approfondita ai tempi di \nLeNet-5. Si è impiegata la \npiù tradizionale tanh.#7 fully connected layer  \nnodi 10\nLa con ﬁgurazione degli \niperparametri e la dimensione \ndell'input non necessita di \nimpiegare il padding.",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#34": "LeNet-5: esempio di \n ﬁ\nltri\nNel caso del dataset MNIST di caratteri numerici (immagini 28x28), \notteniamo \n ﬁ\nltri di questo tipo:  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#4": "CNN - LRF\n5Output layer precedente•In un certo layer convoluzionale , un nodo con indice (i, j) prende in input  gli output dei nodi \ndel layer precedente posizionati all'interno del LRF .\n•la regione LRF  va dalla riga  i alla riga i+f h-1, e dalla colonna j alla colonna j+f w-1\n•fh e fw corrispondono all'altezza e larghezza del LRF . \n•i e j sono indici che scorrono da 1 a dim x-fh-1 e dim y-fh-1\nIl convolutional layer è \nrappresentato da una \ngriglia bidimensionale \nche contiene il risultato \ndelle attivazioni .forward propagation\nEsempio con LRF 3x3  \ncon stride pari a 1.<------ padding ------>\n<------ padding ------><------ dim x ------>\n<--- dimy -->\nPadding  \n(discusso più avanti)\n•Notazioni: rispetto alle slide precedenti 2Δ=fh=fw",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#5": "Cross-correlazione\nSupponendo \n K\n il kernel e \n X\n l'input 2d, possiamo de\n ﬁ\nnire la funzione \n corr2d\n () che \nrestituisce un output di dimensioni pari all'input, meno la dimensione del kernel \n + \n1\n: \nimport \ntensorflow  \nas \ntf \nfrom \nd2l \nimport\n tensorflow \n as\n d2l \ndef \ncorr2d\n(X, K):  \n    h, w = K.shape  \n    Y = tf.Variable(tf.zeros((X.shape[\n 0\n] - h + \n 1\n, X.shape[\n 1\n] - w + \n 1\n))) \n    \n for\n i \nin \nrange\n(Y.shape[\n 0\n]): \n        \n for\n j \nin \nrange\n(Y.shape[\n 1\n]):         \n            # estraggo la parte di X che mi interessa  \n            # calcolo una moltiplicazione element-wise tra le matrici  \n            # ricavo infine la somma  \n            Y[i, j].assign(tf.reduce_sum(  \n                X[i: i + h, j: j + w] * K))  \n    \n return\n Y \nX = tf.constant([[\n 0.0\n, \n1.0\n, \n2.0\n], [\n3.0\n, \n4.0\n, \n5.0\n], [\n6.0\n, \n7.0\n, \n8.0\n]]) \nK = tf.constant([[\n 0.0\n, \n1.0\n], [\n2.0\n, \n3.0\n]]) \ncorr2d(X, K)  \n<tf.Variable \n 'Variable:0'\n  shape=(\n 2\n, \n2\n) dtype=float32, numpy=  \narray([[\n 19.\n, \n25.\n], \n       [\n 37.\n, \n43.\n]], dtype=float32)>  \nNota\n : l'operatore di \n convoluzione\n  è simile all'operatore \n cross-correlazione\n , ma nel \nprimo il kernel è \"\n capovolto\" \n durante il calcolo. Nelle CNN si impiega usualmente \nla cross-correlazione. Non c'è differenza poiché i pesi ricavati durante \nl'addestramento sono i medesimi, ma con ordine invertito. Spesso nei testi e nel \ncodice i due termini assumono lo stesso signi\n ﬁ\ncato.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#6": "Esempio di modello Conv2D\nclass \nConv2D\n(tf.keras.layers.Layer):  \n    \n def \n__init__\n (\nself\n): \n        \n super\n().\n__init__\n () \n    \n def \nbuild\n(\nself\n, kernel_size):  \n        initializer = tf.random_normal_initializer()  \n        \n self\n.weight = \n self\n.add_weight(name=\n 'w'\n, shape=kernel_size,  \n                                      initializer=initializer)  \n        \n self\n.bias = \n self\n.add_weight(name=\n 'b'\n, shape=(\n 1\n, ), \n                                    initializer=initializer)  \n    \n def \ncall\n(\nself\n, inputs):  \n        \n return\n corr2d(inputs, \n self\n.weight) + \n self\n.bias",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#7": "Esempio: riconoscimento bordi\nSupponiamo che vogliamo riconoscere il bordoe in una immagine \nmonitorando il cambio del valore dei pixel.  \nCostruiamo una immagine 6x8 nel seguente modo:  \nX = tf.Variable(tf.ones((\n 6\n, \n8\n))) \nX[:, \n2\n:\n6\n].assign(tf.zeros(X[:, \n 2\n:\n6\n].shape))  \n<tf.Variable \n 'Variable:0'\n  shape=(\n 6\n, \n8\n) dtype=float32, numpy=  \narray([[\n 1.\n, \n1.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n, \n1.\n, \n1.\n], \n       [\n 1.\n, \n1.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n, \n1.\n, \n1.\n], \n       [\n 1.\n, \n1.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n, \n1.\n, \n1.\n], \n       [\n 1.\n, \n1.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n, \n1.\n, \n1.\n], \n       [\n 1.\n, \n1.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n, \n1.\n, \n1.\n], \n       [\n 1.\n, \n1.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n, \n1.\n, \n1.\n]], dtype=float32)>  \nCostruiamo un kernel 1x2  \nK = tf.constant([[\n 1.0\n, -\n1.0\n]]) \nCon la crosscorrelazione, l'output è 0 quando due elementi adiacenti \ndell'input sono uguali, altrimenti un valore diverso da 0.  \nNota\n : la crosscorrelazione corrisponde ad una approssimazione \ndiscreta della derivata del primo ordine.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#8": "Esempio: riconoscimento bordi\nSi nota il risultato +1 nei bordi da bianco a nero, -1 da nero a bianco:  \nY = corr2d(X, K)  \nY \n<tf.Variable \n 'Variable:0'\n  shape=(\n 6\n, \n7\n) dtype=float32, numpy=  \narray([[ \n 0.\n,  \n1.\n,  \n0.\n,  \n0.\n,  \n0.\n, -\n1.\n,  \n0.\n], \n       [ \n 0.\n,  \n1.\n,  \n0.\n,  \n0.\n,  \n0.\n, -\n1.\n,  \n0.\n], \n       [ \n 0.\n,  \n1.\n,  \n0.\n,  \n0.\n,  \n0.\n, -\n1.\n,  \n0.\n], \n       [ \n 0.\n,  \n1.\n,  \n0.\n,  \n0.\n,  \n0.\n, -\n1.\n,  \n0.\n], \n       [ \n 0.\n,  \n1.\n,  \n0.\n,  \n0.\n,  \n0.\n, -\n1.\n,  \n0.\n], \n       [ \n 0.\n,  \n1.\n,  \n0.\n,  \n0.\n,  \n0.\n, -\n1.\n,  \n0.\n]], dtype=float32)>  \nTrasponendo l'immagine, il kernel non individua più i bordi:  \ncorr2d(tf.transpose(X), K)  \n<tf.Variable \n 'Variable:0'\n  shape=(\n 8\n, \n5\n) dtype=float32, numpy=  \narray([[\n 0.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n], \n       [\n 0.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n], \n       [\n 0.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n], \n       [\n 0.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n], \n       [\n 0.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n], \n       [\n 0.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n], \n       [\n 0.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n], \n       [\n 0.\n, \n0.\n, \n0.\n, \n0.\n, \n0.\n]], dtype=float32)>",
    "data_test\\rootfolder\\università\\DeepLearning\\05-CNN parte 2-sbloccato.pdf#9": "Kernel: training\nAl principio non abbiamo kernel precostituiti, dobbiamo ottenerli \ndurante l'addestramento, soprattutto se abbiamo molti layer convolutivi \nin cascata. Il procedimento è simile al caso MLP, es:  \n# Un layer convolutivo, 2d con 1 canale in output, un kernel 1x2  \n# Per semplicità ignoriamo i bias ora  \nconv2d = tf.keras.layers.Conv2D(\n 1\n, (\n1\n, \n2\n), use_bias=\n False\n) \n# L'input è nella forma (batch_size, height, width, channel),  \n# dove batch size e canali sono entrambi 1  \nX = tf.reshape(X, (\n 1\n, \n6\n, \n8\n, \n1\n)) \nY = tf.reshape(Y, (\n 1\n, \n6\n, \n7\n, \n1\n)) \nlr = \n3e-2  \n# Learning rate  \nY_hat = conv2d(X)  \nfor\n i \nin \nrange\n(\n10\n): \n    \n with\n tf.GradientTape(watch_accessed_variables=\n False\n) \nas\n g: \n        \n # indichiamo noi le variabili su cui operare il gradiente  \n        g.watch(conv2d.weights[\n 0\n]) \n        Y_hat = conv2d(X)  \n        l = (\n abs\n(Y_hat - Y)) ** \n 2 \n        \n # aggiornamento kernel  \n        update = tf.multiply(lr, g.gradient(l, conv2d.weights[\n 0\n])) \n        weights = conv2d.get_weights()  \n        weights[\n 0\n] = conv2d.weights[\n 0\n] - update  \n        conv2d.set_weights(weights)  \n        \n if\n (i + \n1\n) % \n2\n == \n0\n: \n            \n print\n(\nf'epoch \n {\ni + \n1\n}\n, loss \n{\ntf.reduce_sum(l)\n :\n.3f\n}\n'\n) \nepoch \n2\n, loss \n17.533 \nepoch \n4\n, loss \n3.607 \nepoch \n6\n, loss \n0.878 \nepoch \n8\n, loss \n0.259 \nepoch \n10\n, loss \n0.089 \n# monitoriamo i tensori ottenuti  \ntf.reshape(conv2d.get_weights()[\n 0\n], (\n1\n, \n2\n))",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nConvolutional Neural Networks (CNN)  \n3a parte\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#1": "Sommario\nCalcolo del numero dei parametri  \nLeNet-5 e calcolo dei parametri  \nArchitettura AlexNet  \n1x1 convolution",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#10": "CNN - Esercizio\nSe le tue GPU non hanno memoria suf\n ﬁ\nciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema?\n11",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#11": "CNN - Esercizio\nSe le tue GPU non hanno memoria suf\n ﬁ\nciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema?  \n1.\nRidurre la \n dimensione del mini-batch\n .\n12",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#12": "CNN - Esercizio\nSe le tue GPU non hanno memoria suf\n ﬁ\nciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema?  \n1.\nRidurre la \n dimensione del mini-batch\n . \n2.\nRidurre la \n dimensionalità nella rete\n , ad esempio con stride > 1 in uno o più \nlayers, o con pooling layers.  \n•\nAnche un convolutional layer riduce la dimensione del layer precedente ma, a \ndifferena del pooling layer, introduce ulteriori parametri da apprendere.\n13",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#13": "CNN - Esercizio\nSe le tue GPU non hanno memoria suf\n ﬁ\nciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema?  \n1.\nRidurre la \n dimensione del mini-batch\n . \n2.\nRidurre la \n dimensionalità nella rete\n , ad esempio con stride > 1 in uno o più \nlayers, o con pooling layers.  \n•\nAnche un convolutional layer riduce la dimensione del layer precedente ma, a \ndifferena del pooling layer, introduce ulteriori parametri da apprendere.  \n3.\nCambiare l'architettura \n rimuovendo un layer\n .\n14",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#14": "CNN - Esercizio\nSe le tue GPU non hanno memoria suf\n ﬁ\nciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema?  \n1.\nRidurre la \n dimensione del mini-batch\n . \n2.\nRidurre la \n dimensionalità nella rete\n , ad esempio con stride > 1 in uno o più \nlayers, o con pooling layers.  \n•\nAnche un convolutional layer riduce la dimensione del layer precedente ma, a \ndifferena del pooling layer, introduce ulteriori parametri da apprendere.  \n3.\nCambiare l'architettura \n rimuovendo un layer\n . \n4.\nUsare rappresentazioni  \nﬂ\noat a 16\n  bit invece che 32.\n15",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#15": "CNN - Esercizio\nSe le tue GPU non hanno memoria suf\n ﬁ\nciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema?  \n1.\nRidurre la \n dimensione del mini-batch\n . \n2.\nRidurre la \n dimensionalità nella rete\n , ad esempio con stride > 1 in uno o più \nlayers, o con pooling layers.  \n•\nAnche un convolutional layer riduce la dimensione del layer precedente ma, a \ndifferena del pooling layer, introduce ulteriori parametri da apprendere.  \n3.\nCambiare l'architettura \n rimuovendo un layer\n . \n4.\nUsare rappresentazioni  \nﬂ\noat a 16\n  bit invece che 32.  \n5.\nDistribuire la computazione\n  su più elaboratori.\n16",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#16": "Architettura CNN più recenti\nNe sono state proposte molte. Anche se sviluppate in un particolare task di \ncomputer vision, esse sono state impiegate in modo pro\n ﬁ\ncuo in altri domini, es. \ntracking, segmentation, object detection, style transformation.  \nLa challenge ImageNet (dal 2010) è favorito lo sviluppo di molte architetture.  \nLe CNN sono relativamente semplici, ma creare una architettura ef\n ﬁ\nciente \nrichiede intuizione, una base algebrica, e molti tentativi.  \nSpeso nuove architetture sfruttano elementi di architetture precedenti.",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#17": "Architettura CNN più recenti #1\nSebbene LeNet sia ef\n ﬁ\nciente per il problema OCR, non si adatta facilmente a \ndataset più grandi ed eterogenei. Effettivamente dal 1995 (LeNet) al 2012 (AlexNet) \nsono state proposte tecniche ML alternative (es. kernels, ensemble, structured \nestimation) ef\n ﬁ\ncienti in molti tasks.  \nPerché abbiamo atteso così a lungo per avere una rete più versatile e capace di \ncompetere con le altre architetture ML?  \nNel anni '90 una scheda GPU come la NVIDIA GeForce 256 era capace di 480 \nMFLOP, senza la disponibilità di framework software per sempli\n ﬁ\ncare la \nprogrammazione. Oggi la NVIDIA Ampere A100 raggiunge i 300 TFLOPS . Un \ndataset di cifre a bassa risoluzione (28x28) era considerato molto arduo da trattare.  \nIn pratica, era molto complesso testare architetture GPU-based anche su \ndataset semplici.  \nI \ndati disponibili\n  adatti all'addestramento sono aumentati sensibilmente, e questo \nha garantito la sperimentazione di un numero maggiore di architetture.  \nImageNet è stato costruito mediante Google Image e per mezzo di Amazon \nMechanical Turk per la classi\n ﬁ\ncazione manuale.",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#18": "LeNet vs AlexNet\nAlexNet ha 8 layers: 5 convolutivi, 2 FC nascosti, 1 FC output.  \nUsa la ReLU invece delle sigmoid o tanh.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#19": "Architettura AlexNet\nArchitettura CNN vincitrice della challenge object detection ILSVRC 2012 con un \ntop-5 error del 17% (il secondo ha ottenuto 26%) sviluppata da Alex Krizhevsky e \nIlya Sutskever.  \nPrimo tentativo di sfruttare piattaforme hardware GPU-enabled per addestrare reti \ncomplesse.  \nE' molto simile a \n LeNet-5\n  ma con più profondità.\nDopo i 5 convolutional \nlayers (11x11, 5x5 e 3x3) \nc'è il max pooling, e una \nrete FC da 3 layer.  \nImpiega ReLI, SGD e \nmomentum.  \n \nLa doppia pipeline è \ndovuta all’hardware \nimpiegato per \nl’addestramento (2 NVIDIA \nGTX 580s con 3Gb).",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#2": "Calcolo del numero di parametri di una rete neurale\nIl calcolo del numero di parametri è\n  fondamentale per \ncomprendere la complessità \n della rete e apportare miglioramenti \nall'architettura (es. introducendo pooling layer per ridurre i \nparametri).  \nIl calcolo dipende dal tipo di layer che stiamo considerando e dai \nvalori ricevuti dal layer precedente.  \nConsideriamo il calcolo del numero di parametri per le seguenti \ncon\nﬁ\ngurazioni:  \nUn \nConvolutional layer \n seguito da un \n FC layer\n   (\nCONV\n FC\n) \nUn\n Input layer \n seguito da un \n Convolutional layer\n  (\nI\nFC\n) \nUn \nFC layer \n seguito da un \n FC layer \n (\nFC\n FC\n)\n→\n→\n→",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#20": "Architettura AlexNet (2)\nLe immagini di ImageNet sono 8x più grandi rispetto a MNIST.  \nI LRF del primo strato sono 11x11, 5x5 nel secondo e 3x3 nel terzo.  \nDopo il primo, il secondo e 5o strato convolutivo, c'è un \n max-pooling layers\n  con \nﬁ\nnestra 3x3 e uno stride pari a 2.  \nAlexNet ha 10 volte i canali di LeNet.  \nLa rete FC multi-layer ha 1Gb di parametri. La doppia pipeline di elaborazione \npermetteva di suddividere l'occupazione.  \nIl numero elevato di parametri rende AlexNet poco ef\n ﬁ\nciente rispetto ad \narchitetture più recenti.  \nLa ReLU rende la computazione dei gradienti più rapida. Inoltre se \nl'inizializzazione dei parametri porta a valori di attivazione vicini ad 1 o 0 \n(estremi dell'intervallo) la derivata è vicina allo 0, e questo rallenta \nl'aggiornamento dei pesi. Il gradiente della ReLU è sempre 1 per valori positivi.  ",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#21": "Architettura AlexNet (3)\nImpiega \n dropout\n  sugli strati FC, e \n data augumentation\n . Nei layer C1 e C3 impiega \nla \nLocal response normalization:\n  se un nodo riceve una attivazione signi\n ﬁ\ncativa, \nsi inibiscono i nodi nella stessa posizione ma in altre feature maps.  \nIl dropout nei layer FC prende il posto del weight decay della LeNet. Questo \ngarantisce una sorta di regolarizzazione dei parametri  \n•\nL'ipotesi è quella di favorire la competitività, specializzando ogni feature map su \ncaratteristiche distinte.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#22": "Esempio: Filtri di AlexNet\nEsempi di \n ﬁ\nltri dei primi layer di Alex Net dopo l'addestramento:\n",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#23": "AlexNet e Keras\n08-AlexNet.ipynb",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#24": "La \n1\n1 convolution\n  è un \n ﬁ\nltro di dimensione \n 1\n1\nC\n e (ovviamente) si \napplica a input con profondità \n C\n. \n•\nPuò essere vista come una \n rete neurale con un layer,\n  che prende in input \nun vettore di \n C\n elementi.  \n•\nPer \nC\n pari a \n 1 \nnon viene impiegato  \n•\nUn \nﬁ\nltro 1\n 1\n1 corrisponde ad una moltiplicazione per uno scalare, operazione \ninutile in una rete neurale.  \nA cosa può servire?\n×\n ×\n×\n×\n×\nCNN: 1\n 1 convolution\n×\noutput layer precedente :\nsupponi una profondità C > 1feature map  \navrà la stessa \ndimensione dell'input \nma profondità pari a 1\ndimensione LRF : \n11C××",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#25": "CNN: 1x1 convolution (2)\nEffettua un \n feature pooling\n  cioè combina linearmente più features legate tra \nloro da un certa legame spaziale (es. i 3 valori dei canali RGB di un pixel).  \n•\nUtile quando si hanno feature maps con grande profondità e si vuole ridurre \nil numero di paremetri nei layer successivi.  \n•\nMentre il \n pooling\n  tradizionale aggrega più feature vicine all'interno della \nstessa feature map.  \nSe in input abbiamo una feature maps con profondità \n C\n, ogni mappa \nrappresenterà l'importanza di una diversa feature in una certa posizione. La  \n1\n1 convolution\n  raccoglie le informazioni di \n C\n features diverse valutate nella \nstessa posizione per determinare un singolo output.\n×\n1x1 conv\nLa profondità è passata da 32 a 1.  \nImpiegano n ﬁltri 1x1 conv, \notteniamo una profondità n della \nfeature maps in output.",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#26": "CNN: 1x1 convolution (3)\nOltre a ridurre il numero di parametri nei layer successivi in presenza di \nfeature maps con grande profondità, la \n 1\n1 convolution\n  viene usata \nanche per creare nuove \n proiezioni  \nlineari\n  a partire dalle feature map \ncorrenti.  \n•\nLe proiezioni creazioni \n nuove features\n  determinate dalla combinazioni \ndi più feature maps nei layer precedenti. \n×\n+verso i layer successivi...",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#3": "I \nparametri\n  consistono nell’insieme dei \n pesi e bias\n  nel layer convoluzionale, che \nprodurranno i valori delle attivazioni nelle feature maps.  \n•\nIl layer di input non ha pesi associati.  \nSe indichiamo con:  \n•\n#\nW\nc\n e #\nB\nc \nil numero di pesi e bias del layer convoluzionale  \n•\nf\n la dimensione del LRF  \n•\nN\nc\n numero dei \n ﬁ\nltri nel convolutional layer  \n•\nC\n profondità delle istanze in input (es. 3 per immagine a colori RGB)  \nallora si ha:  \n#\nW\nc\n = f\n2 \n C \n N\nc \n    e    #\n B\nc\n = N\n c \nLo stesso risultato si ottiene per con\n ﬁ\ngurazioni \n CONV\n CONV\n , considerando come \nprofondità \n C\n la profondità delle feature maps nel layer precedente.  \nSi nota come il numero di parametri è indipendente dalla dimensione X,Y dell'input.\n×\n×\n→\nCalcolo del numero dei parametri: \n I\nFC\n→",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#4": "I \nparametri\n  consistono nell’insieme dei \n pesi e bias\n  del layer FC connesso alle \nfeature maps prodotte dal convolutional layer precedente.  \nSe indichiamo con:  \n•\n#\nW\ncf\n e #\nB\ncf  \nil numero di pesi e bias del layer FC  \n•\nO\n dimensione delle feature maps nel convolutional layer, supponendo larghezza e \naltezza coincidenti.  \n•\nN\nc\n numero dei \n ﬁ\nltri nel convolutional layer  \n•\nF\n numero dei nodi nel layer FC  \nallora si ha:  \n#\nW\ncf\n = O\n2 \n N\nc \n F \n   e   \n #B\ncf\n = F  \nSpesso si opera una \"\n linearizzazione\n \" dell'output del convolutional layer. Se \nabbiamo \n N\nc \nﬁ\nltri e una dimensione delle feature maps pari a OxO, introduciamo \nuna rappresentazione 1-dimensionale con un vettore di \n O\n2\n• N\n c\n elementi, passato in \ninput al layer fully-connected.\n×\n×\nCalcolo del numero dei parametri: \n CONV\n FC\n→",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#5": "I \nparametri\n  consistono nell’insieme dei \n pesi e bias\n  del layer FC connesso al FC \nprecedente.  \nSe indichiamo con:  \n•\n#\nW\nff\n e #\nB\nff \n il numero pesi e bias del layer FC  \n•\nF\n il numero di nodi nel layer FC  \n•\nF\n-1\n il numero di nodi nel layer FC precedente  \nallora si ha:  \n#W\n ff\n = F\n -1 \n F\n    e   \n #B\nff\n = F\n ×\nCalcolo del numero dei parametri: \n FC\n FC\n→",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#6": "LeNet-5: numero di parametri\nIndichiamo con \n f\n, \ns\n e \np\n rispettivamente la dimensione del \n ﬁ\nltro, stride e \npooling (dove 0 corrisponde al pooling VALID).\nNon è un vero layer ,\nma una linearizzazione dei \ndati: rendiamo ﬂat la \nrappresentazion e\n5x5x16 -> 40028x28x6  \nfeature maps di 6 ﬁltri \ndi dimensione 28x28 l'uno\n14x14x6  \nun pooling layer con f e s pari \na 2 dimezza le dimensioni ,\nma mantiene uguale la dept h\ndella feature maps.",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#7": "LeNet-5: numero di parametri (2)\nDopo la convoluzione \nabbiamo 6 ﬁltri 28x28. Dopo il pooling abbiamo  \n6 ﬁltri 14x14\nInvece di avere 240000 \nparametri ne abbiamo \n151600 (vedi commento \ndopo).Stesso procedimento di S2 \nma ora abbiamo 16 ﬁltriPooling\nPoolingncl-1 è la profondità  \ndel  layer precedente. \nsupponiamo input depth = 1  \ncioè scala di grigiil pooling layer non  \naltera la profondità\nognuno dei 28x28 in output \nha 5x5x6 connessioni col \nlayer precedente, cioè \nl’immagine in input.Connections =  \n28x28 x 5x5x1x6 = 117600\nConnections =  \n10x10x5x5x6x10 = 150000",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#8": "LeNet-5: peculiarità\nNel #3 hidden layer, con lo scopo di ridurre potenziali simmetrie e il numero di \nconnessioni, gli autori hanno deciso che\n  solo 10 delle 16 features maps sono connesse \ncon le 6 features maps del layer precedente\n .  \nLa tecnica \n dropout\n  introdotta solo successivamente ha automatizzato questo step, \nperciò non si riscontra in architetture più recenti.\nSchema di interconnessione tra feature maps impiegato.\nConnections =  \n10x10x5x5x6x10 = 150000",
    "data_test\\rootfolder\\università\\DeepLearning\\06-CNN parte 3-sbloccato.pdf#9": "LeNet-5: numero di parametri (3)\nRendiamo “ ﬂat” l’output \nprecedente.  Abbiamo 400 \n(5x5x16) nodi dal layer S4. \nIl primo strato fully \nconnected layer ha 120 nodi. \nOgni nodo del layer è \nconnesso con i 400 nodi \ndello strato precedente.Fully connected layer con \n84 neuroni.softmax",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nConvolutional Neural Networks (CNN)  \n4a parte - Architetture\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#1": "Sommario\nArchitetture avanzate CNN  \nVGG  \nNiN \nGoogleNet",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#10": "Poiché le risorse di calcolo necessarie alla VGG sono molto \nmaggiori di AlexNet, costruiamo una rete con un numero minore di \ncanali, suf\n ﬁ\ncienti per il dataset Fashion-MNIST.  \ntrainer = d2l.Trainer(max_epochs=\n 10\n) \ndata = d2l.FashionMNIST(batch_size=\n 128\n, resize=(\n 224\n, \n224\n)) \nwith\n d2l.try_gpu():  \n    model = VGG(arch=((\n 1\n, \n16\n), (\n1\n, \n32\n), (\n2\n, \n64\n), (\n2\n, \n128\n), (\n2\n, \n128\n)), lr=\n0.01\n) \n    trainer.fit(model, data)  \nC'è una similarità tra val_loss e train_loss, con un discostamento \nminimale che può rappresentare un piccolo over\n ﬁ\ntting.\nTraining VGG Network e Keras\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#11": "L'upsampling di Fashion-MNIST di un fattore 8 (da 28x28 a \n224x224) è molto inef\n ﬁ\nciente. Prova a modi\n ﬁ\ncare l'architettura per \ntrattare immagini 28x28.\nVGG - Esercizio",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#12": "Rispetto a LeNet, AlexNet e VGG intervengono principalmente \ncreando strutture (conv_layer + pooling) più \"profonde\" e più \n\"ampie\".  \nMa i layer FC \n ﬁ\nnali richiedono ancora molti parametri.  \nUna semplice VGG-11 richiede matrici 25088x4096, con una \noccupazione di 400Mb di RAM (FP32). Non adatti a sistemi \nembedded e mobile.  \nL'architettura Network in network (NiN) blocks consiste in un 1x1 \nconv layer che aggiunge non-linearità tra le attivazioni dei canali, e \nun \nglobal average pooling\n  nell'ultimo layer.\nNetwork in Network (NiN)",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#13": "Rimpiazza i layer FC di una rete CNN tradizionale con un pooling.  \nPrende in input un tensore 3d (height,width,channels) e ricava \nl'avg rispetto al dimensione channels.  \nL'idea è generare una feature map per ogni categoria di interesse nel \ntask nei layer \n ﬂ\nattening, inviando l'output direttamente alla softmax.  \nIntroduce una sorta di codi\n ﬁ\nca più diretta tra feature maps e \ncategorie di interesse. Le feature maps possono essere interpretate \ncome \n mappe di con\n ﬁ\ndenze con le categorie\n . \nNon ci sono i parametri tradizionali, e si evitano fenomeni di \nover\nﬁ\ntting.  \nÈ più robusto a traslazioni spaziali poiché l'operazione considera \ntutte le informazioni spaziali disponibili.\nGlobal average pooling\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#14": "Ricordiamo che l'input e output dei conv layers sono tensori 4d: \nistanze, channel, height e width.  \nL'input e output di un layer FC sono tensori 2d (istanze, features).  \nL'idea è applicare un FC layer a ogni posizione di pixel (per ogni \nheight e width). La rete risultante 1x1 conv può essere interpretata \ncome un layer FC indipendente per ogni pixel.  \nIl blocco NiN è costituito da un conv layer seguito da convoluzioni \n1x1. \nIn questo modo non c'è necessità di una grossa rete FC al termine \ndell'architettura.\nBlocchi NiN",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#15": "La rete NiN usa le stesse dimensioni dei \n ﬁ\nltri di AlexNet: 11x11, 5x5 \ne 3x3; e le stesse dimensioni dei canali di output.  \nLe conv net sono seguite da pooling layer 3x3 con stride 2.  \nNiN non include FC layer. Il numero dei canali di output dei blocchi \nNiN corrispondono al numero di classi del task, seguite da un \nglobal average pooling\n , ottenendo un vettore di logits.  \nL'architettura riduce il numero di parametri a scapito del tempo di \ntraining, più lungo.\nArchitettura NiN",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#16": "Architettura NiN\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#17": "NiN in codice Keras:  \nimport\n tensorflow \n as\n tf\n!\npip install d2l==\n 1.0.0\na1.post0\nfrom\n d2l \nimport\n tensorflow \n as\n d2\nl\ndef \nnin_block\n (out_channels, kernel_size, strides, padding):  \n    \n return\n tf.keras.models.Sequential([  \n    tf.keras.layers.Conv2D(out_channels, kernel_size, strides=strides,  \n                           padding=padding),  \n    tf.keras.layers.Activation(\n 'relu'\n), \n    tf.keras.layers.Conv2D(out_channels, \n 1\n), \n    tf.keras.layers.Activation(\n 'relu'\n), \n    tf.keras.layers.Conv2D(out_channels, \n 1\n), \n    tf.keras.layers.Activation(\n 'relu'\n)])\nBlocco NiN in Keras",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#18": "class \nNiN\n(d2l.Classifier):  \n    \n def \n__init__\n (\nself\n, lr=\n0.1\n, num_classes=\n 10\n): \n        \n super\n().\n__init__\n () \n        \n self\n.save_hyperparameters()  \n        \n self\n.net = tf.keras.models.Sequential([  \n            nin_block(\n 96\n, kernel_size=\n 11\n, strides=\n 4\n, padding=\n 'valid'\n), \n            tf.keras.layers.MaxPool2D(pool_size=\n 3\n, strides=\n 2\n), \n            nin_block(\n 256\n, kernel_size=\n 5\n, strides=\n 1\n, padding=\n 'same'\n), \n            tf.keras.layers.MaxPool2D(pool_size=\n 3\n, strides=\n 2\n), \n            nin_block(\n 384\n, kernel_size=\n 3\n, strides=\n 1\n, padding=\n 'same'\n), \n            tf.keras.layers.MaxPool2D(pool_size=\n 3\n, strides=\n 2\n), \n            tf.keras.layers.Dropout(\n 0.5\n), \n            nin_block(num_classes, kernel_size=\n 3\n, strides=\n 1\n, padding=\n 'same'\n), \n            tf.keras.layers.GlobalAvgPool2D(),  \n            tf.keras.layers.Flatten()])  \nmodel = NiN()  \nX = tf.random.normal((\n 1\n, \n224\n, \n224\n, \n1\n)) \nfor\n layer \n in\n model.net.layers:  \n    X = layer(X)  \n    \nprint\n(layer.\n__class__\n .\n__name__\n ,\n'output shape:\n \\t\n'\n, X.shape)  \nSequential output shape:     (\n 1\n, \n54\n, \n54\n, \n96\n) \nMaxPooling2D output shape:   (\n 1\n, \n26\n, \n26\n, \n96\n) \nSequential output shape:     (\n 1\n, \n26\n, \n26\n, \n256\n) \nMaxPooling2D output shape:   (\n 1\n, \n12\n, \n12\n, \n256\n) \nSequential output shape:     (\n 1\n, \n12\n, \n12\n, \n384\n) \nMaxPooling2D output shape:   (\n 1\n, \n5\n, \n5\n, \n384\n) \nDropout output shape:        (\n 1\n, \n5\n, \n5\n, \n384\n) \nSequential output shape:     (\n 1\n, \n5\n, \n5\n, \n10\n) \nGlobalAveragePooling2D output shape:         (\n 1\n, \n10\n) \nFlatten output shape:        (\n 1\n, \n10\n)\nArchitettura NiN in Keras",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#19": "model = NiN(lr=\n 0.05\n) \ntrainer = d2l.Trainer(max_epochs=\n 10\n, num_gpus=\n 1\n) \ndata = d2l.FashionMNIST(batch_size=\n 128\n, resize=(\n 224\n, \n224\n)) \nmodel.apply_init([\n next\n(\niter\n(data.get_dataloader(\n True\n)))[\n0\n]], d2l.init_cnn)  \ntrainer.fit(model, data)  \nTraining NiN in Keras\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#2": "Networks Using Blocks (VGG)\nSebbene \n AlexNet\n  abbia permesso di ottenere buone performance in \ndiversi task, non fornisce dei \n template\n  per la realizzazione di nuove \narchitetture.  \nIl Visual Geometry Group Oxford University ha de\n ﬁ\nnito \nl'architettura VGG che consiste in strutture ripetute de\n ﬁ\nnite per \nmezzo di istruzioni di loop e subroutines.  \nIl \nblocco\n  fondamentale della CNN è una sequenza di (i) \nconvolutional layer con padding (ii) nonlinearità come la ReLU, (iii) \npooling layer per ridurre la risoluzione.  \nIl problema di questo approccio è che la risoluzione spaziale si \nriduce abbastanza rapidamente. Introduce il limite rigido di \n log\n2\nd \nlayer convolutivi prima che tutte le dimensioni (\n d\n) si esauriscano.  \nPer esempio per \n ImageNet\n  non si possono avere più di 8 layer.",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#20": "CNN: Alcune problematiche \nNei seguenti esempi riconosciamo un cane, ma la posizione e \ndimensione dell’animale sono molto diverse tra loro.  \n•\nNon è facile determinare la giusta dimensione (e il numero) dei \nﬁ\nltri negli strati iniziali.  \nE nonostante le tecnologie di apprendimento introdotte, in \narchitetture molto deep (con molti strati) può sempre riproporsi il \nvanishing gradient problem\n . \n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#21": "CNN: Inception module (GoogleNet)\nL'\ninception module\n  si basa sulla ipotesi che \n combinare\n  le \ninformazioni provenienti da diverse pipeline di processamento basate \nconvolutional layer permetta di estendere le caratteristiche salienti \nidenti\n ﬁ\ncate. \n•\nPiù convolution layer in parallelo\n , ognuno con una \n diversa \ndimensione dei \n ﬁ\nltri\n. Gli output dei convolution layers sono \n\"combinati\" in una singola struttura che consisterà nell'input per il \nlayer successivo.  \n•\nSi impiegano \n ﬁ\nltri con dimensioni pari a \n 1x1\n, \n3x3\n e \n5x5\n, tutti con \nstride 1\n , \nSAME\n  padding e \n ReLU\n  activation function.  \nIn pratica si processa lo stesso input contemporaneamente \nconsiderando più dimensioni di LRF.  \nL'inception module è stato impiegato per la prima volta \nnell'architettura \n GoogleLeNet\n .",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#22": "CNN: Inception module (GoogleNet)\nGoogleNet ha vinto la challenge ImageNet 2015 con una struttura \nche combina le caratteristiche di NiN, blocchi ripetuti, e un mix di \nkernel convolutivi.  \nCrea una distinzione tra:  \nstem\n (data ingest), primi 2-3 conv layers per estrarre feature a \nbasso livello  \nbody\n  (data processing), serie di blocchi convolutivi  \nhead\n  (prediction), per problemi di classi\n ﬁ\ncation, segmentation, \ndetection, o tracking.  \nL'idea è combinare l'output di più conv layer con diverse \ndimensioni in un unico output ",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#23": "Inception module\nL'input è dato contemporaneamente a \n 3 convolution layers\n  e un \n 3x3 \nmax pooling\n .  \n•\nLe \n1x1 convolution \n \"\ncomprimono\n \" la profondità dell'input, utili \nsoprattutto per \n sempli\n ﬁ\ncare i dati in input \n alle convoluzioni 3x3 e \n5x5 che richiedono risorse computazionali.  \n•\nLa combinazione \n 1x1+3x3\n  e \n1x1+5x5\n  hanno più possibilità di \nrappresentare \n feature più complesse \n rispetto ai singoli 3x3 e 5x5.  \n•\nSperimentalmente si nota come gli inception module sono più \nef\nﬁ\ncienti se usati negli layer più a valle.\nInception module\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#24": "Architettura GoogLeNet v1\nL’architettura vincitrice della object detection challenge ILSRC 2014 \nraggiungendo un top-5 error < 7%.  \nLa principale caratteristica è la profondità: \n 22 layer\n  (27 considerando anche i \npooling layers) con 9 \n inception module\n  in cascata.  \n•\nDopo ogni \n inception module\n  si opera una average pooling per ridurre il \nnumero di parametri.  \n•\nSebbene più profonda, possiede 1/10 dei parametri di AlexNet (6 milioni \ncirca)\nAltre tecniche impiegate: batch \nnormalization, image distortions e RMSprop?? inception module",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#25": "Architettura GoogLeNet v1 (2)\nL’\noutput di due inception module intermedi (3º e 6º inception module) è valutato \npreliminarmente nel task della classi\n ﬁ\ncazione \n per mezzo di una softmax.  \nSi affrontare il problema del \n vanishing gradient problem\n , dato che si generano \ngradienti addizionali negli hidden layer lontani dall'ultimo layer.  \nIl valore della loss intermedia è chiamato \n auxiliary loss\n . Durante il training \nviene combinato linearmente (scalato del 70%) con la loss dell'intera rete.  \nIn produzione e nel test set non vengono impiegati.  \nNota\n : le versioni v2, v3 e v4 di GoogleNet introducono molti espedienti per \nrendere più ef\n ﬁ\nciente il training e migliorare l’accuracy.\nauxiliary classi ﬁerauxiliary classi ﬁer",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#26": "GoogLeNet: esempio di \n ﬁ\nltri\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#27": "Inception e Keras\nimport\n tensorflow \n as\n tf\n!\npip install d2l==\n 1.0.0\na1.post0\nfrom\n d2l \nimport\n tensorflow \n as\n d2\nl\nclass \nInception\n (tf.keras.Model):  \n    \n# `c1`--`c4` sono il numero di canali in output per ogni ramo  \n    \n def \n__init__\n (\nself\n, c1, c2, c3, c4):  \n        \n super\n().\n__init__\n () \n        \n self\n.b1_1 = tf.keras.layers.Conv2D(c1, \n 1\n, activation=\n 'relu'\n) \n        \n self\n.b2_1 = tf.keras.layers.Conv2D(c2[\n 0\n], \n1\n, activation=\n 'relu'\n) \n        \n self\n.b2_2 = tf.keras.layers.Conv2D(c2[\n 1\n], \n3\n, padding=\n 'same'\n, \n                                           activation=\n 'relu'\n) \n        \n self\n.b3_1 = tf.keras.layers.Conv2D(c3[\n 0\n], \n1\n, activation=\n 'relu'\n) \n        \n self\n.b3_2 = tf.keras.layers.Conv2D(c3[\n 1\n], \n5\n, padding=\n 'same'\n, \n                                           activation=\n 'relu'\n) \n        \n self\n.b4_1 = tf.keras.layers.MaxPool2D(\n 3\n, \n1\n, padding=\n 'same'\n) \n        \n self\n.b4_2 = tf.keras.layers.Conv2D(c4, \n 1\n, activation=\n 'relu'\n) \n    \n def \ncall\n(\nself\n, x): \n        b1 = \n self\n.b1_1(x)  \n        b2 = \n self\n.b2_2(\nself\n.b2_1(x))  \n        b3 = \n self\n.b3_2(\nself\n.b3_1(x))  \n        b4 = \n self\n.b4_2(\nself\n.b4_1(x))  \n        \n return\n tf.keras.layers.Concatenate()([b1, b2, b3, b4])",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#28": "GoogleNet e Keras\nUno stack di 9 blocchi \n inception, \n organizzati in 3 gruppi \nintramezzati da max-pooling per ridurre le dimensioni, e un global \naverage pooling per generare l'ultimo output prima del FC layer.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#29": "GoogleNet e Keras\nclass \nGoogleNet\n (d2l.Classifier):  \n    \n def \nb1\n(\nself\n): \n        \n return\n tf.keras.models.Sequential([  \n            tf.keras.layers.Conv2D(\n 64\n, \n7\n, strides=\n 2\n, padding=\n 'same'\n, \n                                   activation=\n 'relu'\n), \n            tf.keras.layers.MaxPool2D(pool_size=\n 3\n, strides=\n 2\n, \n                                      padding=\n 'same'\n)]) \n@d2l\n.add_to_class(GoogleNet)  \ndef \nb2\n(\nself\n): \n    \n return\n tf.keras.Sequential([  \n        tf.keras.layers.Conv2D(\n 64\n, \n1\n, activation=\n 'relu'\n), \n        tf.keras.layers.Conv2D(\n 192\n, \n3\n, padding=\n 'same'\n, activation=\n 'relu'\n), \n        tf.keras.layers.MaxPool2D(pool_size=\n 3\n, strides=\n 2\n, padding=\n 'same'\n)]) \n@d2l\n.add_to_class(GoogleNet)  \ndef \nb3\n(\nself\n): \n    \n return\n tf.keras.models.Sequential([  \n        Inception(\n 64\n, (\n96\n, \n128\n), (\n16\n, \n32\n), \n32\n), \n        Inception(\n 128\n, (\n128\n, \n192\n), (\n32\n, \n96\n), \n64\n), \n        tf.keras.layers.MaxPool2D(pool_size=\n 3\n, strides=\n 2\n, padding=\n 'same'\n)]) ",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#3": "VGG Blocks\nL'idea è di impiegare convoluzioni multiple e distinte tra periodici \ndownsampling (eg. max-pooling) sotto forma di unico blocco \nfunzionale.  \nL'ipotesi che \n diverse dimensioni di convoluzioni (deep e wide) \npossono meglio rappresentare le features signi\n ﬁ\ncative\n .  \nPer esempio 3x3 convolutions interessa gli stessi pixel della 5x5 \nconvolutions. Ma l'ultima usa un numero di parametri (\n 25•c\n2\n) come \ntre 3x3 convolutions (\n 3•9•c\n2\n), cioè uno \n stacking\n  di convoluzioni \n3x3. Dimostrano che tali con\n ﬁ\ngurazioni (deep & narrow) ottengono \nprestazioni migliori.  \nLa dimensione della rete con stacking 3x3 può oltrepassare i 100 \nlayers, un approccio molto comune nelle moderne architetture.",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#30": "GoogleNet e Keras\n@d2l\n.add_to_class(GoogleNet)  \ndef \nb4\n(\nself\n): \n    \n return\n tf.keras.Sequential([  \n        Inception(\n 192\n, (\n96\n, \n208\n), (\n16\n, \n48\n), \n64\n), \n        Inception(\n 160\n, (\n112\n, \n224\n), (\n24\n, \n64\n), \n64\n), \n        Inception(\n 128\n, (\n128\n, \n256\n), (\n24\n, \n64\n), \n64\n), \n        Inception(\n 112\n, (\n144\n, \n288\n), (\n32\n, \n64\n), \n64\n), \n        Inception(\n 256\n, (\n160\n, \n320\n), (\n32\n, \n128\n), \n128\n), \n        tf.keras.layers.MaxPool2D(pool_size=\n 3\n, strides=\n 2\n, padding=\n 'same'\n)]) \n@d2l\n.add_to_class(GoogleNet)  \ndef \nb5\n(\nself\n): \n    \n return\n tf.keras.Sequential([  \n        Inception(\n 256\n, (\n160\n, \n320\n), (\n32\n, \n128\n), \n128\n), \n        Inception(\n 384\n, (\n192\n, \n384\n), (\n48\n, \n128\n), \n128\n), \n        tf.keras.layers.GlobalAvgPool2D(),  \n        tf.keras.layers.Flatten()])  \n@d2l\n.add_to_class(GoogleNet)  \ndef \n__init__\n (\nself\n, lr=\n0.1\n, num_classes=\n 10\n): \n    \nsuper\n(GoogleNet, \n self\n).\n__init__\n () \n    \nself\n.save_hyperparameters()  \n    \nself\n.net = tf.keras.Sequential([  \n        \n self\n.b1(), \nself\n.b2(), \nself\n.b3(), \nself\n.b4(), \nself\n.b5(), \n        tf.keras.layers.Dense(num_classes)])  ",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#31": "GoogleNet e Keras\nmodel = GoogleNet().layer_summary((\n 1\n, \n96\n, \n96\n, \n1\n)) \nSequential output shape:     (\n 1\n, \n24\n, \n24\n, \n64\n) \nSequential output shape:     (\n 1\n, \n12\n, \n12\n, \n192\n) \nSequential output shape:     (\n 1\n, \n6\n, \n6\n, \n480\n) \nSequential output shape:     (\n 1\n, \n3\n, \n3\n, \n832\n) \nSequential output shape:     (\n 1\n, \n1024\n) \nDense output shape:  (\n 1\n, \n10\n) \nmodel = GoogleNet().layer_summary((\n 1\n, \n96\n, \n96\n, \n1\n)) \nSequential output shape:     (\n 1\n, \n24\n, \n24\n, \n64\n) \nSequential output shape:     (\n 1\n, \n12\n, \n12\n, \n192\n) \nSequential output shape:     (\n 1\n, \n6\n, \n6\n, \n480\n) \nSequential output shape:     (\n 1\n, \n3\n, \n3\n, \n832\n) \nSequential output shape:     (\n 1\n, \n1024\n) \nDense output shape:  (\n 1\n, \n10\n) \ntrainer = d2l.Trainer(max_epochs=\n 10\n) \ndata = d2l.FashionMNIST(batch_size=\n 128\n, resize=(\n 96\n, \n96\n)) \nwith\n d2l.try_gpu():  \n    model = GoogleNet(lr=\n 0.01\n) \n    trainer.fit(model, data)  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#32": "GoogleNet - vantaggi\nGoogleNet richiede meno potenza di calcolo rispetto alle \narchitetture precedenti mantenendo una precisione più elevata.  \nL'approccio è basato sulla approssimazione dell'architettura senza \nandare a scapito delle prestazioni.  \nIntroduce un \n design by block\n , con iperparametri più \"ad alto livello\".",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#33": "Architetture AlexNet, VGG, NiN, GoogleNet\nEsercizio\n : valuta la differenza di prestazioni e i tempi di \naddestramento su medesimi dataset (FashionMNIST) o subset di \ndataset più complessi (ImageNet).",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#34": "Architetture CNN\nPrincipali architetture CNN per le immagini, complessità, numero di operazioni \nrichieste per l'addestramento e accuratezza.  \n35\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#35": "Esercizio su Inception v3 e classi\n ﬁ\ncazione di immagini\nProblema di classi\n ﬁ\ncazione di immagini usando Inception v3  \n•\nScarica alcune immagini di animali, ad esempio usando la funzion \nmatplotlib.image.mpimg.imread(). Ridimensionali e fai crop 299x299 pixel, \ncon 3 canali RGB.  \n•\nScarica i modelli pre-addestrati di Inception v3  \n•\nhttps://github.com/tensor\n ﬂ\now/models/tree/master/research/slim  \n•\nCrea il modello Inception v3 usando la funzione inception_v3() con \nis_training=False, num_classes=1001 nel seguente modo:  \nfrom \n tensor\n ﬂ\now.contrib.slim.nets \n import \n inceptio\n n\nimport \n tensor\n ﬂ\now.contrib.slim \n as \nsli\nm\nX \n= \ntf\n.\nplaceholder\n (\ntf\n.\nﬂ\noat32\n , \nshape\n =[\nNone\n , \n299\n, \n299\n, \n3\n]\n)\nwith \nslim\n.\narg_scope\n (\ninception\n .\ninception_v3_arg_scope\n ())\n:\nlogits\n , \nend_points \n = \ninception\n .\ninception_v3\n (\nX\n, \nnum_classes\n =\n1001\n , \nis_training\n =\nFalse\n )\npredictions \n = \nend_points\n [\n\"Predictions\"\n ]\nsaver \n = \ntf\n.\ntrain\n.\nSaver\n (\n)\n•\n...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#36": "Esercizio su Inception v3 e classi\n ﬁ\ncazione di immagini\n... Problema di classi\n ﬁ\ncazione di immagini usando Inception v3  \n•\nCrea una sessione e usa Saver per recuperare il modello pre-addestrato.  \n•\nLancia il modello per addestrare le immagini che hai scaricato visualizzando \nle top-5 predictions e la relativa probabilità.  \n•\nI nomi delle categorie le trovi qui: \n https://github.com/ageron/handson-ml/\nblob/master/datasets/inception/imagenet_class_names.txt  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#4": "VGG Blocks in Keras\nUn funzione che prende come parametri il numero di layer \nconvolutivi e il numero di channel di output  \nimport\n tensorflow \n as\n tf\n!\npip install d2l==\n 1.0.0\na1.post0\nfrom\n d2l \nimport\n tensorflow \n as\n d2l\ndef \nvgg_block\n (num_convs, num_channels):  \n    blk = tf.keras.models.Sequential()  \n    \n for\n _ \nin \nrange\n(num_convs):  \n        blk.add(  \n            tf.keras.layers.Conv2D(num_channels, kernel_size=\n 3\n, \n                                   padding=\n 'same'\n, activation=\n 'relu'\n)) \n    blk.add(tf.keras.layers.MaxPool2D(pool_size=\n 2\n, strides=\n 2\n)) \n    \n return\n blk",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#5": "L'architettura VGG e AlexNet a confronto, con i blocchi funzionali \nche si ripetono:\nVGG Network e AlexNet\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#6": "L'aspetto distintivo sono i layer convolutivi,raggruppati in \ntrasformazioni non lineari che medesima dimensione per gruppo.  \nSi impiegano \n ﬁ\nltri \n3x3\n con zero padding in modo da scorrere \nl'intera l'immagine.  \nSuccessivamente c'è lo step di riduzione della risoluzione (2x2 \npooling)  \nAl termine ci sono layer FC  \nNota: 100M di parametri nei FC in confronto dei 40M degli strati \nconvolutivi\nVGG Network",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#7": "VGG Network - Dettaglio parametri\n",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#8": "La prima parte della rete VGG è una successione di blocchi VGG.  \nLa conv_arch consiste in una lista di tuple (una per blocco), ognuna \nche contiene 2 valori: il numero di conv layers e il numero di \ncanali.  \nclass \nVGG\n(d2l.Classifier):  \n    \n def \n__init__\n (\nself\n, arch, lr=\n 0.1\n, num_classes=\n 10\n): \n        \n super\n().\n__init__\n () \n        \n self\n.save_hyperparameters()  \n        \n self\n.net = tf.keras.models.Sequential()  \n        \n for\n (num_convs, num_channels) \n in\n arch: \n            \n self\n.net.add(vgg_block(num_convs, num_channels))  \n        \n self\n.net.add(  \n            tf.keras.models.Sequential([  \n            tf.keras.layers.Flatten(),  \n            tf.keras.layers.Dense(\n 4096\n, activation=\n 'relu'\n), \n            tf.keras.layers.Dropout(\n 0.5\n), \n            tf.keras.layers.Dense(\n 4096\n, activation=\n 'relu'\n), \n            tf.keras.layers.Dropout(\n 0.5\n), \n            tf.keras.layers.Dense(num_classes)]))  \nVGG Network e Keras",
    "data_test\\rootfolder\\università\\DeepLearning\\07-CNN parte 4-sbloccato.pdf#9": "La VGG originale chiamata \n VGG-11\n  ha 5 blocchi: i primi 2 con un \nconv layer ognuno, e gli 3 con 2 conv layer ognuno. Il 1o blocco ha \n64 canali, e i successivi raddoppiato i canali, \n ﬁ\nno a 512.  \nVGG(arch=((\n 1\n, \n64\n), (\n1\n, \n128\n), (\n2\n, \n256\n), (\n2\n, \n512\n), (\n2\n, \n512\n))).layer_summary(  \n    (\n1\n, \n224\n, \n224\n, \n1\n)) \nSequential output shape:     (\n 1\n, \n112\n, \n112\n, \n64\n) \nSequential output shape:     (\n 1\n, \n56\n, \n56\n, \n128\n) \nSequential output shape:     (\n 1\n, \n28\n, \n28\n, \n256\n) \nSequential output shape:     (\n 1\n, \n14\n, \n14\n, \n512\n) \nSequential output shape:     (\n 1\n, \n7\n, \n7\n, \n512\n) \nSequential output shape:     (\n 1\n, \n10\n) \nLa dimensione \n ﬁ\nnale dopo la sequenza dei blocchi è 7x7, seguita \ndal \nﬂ\nattening e il successivo processamento FC.\nVGG Network e Keras",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nConvolutional Neural Networks (CNN)  \n5a parte - Batch Normalization e ResNet\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#1": "Sommario\nInternal covariate shift  \nBatch normalization  \nArchitettura Residual Network (ResNet)",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#10": "Batch Normalization layer\nPoiché la BN dipende dalla dimensione del mini batch, e perciò dai dati di \ntraining, non possiamo ignorarla quando de\n ﬁ\nniamo la nostra architettura.  \nPer reti FC si può applicare la BN tra la trasformazione lineare e il calcolo \ndella funzione di attivazione.  \nPer conv layers l'approccio è simile, ma consideriamo la BN per ogni \nsingolo canale, valutandola sui i dati sparsi spazialmente. Perciò ogni canale \navrà una stima diversa di media e deviazione standard.  \nQuesto è in linea col principio di \n invarianza spaziale\n , cioè nel calcolo \npossiamo ignorare l'informazione relativa alla posizione.\n11",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#11": "Batch Normalization - Altri vantaggi\nSi dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, \ngarantisce ulteriori bene\n ﬁ\nci:\n12",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#12": "Batch Normalization - Altri vantaggi\nSi dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, \ngarantisce ulteriori bene\n ﬁ\nci: \n•\nPermette di impiegare\n  funzioni di attivazione che saturano\n  per input molto \ngrandi o piccoli (es. logistic e tanh).\n13",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#13": "Batch Normalization - Altri vantaggi\nSi dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, \ngarantisce ulteriori bene\n ﬁ\nci: \n•\nPermette di impiegare\n  funzioni di attivazione che saturano\n  per input molto \ngrandi o piccoli (es. logistic e tanh).  \n•\nRiduce la dipendenza \n sugli effetti di una certa \n scelta dei parametri iniziali\n .\n14",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#14": "Batch Normalization - Altri vantaggi\nSi dimostra empiricamente che la BN, oltre a ridurre il vanishing gradients, \ngarantisce ulteriori bene\n ﬁ\nci: \n•\nPermette di impiegare\n  funzioni di attivazione che saturano\n  per input molto \ngrandi o piccoli (es. logistic e tanh).  \n•\nRiduce la dipendenza \n sugli effetti di una certa \n scelta dei parametri iniziali\n . \n•\nRichiamo: Introduce una certa \n regolarizzazione \n dei parametri, sebbene non \nsostituisce le tecniche più ef\n ﬁ\ncaci (es. dropout)  \n•\nRichiamo: Permette l'uso di \n learning rate più elevati\n , riducendo i tempi di \napprendimento.  \n•\nEs. Per un tipico task di image classi\n ﬁ\ncation, si ottengono incrementi x14.\n15",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#15": "Batch Normalization\nPerché non ci limitiamo a normalizzare i dati in input ad ogni layer  \ne lasciare alla rete determinare i parametri W per l'ottimalità input-output?\n16",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#16": "Batch Normalization\nPerché non ci limitiamo a normalizzare i dati in input ad ogni layer  \ne lasciare alla rete determinare i parametri W per l'ottimalità input-output?  \nSe impieghiamo funzioni di attivazioni logistiche, \n forziamo al rete a \nlavorare in regime di quasi-linearità\n , riducendo la capacità di costruire \nrelazioni input-output non lineari.\n17",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#17": "Batch Normalization e LeNet - Keras\nimport\n tensorflow \n as\n tf\n!\npip install d2l==\n 1.0.0\na1.post0\nfrom\n d2l \nimport\n tensorflow \n as\n d2\nl\nclass \nBNLeNet\n(d2l.Classifier):  \n    \ndef \n__init__\n (\nself\n, lr=\n0.1\n, num_classes=\n 10\n): \n        \n super\n().\n__init__\n () \n        \n self\n.save_hyperparameters()  \n        \n self\n.net = tf.keras.models.Sequential([  \n            tf.keras.layers.Conv2D(filters=\n 6\n, kernel_size=\n 5\n, \n                                   input_shape=(\n 28\n, \n28\n, \n1\n)), \n            tf.keras.layers.BatchNormalization(),  \n            tf.keras.layers.Activation(\n 'sigmoid'\n ), \n            tf.keras.layers.AvgPool2D(pool_size=\n 2\n, strides=\n 2\n), \n            tf.keras.layers.Conv2D(filters=\n 16\n, kernel_size=\n 5\n), \n            tf.keras.layers.BatchNormalization(),  \n            tf.keras.layers.Activation(\n 'sigmoid'\n ), \n            tf.keras.layers.AvgPool2D(pool_size=\n 2\n, strides=\n 2\n), \n            tf.keras.layers.Flatten(), tf.keras.layers.Dense(\n 120\n), \n            tf.keras.layers.BatchNormalization(),  \n            tf.keras.layers.Activation(\n 'sigmoid'\n ), \n            tf.keras.layers.Dense(\n 84\n), \n            tf.keras.layers.BatchNormalization(),  \n            tf.keras.layers.Activation(\n 'sigmoid'\n ), \n            tf.keras.layers.Dense(num_classes)])  \ntrainer = d2l.Trainer(max_epochs=\n 10\n) \ndata = d2l.FashionMNIST(batch_size=\n 128\n) \nwith\n d2l.try_gpu():  \n    model = BNLeNet(lr=\n 0.5\n) \n    trainer.fit(model, data)\n18\n",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#18": "Architettura Residual Network - Motivazioni\nIn generale, architetture di reti complesse (es. più profonde) possono stimare \nuna classe più ampia di funzioni. Ma se aggiungiamo layer, nessuno ci \ngarantisce che l'apprendimento ci permette di trovarle, anzi in taluni casi \npossiamo allontanarci dall'ottimo.  \nInoltre reti profonde potrebbero soffrire del vanishing gradient problem.  \nMa se aggiungiamo layer che mirano a stimare una funzione identità, i.e., \nf(x)=x, sicuramente manteniamo la stessa ef\n ﬁ\ncacia della rete iniziale.  \nL'ipotesi è che, i layer che aggiungiamo alla rete dovrebbero avere più \nprobabilità nel rappresentare funzioni identità per garantire prestazioni ottimali.",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#19": "Architettura Residual Network (ResNet)\nResNet\n  è stata presentata a ILSVRC 2015 (top-5: 3.6%) e consiste in 152 layers.  \nSi introducono le \n skip connections\n , che propagano l'output di un certo layer \nnell'input di un layer che è posizionato più a valle.   \n•\nL'ipotesi è di rendere \n più semplice e veloce propagare segnali \n su varie parti \ndella rete.  \n•\nNelle fasi iniziali (comportamento random) si obbliga parti della rete ad \ncomportarsi in modo da riproporre i valori in input, rendendo \n più veloce \nl'apprendimento\n .\n",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#2": "Motivazioni\nL'addestramento delle architetture Deep mostra alcune problematiche \naggiuntive oltre quelle già discusse per le MLP. Una signi\n ﬁ\ncativa è il tempo \nnecessario per addestrarle.  \nSpesso si operano \n standardizzazioni\n  nei valori delle features in ingresso con \nforme di pre-processamento, es:  \nimporre µ=0 (zero mean) o la unit-variance (cioè dividere per la stddev)  \nzero mean\n  sul valore delle features, considerando la singola istanza; spesso \nutile per dati con informazioni spaziali.  \nCi garantisce che durante l'addestramento i valori dei parametri rimangano in \nintervalli ottimali, sia considerando i layer per l'intera profondità della rete, sia \ntra i nodi di un singolo layer, sia tra i valori di ogni parametro per la durata \ndell'addestramento.",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#20": "ResNet: Residual learning e residual block\nAddestrare una rete neurale può essere interpretato come approssimare una \nfunzione h(\n x\n). Se aggiungi un valore x all'output della rete, allora la rete è \nobbligata a modellare la funzione f(\n x\n) = h(\n x\n) - \nx\n. Tale approccio è chiamato \nresidual learning o mapping\n . \nDal punto di vista operativo, è suf\n ﬁ\nciente combinare l'output di un layer con \nl'output di un layer posizionato più a monte prima di valutare la funzione di \nattivazione (ReLU).\n",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#21": "Architettura ResNet\nL'architettura ResNet impiega conv layer 3x3 (simili a VGG).  \nOgni blocco ResNet ha due 3x3 conv layer seguite dalla batch normalization e \nattivazione ReLU. Prima dell'ultima ReLU sommiamo l'input dalla skip \nconnection.  \nLa 1x1 conv layer è necessaria per adattare i canali dell'input con quelli \nottenuti a valle del blocco.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#22": "Blocco ResNet e Keras\nclass \nResidual\n (tf.keras.Model):  \n    \ndef \n__init__\n (\nself\n, num_channels, use_1x1conv=\n False\n, strides=\n 1\n): \n        \n super\n().\n__init__\n () \n        \n self\n.conv1 = tf.keras.layers.Conv2D(num_channels, padding=\n 'same'\n, \n                                            kernel_size=\n 3\n, strides=strides)  \n        \n self\n.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=\n 3\n, \n                                            padding=\n 'same'\n) \n        \n self\n.conv3 = \n None \n# dipende se vogliamo usare o meno il 1x1 conv layer  \n        \n if\n use_1x1conv:  \n            \n self\n.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=\n 1\n, \n                                                strides=strides)  \n        \n self\n.bn1 = tf.keras.layers.BatchNormalization()  \n        \n self\n.bn2 = tf.keras.layers.BatchNormalization()  \n    \ndef \ncall\n(\nself\n, X): \n        Y = tf.keras.activations.relu(\n self\n.bn1(\nself\n.conv1(X)))  \n        Y = \n self\n.bn2(\nself\n.conv2(Y))  \n        \n if \nself\n.conv3 \nis \nnot \nNone\n: \n            X = \n self\n.conv3(X)  \n        Y += X  \n        \n return\n tf.keras.activations.relu(Y)  \nblk = Residual(\n 3\n) \nX = tf.random.normal((\n 4\n, \n6\n, \n6\n, \n3\n)) \nY = blk(X)  \nY.shape \nTensorShape([\n 4\n, \n6\n, \n6\n, \n3\n]) ",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#23": "Architettura ResNet-18\nI primi layer di ResNet sono simili a GoogleNet, ma in ResNet si usa la Batch \nnormalization.  \nSeguono vari moduli ripetuti ResNet. La ResNet-18 include 18 layer totali, ma \nsi hanno modelli addestrati con molti più layer, es. ResNet-152.\n",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#24": "Architettura ResNet e Keras\nclass \nResNet\n(d2l.Classifier):  \n    \ndef \nb1\n(\nself\n): \n        \n return\n tf.keras.models.Sequential([  \n            tf.keras.layers.Conv2D(\n 64\n, kernel_size=\n 7\n, strides=\n 2\n, \n                                   padding=\n 'same'\n), \n            tf.keras.layers.BatchNormalization(),  \n            tf.keras.layers.Activation(\n 'relu'\n), \n            tf.keras.layers.MaxPool2D(pool_size=\n 3\n, strides=\n 2\n, \n                                      padding=\n 'same'\n)]) \n@d2l\n.add_to_class(ResNet)  \ndef \nblock\n(\nself\n, num_residuals, num_channels, first_block=\n False\n): \n    blk = tf.keras.models.Sequential()  \n    \nfor\n i \nin \nrange\n(num_residuals):  \n        \n if\n i == \n0 \nand \nnot\n first_block:  \n            blk.add(Residual(num_channels, use_1x1conv=\n True\n, strides=\n 2\n)) \n        \n else\n: \n            blk.add(Residual(num_channels))  \n    \nreturn\n blk \n@d2l\n.add_to_class(ResNet)  \ndef \n__init__\n (\nself\n, arch, lr=\n 0.1\n, num_classes=\n 10\n): \n    \nsuper\n(ResNet, \n self\n).\n__init__\n () \n    \nself\n.save_hyperparameters()  \n    \nself\n.net = tf.keras.models.Sequential(\n self\n.b1()) \n    \nfor\n i, b \nin \nenumerate\n (arch): \n        \n self\n.net.add(\n self\n.block(*b, first_block=(i==\n 0\n))) \n    \nself\n.net.add(tf.keras.models.Sequential([  \n        tf.keras.layers.GlobalAvgPool2D(),  \n        tf.keras.layers.Dense(units=num_classes)]))  ",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#25": "Architettura ResNet e Keras\nclass \nResNet18\n (ResNet):  \n    \ndef \n__init__\n (\nself\n, lr=\n0.1\n, num_classes=\n 10\n): \n        \n super\n().\n__init__\n (((\n2\n, \n64\n), (\n2\n, \n128\n), (\n2\n, \n256\n), (\n2\n, \n512\n)), \n                       lr, num_classes)  \nResNet18().layer_summary((\n 1\n, \n96\n, \n96\n, \n1\n)) \nSequential output shape:     (\n 1\n, \n24\n, \n24\n, \n64\n) \nSequential output shape:     (\n 1\n, \n24\n, \n24\n, \n64\n) \nSequential output shape:     (\n 1\n, \n12\n, \n12\n, \n128\n) \nSequential output shape:     (\n 1\n, \n6\n, \n6\n, \n256\n) \nSequential output shape:     (\n 1\n, \n3\n, \n3\n, \n512\n) \nSequential output shape:     (\n 1\n, \n10\n) \ntrainer = d2l.Trainer(max_epochs=\n 10\n) \ndata = d2l.FashionMNIST(batch_size=\n 128\n, resize=(\n 96\n, \n96\n)) \nwith\n d2l.try_gpu():  \n    model = ResNet18(lr=\n 0.01\n) \n    trainer.fit(model, data)  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#26": "CNN - Esercizio\nQuali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda \nGoogleLeNet e ResNet?\n27",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#27": "CNN - Esercizio\nQuali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda \nGoogleLeNet e ResNet?  \n•\nAlexNet\n  è più profonda e ampia rispetto a LeNet-5, e crea stack di \nconvolutional layer uno sull'altro, invece di alternarli con pooling layer.\n28",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#28": "CNN - Esercizio\nQuali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda \nGoogleLeNet e ResNet?  \n•\nAlexNet\n  è più profonda e ampia rispetto a LeNet-5, e crea stack di \nconvolutional layer uno sull'altro, invece di alternarli con pooling layer.  \n•\nGoogleNet\n  impiega inception modules, che permettono di avere reti ancora \npiù profonde ma con meno parametri rispetto alle precedenti.\n29",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#29": "CNN - Esercizio\nQuali sono le innovazioni di AlexNet rispetto a LeNet-5? E per quanto riguarda \nGoogleLeNet e ResNet?  \n•\nAlexNet\n  è più profonda e ampia rispetto a LeNet-5, e crea stack di \nconvolutional layer uno sull'altro, invece di alternarli con pooling layer.  \n•\nGoogleNet\n  impiega inception modules, che permettono di avere reti ancora \npiù profonde ma con meno parametri rispetto alle precedenti.  \n•\nResNet\n  introduce le skip connections, che permettono un numero di layer \noltre i 100. Anche la relativa semplicità la contraddistingue. \n30",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#3": "Motivazioni\nInoltre un layer che produce valori di attivazione molto elevati rispetto agli altri \n(es. x100) richiede aggiustamenti (es. modi\n ﬁ\ncando il learning rate in modo \nadattivo per produrre variazioni più ef\n ﬁ\ncaci durante il training).  \nIn\nﬁ\nne, per affrontare l'over\n ﬁ\ntting è spesso utile introdurre \n regolarizzazioni\n  sul \nvalore dei parametri (es. aggiungendo del rumore).",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#30": "Esercizio su CNN e MNIST\nProva costruire una tua architettura CNN (cioè con uno o più convolution \nlayers, pooling layers, etc) per raggiungere la migliore accuratezza per i \ndataset MNIST.  \n•\nMNIST dataset: \n http://yann.lecun.com/exdb/mnist/   \n•\nMNIST e Tensor\n ﬂ\now: \nhttps://www.tensor\n ﬂ\now.org/quantum/tutorials/mnist  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#4": "Internal covariate shift\nCon \nInternal covariate shift\n  si indica la circostanza in cui \n la distribuzione \ndei valori di attivazione nella rete cambia a causa della variazione dei \nparametri durante il training\n .  \n•\nFenomeno fondamentale nelle architetture deep (con molti layers).  \n•\nE' chiaro che i parametri in\n ﬂ\nuenzano le attivazioni, ma \n la distribuzione \ndei valori \n non dovrebbe alterarsi a causa dei parametri.  \n•\nIl vanishing/exploding gradient ricade in questa circostanza.  \n•\nReLU, e le sue varianti, riducono il fenomeno ma non lo escludono.  \nL'obiettivo è ridurre il \n covariance shift\n  all'interno della reti.\n5",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#5": "Batch Normalization\nLa \nbatch normalization\n  (\nBN\n) è una tecnica per affrontare tale problema. \nPrima della funzione di attivazione di ogni layer:  \n•\nNormalizza gli input\n , centrandoli in 0 e dividendoli per la deviazione \nstandard \n σ\n. \n•\nIntroduce \n 2 parametri\n , uno per determinare la \n scalatura\n  e uno per lo \n shift\n. \nTali parametri saranno soggetti ad addestramento.  \nDopo la normalizzazione \n la rete apprende il valore medio e la scala più \ngiusta degli input per ogni layer\n . \n•\nLa normalizzazione è frequente nei dati in ingresso degli approcci basati su \nML. La tecnica proposta estende tale tecnica ad ogni layer della rete.  \nPer normalizzare bisogna prima conoscere valor medio e varianza dei dati. \nSi stimano entrambi \n impiegando \n mini-batch,  \ncioè un piccolo sottoinsieme \ndel training set. Da questo il termine \n batch normalization\n .\n6",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#6": "Batch Normalization\nConsiste in un \n algoritmo\n  applicato ad ogni singola istanza in input \n x\ni\n, \nconsiderando un mini-batch \n B\n di \nm\n istanze con \n media  \n e \nvarianza   \nI parametri da apprendere durante il training sono \n γ\n (\nscale\n ) e \nβ\n (\noffset\n ). \nε\n è una costante aggiunta alla varianza per evitare divisione per 0 (es. 10\n-3\n)\nμ\nB\n σ\n2\nB\n7\nda Ioffe e Szegedy \"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\" 2015Trasformazione lineare",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#7": "Batch Normalization - Considerazioni\nLa tecnica BN può essere impiegata sui singoli layer, soprattutto sugli \nhidden, oppure all'intera rete.  \nLa stima di media e deviazione standard sono ricavate sul mini batch \ncorrente.  \nPossiamo interpretare i parametri \n scale\n  e \noffset\n  stimati durante \nl'apprendimento come un mezzo per \"recuperare\" i gradi di libertà persi a \ncausa della normalizzazione e limitarsi a considerare mini-batch invece \ndell'intero dataset.  \nCon mini-batch di dimensione adeguata (un iperparametro da de\n ﬁ\nnire) si \nraggiungono buoni incrementi di prestazioni e una \n stabilità\n  nell'andamento. \nMa richiede un tuning che dipende dai dati impiegati.  \nLa tecnica non permette al valore dei parametri di divergere. Inoltre permette \ndi incrementare il \n learning rate\n . \n8",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#8": "Batch Normalization - Considerazioni (2)\nPuò sembrare illogico introdurre approssimazioni nei valori di media e \ndeviazione standard, ma nella pratica rappresentano una sorta di rumore \nintrodotto arti\n ﬁ\ncialmente che garantisce tempi più rapidi e minor effetto \nover\nﬁ\ntting.  \nValori spesso ottimali della dimensione del mini batch sono 50-100 istanze, \nche garantiscono la giusta \n quantità di rumore\n  introdotto durante \nl'apprendimento.\n9",
    "data_test\\rootfolder\\università\\DeepLearning\\08-CNN parte 5-sbloccato.pdf#9": "Batch Normalization - Considerazioni (3)\nIn casi particolari \n γ\n e \nβ\n possono assumere valori tali da \"invertire\" il processo \ndi normalizzazione degli input del processo di \n batch normalization\n , se \nquesto garantisce l'ottimalità durante il training.  \nLa BN può essere vista come una \n trasformazione lineare\n , perciò facilmente \ndifferenziabile\n  durante il calcolo dei gradienti.  \nLa normalizzazione basata su mini-batch è essenziale per garantire \nl'ef\nﬁ\ncienza di tale tecnica, ma è inutile nel test e in produzione.  \nIn \nproduzione\n  vogliamo una rete che renda l'output dipendente \nunicamente e deterministicamente dall'input\n , perciò non in\n ﬂ\nuenzata \ndallo speci\n ﬁ\nco mini-batch.  \nPer tale motivo la normalizzazione sarà calcolata sull'intera popolazione \n {x} \ncon valori di media e varianza costanti durante l'elaborazione:\n10\n",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nL'addestramento delle reti neurali Deep\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#1": "Sommario\nMotivazioni dell'apprendimento speci\n ﬁ\nco per reti Deep  \nVanishing/Exploding gradients  \nLa funzione di attivazione softmax  \nInizializzazione dei parametri  \nFunzione di attivazione ReLU e variazioni  \nBatch normalization  \nGradient clipping  \nReusing Pretrained layers - Transfer learning  \nUnsupervised Pretraining  \nPretraining su Auxiliary tasks",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#10": "Inizializzazione di Xavier e He  \nSchema di dimostrazione\nImpiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché \nporre un vincolo sulla varianza?  \nConsideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore \nX\n di \nn\n elementi, con una matrice di pesi \n W \nsi ha:  \n                             \nVale anche:  \n                      \nSupponendo \n X\n e \ny\n indipendenti, vale la seguente uguaglianza:  \n             \nAvendo media pari a 0, si riduce a:   \nSupponendo \n w\ni\n e \nx\ni  \nindipendenti, e ogni \n w\ni\n (e \nx\ni\n) generato con stessa distribuzione, si ha:  \n  \nSe imponiamo che le due varianza \n  e \n  siano identiche, allora otteniamo:  \ny\n=\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\nσ\n2\n(\ny\n)\n=\nσ\n2\n(\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nμ\n(\nx\ni\n)\n2\nσ\n2\n(\nw\ni\n)\n+\nμ\n(\nw\ni\n)\n2\nσ\n2\n(\nx\ni\n)\n+\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\n=\nn\n⋅\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\n)\n=\n1\nn\n11",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#11": "Inizializzazione di Xavier e He  \nSchema di dimostrazione\nImpiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché \nporre un vincolo sulla varianza?  \nConsideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore \nX\n di \nn\n elementi, con una matrice di pesi \n W \nsi ha:  \n                             \nVale anche:  \n                      \nSupponendo \n X\n e \ny\n indipendenti, vale la seguente uguaglianza:  \n             \nAvendo media pari a 0, si riduce a:   \nSupponendo \n w\ni\n e \nx\ni  \nindipendenti, e ogni \n w\ni\n (e \nx\ni\n) generato con stessa distribuzione, si ha:  \n  \nSe imponiamo che le due varianza \n  e \n  siano identiche, allora otteniamo:  \ny\n=\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\nσ\n2\n(\ny\n)\n=\nσ\n2\n(\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nμ\n(\nx\ni\n)\n2\nσ\n2\n(\nw\ni\n)\n+\nμ\n(\nw\ni\n)\n2\nσ\n2\n(\nx\ni\n)\n+\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\n=\nn\n⋅\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\n)\n=\n1\nn\n12",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#12": "Inizializzazione di Xavier e He  \nSchema di dimostrazione\nImpiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché \nporre un vincolo sulla varianza?  \nConsideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore \nX\n di \nn\n elementi, con una matrice di pesi \n W \nsi ha:  \n                             \nVale anche:  \n                      \nSupponendo \n X\n e \ny\n indipendenti, vale la seguente uguaglianza:  \n             \nAvendo media pari a 0, si riduce a:   \nSupponendo \n w\ni\n e \nx\ni  \nindipendenti, e ogni \n w\ni\n (e \nx\ni\n) generato con stessa distribuzione, si ha:  \n  \nSe imponiamo che le due varianza \n  e \n  siano identiche, allora otteniamo:  \ny\n=\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\nσ\n2\n(\ny\n)\n=\nσ\n2\n(\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nμ\n(\nx\ni\n)\n2\nσ\n2\n(\nw\ni\n)\n+\nμ\n(\nw\ni\n)\n2\nσ\n2\n(\nx\ni\n)\n+\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\n=\nn\n⋅\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\n)\n=\n1\nn\n13",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#13": "Inizializzazione di Xavier e He  \nSchema di dimostrazione\nImpiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché \nporre un vincolo sulla varianza?  \nConsideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore \nX\n di \nn\n elementi, con una matrice di pesi \n W \nsi ha:  \n                             \nVale anche:  \n                      \nSupponendo \n X\n e \ny\n indipendenti, vale la seguente uguaglianza:  \n             \nAvendo media pari a 0, si riduce a:   \nSupponendo \n w\ni\n e \nx\ni  \nindipendenti, e ogni \n w\ni\n (e \nx\ni\n) generato con stessa distribuzione, si ha:  \n  \nSe imponiamo che le due varianza \n  e \n  siano identiche, allora otteniamo:  \ny\n=\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\nσ\n2\n(\ny\n)\n=\nσ\n2\n(\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nμ\n(\nx\ni\n)\n2\nσ\n2\n(\nw\ni\n)\n+\nμ\n(\nw\ni\n)\n2\nσ\n2\n(\nx\ni\n)\n+\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\n=\nn\n⋅\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\n)\n=\n1\nn\n14",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#14": "Inizializzazione di Xavier e He  \nSchema di dimostrazione\nImpiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché \nporre un vincolo sulla varianza?  \nConsideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore \nX\n di \nn\n elementi, con una matrice di pesi \n W \nsi ha:  \n                             \nVale anche:  \n                      \nSupponendo \n X\n e \ny\n indipendenti, vale la seguente uguaglianza:  \n             \nAvendo media pari a 0, si riduce a:   \nSupponendo \n w\ni\n e \nx\ni  \nindipendenti, e ogni \n w\ni\n (e \nx\ni\n) generato con stessa distribuzione, si ha:  \n  \nSe imponiamo che le due varianza \n  e \n  siano identiche, allora otteniamo:  \ny\n=\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\nσ\n2\n(\ny\n)\n=\nσ\n2\n(\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nμ\n(\nx\ni\n)\n2\nσ\n2\n(\nw\ni\n)\n+\nμ\n(\nw\ni\n)\n2\nσ\n2\n(\nx\ni\n)\n+\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\n=\nn\n⋅\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\n)\n=\n1\nn\n15",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#15": "Inizializzazione di Xavier e He  \nSchema di dimostrazione\nImpiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché \nporre un vincolo sulla varianza?  \nConsideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore \nX\n di \nn\n elementi, con una matrice di pesi \n W \nsi ha:  \n                             \nVale anche:  \n                      \nSupponendo \n X\n e \ny\n indipendenti, vale la seguente uguaglianza:  \n             \nAvendo media pari a 0, si riduce a:   \nSupponendo \n w\ni\n e \nx\ni  \nindipendenti, e ogni \n w\ni\n (e \nx\ni\n) generato con stessa distribuzione, si ha:  \n  \nSe imponiamo che le due varianza \n  e \n  siano identiche, allora otteniamo:  \ny\n=\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\nσ\n2\n(\ny\n)\n=\nσ\n2\n(\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nμ\n(\nx\ni\n)\n2\nσ\n2\n(\nw\ni\n)\n+\nμ\n(\nw\ni\n)\n2\nσ\n2\n(\nx\ni\n)\n+\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\n=\nn\n⋅\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\n)\n=\n1\nn\n16",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#16": "Inizializzazione di Xavier e He  \nSchema di dimostrazione\nImpiegare una distribuzione casuale gaussiana con media 0 sembra ragionevole, ma perché \nporre un vincolo sulla varianza?  \nConsideriamo un singolo neurone. Per un certo layer, se in input un vettore abbiamo un vettore \nX\n di \nn\n elementi, con una matrice di pesi \n W \nsi ha:  \n                             \nVale anche:  \n                      \nSupponendo \n X\n e \ny\n indipendenti, vale la seguente uguaglianza:  \n             \nAvendo media pari a 0, si riduce a:   \nSupponendo \n w\ni\n e \nx\ni  \nindipendenti, e ogni \n w\ni\n (e \nx\ni\n) generato con stessa distribuzione, si ha:  \n  \nSe imponiamo che le due varianza \n  e \n  siano identiche, allora otteniamo:  \ny\n=\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\nσ\n2\n(\ny\n)\n=\nσ\n2\n(\nw\n1\nx\n1\n+\nw\n2\nx\n2\n+\n.\n.\n.\n+\nw\nn\nx\nn\n+\nb\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nμ\n(\nx\ni\n)\n2\nσ\n2\n(\nw\ni\n)\n+\nμ\n(\nw\ni\n)\n2\nσ\n2\n(\nx\ni\n)\n+\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\nx\ni\n)\n=\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\n=\nn\n⋅\nσ\n2\n(\nw\ni\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\ny\n)\nσ\n2\n(\nx\ni\n)\nσ\n2\n(\nw\ni\n)\n=\n1\nn\n17",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#17": "Altre inizializzazioni\nRicerche più recenti adattano la suddetta inizializzazione considerando \ndiversi scenari di funzione attivazione\n , dove si distinguono per ogni layer il \nnumero di connessioni in input (\n n\ninputs\n) e in output (\n n\noutputs\n ). \nRiferimenti:  \n•\nHe et al. \n Delving Deep into Recti\n ﬁ\ners: Surpassing Human-Level Performance on ImageNet Classi\n ﬁ\ncation\n  2015\n18\nHu initialization →",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#18": "Inizializzazione dei pesi\nPerché non usiamo la \n zero initialization\n  (valori iniziali tutti uguali a 0)?\n19",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#19": "Inizializzazione dei pesi\nPerché non usiamo la \n zero initialization\n  (valori iniziali tutti uguali a 0)?  \n1.\nValori dei pesi prossimi allo 0 favoriscono i vanishing gradients \nproblem\n . \n•\nAllo stesso modo, valori troppo grandi \"saturano\" la logistic function, \ngenerando gradienti vicini allo 0.\n20",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#2": "Motivazioni\nAbbiamo visto architetture di Reti neurali (\n NN\n) con più strati (\n layer\n ), ognuno \ncomposto da molti nodi completamente connessi con i layer precedenti e \nsuccessivi (\n fully connected\n ). \nL'addestramento (training) di tali architetture mostra le seguenti \nproblematiche:  \n•\nVanishing gradients\n  o \nExploding gradients\n : che rendono la ricerca dei \nparametri molto dif\n ﬁ\ncile \n•\nLentezza\n : la stima di molti parametri richiede molto tempo  \n•\nOver\n ﬁ\ntting\n: la presenza di molti parametri aumenta la possibilità di \nover\nﬁ\ntting (cioè mancanza di generalizzazione).  \nPer tale motivo introduciamo\n  tecniche di addestramento speci\n ﬁ\nche\n per \naffrontarle, che permettono di de\n ﬁ\nnire architetture NN più complesse e \ndeep\n .\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#20": "Inizializzazione dei pesi\nPerché non usiamo la \n zero initialization\n  (valori iniziali tutti uguali a 0)?  \n1.\nValori dei pesi prossimi allo 0 favoriscono i vanishing gradients \nproblem\n . \n•\nAllo stesso modo, valori troppo grandi \"saturano\" la logistic function, \ngenerando gradienti vicini allo 0.  \n2.\nPer \nvalori prossimi allo 0 la logistic function si comporta in modo \nlineare\n .  \n•\nTale comportamento ci preclude l'addestramento di funzioni complesse e non \nlineari, anche in presenza di più layer.\n21",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#21": "Inizializzazione dei pesi\nPerché non scegliere un singolo valore random diverso da 0 per tutti i \npesi?\n22",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#22": "Inizializzazione dei pesi\nPerché non scegliere un singolo valore random diverso da 0 per tutti i \npesi?  \n1.\nAvere \n una rete inizializzata con gli stessi valori implica avere stessi \ngradienti e stessi aggiornamenti per ogni nodo di un layer\n .  \n•\nUno degli obiettivi della inizializzazione dei parametri è \n rompere eventuali \nsimmetrie\n  nel comportamento della rete.  \n•\nLa simmetria \n non permette di specializzare diversi neuroni su diversi scopi\n .  \n•\nUn layer con tutti nodi con lo stesso peso è equivalente ad un layer con un \nsingolo nodo.  \n•\nLa \nbackpropagation  \nnon è in grado di risolvere in modo adeguato questo tipo \ndi simmetrie\n .\n23",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#23": "Inizializzazione dei pesi\nPossiamo inizializzare il valore dei bias a 0?\n24",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#24": "Inizializzazione dei pesi\nPossiamo inizializzare il valore dei bias a 0?  \n•\nÈ possibile inizializzare i \n bias\n a 0, oppure seguire il procedimento di \ninizializzazione usato per i pesi \n w\n.\n25",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#25": "Inizializzazione dei pesi e softmax\nLa \nsoftmax\n  è spesso usata nella classi\n ﬁ\ncazione multi label.  \nTende a dare \n molta più probabilità\n  alle classi associate ai nodi che hanno in \noutput \n attivazione superiori agli altri,\n  soprattutto se l'intervallo dei valori \ndelle attivazioni è esteso.  \nSi cerca di ridurre questo intervallo (ad esempio con vincoli sulla varianza) \nper alleviare questo comportamento \"\n opinionated\n \", soprattutto nelle prime \nfasi di training.  \n•\nL'inizializzazione dei pesi è fondamentale.  \n•\nSi garantisce una esplorazione più ampia dello spazio di ricerca.\n26\n",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#26": "Nonsaturing activation functions\nLa \nlogistic function\n  è molto popolare, ed è in parte ispirata al \ncomportamento di un neurone \n ﬁ\nsico.  \nMa nelle architetture \n deep\n  è più conosciuta la:  \nRecti\n ﬁ\ned Linear Function  \nReLU :  \nf(x)=max(0,x)  \nFino a pochi anni fa la più popolare nelle architetture deep.\n27\n",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#27": "ReLU activation function\nI principali \n vantaggi\n  della ReLU sono:\n28",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#28": "ReLU activation function\nI principali \n vantaggi\n  della ReLU sono:  \n•\nGarantisce la \n non linearità\n .\n29",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#29": "ReLU activation function\nI principali \n vantaggi\n  della ReLU sono:  \n•\nGarantisce la \n non linearità\n  anche per valori prossimi allo 0.  \n•\nNon satura per valori positivi elevati\n . I gradienti sono sempre signi\n ﬁ\ncativi. \nRispetto alla logistic (o tanh) \n riduce il vanishing problem\n .\n30",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#3": "Vanishing/Exploding gradients\nL'\nalgoritmo di backpropagation\n  usato per addestrare una NN segue questi passi:  \n•\nPer ogni coppia input-output si valuta l'errore tra output ottenuto dalla NN e \noutput atteso mediante la \n loss function \n (o \ncost function\n ). \n•\nSi calcola il \n gradiente\n , cioè l'insieme delle derivate parziali dell'errore rispetto \nai parametri (pesi), mediante la \n chain rule\n . \n•\nIn base a tali valori si aggiornano i pesi in modo da ridurre l'errore, ad esempio \nmediante il \n gradient descent.  \nImpiegando i gradienti per addestrare la rete può capitare di ottenere valori \nmolto piccoli (\n vanishing gradients\n ), soprattutto per i layer vicini all'input.  \n•\nIl gradiente nei primi strati si ottiene come \n prodotto\n  dei gradienti degli strati più \nlontani.  \n•\nQuesto implica che nei primi layer i pesi non vengono pressoché alterati \ndurante il training \n e dif\nﬁ\ncilmente si converge ad una soluzione\n .\n4",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#30": "ReLU activation function\nI principali \n vantaggi\n  della ReLU sono:  \n•\nGarantisce la \n non linearità\n  anche per valori prossimi allo 0.  \n•\nNon satura per valori positivi elevati\n . I gradienti sono sempre signi\n ﬁ\ncativi. \nRispetto alla logistic (o tanh) \n riduce il vanishing problem\n . \n•\nRiduce la complessità computazione\n  non essendoci la componente \nesponenziale da differenziare.\n31",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#31": "ReLU activation function\nI principali \n vantaggi\n  della ReLU sono:  \n•\nGarantisce la \n non linearità\n  anche per valori prossimi allo 0.  \n•\nNon satura per valori positivi elevati\n . I gradienti sono sempre signi\n ﬁ\ncativi. \nRispetto alla logistic (o tanh) \n riduce il vanishing problem\n . \n•\nRiduce la complessità computazione\n  non essendoci la componente \nesponenziale da differenziare.  \nMa ha dei \n svantaggi\n :\n32",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#32": "ReLU activation function\nI principali \n vantaggi\n  della ReLU sono:  \n•\nGarantisce la \n non linearità\n  anche per valori prossimi allo 0.  \n•\nNon satura per valori positivi elevati\n . I gradienti sono sempre signi\n ﬁ\ncativi. \nRispetto alla logistic (o tanh) \n riduce il vanishing problem\n . \n•\nRiduce la complessità computazione\n  non essendoci la componente \nesponenziale da differenziare.  \nMa ha dei \n svantaggi\n : \n•\nSperimentalmente \n è più prona all'over\n ﬁ\ntting\n, perciò si usa insieme a tecniche \nper ridurre questo problema (es. dropout).  \n33",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#33": "ReLU activation function\nI principali \n vantaggi\n  della ReLU sono:  \n•\nGarantisce la \n non linearità\n  anche per valori prossimi allo 0.  \n•\nNon satura per valori positivi elevati\n . I gradienti sono sempre signi\n ﬁ\ncativi. \nRispetto alla logistic (o tanh) \n riduce il vanishing problem\n . \n•\nRiduce la complessità computazione\n  non essendoci la componente \nesponenziale da differenziare.  \nMa ha dei \n svantaggi\n : \n•\nSperimentalmente \n è più prona all'over\n ﬁ\ntting\n, perciò si usa insieme a tecniche \nper ridurre questo problema (es. dropout).  \n•\nSe durante l'apprendimento l'input \n x\n combinato coi pesi \n w\n genera un valore \nnegativo, e l'output è pari a \n 0\n. Può capitare che \n i neuroni smettano di generare \nvalori diversi da 0\n  (\ndying ReLUs\n ). \n34",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#34": "ReLU activation function\nI principali \n vantaggi\n  della ReLU sono:  \n•\nGarantisce la \n non linearità\n  anche per valori prossimi allo 0.  \n•\nNon satura per valori positivi elevati\n . I gradienti sono sempre signi\n ﬁ\ncativi. \nRispetto alla logistic (o tanh) \n riduce il vanishing problem\n . \n•\nRiduce la complessità computazione\n  non essendoci la componente \nesponenziale da differenziare.  \nMa ha dei \n svantaggi\n : \n•\nSperimentalmente \n è più prona all'over\n ﬁ\ntting\n, perciò si usa insieme a tecniche \nper ridurre questo problema (es. dropout).  \n•\nSe durante l'apprendimento l'input \n x\n combinato coi pesi \n w\n genera un valore \nnegativo, e l'output è pari a \n 0\n. Può capitare che \n i neuroni smettano di generare \nvalori diversi da 0\n  (\ndying ReLUs\n ). \n•\nL'intervallo dell'output è \n [\n0,\n∞\n]\n35",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#35": "Leaky ReLU\nPer risolvere il problema\n  dying ReLUs\n  si introduce la \n Leaky ReLU \n o \nLReLU:  \n                               \ndove \n α\n è un \n iperparametro\n  (es. \n0.01\n) che garantisce un valore diverso da \n 0 \nper \nx < 0\n . \nf\n(\nx\n)\n=\nm\na\nx\n(\nα\n⋅\nx\n,\nx\n)\n36\n",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#36": "Altre ReLU\nParametric ReLU (PReLU)\n :  \n•\nα\n diviene un parametro che viene stimato durante il training\n . \n•\nRispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  \nRandomized Leaky (RReLU):  \nα\n viene impostato in modo casuale durante il training,  \ne tenuto \n ﬁ\nsso durante il test.  \nPuò ridurre fenomeni di over\n ﬁ\ntting.  \nExponential Linear Unit (ELU):     \nHa un gradiente <> 0 per x < 0\n  (contro il dying ReLU)\n .\n La media degli output di un layer \nè più vicina allo 0 rispetto a quella della ReLU, e si riduce il vanishing problem.  \nNon ha singolarità nello 0\n , cioè ha sempre derivate <> 0.  \nSebbene richieda più tempo per il calcolo del gradiente, compensa con un tasso di \nconvergenza più veloce.\nE\nL\nU\nα\n(\nz\n)\n=\n{\nα\n(\ne\nx\n−\n1\n)\n,\nx\n<\n0\nx\n,\nx\n≥\n0\n37",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#37": "Altre ReLU\nParametric ReLU (PReLU)\n :  \n•\nα\n diviene un parametro che viene stimato durante il training\n . \n•\nRispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  \nRandomized Leaky (RReLU)\n : \n•\nα\n viene alterato in modo casuale durante il training,  \ne tenuto \n ﬁ\nsso durante il test.  \n•\nPuò ridurre fenomeni di over\n ﬁ\ntting.  \nExponential Linear Unit (ELU):     \nHa un gradiente <> 0 per x < 0\n  (contro il dying ReLU)\n .\n La media degli output di un layer \nè più vicina allo 0 rispetto a quella della ReLU, e si riduce il vanishing problem.  \nNon ha singolarità nello 0\n , cioè ha sempre derivate <> 0.  \nSebbene richieda più tempo per il calcolo del gradiente, compensa con un tasso di \nconvergenza più veloce.\nE\nL\nU\nα\n(\nz\n)\n=\n{\nα\n(\ne\nx\n−\n1\n)\n,\nx\n<\n0\nx\n,\nx\n≥\n0\n38",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#38": "Altre ReLU\nParametric ReLU (PReLU)\n :  \n•\nα\n diviene un parametro che viene stimato durante il training\n . \n•\nRispetto alla ReLU incrementa le performance in dataset di immagini molto grandi.  \nRandomized Leaky (RReLU)\n : \n•\nα\n viene alterato in modo casuale durante il training,  \ne tenuto \n ﬁ\nsso durante il test.  \n•\nPuò ridurre fenomeni di over\n ﬁ\ntting.  \nExponential Linear Unit (ELU)\n :     \n•\nHa un gradiente <> 0 per x < 0\n  (contro il dying ReLU)\n .\n Producendo valori <0, la media \ndegli output di un layer è più vicina allo 0 rispetto a quella della ReLU, e si riduce il \nvanishing problem.  \n•\nNon ha singolarità nello 0\n , cioè è sempre derivabile.  \n•\nSebbene richieda più tempo per il calcolo del gradiente, compensa con un \n tasso di \nconvergenza più veloce \n della ReLU.\nE\nL\nU\nα\n(\nz\n)\n=\n{\nα\n(\ne\nx\n−\n1\n)\n,\nx\n<\n0\nx\n,\nx\n≥\n0\n39\n",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#39": "Funzioni di Attivazione\nIn quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, \nlogistic, softmax?\n40",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#4": "Vanishing/Exploding gradients\nIn modo simile i \n gradienti possono aumentare \n e in alcuni layer il valore può \neccedere gli intervalli rappresentabili nei framework di NN (\n exploding \ngradients\n ). \n•\nFenomeno che capita spesso nelle \n Recurrent NN\n  che studieremo più avanti  \nPiù in generale, \n strati diversi della rete possono aggiornarsi con \n\"velocità\" \n (cioè valori di gradienti)\n  molto diverse\n . \nTali problemi sono ancora più evidenti \n con funzioni di attivazione con \nvalore medio <> 0\n , e \ninizializzazione dei pesi casuale \n con distribuzione \ngaussiana\n . \n•\nAd esempio, nel caso della \n logistic \n (o\n sigmoid\n )\n function\n , per valori in input \ngrandi in modulo, la funzioni \n satura a 0 o 1\n , con \n derivate\n  tendenti allo \n 0\n. \nSi ha perciò \n vanishing gradients\n . \n5",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#40": "Funzioni di Attivazione\nIn quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, \nlogistic, softmax?  \n1.\nLa \nELU\n è una buona scelta iniziale.  \n41",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#41": "Funzioni di Attivazione\nIn quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, \nlogistic, softmax?  \n1.\nLa \nELU\n è una buona scelta iniziale.  \n2.\nPer reti veloci, meglio una \n leaky ReLU\n , o varianti.  \n42",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#42": "Funzioni di Attivazione\nIn quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, \nlogistic, softmax?  \n1.\nLa \nELU\n è una buona scelta iniziale.  \n2.\nPer reti veloci, meglio una \n leaky ReLU\n , o varianti.  \n3.\nLa semplicità della \n ReLU\n  motiva la sua diffusione, sebbene \n ELU\n e \nleaky  \nReLU\n  si comportino generalmente meglio.  \n43",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#43": "Funzioni di Attivazione\nIn quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, \nlogistic, softmax?  \n1.\nLa \nELU\n è una buona scelta iniziale.  \n2.\nPer reti veloci, meglio una \n leaky ReLU\n , o varianti.  \n3.\nLa semplicità della \n ReLU\n  motiva la sua diffusione, sebbene \n ELU\n e \nleaky  \nReLU\n  si comportino generalmente meglio.  \n4.\nLa possibilità della \n ReLU\n  di produrre esattamente 0 torna utile in certi task.  \n44",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#44": "Funzioni di Attivazione\nIn quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, \nlogistic, softmax?  \n1.\nLa \nELU\n è una buona scelta iniziale.  \n2.\nPer reti veloci, meglio una \n leaky ReLU\n , o varianti.  \n3.\nLa semplicità della \n ReLU\n  motiva la sua diffusione, sebbene \n ELU\n e \nleaky  \nReLU\n  si comportino generalmente meglio.  \n4.\nLa possibilità della \n ReLU\n  di produrre esattamente 0 torna utile in certi task.  \n5.\nLa tangente iperbolica \n tanh\n è usata nell'output layer per produrre valori tra \n-1\n e \n1\n, ma non viene più usata negli hidden layers.  \n45",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#45": "Funzioni di Attivazione\nIn quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, \nlogistic, softmax?  \n1.\nLa \nELU\n è una buona scelta iniziale.  \n2.\nPer reti veloci, meglio una \n leaky ReLU\n , o varianti.  \n3.\nLa semplicità della \n ReLU\n  motiva la sua diffusione, sebbene \n ELU\n e \nleaky  \nReLU\n  si comportino generalmente meglio.  \n4.\nLa possibilità della \n ReLU\n  di produrre esattamente 0 torna utile in certi task.  \n5.\nLa tangente iperbolica \n tanh\n è usata nell'output layer per produrre valori tra \n-1\n e \n1\n, ma non viene più usata negli hidden layers.  \n6.\nLa \nlogistic\n  è usata nell'output layer per stimare probabilità (es. \nclassi\n ﬁ\ncazione binaria), ma è raramente usata per gli hidden layers.  \n46",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#46": "Funzioni di Attivazione\nIn quali casi impiegheresti ELU, leaky ReLU (e sue varianti), ReLU, tanh, \nlogistic, softmax?  \n1.\nLa \nELU\n è una buona scelta iniziale.  \n2.\nPer reti veloci, meglio una \n leaky ReLU\n , o varianti.  \n3.\nLa semplicità della \n ReLU\n  motiva la sua diffusione, sebbene \n ELU\n e \nleaky  \nReLU\n  si comportino generalmente meglio.  \n4.\nLa possibilità della \n ReLU\n  di produrre esattamente 0 torna utile in certi task.  \n5.\nLa tangente iperbolica \n tanh\n è usata nell'output layer per produrre valori tra \n-1\n e \n1\n, ma non viene più usata negli hidden layers.  \n6.\nLa \nlogistic\n  è usata nell'output layer per stimare probabilità (es. \nclassi\n ﬁ\ncazione binaria), ma è raramente usata per gli hidden layers.  \n7.\nLa \nsoftmax\n  è adatta per ottenere distribuzioni di probabilità su classi \nmutuamente esclusive.\n47",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#47": "Gradient clipping\nUna tecnica molto facile per ridurre il fenomeno del \n exploding gradients\n  è \nintrodurre \n una soglia per limitare il valore dei gradienti\n  durante il \nbackpropagation, chiamata \n gradient clipping\n . \nChiaramente ponendo valori soglia rischiamo di ridurre l'informazione che \ntali parametri possono propagare.  \nLa rivedremo tra poco ma nel dominio della regolarizzazione dei parametri \nW\n.\n48",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#48": "Reusing pretrained layers\nAddestrare un rete deep complessa \n richiede molte risorse\n , a volte \nimpossibili da avere, ad eccezione di pochi laboratori al mondo.  \nIl \ntransfer learning\n  è l'approccio che ha l'obiettivo di\n  ri-utilizzare parametri \nottenuti da architetture già addestrate \n su obiettivi simili.  \nHa il duplice vantaggio di ridurre:  \n•\nil \ntempo di addestramento,  \n•\nla \ndimensione del training set\n  relativo all'obiettivo di interesse.  \nAd esempio, una rete è addestrata a riconoscere animali, piante, automobili, \netc., mentre siamo interessati a distinguere il modello di certe auto.  \n•\nConviene riutilizzare i parametri che permettono di rappresentare speci\n ﬁ\nche \nfeatures della classe auto (es. forme di fanali e paraurti) e sfruttarli per \nadattare la rete alle nuove classi.\n49",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#49": "Esempio di complessità della architettura GPT-3\nGenerative Pre-trained Transformer 3\n  (\nGPT-3\n ) è un architettura deep creata \nda \nOpenAI\n  per ottenere modelli (transformer) di linguaggio naturale.  \nApparsa nel 2020 come evoluzione delle versioni v2 e v1, è popolare \nper la capacità di redigere testo (es. news) simili a quelle scritte da \npersone umane. E' suf\n ﬁ\nciente dare poche parole per farla partire.  \nContiene 175 miliardi di parametri.  \nAddestrata su quasi 500 miliardi di parole estratte da varie fonti \n(CommonCrawl, WebText2, Books, Wikipedia)  \nCon una GPU cloud Tesla V100 richiederebbe $4.6M e 355 anni per \nl'addestramento.  \nEsempi di applicazione: \n https://beta.openai.com/examples/  \n50",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#5": "Logistic (sigmoid) function\n6\nSaturazione  \n(risposta max)  \ngradiente basso\nSaturazione  \n(risposta max )\ngradiente basso Quasi-lineare \nderivata costante \ncioè indipendente dagli input\n",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#50": "Reusing pretrained layers\nNelle architetture deep i \n layer rappresentano features \n rilevanti per la \nclassi\n ﬁ\ncazione \n con diversi livelli di \n astrazione\n . Ad esempio nel task della \nclassi\n ﬁ\ncazione delle immagini:  \n•\nI \nprimi layer\n  (vicini all'input) si specializzano su  \nfeatures di base\n , come \nline, angoli, variazioni cromatiche  \n•\nI \nlayer più vicini all'output\n  legano le feature precedenti per rappresentare \noggetti complessi e relative \n caratteristiche salienti\n  (es. il muso e le orecchie \ndi un animale).  \nIl transfer learning \n mira a riutilizzare i parametri (e il tipo di feature) più \nimportanti.  \n•\nI pesi che si riusano si possono \n congelare, \n e focalizzare l'addestramento \nsolo sui nuovi parametri che dipendono dal nuovo task.  \n•\nSi sempli\n ﬁ\nca l'addestramento poiché alcuni parametri non si alterano. \n51",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#51": "Transfer learning - procedimento\nGli output layers della rete iniziale spesso si scartano perché tipicamente \nnon riadattabili al nuovo task, cioè non rappresentano le feature signi\n ﬁ\ncative \nper il nuovo task e ai nuovi output di interesse.  \nIl \nprocedimento\n  generale del \n transfer learning\n  è il seguente:  \n1.\nSi tenta di \n riutilizzare tutti i parametri della vecchia rete\n  e si valutano le \nperformance.  \n2.\nSi \n\"scongelano\" gli ultimi 1 o 2 layer\n  e si permette il loro addestramento, \nvalutando miglioramenti.  \n3.\nIn caso il training set sia limitato, \n si scartano gli ultimi layer,\n  e si \ncongelano i restanti. Si valutano le performance.  \n4.\nSe si hanno suf\n ﬁ\ncienti dati, i\n  layer scartati si rimpiazzano con nuovi \nlayer\n , eventualmente aumentano la profondità della rete rispetto a quella \ndi partenza.\n52",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#52": "Reusing pretrained layers\nNota: \n Il transfer learning è adatto quando le istanze in input hanno feature a basso livello  \n(es. numero di pixel di una immagine) simili a quelle delle istanze in input alla nuova rete.\n53\nParametri da addestrare,  \nparzialmente riutilizzati\nParametri ﬁssi ottenuti  \ndalla rete già addestrata.\nRete già addestrata  \nper un certo task.Rete da addestrare  \nper un task simile.CongelatiNon congelati\n}}",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#53": "Transfer learning\nDove posso trovare parametri già addestrati?\n54",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#54": "Transfer learning\nDove posso trovare parametri già addestrati?  \nSui repository dei framework di DL, o su blog specializzati, si trovano \nelenchi aggiornati di modelli per diversi task, es:  \n•\nhttps://github.com/tensor\n ﬂ\now/models  \n•\nhttps://pytorch.org/docs/stable/torchvision/models.html   \nI modelli fanno riferimento ad architetture DL conosciute in letteratura  \n•\nEs. AlexNet, VGG, ResNet, SqueezeNet, DenseNet, Inception v3, GoogLeNet, \nShuf\nﬂ\neNet v2, MobileNet v2, ResNeXt, Wide ResNet, MNASNet\n55",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#55": "Unsupervised Pretraining\nPuò capitare di lavorare su un task dove abbiamo \n un training set di istanze \nlabelled\n  ridotto\n , e non esistono modelli pre-addestrati da impiegare.  \nNel \nunsupervised pretraining\n  la rete viene addestrata \n uno strato alla volta\n , \npartendo da quello più vicino agli input.  \n•\nOgni layer è addestrato impiegando l'output del layer precedente, quindi in \nmodo \n unsupervised\n . \n•\nTutti i layer sono congelati, tranne quello sotto addestramento.  \n•\nQuando tutti i layer sono stati addestrati, la rete può essere addestrata con \nun approccio \n ﬁ\nne-tuned \n supervised\n .  \n•\nTipicamente (1) si aggiunge un ultimo layer, (2) si congelano i pesi dei \nlayer precedenti, e (3) si considera il training set disponibile.\n56",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#56": "Unsupervised Pretraining\nLa fase di unsupervised permette di creare \n una approssimazione dei \nparametri (o inizializzazione) \n utile per la fase di addestramento reale.  \nIpotesi sostengono che tale fase individua il sottoinsieme di \n minimi\n  più \nprobabili nello spazio di ricerca.  \nÈ un approccio piuttosto lungo da completare, ma è stato impiegato di \nfrequente \n ﬁ\nno alla comparsa delle prime tecniche che hanno affrontato il \nvanishing gradients\n  problem. \n57",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#57": "Unsupervised Pretraining - considerazioni\nRicordiamoci che in una architettura deep è facile ricavare valori di errore \nsugli strati \n ﬁ\nnali, vicini all'output atteso. Ma a causa del vanishing problem, \n i \nprimi strati potrebbero non avere suf\n ﬁ\nciente informazione per il relativo \naddestramento\n . \nL'approccio iterativo del \n unsupervised pretraining  \naddestra \n uno strato alla \nvolta\n , mantenendo costanti gli altri parametri, perciò senza la possibilità che \npossano in\n ﬂ\nuenzare il training in modo sub-ottimale.  \n•\nL'addestramento è suddiviso in più fasi, e in ogni fase abbiamo pochi \nparametri da determinare.  \n•\nL'\noutput atteso \n di un layer sotto addestramento \n corrisponde all'output dello \nstrato precedente\n  (approccio unsupervised)  \n•\nIn ogni fase si tenta di identi\n ﬁ\ncare \n minimi locali \n utili per la fase \n ﬁ\nnale.  \nCon \npretraining\n  si indica in generale \n il procedimento di addestrare modelli \nsempli\n ﬁ\ncati su dati sempli\n ﬁ\ncati \nprima di arrivare al modello \n ﬁ\nnale su dati \ncomplessi.\n58",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#58": "Unsupervised Pretraining\n59\nLayer addestratoLayer addestratoLayer addestratoRete addestrata",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#59": "Pretraining su auxiliary task\nUn modo alternativo per addestrare una rete con scarsi dati di training e \ntrovare un \n auxiliary task\n , cioè un task simile che condivide un insieme di \nfeature detectors\n  salienti con il task di nostro interesse.  \nIpotesi\n : se riusciamo ad addestrare la rete sul task alternativo, potremmo \nriutilizzare i primi layer dato che si sono specializzati sulle features di \ncomune interesse.  \nEsempio: \n face detection  \nTipicamente ci sono\n  poche istanze \n per ogni viso da riconoscere.  \nPossiamo andare su Google e collezionare facilmente molti visi di \ncelebrity. La rete imparerà a riconoscere le \n feature salienti\n  che potranno \nessere impiegate sul nostro training set.  \nUn approccio alternativo è \"corrompere\" un sottoinsieme di istanze \ndisponibili di una certa classe per associarle ad una classe negativa.\n60",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#6": "Vanishing/Exploding gradients\nUna possibilità sarebbe \n comprimere\n  i valori delle attivazioni in un intervallo \nristretto, ma intorno allo 0 la logistic mostra comportamenti prettamente \nlineari, che non permettono di rappresentare funzioni complesse.\n7",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#7": "Vanishing/Exploding gradients\n8\n",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#8": "Vanishing/Exploding gradients problem:  \nCosa succede durante l'addestramento?\nComportamenti tipici in presenza di vanishing gradients problem sono:  \n•\nLe performance migliorano \n troppo lentamente\n , o \nnon migliorano  \n•\nPrematura convergenza\n  (ma non a valori ottimi)  \n•\nAnalizzando i parametri appresi si notano \n variazioni più signi\n ﬁ\ncative negli \nultimi strati\n , vicini all'output, \n rispetto ai primi strati\n .\n9",
    "data_test\\rootfolder\\università\\DeepLearning\\09-Training Deep 1-sbloccato.pdf#9": "Inizializzazione di Xavier e He \nL'obiettivo è garantire la propagazione delle attivazioni (forward) e dei \ngradienti (backward) in modo corretto, cioè senza \n exploding\n  e \nvanishing\n . \nXavier e He\n  propongono di mantenere uguali:  \n•\ni valori della varianza degli output di ogni layer con la varianza degli input \ndel layer successivo\n  (forward propagation).  \n•\nle varianze dei gradienti ottenuti prima e dopo un certo layer\n  (backward \npropagation)  \nTali condizioni possono essere veri\n ﬁ\ncate solo se ogni layer ha lo \n stesso \nnumero di connessioni in entrata e in uscita\n .  \nIntroducendo una approssimazione de\n ﬁ\nniamo la \n Xavier initialization\n  così:\n10I pesi della rete sono inizializzati per ogni layer in modo casuale  \ncon distribuzione gaussiana  con media 0  e varianza pari a n-1, \ndove n il numero di nodi del layer precedente.",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nL'addestramento delle reti neurali Deep  \nParte 2: Optimizers, learning rates adattivi\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#1": "Sommario\nFaster Optimizer  \nMomentum optimization  \nNesterov Accelerated Gradient  \nAdaGrad Algorithm  \nRMSProp algorithm  \nAdam Optimization  \nLearning rate schedule   \nAdaptive learning rate algorithms",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#10": "Richiami: Gradient descent\n•\nAlterazioni troppo piccole allungano i tempi di esplorazioni.  \n•\nAlterazioni troppo grandi (es. learning rate elevati) generare comportamenti \nche possono allontanarci dall'ottimo.\n11\nRicerca lenta Ricerca imprecisa",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#11": "Gradient descent vs Stochastic vs Minibatch\n•\nGradient descent\n : iteriamo sull'intero training set, cioè su tutte le istanze, \nprima di aggiornare i pesi.  \n•\nSebbene la stima dell'errore sia molto precisa, per training set grandi \ndobbiamo attendere molto prima di aggiornare i parametri. Gli output \nsono ricavati con i parametri ricavati nel ciclo precedente, senza poterli \naggiornare durante l'epoca.  \n•\nStochastic Gradient descent (SGD)\n : ad ogni istanza estratta dal training set \n(in modo random) aggiorniamo i parametri.  \n•\nLa stima dei gradienti è approssimata su una singola istanza, perciò poco \nprecisa. Ma aggiorniamo i parametri istantaneamente. Convergenza più \nrapida, ma meno probabilità di raggiungere l'ottimo.  \n•\nMinibatch SGD\n : dopo un minibatch di istanze aggiorniamo i pesi.  \n•\nSi suppone che il minibatch stimi meglio le variazioni dei parametri \nsimulando la stima sull'training set. In altre parole, riduce la varianza sui \nvalori stimati. Combina i vantaggi di entrambi.\n12",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#12": "Richiami: (Mini)Batch Normalization\nConsiste in un \n algoritmo\n  applicato ad ogni singola istanza in input \n x\ni\n, \nconsiderando un mini-batch \n B\n di \nm\n istanze con \n media  \n e \nvarianza   \nI parametri da apprendere durante il training sono \n γ\n (\nscale\n ) e \nβ\n (\noffset\n ). \nε\n è una costante aggiunta alla varianza per evitare divisione per 0 (es. 10\n-3\n)\nμ\nB\n σ\n2\nB\n13\nda Ioffe e Szegedy \"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\" 2015Trasformazione lineare",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#13": "Gradient vs Stochastic Gradient descent\nIn condizioni ideali (es. convex function) un gradient descent tradizionale è \nl'approccio ottimale per raggiungere il minimo in poche iterazioni.  \nL'approccio stocastico introduce rumore che può rallentare il \nraggiungimento del minimo (es. a dx dopo 50 iterazioni non si hanno ancora \nvalori ottimali, a sx dopo 20 iterazioni possiamo fermarci).  \nMa generalmente nel DL non abbiamo \n convex functions\n .\n14\n",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#14": "Gradient descent e learning rate\n•\nPer rendere la ricerca \n più ef\n ﬁ\nciente \n potremmo pensare di \n variare il learning \nrate \n  durante l'esplorazione:  \n•\nAumentandolo ulteriormente al principio\n , per rendere la ricerca più rapida,  \ne riducendolo alla \n ﬁ\nne\n, soprattutto nel caso del SGD e minibatch SGD, per \nridurre gli effetti che il rumore possa avere sulla ricerca dell'ottimo.  \n•\nNell'esempio, aumentiamo la velocità durante la discesa della curva, e la \nriduciamo quando la curva riduce la pendenza.\nη\n15\nCosto\nΘ",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#15": "Momentum optimization\nLa \nmomentum optimization \n introduce il concetto di \n accelerazione\n  e \nvelocità  \ndurante l'esplorazione.  \nIntroduco il \n vettore momentum  \nm\n, usato per aggiornare i pesi \n . Il suo compito è \ninterpretare il gradiente \n  come una \n accelerazione,\n  che altera la \n velocità \ncorrente\n  rappresentata da \n . \n \n \n è chiamato \n parametro momentum\n , o semplicemente \n momentum\n , e ha lo scopo \ndi evitare che la velocità cresca eccessivamente.  \n•\n=0 resistenza massima (corrisponde al gradient descent), \n =1 nessuna resistenza.  \nSi veri\n ﬁ\nca facilmente che, se il il valore del gradiente rimane costante, la variazione \nmassima dei pesi è \n . \n•\nPer \n =0.9 e \n =1\n, si ottiene 10 volte il valore del gradiente.\nΘ\nη\n∇\nΘ\nJ\n(\nΘ\n)\nβ\n⋅\nm\nm\n←\nβ\n⋅\nm\n+\nη\n∇\nΘ\nJ\n(\nΘ\n)\nΘ\n←\nΘ\n−\nm\nβ\nβ\n β\nη\n1\n1\n−\nβ\nβ\n η\n16",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#16": "Momentum optimization (2)\nAnalogia con una biglia su una super\n ﬁ\ncie. La direzione non corrisponde più \na quella determinata dal gradiente calcolato attualmente, ma in base alle \nmedia pesata di tutti i gradienti precedenti.  \nL'approccio rientra nella classi dei \n accelerated gradient methods\n . \nHa molteplici \n vantaggi\n : \n•\nRende più stabile la ricerca quando qualche gradiente risulta scarsamente \naccurato (es. scelta sbagliata della istanza/minibatch), mediando su una serie \ndi valori.  \n•\nSi \naccelera l'esplorazione\n  quando stiamo esplorando spazi dei parametri \nampi, e dove le super\n ﬁ\nci de\n ﬁ\nnite dalla funzione di costo variano lentamente.  \n•\nL'accelerazione permette più facilmente di \n evitare (o uscire) minimi locali \nrispetto al gradient descent tradizionale\n . \nIl momentum \n  è un \n iperparametro da stimare\n  caso per caso, ma valori \nintorno allo \n 0.9\n sono molto comuni.\nβ\n17",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#17": "Momentum optimization\n18apprendimento lento\napprendimento veloce\nDiscesa del gradiente  \ncon Momentum optimizationDiscesa del gradiente  \ntradizionale",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#18": "Momentum optimization: esempio\n10-momentum.ipynb\n19",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#19": "Nesterov Accelerated Gradient\nIl \nNesterov Accelerated Gradient\n  (\nNAG\n ) è una variazione del momentum \noptimization dove il \n gradiente\n  viene valutato non nella posizione corrente \nma nella direzione del momentum  \n : \n \n \nIn genere il vettore momentum indica la direzione verso l'ottimo, perciò \nsembra più logico misurare il gradiente verso quella direzione.  \nQueste piccole variazioni si sommano e il NAG si dimostra essere \n più \nrapido rispetto al momentum optimization\n .\nΘ\n+\nβ\n⋅\nm\nm\n←\nβ\n⋅\nm\n+\nη\n∇\nΘ\nJ\n(\nΘ\n+\nβ\n⋅\nm\n)\nΘ\n←\nΘ\n−\nm\n20",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#2": "Gli optimizer\nUn \noptimizer\n  è un algoritmo usato per alterare i parametri della rete, ed \neventualmente alcuni iperparametri quali il learning rate, in modo da \nminimizzare la misura di loss.  \nPer tale motivo la funzione di loss è anche chiamata \n objective function\n . \nNelle architetture deep si impiegano spesso \n optimizer\n  alternativi alla discesa \ndel gradiente.  \nConcettualmente, l'apprendimento delle architetture DL è ricavare un \nmodello adatto al task in base ai dati disponibili, mentre l'optimizer si \nfocalizza sulla objective function.  \nL'ottimizzazione si focalizza sulla loss è sui dati disponibili, perciò ul \ntraining error\n . \nAltrettanto fondamentale nel DL è minimizzare l'\n over\nﬁ\ntting\n, cioè \nmassimizzare le capacità di \n generalizzazione\n . Per questo durante \nl'ottimizzazione dobbiamo includere ulteriori analisi. \n3",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#20": "Nesterov Accelerated Gradient\nNello scenario classico di una discesa verso l'ottimo il NAG \n riduce eventuali \noscillazioni \n causate dall'accelerazione puntuale del momentum \noptimization.\n21\nβm",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#21": "AdaGrad Algorithm: Motivazioni\nIn presenza di \n dati sparsi\n , i parametri \n  associati alle\n  features poco \nfrequenti riceveranno update signi\n ﬁ\ncativi molto raramente\n .  \n•\nSe decrementiamo il learning rate durante l'esplorazione, nel caso tali \nfeatures non compaiono al principio del training, \n è probabile che i relativi \npesi non verranno aggiornati adeguatamente prima di raggiungere la \ncondizione di ottimo.  \nFacciamo l'ipotesi  \nche il \n learning rate  \n è legato \n al numero di volte  \ns(i,t)\n che \nabbiamo \n \"notato\" una certa features \n i\n durante il training \n ﬁ\nno al tempo \n t\n. \n•\nFeatures frequenti vedranno il learning rate associato ai relativi parametri \ndiminuire più velocemente:  \n \nMa se contiamo solo le occorrenze \n non teniamo in considerazione il valore \ndel gradiente\n , a volte molto grande, a volte irrilevante.\nΘ\nη\nη\n=\nη\n0\ns\n(\ni\n,\nt\n)\n+\nϵ\n22",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#22": "AdaGrad Algorithm\nIl \nAdaGrad algorithm\n  rende il \n learning rate adattivo\n , dove \n ogni parametro \nha un proprio rate\n . \nPer tale motivo si considera un \n vettore  \ns\n che \n memorizza gli update per ogni \nparametro\n  calcolato nel seguente modo:  \n \n \nsi assume \n s\n0\n = 0. \nLa prima espressione accumula nel vettore \n s\n i quadrati dei gradienti rispetto \nai parametri  \nﬁ\nno all'istante attuale.  \n•\nSe \nla funzione di costo è ripida\n  rispetto ad una direzione \n i\n, la sequenza dei \ngradienti assumeranno un valore elevato\n  in modulo, e la componente  \naumenterà ad ogni iterazione.\ns\n←\ns\n+\n∇\nΘ\nJ\n(\nΘ\n)\n⊗\n∇\nΘ\nJ\n(\nΘ\n)\nΘ\n←\nΘ\n−\nη\n∇\nΘ\nJ\n(\nΘ\n)\n⊘\n s\n+\nϵ\nΘ\ns\ni\n23...cont",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#23": "AdaGrad Algorithm (\n cont.\n )\nLa seconda è simile alla discesa del gradiente, ma \n il vettore dei gradienti è \nscalato del fattore  \n , dove \n  è il solito parametro di smoothing per \nevitare divisioni per 0.  \n•\nLe coordinate che mostreranno spesso gradienti elevati saranno \nmaggiormente \n ridimensionate\n , al contrario, gradienti signi\n ﬁ\ncativi sporadici \no in valore ridotto corrisponderanno a learning rate più importanti.  \nI principali vantaggi di \n AdaGrad\n  sono i seguenti:  \n•\nAdatto a training data sparsi e addestramenti molto lunghi.  \n•\nIl\n tuning del learning rate super\n ﬂ\nuo\n. Si imposta a un valore comune,  \nes. \n=0.01, evitandolo di considerare come iperparametro da ottimizzare.  \n•\nLa \ncomplessità computazione è paragonabile alla discesa del gradiente \ntradizionale.\ns\n+\nϵ\n ϵ\nη\n24",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#24": "AdaGrad Algorithm\n25\nparametro soggetto a gradienti \nelevati e legati a features frequenti\nparametro soggetto a gradienti  \nridotti e legati a features sparse",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#25": "RMSProp algorithm\nAdaGrad può rallentare la discesa del gradiente interrompendo \nanticipatamente il training.  \nL'\nalgoritmo RMSProp\n  è una variazione di AdaGrad dove \n il vettore \naccumulatore \n s\n considera maggiormente gli ultimi gradienti calcolati\n .  \n•\nSi introduce un \n fattore di decay  \n. \n \n \n•\nSebbene \n  sia un iperparametro, valori intorno allo 0.9 mostrano un buon \ncomportamento.  \nRMSProp\n  si dimostra\n  spesso migliore di AdaGrad\n  e di altre ottimizzazioni \n(es. Momentum optimization e NAG).\nβ\ns\n←\nβ\ns\n+\n(\n1\n−\nβ\n)\n∇\nΘ\nJ\n(\nΘ\n)\n⊗\n∇\nΘ\nJ\n(\nΘ\n)\nΘ\n←\nΘ\n−\nη\n∇\nΘ\nJ\n(\nΘ\n)\n⊘\n s\n+\nϵ\nβ\n26",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#26": "Adam Optimization\nAdam (Adaptive Moment Estimation)  \nè una combinazione di Momentum \noptimization e RMSProp\n . \n \n \n \n \n \ndove \n T\n indica l'iterazione corrente  \nRispetto al Momentum, nella prima espressione si introduce il decay dei gradienti \ncon  \nLa 3\na\n e 4\na\n espressione sono utili per incrementare il valore di \n m\n ed \ns\n all'inizio del \ntraining, essendo i valori iniziali pari a 0.\nm\n←\nβ\n1\nm\n+\n(\n1\n−\nβ\n1\n)\n∇\nΘ\nJ\n(\nΘ\n)\ns\n←\nβ\n2\ns\n+\n(\n1\n−\nβ\n2\n)\n∇\nΘ\nJ\n(\nΘ\n)\n⊗\n∇\nΘ\nJ\n(\nΘ\n)\nm\n←\nm\n1\n−\nβ\nT\n1\ns\n←\ns\n1\n−\nβ\nT\n2\nΘ\n←\nΘ\n−\nη\n⋅\nm\n⊘\n s\n+\nϵ\nβ\n1\n27Momentum :  \n \nRMSProp :  \n \n \n \n \n \nRMSProp : m←β⋅m+η∇ΘJ(Θ)\ns←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)\nΘ←Θ−η∇ΘJ(Θ)⊘ s+ϵ",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#27": "Adam Optimization\nRiguardo il \n tuning\n  dell'Adam Optimization:  \n•\nValori tipici per \n  e \n sono 0.9 e 0.999, rispettivamente.  \n•\nCome per gli altri \n algoritmi di adaptive learning rate\n , il valore iniziale di  \npuò essere impostato ad un valore tipico di 0.001 senza ulteriore tuning.\nβ\n1\nβ\n2\nη\n28",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#28": "Tecniche di ottimizzazione e complessità\nGli approcci \n ﬁ\nnora trattati si basano su \n derivate parziali del primo ordine  \n(Jacobians). Il numero di output per ogni dimensione in input è \n n\n,\n con \n n \nnumero di parametri.  \nEsistono molti approcci del \n secondo ordine (\n Hessians), ma richiedono \n n\n2 \nHessians per output.  \n•\nRecenti architetture Deep contengono oltre 10\n8\n parametri.  \n•\nLimiti sulla memoria di calcolo non permettono di usare tali approcci.\n29",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#29": "Momentum\nCosa succede se usiamo il momentum optimizer con iperparametro \nquasi 1 (es. 0.99999)?\n30",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#3": "Gli optimizer (2)\nNel DL le funzioni di \n loss\n sono complesse e non hanno una \n soluzione \nanalitica\n , cioè non possono essere formalizzati in modo da poter ricavare la \nsoluzione ottima con le risorse (tempo e hardware) disponibili in una serie di \nstep. Per questo si impiegano \n soluzioni numeriche\n  che seguono un \nprocedimento di trail & error su un insieme di soluzioni candidate.  \nEs.\n i coef\n ﬁ\ncienti di una regressione lineare possono essere ricavati \nanaliticamente via algebra lineare (es. \n matrix factorization\n ), oppure \nnumericamente (es. \n gradient descent\n ) quando i dati non sono \ninteramente memorizzabili.\n4",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#30": "Momentum\nCosa succede se usiamo il momentum optimizer con iperparametro \nquasi 1 (es. 0.99999)?  \n1.\nLa ricerca sarà molto veloce verso l'ottimo, ma a causa del \nmomentum, la ricerca oltrepasserà il momentum. \n31",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#31": "Momentum\nCosa succede se usiamo il momentum optimizer con iperparametro \nquasi 1 (es. 0.99999)?  \n1.\nLa ricerca sarà molto veloce verso l'ottimo, ma a causa del \nmomentum, la ricerca oltrepassera il momentum.  \n2.\nRallenterà, tornerà indietro, accelererà e lo oltrepasserà di nuovo.\n32",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#32": "Momentum\nCosa succede se usiamo il momentum optimizer con iperparametro \nquasi 1 (es. 0.99999)?  \n1.\nLa ricerca sarà molto veloce verso l'ottimo, ma a causa del \nmomentum, la ricerca oltrepassera il momentum.  \n2.\nRallenterà, tornerà indietro, accelererà e lo oltrepasserà di nuovo.  \n3.\nPotrà oscillare molte volte prima di arrivare al minimo.\n33",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#33": "Keras e optimizer\nSi può de\n ﬁ\nnire facilmente via compile()  \nfrom\n tensorflow \n import\n keras\nfrom\n tensorflow.keras \n import\n layers\nmodel = keras.Sequential()\nmodel.add(layers.Dense(\n 64\n, kernel_initializer=\n 'uniform'\n , input_shape=(\n 10\n,)))\nmodel.add(layers.Activation(\n 'softmax'\n ))\nopt = keras.optimizers.Adam(learning_rate=\n 0.01\n)\nmodel.\ncompile\n(loss=\n'categorical_crossentropy'\n , optimizer=opt\n )\n# oppur\ne\nmodel.compile(loss='categorical_crossentropy', \n optimizer='adam'\n )\nOppure all'interno del training loop:  \noptimizer = tf.keras.optimizers.Adam()\n# Iterate over the batches of a dataset.\nfor\n x, y \nin\n dataset:\n   \nwith\n tf.GradientTape() \n as\n tape:\n        \n # Forward pass.\n        logits = model(x)\n        \n # Loss value for this batch.\n        loss_value = loss_fn(y, logits)\n    \n# Get gradients of loss wrt the weights.\n    gradients = tape.gradient(loss_value, model.trainable_weights)\n    \n# Update the weights of the model.\n    \noptimizer.apply_gradients\n (\nzip\n(gradients, model.trainable_weights))\n34\nOptimizer disponibili:  \n•\nSGD,  \n•\nRMSprop,  \n•\nAdam,  \n•\nAdadelta,  \n•\nAdagrad,  \n•\nAdamax,  \n•\nNadam,  \n•\nFtrl",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#34": "Richiami: Learning rate\nImpostare un \n learning rate troppo alto\n  può far \n divergere\n  l'apprendimento \ndall'ottimo.  \nValori \n troppo bassi \n provocano \n tempi di addestramento lunghi\n .  \nValori \n elevati\n  rendono il processo più rapido avvicinandosi all'ottimo ma \nsenza convergere realmente\n .  \n•\nTecniche quali\n  AdaGrad, RMSProp\n  e \nAdam\n  affrontano questo problema ma \nrichiedono comunque tempo, perciò \n risorse di calcolo\n . \nAvviando il training più volte \n su un training set ridotto e con diversi learning \nrate ci permette di \n stimare\n  quello più adatto.\n35\nEpocheLoss",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#35": "Richiami: Learning rate\n36\nMinimo cost function\nlearning rate elevato\nlearning rate basso\nlearning rate ideale",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#36": "Learning rate schedule\nLe strategie di \n learning schedules\n  mirano ad \n adattare il valore del learning rate  \ndurane il training.  \nI più popolari algoritmi di \n adaptive learning rate\n  sono:  \n•\nPredetermined piecewise constant learning rate\n : \n•\nOgni \n n\n epoche decrementa il rate di un valore predeterminato.  \n•\nPerformance scheduling\n : \n•\nMisura le perfomance (es. validation error) ogni \n n\n steps e riduce il rate di un \nfattore prede\n ﬁ\nnito quando le performance non migliorano.  \n•\nExponential scheduling\n : \n•\nIl rate si riduce di \n  dopo \n r\n steps:  \n•\nPower scheduling\n : \n•\nSimile al precedente ma il rate decresce più lentamente: \n1\n10\nη\n(\nt\n)\n=\nη\n0\n⋅\n10\n−\nt\nr\nη\n(\nt\n)\n=\nη\n0\n(\n1\n+\nt\nr\n)\n−\nc\n37",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#37": "Learning rate schedule: considerazioni\nNel dominio dello \n speech recognition\n  e impiegando il Momentum \noptimization, il \n performance scheduling\n  e \nexponential scheduling  \ndimostrano \n migliori performance\n . \n•\nL'\nexponential scheduling \n è da preferire perché \n più facile nel tuning\n . \nSe si impiegano i seguenti optimizer \n AdaGrad, RMSProp\n  e \nAdam \n non è \nnecessario implementare il learning rate schedule.\n38",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#38": "Keras e learning rate\nNell'esempio si de\n ﬁ\nnisce un learning rate adattivo basato su exponential \ndecay:  \nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=\n 1e-2\n,\n    decay_steps=\n 10000\n,\n    decay_rate=\n 0.9\n)\noptimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n39",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#4": "Local vs Global minimum\nUn approccio numerico tradizionale che porta lo stato vicino ad un minimo \nlocale restituirà una soluzione sub-ottima. Introducendo un certo grado di \nrumore abbiamo possibilità di continuare la ricerca altrove  \nNel \nminibatch stoachastic gradient descent\n , si introducono variazioni \ndovute ai gradienti calcolati sui minibatch e non sull'intero batch. \n5\n",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#5": "Saddle points\nI punti di sella generano vanishing gradients, e creano problemi se non \nsiamo in minimi locali o globali.  \nNell'esempio \n f(x)=x\n3\n6\n",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#6": "Saddle points (2)\nNell'esempio sotto abbiamo \n f(x,y)=x\n2\n-y\n2 \ncon punto di sella in (0,0), massimo \nper y e minimo per x. Se assumiamo l'input di f un vettore k-dimensionale e \nl'output scalare, abbiamo  \nDerivate parziali  \nLa \nmatrice di Hessian\n  (H) consiste nelle derivate parziali del secondo \nordine. Essa rappresenta proprietà geometriche della super\n ﬁ\ncie, \nsoprattutto quando i gradienti sono pari a 0.\n7\n∇f(x)=[∂f(x)\n∂x1,∂f(x)\n∂x2,⋯,∂f(x)\n∂xk]\nHf=∂2f\n∂x1∂x1∂2f\n∂x1∂x2⋯∂2f\n∂x1∂xk\n∂2f\n∂x2∂x1∂2f\n∂2x2⋯∂2f\n∂x2∂xk\n⋯\n∂2f\n∂x1∂xk∂2f\n∂x2∂xk⋯∂2f\n∂2xk",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#7": "Punti critici\nIn particolare gli autovalori e il determinante di H ci danno indicazioni sui punti \ncritici e sulla funzione di costo.  \nUna \n convex function\n  (cioè con un unico minimo) ha sempre autovalori non negativi.  \nMa il calcolo di H è oneroso di risorse (spazio e calcolo). Inoltre i task su cui si \napplicano architetture di DL non sono tipicamente associati a convex functions.\n8\n",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#8": "Formalismo\nNei lucidi seguenti useremo il formalismo:  \n•\n:   i pesi attuali \n w\n e \nb\n della RN (in passato \n W\n) \n•\n :  \nfunzione di costo\n  (in passato \n E \no \nf\n) \n•\n : \ngradiente\n  della funzione di costo  \n•\n:   \n learning rate \n o step size (in passato \n ) \n•\n, \n:  \nmoltiplicazione\n  e \ndivisione element-wise\n , \n   cioè posizione \n  posizione  \nΘ\nJ\n(\nΘ\n)\n∇\nΘ\nJ\n(\nΘ\n)\nη\n α\n⊗\n⊘\n×\n9",
    "data_test\\rootfolder\\università\\DeepLearning\\10-Training Deep 2-sbloccato.pdf#9": "Richiami: Gradient descent\nIl processo di ottimizzazione \n Gradient descent\n  opera una \n sequenza di step \nregolari\n  per ogni punto verso la direzione di massima discesa che \ncorrisponde a quella determinata dall'opposto del suo gradiente in quel \npunto.  \n \nIn questo modo si ha che:  \n•\nL'\naggiornamento dipende solo dal gradiente calcolato localmente\n , e non \nda quelli precedenti.  \n•\nSe il \n gradiente locale è piccolo\n , l'aggiornamento sarà \n poco signi\n ﬁ\ncativo\n .\nΘ\n←\nΘ\n−\nη\n∇\nΘ\nJ\n(\nΘ\n)\n10",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nL'addestramento delle reti neurali Deep  \nParte 3: Over\n ﬁ\ntting \n1",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#1": "Sommario\nAffrontare l'Over\n ﬁ\ntting \nRichiami  \nEarly stopping  \n1 e \n 2 regularization  \nDropout  \nMax-Norm regularization  \nData Augumentation  \nEsercizi\nℓ\n ℓ",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#10": "Early stopping - ipotesi\nAlcuni studi mostrano che le reti DL hanno la capacità di fare \n ﬁ\ntting di label \narbitrarie, per\n ﬁ\nno generate casualmente, ma solo dopo un numero elevato \ndi iterazioni. In presenza di label ben de\n ﬁ\nnite nel training set, la rete tende a \nrappresentarle per prime, e poi interpolare i dati associati a label \"rumore\".  \nCi garantisce la capacità di generalizzazione: è suf\n ﬁ\nciente riuscire ad \naddestrare il modello sui dati con label ben de\n ﬁ\nnite, ed evitare di \ncontinuare su dati mal addestrati.\n11",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#11": "Early stopping\nInvece di introdurre vincoli sui parametri (l1 e l2 regularization), il vincolo \npuò essere sul numero di epoche del training.   \nNella tecnica di regolarizzazione \n early stopping\n  interrompiamo il training \nquando le prestazioni della rete non migliorano, ad esempio:  \n•\nAlla \nﬁ\nne di ogni epoca possiamo valutare le prestazioni sul \n validation set\n .  \n•\nTeniamo traccia dell'ultima volta in cui il modello ha migliorato le \nprestazioni.  \n•\nSe dopo un certo numero di epoche non ci sono stati miglioramenti \nsigni\nﬁ\ncativi (> \n ε\n), spesso chiamata \n patience criteria\n , interrompiamo e \nscegliamo lo snapshot del modello che in passato si è dimostrato migliore.  \nIl vantaggio è aumentare il potere di generalizzazione evitando di \nconsiderare label noisy. Inoltre riduce il tempo di training.  \nÈ spesso utile combinarlo ad altre tecniche di regolarizzazione.\n12",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#12": "1\n e \n 2\n regularization\n ℓ\nℓ\n1\n e \n 2 \nregularization\n  introducono limiti sul valore dei parametri e possono \nprevenire l'over\n ﬁ\ntting.  \n•\nCorrispondono rispettivamente alle tecniche di \n Lasso\n  e \nRidge \n nella \nregressione e \n 1\n e \n 2\n-penalty nella classi\n ﬁ\ncazione.  \n•\nIn pratica, oltre alla corrispondenza tra output attesi e output prodotti dalla \nrete, aggiungiamo un ulteriore vincolo da soddisfare durante il training.  \nModelli complessi tendono a rappresentare anche \n ﬂ\nuttuazioni causate dal \nrumore.  \nLe due regolarizzazioni spingono i parametri del modello ad assumere valori \nvicini allo 0 e, come effetto collaterale, a ridurre gli effetti dei layer nascosti \ndella rete, perciò rendendo il modello meno complesso.\nℓ\nℓ\nℓ\nℓ\n13",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#13": "1\n regularization\nℓ\nNella \n 1\n  si \naggiunge la magnitudo sui pesi \n (valore assoluto) come \ncoef\nﬁ\nciente di penalità\n  (o \ntermine di regolarizzazione\n ) alla funzione di loss.  \n1\n riduce signi\n ﬁ\ncativamente il valore dei pesi associati alle feature meno \nimportanti, operando una sorta di \n feature selection\n , che\n  riduce complessità \ne signi\n ﬁ\ncatività di alcune feature\n .  \nAlfa è l'iperparametro \n regularization rate\n . Valori \n troppo elevati \n comportano \nmodelli semplici e potenziali \n under\n ﬁ\ntting, valori molto bassi \n annullano la \nregolarizzazione.\nℓ\nℓ\n14\n",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#14": "2\n regularization\nℓ\nNella \n 2\n  si \naggiunge la magnitudo al quadrato sui pesi \n (o norma Ecluidea)  \ncome coef\n ﬁ\nciente di penalità.\nℓ\n15\n",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#15": "Dropout - motivazioni\nAbbiamo visto come modelli semplici possono garantire la generalizzazione. \nPossiamo intervenire (1) riducendo il numero delle dimensioni, o (2) \nriducendone l'importanza \n (\n2\n regularization), oppure (3) imponendo che la \nfunzione stimata sia \n smooth\n  cioè poco sensibile a piccoli cambiamenti \ndell'input.  \nAlcune teorie mettono in correlazione la smoothness con la capacità di \nessere resilienti alle perturbazioni nell'input. In base ad esse è stata proposta \nla tecnica di \n iniettare\n  rumore durante la forward propagation negli strati \nintermedi. L'obiettivo è minimizzare la situazione in cui un layer si \nspecializza solo su un sottoinsieme di pattern di attivazione del layer \nprecedente (\n co-adaptation\n ). \nNella pratica, si disabilitano una frazione di nodi del layer precedente così \nda contribuire con un valore pari a 0 nell'input del layer attuale\nℓ\n16",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#16": "Dropout (1)\nNel \ndropout\n  si assegna ad ogni nodo una probabilità \n p\n di essere disattivato \n(ignorato) in un certo step durante la fase di forward e backward propagation, \nad eccezione dell'output layer.  \n•\np\n è un iperparametro chiamato \n dropout rate\n  (es. p=0.5).  \n•\nOgni attivazione di un layer intermedia è sostituita con:  \n•\nNel caso fosse 0 i gradienti svaniscono durante il backpropagation.  \nDopo la fase di training (es. in produzione) tutti i nodi saranno attivati.  \nAd ogni step abbiamo una diversa con\n ﬁ\ngurazione di rete. \n Con N nodi \npossiamo avere 2\nN\n con\nﬁ\ngurazioni diverse, tutte addestrate per lo stesso scopo.\n17\n",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#17": "Dropout (2)\nUna impresa funziona meglio senza un dipendente?  \n•\nSì, se i lavoratori sanno adattarsi, cioè: ognuno si occupa di più cose, \nmaggiore cooperazione, e non contare solo sui vicini.  \nGarantisce reti più \n robuste \n e con capacità di \n generalizzazione\n . \nSi ottiene un incremento delle prestazioni del \n 1-2% \n per\nﬁ\nno nelle architetture \npiù ottimizzate.\n18",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#18": "Dropout - esempio\n19\nsenza Dropout con Dropout",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#19": "Dropout: altre considerazioni\nUna \n rete complessa\n  con molti parametri facilmente incorpora \ndipendenze che rappresentano feature dei dati di ingresso di scarso \ninteresse (\n over\nﬁ\ntting\n).  \n•\nSe ad ogni step proponiamo dati a diverse con\n ﬁ\ngurazioni di layer è \nmeno probabile che un certo peso si focalizzi su una feature poco \nsigni\nﬁ\ncativa.  \nLa tecnica dropout \n raddoppia circa il numero di iterazioni per \nraggiungere la convergenza\n , ma il \n tempo di addestramento per una \nepoca è più breve \n dato che ho meno nodi funzionanti.  \nPer avere aggiornamenti più lenti si può considerare un singolo mini-\nbatch per ogni con\n ﬁ\ngurazione considerata.\n20",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#2": "Richiami: Over\n ﬁ\ntting\nLe reti deep contengono molti parametri che mirano a modellare un insieme \nvasto di funzioni, anche complesse.  \nL'obiettivo dell'\n addestramento\n  è ottenere una rete che mostra \n buone \nprestazioni sia sul training set, sia in produzione \n (cioè su dati mai visti).  \n•\nIn queste condizioni si ha \n generalizzazione\n . \nIl \ntest set  \npermette di \n valutare l'over\n ﬁ\ntting\n del modello \n ﬁ\nnale testandolo su \ndati mai visti in precedenza durante il training, ma con distribuzione di \nprobabilità simile.  \n•\nSe un modello \n ﬁ\ntta\n i dati di training e di test contemporaneamente, si ha \nminimo over\n ﬁ\ntting.  \nIl \nvalidation set\n  è usato più raramente per \n valutare la combinazione migliore \ndegli iperparametri\n  durante lo sviluppo della rete. Non è impiegato durante il \ntraining né Nonostante ciò, le sue caratteristiche possono essere parzialmente \nrappresentate all'interno della rete, \n rendendo la valutazione meno oggettiva\n .\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#20": "Dropout e analogia col boosting\nSupponiamo di avere un problema di \n classi\n ﬁ\ncazione\n . Il \ndropout  \ninterpreta la rete come un insieme (molto grande) di classi\n ﬁ\ncatori \n“\nweak\n ”.  \n•\nDurante l’addestramento \n disattivo una parte della rete per \nsfruttare solo un sotto-modello alla volta\n . \n•\nL'\naccuratezza dei singoli sotto-modelli è minore di quella che \npotrei ottenere addestrando l'intera rete \n su tutto il training set.  \n•\nMa alla \n ﬁ\nne considero la \n rete nella sua interezza\n , cioè con tutti i \nsotto-modelli attivati, \n ottenendo un aumento delle prestazioni\n . \n•\nNel \nboosting si suppongono modelli indipendenti\n  mentre nel \ndropout c’è inevitabilmente dipendenza\n  dovuta alla condivisione \ndei parametri tra sotto-modelli.\n21",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#21": "Dropout nella pratica\nDal punto di vista operativo, con \n p=0.5,\n  durante il test ogni nodo di \nun qualsiasi hidden layer riceve il doppio degli input rispetto alla \nfase di training.  \n•\nDopo il training è importante moltiplicare il valore degli input per  \n1-p\n o avremmo dei segnali di ingresso con magnitudine troppo \nelevata. In alternativa, si può scalare l'output di ogni neurone.  \nDurante lo sviluppo della rete, se notiamo che il modello mostra \nover\nﬁ\ntting possiamo introdurre il dropout, ovvero incrementare \n p\n. \nSe mostra unde\n ﬁ\ntting lo decrementiamo.  \nDropconnect\n  è una variazione del dropout, dove sono gli archi ad \nessere disattivati.\n22",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#22": "Dropout\nIn una rete multi-layer, consideriamo il dropout su ogni layer?",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#23": "Dropout\nIn una rete multi-layer, consideriamo il dropout su ogni layer?  \nNegli \n hidden layers\n , per creare diverse con\n ﬁ\ngurazioni di rete da \naddestrare singolarmente.",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#24": "Dropout\nIn una rete multi-layer, consideriamo il dropout su ogni layer?  \nNegli \n hidden layers\n , per creare diverse con\n ﬁ\ngurazioni di rete da \naddestrare singolarmente.  \nNon lo consideriamo nel \n output layer \n essendo quello che genera \nil feedback necessario per addestrare la con\n ﬁ\ngurazione corrente.  \nEs. nel caso della classi\n ﬁ\ncazione, se omettiamo un nodo nel \nlayer di output, non otteniamo il comportamento della rete \nper quella classe. ",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#25": "Dropout\nIn una rete multi-layer, consideriamo il dropout su ogni layer?  \nNegli \n hidden layers\n , per creare diverse con\n ﬁ\ngurazioni di rete da \naddestrare singolarmente.  \nNon lo consideriamo nel \n output layer \n essendo quello che genera \nil feedback necessario per addestrare la con\n ﬁ\ngurazione corrente.  \nEs. nel caso della classi\n ﬁ\ncazione, se omettiamo un nodo nel \nlayer di output, non otteniamo il comportamento della rete \nper quella classe.  \nLo possiamo usare nel \n input layer \n perché permette di addestrare \nil modello ignorando alcune feature in ingresso che possono \nin\nﬂ\nuenzare negativamente l'addestramento (es. p=0.8)  \nE simile ad una feature selection.",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#26": "Dropout\n10-dropout\n  (python)\n",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#27": "Max-Norm regularization\nLa \nMax-norm regularization\n  introduce il \n vincolo sul modulo dei \npesi\n con un iperparametro \n r\n: \n ,            dove\n  indica la \n 2\n-norm  \nAd ogni training step normalizziamo i pesi:  \n \nRiducendo \n r\n, oltre a regolarizzare i pesi, si affronta anche il \nvanishing/exploding problem.  \nw\n2\n≤\nr\n ⋅\n2\nℓ\nw\n←\nw\nr\nw\n2",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#28": "Data Augumentation\nLa \ndata augumentation\n  genera nuove istanze da dare in input\n , \naumentando la dimensione del training set.  \nNel caso delle immagini (\n image augumentation\n ), si automatizza \nil processo con tecniche tradizionali quali:  \n•\nRuotare, spostare, ridimensionare, aggiungere un rumore, copie \nspeculari, variazioni di luce e contrasto, etc.  \n•\nEs. fare crop dell'immagine in modo che il soggetto compaia in \ndiverse posizioni, modi\n ﬁ\ncare l'intensità dei colori per ridurre la \nrelativa sensitività del modello.  \nLo scopo e (1) rendere la rete meno dipendente da queste \nvariazioni e (2) incrementare il set di training nel caso ci fossero \nun numero insuf\n ﬁ\nciente di istanze.",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#29": "Data Augumentation in Keras\n11-data_augmentation.ipynb\n",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#3": "Richiami: Over\n ﬁ\ntting\nPer ridurre l'over\n ﬁ\ntting si può intervenire:  \n•\nCambiando la struttura della rete\n  (es. riducendo il numero di nodi/pesi/\nlayer).  \n•\nAlterando i valori del parametri\n  durante l'addestramento.\n4",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#30": "Sparse Model\nElenca 2 modi per creare modelli sparsi  \nCon \nmodello sparso\n  indichiamo una versione \"sempli\n ﬁ\ncata\" di \nmodello tipicamente più complesso, utile per elaboratori con \nmeno risorse computazionali.  \nAd esempio: mini computers e smartphones.",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#31": "Sparse Model\nElenca 2 modi per creare modelli sparsi  \nUna volta addestrato il modello si possono azzerare i parametri \nvicini allo 0",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#32": "Sparse Model\nElenca 2 modi per creare modelli sparsi  \nUna volta addestrato il modello si possono azzerare i parametri \nvicini allo 0  \nLa \n 1\n regularization incrementa il numero di parametri vicino \nallo 0 che possono essere azzerati  \nIl \nFTRLOptimizer\n  è una altro algoritmo adatto per questo scopo.\nℓ",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#33": "Tool: Gradient Descent Visualization\nθ1\nθ2loss",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#34": "Richiami \n \n \n \n \nm\n←\nβ\n1\nm\n+\n(\n1\n−\nβ\n1\n)\n∇\nΘ\nJ\n(\nΘ\n)\ns\n←\nβ\n2\ns\n+\n(\n1\n−\nβ\n2\n)\n∇\nΘ\nJ\n(\nΘ\n)\n⊗\n∇\nΘ\nJ\n(\nΘ\n)\nm\n←\nm\n1\n−\nβ\nT\n1\ns\n←\ns\n1\n−\nβ\nT\n2\nΘ\n←\nΘ\n−\nη\n⋅\nm\n⊘\n s\n+\nϵ\n35Momentum :  \n \nRMSProp :  \n \n \n \n \n \nRMSProp : m←β⋅m+η∇ΘJ(Θ)\ns←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)\nΘ←Θ−η∇ΘJ(Θ)⊘ s+ϵ\n s←s+∇ΘJ(Θ)⊗∇ΘJ(Θ)\nΘ←Θ−η∇ΘJ(Θ)⊘ s+ϵAdaGradAdam",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#35": "Qualche indicazione pratica\nPer problemi di classi\n ﬁ\ncazione, inizia da una con\n ﬁ\ngurazione di default,  \ncome la seguente:  \nOppure cerca modelli pre-addestrati per compiti uguali o simili.  \nModi\n ﬁ\nca la con\n ﬁ\ngurazione intervenendo:  \n•\nSe \nconverge troppo lentamente incrementa il learning rate  \n•\nSe converge ma \n con performance non adeguate\n , prova un \n learning schedule\n , es. \nexponential decay.  \n•\nSe \nil training set è troppo piccolo, fai data augumentation\n",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#36": "Kaggle: piattaforma per competizioni ML-based\nOgni competizione consiste in un dataset di training e uno di test.  \nIl partecipante suddivide il training set in due, una parte per la \nvalidazione, oppure opera una cross-fold validation.  \nIl test set completo rimane privato \n ﬁ\nno alla \n ﬁ\nne della competizione.\n37\nhttps://www.kaggle.com/c/digit-recognizer/data",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#37": "Over\n ﬁ\ntting: un caso reale\nIl ranking \n ﬁ\nnale viene calcolato sul \n test set\n .\n38\nDifferenza rispetto al training (e validation) set pubblico\nScendendo si hanno di solito valori negativi: approcci che \nsi comportano molto bene nel training ma non nel test set.",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#38": "La regola del 30\nLa \nregola del 30  \nè un semplice procedimento empirico adatto per \nclassi bilanciate\n  (cioè con lo stesso numero di istanze per ogni label).  \nFornisce una idea \n se un incremento di prestazioni è signi\n ﬁ\ncativo o \nmeno\n  (es. dovuto solo al caso).  \nSe dopo aver aggiornato il classi\n ﬁ\ncatore ottengo un incremento \n(o decremento) di accuratezza che riguarda almeno 30 istanze, \nallora il miglioramento (peggioramento) è signi\n ﬁ\ncativo.  \n39",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#39": "La regola del 30\nSe il set di validazione ha \n N\n istanze, qual è la differenza minima \npercentuale per dire che l’incremento di accuratezza è signi\n ﬁ\ncativo? \n40",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#4": "Richiami: Over\n ﬁ\ntting\n5Training/Validation\n Produzione/\nTest\nlabel:A\nlabel:J\n",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#40": "La regola del 30: soluzione\nSe il set di validazione ha \n N\n istanze, qual è la differenza minima percentuale per \ndire che l’incremento di accuratezza è signi\n ﬁ\ncativo?  \nL’incremento percentuale si calcola:  \nEsempio:  \nSe N = 1000 -> 3%  \nSe N = 3000 -> 1%  \nSe N = 30.000 -> 0.1%  \nSeguendo la regola, è meglio usare un validation set ampio, così anche \nincrementi (es. 0.1%) possono essere tenuti in considerazione.  \nIndicazioni più accurate sono ottenute con \n test di signi\n ﬁ\ncatività\n .\n41(N+30)−N\nN⋅100",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#41": "Esercizio su Deep NN\nCostruisci una rete Deep, con 5 layer hidden da 100 nodi l'uno, \ninizializzazione Xavier e He, e funzione di attivazione ELU  \nUsa la Adam optimization con early stopping.  \nImpiega il dataset di cifre MNIST, ma solo da 0 a 4. Usa come output \nun layer softmax da 5 neuroni.  \nRicordati di salvare periodicamente i checkpoints, e il modello \n ﬁ\nnale.  \nFai tuning sugli iperparametri usando la cross-validation, e vedi se \npuoi incrementare la precisione.  \nProva ad aggiungere la Batch normalization e confronta le curve di \nlearning. Converge prima? Produce un modello migliore?  \nSecondo te c'è over\n ﬁ\ntting sul training set? Prova ad aggiungere il \ndropout ad ogni layer e valuta miglioramenti.\n42",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#42": "Esercizio sul Transfer Learning\nCrea una nuova Deep NN e riusa i parametri degli hidden layer della \nrete precedente. Congelali e rimpiazza il layer softmax con uno \nnuovo.  \nAddestra la rete sulle cifre 5-9, usando solo 100 immagini per cifra, e \nvedi quanto impiega. Nonostante le poche immagini riesci ad avere \nuna buona precisione?  \nProva a fare caching dei layer congelati, e addestra di nuovo il \nmodello. Quanto è veloce ora?  \nProva di nuovo usando solo 4 hidden layer. La precisione aumenta?  \nOra scongela i primi 2 layer e continua il training. Ottieni maggiori \nperformance?\n43",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#43": "Esercizio sul Pretraining su auxiliary task\nCostruiamo una Deep NN che confronta due cifre MNIST per veri\n ﬁ\ncare se sono le \nstesse. Dopodiché impieghiamo gli stessi layer \n ﬁ\nnali della rete per addestrare un \nclassi\n ﬁ\ncatore MNIST su pochissimi dati di training.  \nInizia da 2 Deep NN (A e B), simili a quanto costruito nel esercizio su Deep NN. \nAggiungi un singolo layer di output che connette l'output di ambedue le reti. Usa la \nfunzione concat() di Tensor\n ﬂ\now con axis=1. Usa quanto ottieni come input al nuovo \noutput layer. L'output layer contiene un singolo nodo e usa la logistic come funzione \ndi attivazione.  \nSuddividi MNIST in 2 sets: primo split da 55,000 immagini, secondo split da 5,000. \nCrea una funzione che genera un batch dove ogni istanza è una coppia di immagini \nprese dallo split #1. Metà devono appartenere alla classe \"stessa classe\" (label 0), \nl'altra metà \"classi diverse\" (label 1).  \nAddestra la rete sul training set. Per ogni coppia manda in input in simultanea \nl'immagina da A e l'immagine da B.  \nOra crea una nuova rete riutilizzando e congelando i pesi degli hidden layers di A e \naggiungendo una softmax layer di 10 nodi. Addestra la rete sullo split #2 e vedi se \nottieni prestazioni elevate avendo solo 500 immagini per classe.\n44",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#5": "Affrontare l'Over\n ﬁ\ntting\nValori dei pesi limitati in modulo signi\n ﬁ\ncano spesso modelli meno complessi, e meno \nin\nﬂ\nuenzati da \n ﬂ\nuttuazioni statistiche dei dati in input.  \n•\nValori elevati nei pesi implicano attivazioni molto diverse per leggere variazioni in input.  \nTranne nei casi di training set molto grandi, si impiegano sempre \n tecniche di \nregolarizzazione\n , tra le quali:  \n•\nEarly stopping\n : \n•\nterminare l'addestramento quando le performance degradano  \n•\n 1\n e \n 2\n regularization (o weight regularization)\n :  \n•\npenalizzare il modello in base alla magnitudo dei pesi  \n•\nDropout\n : \n•\nper ogni layer ignorare alcuni input durante l'addestramento  \n•\nMax-Norm regularization (o weight constraint)\n :  \n•\nintrodurre un range di ammissibilità per il valore dei pesi  \n•\nData Augumentation (non regolarizza i pesi, ma aumenta la dimensione del training set)\n : \n•\nmodi\n ﬁ\ncare il training set, es. aggiungendo del rumore\nℓ\nℓ\n6",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#6": "Richiami: Over\n ﬁ\ntting\n7\nComplessità del modello",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#7": "Richiami: bias e varianza \nHigh Validation error\nHigh Test errorSi\nSiNo\nNo\nDone! •Bigger mode l\n•Train longer  \n•New model architecture \n•More data  \n•Regularization  \n•New model architecture Bias \n(unde ﬁt)\nVarianc e\n(over ﬁt)\n",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#8": "Over\n ﬁ\ntting e regolarizzazione\nIl procedimento di training \n ﬁ\nnora seguito è:  \n•\naddestrare\n  il modello su un training set, e valutare l'\n errore di \ngeneralizzazione\n  su holdout data (test set).  \nLa differenza di performance tra i due set si chiama \n generalization gap\n . Se \nla differenza è elevata si ha \n over\nﬁ\ntting\n sul training data.  \nNello scenario del DL, prendendo l'esempio del task della classi\n ﬁ\ncazione, \nsi hanno tipicamente modelli complessi a suf\n ﬁ\ncienza per \n ﬁ\nttare\n ogni istanza \ndi training, anche per training set molto grandi. Farebbe pensare che per \nridurre il generalization error siamo costretti a introdurre regolarizzazioni \n(es. riducendo la complessità, vincoli sul valore dei parametri).  \nIn realtà si nota come nel DL si raggiungano spesso 0 training error, perciò \nl'unico aspetto da ottimizzare è il generalization error. Inoltre, contrario alla \nlogica, l'errore si può ridurre anche rendendo l'architettura più complessa \n(es. più layer e nodi). I progettisti hanno più possibilità di affrontare \nl'over\n ﬁ\ntting rispetto alle architetture NN tradizionali.\n9",
    "data_test\\rootfolder\\università\\DeepLearning\\11-Training Deep 3-sbloccato.pdf#9": "Ispirazione ai modelli non parametrici\nGli approcci parametrici possono essere de\n ﬁ\nniti in vari modi, es. sono \nbasati su modelli statistici che rappresentano i parametri con distribuzioni \nstandard. Nei modelli nonparametrici la variabilità dei parametri è più \nampia e ci sono meno vincoli da rispettare (es. su media, varianza).  \nSpesso i modelli nonparametrici confrontano le istanze e si basano \nsull'ipotesi che istanze simili in input producono output simili (es. k-NN).  \nUn altro modo per caratterizzare i modelli nonparametrici è sulla \ncomplessità che tende a crescere al crescere del numero di dati disponibili \ndi training.  \nLe reti NN sono spesso viste come modelli non parametrici\n . Si hanno un \nnumero molto abbondate di parametri che tendono a interpolare i training \ndata.\n10",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nRecurrent Neural Networks (RNN) - parte #1\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#1": "Sommario\nNodi e layers ricorrenti  \n•\nCalcolo degli output  \nPredizione  \nArchitetture RNN  \n•\nSequence-to-sequence  \n•\nSequence-to-vector  \n•\nVector-to-sequence  \n•\nEncoder-decoder  \nMemory cells  \n•\nLSTM  \n•\nGRU",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#10": "Architetture RNN (1) \nCi sono vari tipi di architetture RNN, che dipendono dal task che si vuole \naffrontare.  \nLa rete \n sequence-to-sequence\n  è utile per task di \n predizione\n .  \n•\nSupponiamo di avere la quotazione di chiusura di un titolo in borsa, misurata \nnegli ultimi N giorni. La rete deve produrre in output le stesse quotazioni \ntraslate di un giorno nel futuro.  \nLa rete \n sequence-to-vector\n  è simile alla precedente ma \n scarta tutti i valori in \noutput tranne l'ultimo\n . \n•\nSe in input abbiamo una sequenza di \n id\n di parole, l'ultimo output può \ncorrispondere al \n sentiment\n  (es. -1 [hate], +1 [love).\n11\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#11": "Architetture RNN (2) \nLa rete \n vector-to-sequence\n  prende in input ripetutamente lo stesso vettore per \nuna successione di steps e produce una sequenza in output.  \n•\nSe il vettore in input corrisponde ad una immagine, possiamo addestrare la \nrete per produrre una descrizione testuale associata (sequenza di parole).\n12\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#12": "Architetture RNN (3) \nIn\nﬁ\nne si può combinare una rete \n sequence-to-vector\n  (\nencoder\n ) con una \nvector-to-sequence\n  (\ndecoder\n ) ottenendo una rete \n encoder-decoder\n . \n•\nUn \nencoder\n  può rappresentare una frase in un linguaggio in un singolo \nvettore che viene impiegato poi dal \n decoder\n  per generare la frase in diverso \nlinguaggio.  \n•\nUna rete \n sequence-to-sequence\n  non è adatta poiché l'intera frase. Le ultime \nparole dell'input potrebbero in\n ﬂ\nuenza l'inizio dell'output, mentre la rete \ntraduce ogni parola via via che l'input è reso disponibile. Inoltre le lunghezze \ndell'input e output potrebbero non corrispondere.\n13\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#13": "RNN: Addestramento \nL'addestramento di una RNN richiede l'\n unrolling through time\n  e l'uso della \ntecnica \n backpropagation through time\n  (\nBPTT\n ). \n•\nLa prima passata corrisponde alla \n forward\n  pass tradizionale (frecce \ntratteggiate).  \n•\nL'output è valutato con una \n funzione di costo  \n . Per talune \narchitetture la funzione può ignorare alcuni output.  \n•\nIl gradiente della funzione di costo è propagato \n backward\n  (frecce continue) e \ni parametri aggiornati di conseguenza.\nC\n(\nY\n(\n0\n)\n,\nY\n(\n1\n)\n,\n⋯\n,\nY\n(\nT\n)\n)\n14\nIn questo esempio la funzione  \nè valutata con gli ultimi 3 \noutput, e perciò i gradienti non \ntransitano per Y (0) e Y (1).\nDa notare che i medesimi \nparametri W,b sono impiegati \nad ogni step. La \nbackpropagation considera \ntutti gli steps per fare \nl'aggiornamento.",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#14": "Time series: Predizione (forecasting)\nAnalizziamo le seguenti \n time series\n :  \n•\nnumero orario di utenti attivi su un sito web,  \n•\ntemperatura giornaliera in un certo luogo  \n•\nsituazione \n ﬁ\nnanziare di una società misurata trimestralmente con metriche \nmultiple (es. reddito, debito, etc).  \nLe prime due sono \n univariate  \ntime series\n  perché valutiamo temporalmente \nuna singola metrica, l'ultima è una \n multivariate  \ntime series\n . \nLa predizione di un valore in un tempo futuro è chiamato \n forecasting\n . \nCon \nimputation\n  si intende stimare un valore mancante all'interno della time \nseries.  \nLe RNN si usano spesso per fare \n forecasting\n  e \nimputation\n .\n15",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#15": "RNN e Keras (1)\nGeneriamo \n time series\n  in modo random:  \ndef \ngenerate_time_series\n (\nbatch_size\n , \nn_steps\n)\n:\n    \n# valori random in [0,1); il parametro di rand è lo shape\n    freq1, freq2, offsets1, offsets2 = np.random.rand(\n 4\n, batch_size, \n 1\n)\n    \n# n_steps valori nell'intervallo 0, 1 equamente spaziati\n    time = np.linspace(\n 0\n, \n1\n, n_steps)\n    series = \n 0.5\n * np.sin((time - offsets1) * (freq1 * \n 10\n + \n10\n))  \n#   wave 1\n    series += \n 0.2\n * np.sin((time - offsets2) * (freq2 * \n 20\n + \n20\n)) \n# + wave 2\n    series += \n 0.1\n * (np.random.rand(batch_size, n_steps) - \n 0.5\n)   \n# + noise\n    \nreturn\n series[..., np.newaxis].astype(np.float32)\nDove \nbatch_size\n  sono il numero di \n time series\n  da generare con lunghezza \nn_steps\n . Le serie sono \n univariate\n . La funzione restituisce un array NumPy di \ndimensioni [\n batch_size\n , \nn_steps\n , 1].  \nOgni serie è generata come somma di due funzioni \n seno\n di ampiezza \n ﬁ\nssa ma \nfrequenza e fase random, e con aggiunta di rumore.  \n16",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#16": "RNN e Keras (2)\nCreiamo training set, validation set e test set:  \nn_steps = \n 50\nseries = generate_time_series(\n 10000\n, n_steps + \n 1\n)\nX_train, y_train = series[:\n 7000\n, :n_steps], series[:\n 7000\n, \n-1\n]\nX_valid, y_valid = series[\n 7000\n:\n9000\n, :n_steps], series[\n 7000\n:\n9000\n, \n-1\n]\nX_test, y_test = series[\n 9000\n:, :n_steps], series[\n 9000\n:, \n-1\n]\nX_train\n  contiene 7000 time series di lunghezza 50 steps, e ha dimensioni \n[7000,50,1]  \nX_valid\n  contiene 2000 time series  \nX_test\n  contiene 1000 time series  \nPoiché vogliamo un \n forecast\n  di un singolo valore per time series, il vettore \ncolonna target ha dimensioni [7000,1]  \n17",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#17": "RNN e Keras (3)\nPer valutare il modello introduciamo degli approcci \n baseline\n , con cui \nconfrontarci.  \nUn semplice modello stima il valore futuro facendolo coincidere con l'ultimo \nvalore nella time series (\n naive forecoasting\n ). \n>>> y_pred = X_valid[:, \n -1\n]\n>>> np.mean(keras.losses.mean_squared_error(y_valid, y_pred))\n0.020211367\n•\nSebbene banale, ottiene buone prestazioni: \n Mean squared error (MSE) di 0.02  \nUn altro approccio è impiegare una rete \n fully connected\n . Ad esempio con un \nsingolo layer, perciò si riduce ad una combinazione lineare dei valori della \ntime series in ingresso.  \nmodel = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[\n 50\n, \n1\n]),\n    keras.layers.Dense(\n 1\n)\n]\n)\n•\nCon la con\n ﬁ\ngurazione: MSE loss, Adam optimizer, 20 epoche di training; si \nottiene un MSE di 0.004.\n18",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#18": "RNN e Keras (4)\nImplementiamo una semplice RNN, con un layer con un singolo nodo con la \nfunzione Keras \n SimpleRNN\n .  \nmodel = keras.models.Sequential(\n [\n  keras.layers.SimpleRNN(1, input_shape=[None, 1]\n )\n]\n)\nCome dimensione dell'input impostiamo \n None\n  poiché una RNN elabora \n time \nseries\n  di qualsiasi lunghezza e non occorre speci\n ﬁ\ncarla anticipatamente.  \nDi default la \n SimpleRNN\n  usa la attivazione \n tangente iperbolica\n .  \nIl primo output viene elaborato con \n h\n(init)\n=0\n e \nx\n(0)\n pari al valore in input al \nprimo step. Il nodo calcola la somma pesata dei 2 contributi e valuta la \ntangente iperbolica al risultato, ottenendo il primo valore in output \n y\n0\n. Nella \nSimpleRNN\n  tale valore corrisponde al valore per lo stato \n h\n(0)\n.  \nAl successivo step, lo stesso nodo prende in input il successivo input \n x\n(0) \ne lo \nstato \n h\n(0)\n e ripete l'elaborazione.  \nL'unico valore in output corrisponde \n y\n49\n. Se si vogliono ottenere tutti i valori in \noutput impostare \n return_sequences=True\n .\n19",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#19": "RNN e Keras (5)\nUna volta compilato e sottoposto a \n ﬁ\nt (con\n ﬁ\ngurazione: 20 epoche, Adam op.), \ntale modello raggiunge un MSE di 0.014, perciò al di sotto del modello \nlineare.  \n•\nIl modello lineare ha un totale di 51 parametri, cioè un parametro per ogni \ninput e il bias. Nella SimpleRNN abbiamo un singolo parametro per input, \nuno per l'hidden state e per il bias, cioè 3 parametri in totale.  \n•\nUn SimpleRNN è una rete troppo semplice per avere questo task.\n20",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#2": "Motivazioni\nAbbiamo assunto input per i nostri modelli di tipo vettoriale, dove ogni \nelemento \n x\nj\n corrisponde ad un attributo (o feature). Perciò possiamo \nraggruppare facilmente i dati in formato tabellari \n istanze \n x\n attributi\n . \nSuccessivamente abbiamo considerato immagini, dove per ogni coordinata \nabbiamo il valore del pixel. In questo scenario abbiamo introdotto le CNN, \ncapaci di implementare logiche gerarchiche e gestire proprietà di \ninvarianza.  \nCome possiamo trattare input sotto forma di sequenze, come time series \nprediction, video analysis, etc?  \nOppure affrontare task che producono in output sequenze come l'\n image \ncaptioning, speech synthesis, \n e\n music generation.\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#20": "Trend e stagionalità (seasonality)\nCi sono molti altri modelli per il forecast di time series, come il \n weighted \nmoving average\n  e l'\nautoregressive integrated moving average \n (\nARIMA\n ). \nAlcune modelli richiedono di \n rimuovere preliminarmente trend e stagionalità \nnei dati, ad esempio:  \n•\nSe i visitatori di un sito web crescono stabilmente 10% al mese, occorre \nrimuovere questa variazione dai dati in input. Una volta ottenuta la \npredizione si può reintegrare al valore \n ﬁ\nnale.  \n•\nPer predire la vendita di creme solari, occorre preliminarmente rimuovere la \nstagionalità annuale associata ai mesi estivi. Per esempio, rimuovendo al \nvalore attuale il valore nell'anno precedente (\n differencing\n ). Si può reintegrare \nal valore \n ﬁ\nnale ottenuto.  \nLe RNN non richiedono generalmente questi preprocessamenti, anche se \npossono aumentare le prestazioni, poiché la rete non è costretta ad \napprenderli.\n21",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#21": "Deep RNN: considerazioni\nUna DeepRNN raggiunge un MSE di 0.003.  \nUna architettura più adatta avrebbe un ultimo layer con un singolo valore in \noutput per time step. Ma in questo caso avremmo un \n hidden state  \nrappresentato con un solo valore, che non avrebbe molta utilità. Una \nDeepRNN sfrutta tutti gli hidden states dei layer precedente per \"trasportare\" \nl'informazione necessaria per produrre l'ultimo output, e il contributo \ndell'hidden dell'ultimo layer risulta assai limitato.  \nPossiamo sostituire il layer in output con un layer fully connected (o Dense). \nL'accuratezza non è alterata, il tempo di addestramento si riduce leggermente \ne possiamo scegliere qualsiasi funzione di attivazione.  \nmodel = keras.models.Sequential([\n    keras.layers.SimpleRNN(\n 20\n, return_sequences=\n True\n, input_shape=[\n None\n, \n1\n]),\n    keras.layers.SimpleRNN(\n 20\n),\n    keras.layers.Dense(\n 1\n)\n])\n22",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#22": "Predizione di più dati\nPossiamo tentare di stimare più valori temporalmente futuri, impi  \nElenchiamo alcuni approcci:  \n•\nUsare l'output come input nello step successivo ottenendo un valore alla \nvolta  \n•\nSimile al precedente ma in output prediciamo contemporaneamente più \nvalori ma considerando una unica loss (\n sequence-to-vector\n ) \n•\nSimile al precedente ma con una loss per ogni valore predetto (\n sequence-to-\nsequence\n )\n23",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#23": "Predizione di più dati - uno dato alla volta\nPossiamo tentare di stimare più valori temporalmente futuri.  \nUna possibilità è impiegare il modello attuale, ottenere l'output e \nconcatenarlo al predente input, ottenendo un secondo input e così via.  \n•\nAd esempio, per predire 10 dati:  \nseries = generate_time_series(\n 1\n, n_steps + \n 10\n)\nX_new, Y_new = series[:, :n_steps], series[:, n_steps:]\nX = X_new\nfor\n step_ahead \n in \nrange\n(\n10\n):\n    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n    X = np.concatenate([X, y_pred_one], axis=\n 1\n)\nY_pred = X[:, n_steps:]\nOtteniamo un MSE=0.029. L'approccio \n naive\n  ottiene 0.223, ma il modello \nlineare 0.0188, ed è più accurato e veloce da addestrare.  \nLa Deep RNN rimane valida se limitiamo il numero di valori da predire.\n24",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#24": "Predizione di più dati - sequence-to-vector\nUna seconda opzione è addestrare la RNN per predire 10 valori \ncontemporaneamente.  \n•\nUsiamo la \n sequence-to-vector\n , ma con 10 valori in output invece di 1.  \nIntanto cambiamo i valori target:  \nseries = generate_time_series(\n 10000\n, n_steps + \n 10\n)\nX_train, Y_train = series[:\n 7000\n, :n_steps], series[:\n 7000\n, \n-10\n:, \n0\n]\nX_valid, Y_valid = series[\n 7000\n:\n9000\n, :n_steps], series[\n 7000\n:\n9000\n, \n-10\n:, \n0\n]\nX_test, Y_test = series[\n 9000\n:, :n_steps], series[\n 9000\n:, \n-10\n:, \n0\n]\nL'output layer consisterà di 10 nodi:  \nmodel = keras.models.Sequential([\n    keras.layers.SimpleRNN(\n 20\n, return_sequences=\n True\n, input_shape=[\n None\n, \n1\n]),\n    keras.layers.SimpleRNN(\n 20\n),\n    keras.layers.Dense(\n 10\n)\n]\n)\nE si potranno predire 10 valori in modo simile:  \nY_pred = model.predict(X_new)\nOra l'MSE è di 0.008, migliore del modello lineare.\n25",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#25": "Predizione di più dati - sequence-to-sequence\nUn ulteriore modello da impiegare è il \n sequence-to-sequence\n , dove le 10 \npredizioni sono comunque ottenute sequenzialmente step-by-step.  \n•\nIl vantaggio è avere una \n loss\n ad ogni step, perciò più gradienti che saranno \nusati per aggiornare il modello, non solo seguendo un approccio \n through-time,  \nma direttamente dagli output generati, come avviene nelle reti non ricorrenti.  \nAl primo step il modello produrrà in output la predizione per gli step da 1 a 10, \nallo step successivo le predizioni da 2 a 11, e così via. Il target avrà la stessa \nlunghezza dell'input.  \n•\nSebbene in output otteniamo una parte dei valori usati in input, l'input \ncorrente consiste sempre in valori apparsi nel passato. Sarebbe scorretto \nimpiegare valori del dataset che temporalmente sono da considerarsi futuri.  \nCreiamo le sequenze target di 10 elementi:  \nY = np.empty((\n 10000\n, n_steps, \n 10\n)) \n# each target is a sequence of 10D vectors\nfor\n step_ahead \n in \nrange\n(\n1\n, \n10\n + \n1\n):\n    Y[:, :, step_ahead - \n 1\n] = series[:, step_ahead:step_ahead + n_steps, \n 0\n]\nY_train = Y[:\n 7000\n]\nY_valid = Y[\n 7000\n:\n9000\n]\nY_test = Y[\n 9000\n:]\n26",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#26": "Predizione di più dati - sequence-to-sequence\nPer avere un modello \n sequence-to-sequence\n  impostiamo \nreturn_sequences=True\n  per ogni layer, compreso l'ultimo. Ad ogni step \nvalutiamo l'output del layer FC.  \n•\nKeras fornisce il \n TimeDistributed\n  layer, adatto ad essere valutato ad ogni step. \nI valori in input vengono automaticamente ridimensionati cosicché ogni step \nè trattato come una istanza separata  \n•\n[\nbatch size, time steps, input dim.\n ] \n [\nbatch size × time steps, input dim.\n ] \n•\nNell'esempio abbiamo 20 nodi nel layer \n SimpleRNN\n . L'output sarà una \nsequenza e non un singolo vettore. Il layer Dense viene applicato in modo \nindipendente ad ogni step.  \nmodel = keras.models.Sequential([\n    keras.layers.SimpleRNN(\n 20\n, return_sequences=\n True\n, input_shape=[\n None\n, \n1\n]),\n    keras.layers.SimpleRNN(\n 20\n, return_sequences=\n True\n),\n    keras.layers.TimeDistributed(keras.layers.Dense(\n 10\n))\n])\n→\n27",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#27": "Predizione di più dati - sequence-to-sequence\nL'output nell'ultimo step è impiegato per la predizione e valutazione.  \nSebbene usiamo la MSE su tutti gli output, per la valutazione ci limitiamo a \nusare una metrica \n custom\n  che elabora l'MSE sull'ultimo step.  \ndef \nlast_time_step_mse\n (\nY_true\n, \nY_pred\n):\n    \nreturn\n keras.metrics.mean_squared_error(Y_true[:, \n -1\n], Y_pred[:, \n -1\n])\noptimizer = keras.optimizers.Adam(lr=\n 0.01\n)\nmodel.\ncompile\n(loss=\n\"mse\"\n, optimizer=optimizer, metrics=[last_time_step_mse])\nSi ottiene MSE di 0.006, 25% meglio del modello precedente.  \nÈ possibile combinare i due approcci: predire 10 valori, concatenarli ai dati in \ninput e predire i successivi 10, ottenendo sequenze di lunghezza arbitraria.  \nNota: Il \n Montecarlo Dropout\n  (\nMC Dropout\n ) è spesso inclusa in ogni cella per \nomettere in modo random parte degli input e degli hidden state.  \n28",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#28": "Predizione di più dati: limiti (1)\nPer addestrare una RNN su sequenze molto lunghe occorre creare \n reti molto \ndeep\n , coi noti problemi di \n instabilità dei gradienti\n  (es. tempo di \napprendimento troppo lungo, o instabile).  \nInoltre la rete fa più fatica a ricordare le informazioni iniziali della sequenza.  \nAlcune tecniche viste possono essere nuovamente applicate (es. dropout, \noptimizers più adatti alla architettura deep).  \nLe \nReLU  \nnon sono adatte\n  per le \n RNN\n . \n•\nSupponiamo che la discesa del gradiente aggiorni i parametri in modo da \nincrementare leggermente l'output. Siccome ad ogni step sono usati gli stessi \nparametri, anche l'output al successivo step può essere leggermente \nincrementato, e così via, \n ﬁ\nno a valori troppo elevati o instabili. \n Una funzione \nche non satura non può prevenire questo\n .  \n•\nAnche i gradienti possono assumere valori troppo elevati, perciò sono utili \ntecniche quali il \n Gradient clipping.\n29",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#29": "Predizione di più dati: limiti (2)\nLa \nBatch normalization\n  non mostra sperimentalmente la stessa ef\n ﬁ\ncacia \nrispetto alle reti deep tradizionali e non ottiene bene\n ﬁ\nci. \n•\nTeoricamente un layer BN può essere aggiunto ad ogni memory cell, e \ninterverrà dopo ogni step, sia sugli input correnti sia sull'hidden state (dello \nstep precedente).  \n•\nMa il layer BN sarà usato ad ogni step, con gli stessi parametri, senza \nconsiderare la scala di valori e l'offset degli input e dell'hidden state attuali.  \nNota: un tecnica simile ma più adatta è la \n Layer normalization\n , ma invece di \nnormalizzare rispetto al batch, normalizza rispetto alla dimensione delle \nfeatures.\n30",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#3": "Introduzione\nUna \n time series\n  consiste in una serie di misurazioni indicizzate con un \nordine temporale.  \n•\nEs. ultima quotazione giornaliera di un titolo \n ﬁ\nnanziario, situazione oraria del \nmeteo, traiettoria di una automobile  \nLe \nRecurrent Neural Networks\n  (\nRNN\n ) sono architetture di reti neurali \nadatte ad analizzare time series e stimare misure mancanti o future.  \nRispetto alle \n CNN\n  possono elaborare dati in ingresso con lunghezza \narbitraria non pre\n ﬁ\nssata, più adatte in certi contesti.  \n•\nEs. analisi di una frase per fare una traduzione automatica o speech-to-text  \nCiononostante non sono le uniche architetture per \n time series\n . \n•\nReti\n fully-connected \n sono sempre adatte per sequenze di lunghezza \nlimitata, mentre sequenze molto lunghe possono essere elaborate da \nﬁ\nltri convoluzionali.\n4",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#30": "RNN più recenti\nLe celle introdotte \n ﬁ\nnora soffrono del problema del \n vanishing\n  (e exploding) \ngradient. Il gradient clipping o altre tecniche, sebbene risolvano il problema, \nnon permettono alle RNN di analizzare sequenze lunghe.  \nPer tale motivo sono state introdotte le \n memory cells\n , cioè unità di \nelaborazione che mantengono lo stato memorizzato e lo propagano alle celle \nsuccessive evitando che \"svanisca\" a causa dei gradienti troppo bassi.  \nLe \nLong Short-Term Memory (LSTM)\n  sono le prime memory cell introdotte in \nletteratura, le \n Gated Recurrent Unit (GRU)\n  ne sono una versione sempli\n ﬁ\ncata. \nNelle \n Bidirectional Recurrent Neural Networks\n  si sfruttano le informazioni \nraccolte negli step precedenti e successivi per determinare l'output nello step \ncorrente.\n31",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#31": "Celle LSTM - motivazioni\nLe \nLSTM\n  sono memory cells introdotte per dotare la cella di memoria \n a lungo \ntermine \n utile per riconoscere pattern di segnale più estesi.  \nOltre alla rappresentazione \n long-term\n , determinata dai pesi che sono appresi \ndurante il training, le celle hanno una memoria\n  short-term\n  capace di \nrappresentare le attivazioni ef\n ﬁ\nmere. Tale memoria viene condivisa da una \ncella alla successiva.  \nAll'interno delle memory cells, oltre allo stato, esistono una serie di \n gate \ncontrollers\n  che determinano quali input in\n ﬂ\nuenzano lo stato, se lo stato deve \nessere azzerato (o dimenticato) e come lo stato in\n ﬂ\nuenza l'output della cella.  \n•\nPerciò nella LSTM esistono meccanismi dedicati sia per aggiornare lo stato, \nsia per azzerarlo.  \nI gate sono governati da parametri che sono stimati durante l'apprendimento.\n32",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#32": "Celle LSTM e Keras\nKeras ne sempli\n ﬁ\nca l'uso con la funzione \n LSTM\n : \nmodel = keras.models.Sequential([\n    keras.layers.LSTM(\n 20\n, return_sequences=\n True\n, input_shape=[\n None\n, \n1\n]),\n    keras.layers.LSTM(\n 20\n, return_sequences=\n True\n),\n    keras.layers.TimeDistributed(keras.layers.Dense(\n 10\n))\n]\n)\nO impiegando la cella general purpose \n RNN\n  che può assumere come \nargomento \n LSTMCell\n , utile per creare celle \n custom\n , con lo svantaggio di \nperdere parte delle ottimizzazioni GPU:  \nmodel = keras.models.Sequential([\n    keras.layers.RNN(keras.layers.LSTMCell(\n 20\n), return_sequences=\n True\n,\n                     input_shape=[\n None\n, \n1\n]),\n    keras.layers.RNN(keras.layers.LSTMCell(\n 20\n), return_sequences=\n True\n),\n    keras.layers.TimeDistributed(keras.layers.Dense(\n 10\n))\n]\n)\nSuccessivamente vedremo una implementazione con le funzionalità\n  d2l\n.\n33",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#33": "Celle LSTM: Architettura (1)\nL'architettura di una cella \n LSTM\n  è la seguente:  \nEsistono 4 gates (\n FC\n) i cui input sono: l'\n hidden state\n  dello step precedente \n h\n(t-1) \ne l'input corrente \n x\n(t)\n.  \nI gate sono: \n forget gate\n , \ninput gate\n , \noutput gate\n , e \ninput node\n . I relativi output, \nf(t)\n, \ni(t)\n, \no(t)\n e \ng(t)\n; sono determinati da una rete fully connected (FC). Hanno \ntutti funzione di attivazione \n logistic\n , tranne l'\n input node\n  che impiega la \n tanh\n.\n34\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#34": "Celle LSTM: Architettura (2)\nPossiamo interpretare i gate nel seguente modo:  \n•\nL'\ninput gate\n  determina quanto dell'input corrente deve essere aggiunto ad \n c\n(t) \nche assume il ruolo di stato corrente.  \n•\nIl \nforget gate \n in\nﬂ\nuenza quanto tenere e quanto dimenticare dello stato interno \nprecedente \n c\n(t-1)\n.  \n•\nL'\noutput gate\n  quanto la cella corrente in\n ﬂ\nuenzerà l'output \n y\n(t)\n. \n•\nL'\ninput node\n  rappresenta la computazione di una cella ricorrente tradizionale.\n35\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#35": "Celle LSTM: Architettura (3)\nPer esempio, se il \n forget gate\n  fosse sempre 1 e l'\n input gate\n  fosse 0, lo stato \n c\n(t-1) \nrimarrebbe imperturbato negli step futuri. Nella realtà, i gate saranno addestrati \nin modo da perturbare lo stato in funzione degli input analizzati dalla cella.  \n•\nQuesta tecnica basata su gate affronta il \n vanishing gradient problem  \ngarantendo che gli stati possano propagarsi temporalmente per molti step.  \nL'\ninput node\n  produce \n g\n(t)\n e si comporta come una cella \"base\", ma nella LSTM \nuna parte rilevante del output del cella base è memorizzato nello stato interno \nc(t)\n, e il resto scartato. La suddivisione tra output e stato è più netta. \n36\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#36": "Celle LSTM: Architettura (4)\nL'output della cella \n h(t), \n corrispondente al valore y di una cella tradizionale, è \ngenerato prendendo il valore \n tanh\n dello stato interno corrente \n c(t)\n e calcolando \nuna moltiplicazione element-wise con il valore ottenuto dall'\n output gate\n . \n•\nSe l'\noutput gate\n  è 1 lo stato interno in\n ﬂ\nuenzerà i layer successivi (in una \narchitettura multilayer) nello step corrente. Se è 0 lo stato non li in\n ﬂ\nuenzerà.  \n•\nÈ sempre possibile che lo stato interno si propaghi per molti step, e che non \nin\nﬂ\nuenzi l'output a causa dell'\n output gate \n che lo inibisce, \n ﬁ\nno ad un certo \nstep in cui il gate potrà invertire il valore. Per tale motivo \n h(t)\n è visto come \nstato \n short-term,\n  mentre \n c(t) \nlong-term\n .\n37\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#37": "Celle LSTM: Architettura (5)\nIn sintesi, la \n LSTM\n  è in grado di riconoscere sequenze lunghe, per mezzo dell'\n input \ngate\n, memorizzarlo in uno stato long-term, e preservarlo \n ﬁ\nnché è giudicato \nimportante, per mezzo del\n  forget gate\n , e ripescarlo quando necessario.  \n•\nPer tale motivo le LSTM hanno ottenuto buoni risultati nell'analisi di pattern, anche molto estesi, in \ntime series, testi, audio, etc.  \nIn termini analitici, per una singola istanza in input si ha:  \n•\ndove \n W\nxi\n, \nW\nxf\n, \nW\nxo\n,\nW\nxg\n sono le matrici dei pesi dei 4 layer per le connessioni con \nl'input vector \n x\n(t)\n. \n•\nW\nhi\n, \nW\nhf\n, \nW\nho\n,\nW\nhg\n sono le matrici dei pesi dei 4 layer per le connessioni con lo stato \nshort-term precedente \n h\n(t-1)\n. \n•\nb\ni\n, \nb\nf\n, \nb\no\n,\nb\ng\n sono i bias, inizializzati a 1 invece di 0 per evitare di \"dimenticare\" tutto \nall'inizio del training.\n38\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#38": "Celle LSTM, Keras e d2l\n11-memory_cells.ipynb\n39",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#39": "Celle LSTM: Peephole connections\nIn una cella LSTM tradizionale i gate controllers analizzano \n x\n(t)\n e \nh\n(t-1)\n. Può \nessere utile dargli la possibilità di usare le informazioni nello stato long-term.  \nLe \npeephole connections\n  aggiungono il precedente stato long-term \n c\n(t-1) \nall'input dei controllers del \n forget\n  e \ninput\n  gate. Lo stato long-term corrente \n c\n(t)\n è \naggiunto all'input controller dell'output gate.  \nNon sempre ci sono miglioramenti,  \nperciò si può tentare di usarli e valutare.  \nIn Keras non c'è supporto uf\n ﬁ\nciale alla cella con \n peephole connections\n , ma si \npuò creare un layer RNN generico e passargli \n PeepholeLSTMCell\n  al suo \ncostruttore.\n40\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#4": "Alcuni task con dati temporali\nSpeech recognition  \nMusic generation  \nSentiment classi\n ﬁ\ncation  \nDNA sequence analysis  \nMachine translation  \n(Video) Activity recognition\n“It was a bright cold day in \nApril, and the clocks were \nstriking thirteen\n“I loved this so much. I crap out \non books about 40 pages in about \n90% of the time.”\nØ  \no few inputs\nACAAGATGCCATTGTCCCCCGGCCTCCTGCTGC ACAAGATG CCATTGTCCCCCGGCCTCCT GCTGC\n“Ho corso per arrivare in orario.” “I ran to get on time.”\nAlzarsi -> In piedi -> Camminare",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#40": "Celle GRU - motivazioni\nDopo le LSTM sono state studiate altre architetture che potessero mantenere i \nvantaggi ma con meno risorse di calcolo necessarie.  \nLe celle \n Gated Recurrent Unit (GRU)\n , con un numero minore di gate, sono \nstate proposte per tale scopo, \n41",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#41": "Celle GRU\nLe celle \n Gated Recurrent Unit\n  (\nGRU\n ) sono una versione sempli\n ﬁ\ncata, e con \nmeno parametri, delle LSTM. In molti task mostrano prestazioni simili con \ntempi di addestramento ridotti.  \nLe sempli\n ﬁ\ncazioni sono le seguenti:  \n•\nEntrambi i vettori di stato sono fusi in un singolo vettore \n h\n(t)\n. \n•\nUn singolo \n update gate  \nz\n(t)\n rappresenta una fusione del \n forget\n  e \ninput gate\n . \nLa funzione \n keras.layers.GRU\n  è impiegata in modo simile a SimpleRNN e \nLSTM.\n42\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#42": "Celle GRU (2)\nIntuitivamente il \n reset gate\n  r(t)\n controlla quanto dello stato precedente \nvogliamo mantenere nelle successive elaborazioni.  \nL'\nupdate gate  \nz(t)\n controlla quanto il nuovo stato sia copia dello stato \nprecedente.  \nEntrambi i gate sono implementati con una FC e funzione di attivazione \nsigmoid\n , perciò con output in (0,1).\n43\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#43": "Celle GRU (3)\nIl \nhidden state candidato h(t) \n (candidato poiché dobbiamo ancora sommare la \ncomponente del \n update gate\n ) sarà generato combinando insieme \n x(t)\n e \nl'output del reset gate \n r(t)\n, e impiegando una funzione di attivazione \n tanh\n. \nQuando il  \nreset gate  \nha output pari a 1, otteniamo una RNN tradizionale. Se il \ngate\n genera 0, l'hidden state candidato coincide con l'output della FC con \n x(t) \ncome input. Perciò l'hidden state sarà resettato. \n44\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#44": "Celle GRU (4)\nIl \nhidden state h(t)  \ndipende dal \n update gate\n , che determina quanto il nuovo \nstato corrisponde al vecchio oppure al nuovo stato candidato.  \nQuando l'\n update gate\n  è 1, manteniamo lo stato così com'è, e l'informazione \nx(t) non sarà considerata per alterarlo. Perciò ignoriamo lo step corrente nella \ncatena di correlazioni che stiamo rappresentando con lo stato. Se l'output del \ngate è 0, lo stato corrisponde al candidato che abbiamo appena creato.\n45\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#5": "Nodi Ricorrenti\nFinora abbiamo considerato reti neurali \n feedforward\n , dove le attivazioni si \npropagano\n  dall'input all'output layer.   \nLe \nRNN\n  sono simili alle reti feedforward, ma hanno connessioni anche \n verso i \nlayer precedenti\n , creando una specie di ciclo.  \nLa più semplice \n RNN\n  consiste in un \n nodo ricorrente \n (o\n recurrent neuron\n ) \nche \nriceve l'input \n x\n, produce in output \n y,\n e lo stesso output viene \n riproposto\n  in input.  \n•\nAd ogni \n iterazione  \nt\n, (o \nstep\n, o \nframe\n ), il nodo ricorrente riceve l'input \n x\n(t)\n e \nl'output precedente \n y\n(t-1)\n. Il valore \n y\n(t)\n alla prima iterazione si considera pari a 0.  \nLa RNN si può rappresentare esplicitando l'asse temporale (\n unrolling the \nnetwork through time\n ).\n6\n",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#6": "Nodi Ricorrenti e Layers\nSe \nx\n(t) \ne \ny\n(t-1)\n sono vettori, i parametri che de\n ﬁ\nniscono il comportamento di un \nnodo ricorrente consistono in due vettori di pesi: \n w\nx\n e \nw\ny\n.  \nL'\noutput  \ndi un singolo nodo\n  si ricava nel modo usuale:  \n \nUn\n layer di nodi ricorrenti \n comprende più nodi, ed i parametri saranno \nperciò rappresentati da due matrici \n  e \n .\ny\n(\nt\n)\n=\nσ\n(\nw\nT\nx\nx\n(\nt\n)\n+\nw\nT\ny\ny\n(\nt\n−\n1\n)\n+\nb\n)\nW\nx\nW\ny\nlayer di nodi ricorrenti",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#7": "Nodi ricorrenti: calcolo degli output\nNel caso più generale di\n  un layer di nodi ricorrenti \n con un input costituito da \nvettori\n , cioè istanze rappresentate con più features:  \n  dove:  \n•\n  è una matrice \n m\nn\nnodi\n, che contiene gli output del layer di \n n\nnodi\n nodi \nricorrenti, per ognuna delle \n m\n istanze all'interno del mini-batch,  \n•\n  è una matrice \n m\nn\ninputs\n, dove \n n\ninputs\n sono il numero di features in input,  \n•\n  è la matrice \n n\ninputs\n n\nnodi\n dei pesi delle connessioni per le istanze in input,  \n•\n  è la matrice \n n\nnodi\nn\nnodi\n dei pesi delle connessioni per i valori in output \nottenuti nello step precedente.  \n•\nSi può dire che una RNN è una feedforward NN dove i parametri di ogni \nlayer sono condivisi (cioè sono gli stessi) per tutti i time steps.\nY\n(\nt\n)\n=\nσ\n(\nx\n(\nt\n)\nW\nx\n+\ny\n(\nt\n−\n1\n)\nW\ny\n+\nb\n)\ny\n(\nt\n)\n×\nx\n(\nt\n)\n×\nW\nx\n×\nW\ny\n×\n8",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#8": "Nodi ricorrenti: forma compatta\nLe matrici dei pesi \n  e \n   sono spesso \n concatenate\n  verticalmente in una \nsingola matrice (\n n\ninputs\n+n\nnodi\n)\nn\nnodi \nLa notazione \n  rappresenta la concatenazione delle matrici \n  \nIn questo modo si ottiene la seguente \n forma compatta\n : \n   con    \nÈ chiaro che \n  è funzione di \n  e \n , quest'ultimo è funzione di \n  e \n, che è funzione di \n  e \n , e così via.  \nDi conseguenza  \ndipende da tutti i valori in input \n ﬁ\nno a \nt=0\n. \nSi può dire che il nodo contiene memoria di tutti gli input precedenti. In realtà \ni pattern che può riconoscere non sono lunghi tipicamente più di 10 steps.\nW\nx\nW\ny\n×\n[\nX\n(\nt\n)\nY\n(\nt\n−\n1\n)\n]\nX\n(\nt\n)\n e \nY\n(\nt\n−\n1\n)\nσ\n(\n[\nX\n(\nt\n)\nY\n(\nt\n−\n1\n)\n]\nW\n+\nb\n)\n W\n=\n[\nW\nx\nW\ny\n]\nY\n(\nt\n)\n X\n(\nt\n)\nY\n(\nt\n−\n1\n)\n X\n(\nt\n−\n1\n)\nY\n(\nt\n−\n2\n)\n X\n(\nt\n−\n2\n)\nY\n(\nt\n−\n3\n)\nY\n(\nt\n)\n9",
    "data_test\\rootfolder\\università\\DeepLearning\\12-RNN 1-sbloccato.pdf#9": "Memory Cells\nUna rete neurale in grado di tenere traccia degli stati in cui si è trovata nelle \npassate iterazioni si chiama \n memory cell\n  (o \ncell\n). \n•\nUn singolo\n  recurrent node,\n  o un layer di tali nodi, è una \n cella\n elementare, in \ngrado di riconoscere piccoli patterns, tipicamente non più lunghi di 10 steps.  \nIndichiamo \n stato\n  di una cella all'istante \n t\n con la notazione \n , dove \n h\n sta per \nhidden\n . Lo stato dipende dall'input corrente e dallo stato precedente:  \n \n•\nAnche l'\n output  \n dipende dalle stesse quantità.  \nNelle celle elementari \n output\n  e \nstato  \ncoincidono\n , ma nelle celle più \ncomplesse non sempre accade, come nel seguente esempio:\nh\n(\nt\n)\nh\n(\nt\n)\n=\nf\n(\nh\n(\nt\n−\n1\n)\n,\nx\n(\nt\n)\n)\ny\n(\nt\n)\n10\n",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nRecurrent Neural Networks (RNN) - parte #2\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#1": "Sommario\n1d convolution per sequenze  \nWaveNet  \nDeep RNN  \nBidirectional RNN  \nEncoder-decoder e Keras  \nEsercizi",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#10": "Bidirectional RNN - motivazioni\nFinora abbiamo visto scenari di predizione dove un valore in output dipende \ndai valori precedenti (es. predizione di una parola data una frase iniziale).  \nIn altri task è utile considerare il contesto di un valore in entrambe le \ndirezioni, es. Part-of-speech tagging.  \n•\nAd esempio, nel seguente task tentiamo di predire il token mancante dal \ntesto dato come input:\n11\n",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#11": "Bidirectional RNN\nNelle Bidirectional RNN abbiamo 2 layer unidirezionali con direzioni opposte, \nche operano sul medesimo input. Nel primo layer, il primo input è \n x\n1\n e l'ultimo \nx\nT\n, nel secondo il primo input è \n x\nT\n e l'ultimo \n x\n1\n. \nL'output è generato concatenando l'output dei 2 layers.  \n•\nNel caso multilayer, l'output diverrà l'input dei successivi 2 layers \nbidirezionali, e così via \n ﬁ\nno al layer di output.  \nIn Keras sono implementate con il parametro \n bidirectional=\n True\n.\n12\n",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#12": "Architettura Encoder-decoder - Keras\n14-encoder_decoder_interfaces.ipynb\n13\n",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#13": "RNN - Applicazioni\nPuoi immaginare a possibili applicazioni di una RNN sequence-to-sequence?  \nE di una sequence-to-vector, o di una vector-to-sequence?\n14",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#14": "RNN - Applicazioni\nPuoi immaginare a possibili applicazioni di una RNN sequence-to-sequence?  \nE di una sequence-to-vector, o di una vector-to-sequence?  \nSequence-to-sequence: previsioni meteo, machine translation (con Encoder-\ndecoder), video captioning, speech to text, music generation, identi\n ﬁ\ncare \naccordi nella musica.  \nSequence-to-vector: classi\n ﬁ\ncare brani musicali in base al genere, analizzare il \nsentimento di una recensione di un libro, predire quale parola sta pensando un \npaziente afasico in base ai segnali di impianti cerebrali, stimare la probabilità \ndi vedere un certo \n ﬁ\nlm in base ai \n ﬁ\nlm visti in passato.  \nVector-to-sequence: image captioning, creare una playlist di musica in base agli \nembedding dell'artista corrente, generare una melodia in base a dei parametri, \nidenti\n ﬁ\ncare pedoni in una foto.\n15",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#15": "RNN - Dimensioni\nQuante dimensioni deve avere l'input layer di una RNN? Cosa rappresenta ogni \ndimensione? E riguardo gli output?\n16",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#16": "RNN - Dimensioni\nQuante dimensioni deve avere l'input layer di una RNN? Cosa rappresenta ogni \ndimensione? E riguardo gli output?  \nUn layer RNN deve avere input 3 dimensionali: la prima dimensione è la \ndimensione del batch (cioè il numero di time series), la seconda rappresenta il \ndimensione temporale, e la terza indica il numero di features per step.  \nL'output sarà ancora 3 dimensionale, con le stesse 2 dimensioni dell'input, ma \ncon l'ultima dimensione uguale al numero di nodi. \n17",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#17": "RNN - Parametro return_sequence\nSe vuoi costruire una sequence-to-sequence RNN, quali layer devono avere \nreturn_sequence=True? E per quanto riguarda la sequence-to-vector?\n18",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#18": "RNN - Parametro return_sequence\nSe vuoi costruire una sequence-to-sequence RNN, quali layer devono avere \nreturn_sequence=True? E per quanto riguarda la sequence-to-vector?  \nPer una sequence-to-sequence, il parametro è True per tutti i layer.  \nPer una sequence-to-vector, il parametro è True per tutti gli RNN layers eccetto \nl'ultimo layer, impostato a False.\n19",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#19": "RNN - Forecasting\nSupponi di avere una time series univariate con campionamento giornaliero e \nvuoi fare forecasting dei prossimi 7 giorni. Quale architettura RNN impieghi?\n20",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#2": "1d convolution per le sequenze\nSebbene popolari, \n LSTM\n  e \nGRU\n  non sono adatte a sequenze che contengono \npattern signi\n ﬁ\ncativi che si estendo per molti steps (es. 100). Una alternativa è \nridurre\n  la lunghezza delle sequenze in input.  \nImpieghiamo le \n 1d convolution\n  sulle sequenze in input considerando come \nprofondità la dimensione temporale piuttosto che spaziale. Fissiamo segmenti \ndi dimensioni prede\n ﬁ\nnita sulle sequenze in input per creare tali sequenze che \ncorrispondono alle dimensioni del kernel.  \nEstendiamo l'approccio considerando più \n ﬁ\nltri 1d convolution.  Ogni \n ﬁ\nltro \nriconoscerà determinati pattern.  \n•\nAd esempio, con 10 kernels, l'output complessivo del layer consisterà in 10 \nsequenze 1-dimensionali, tutte della stessa lunghezza, o una singola \nsequenza 10-dimensionale.  \nPossiamo avere reti che alternano layer 1d convolution e layer ricorrenti, ed \neventualmente layer di pooling. In questo modo le celle analizzeranno dati \ntemporali più \n compatti\n . Oppure possiamo avere reti costituite interamente da \nmoduli convolutivi (es. WaveNet).\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#20": "RNN - Forecasting\nSupponi di avere una time series univariate con campionamento giornaliero e \nvuoi fare forecasting dei prossimi 7 giorni. Quale architettura RNN impieghi?  \nL'architettura più semplice è una sequence-to-vector, cioè uno stack di RNN \nlayers (tutti con return_sequences=True eccetto il primo), con 7 nodi nel layer \ndi output. Si addestra il modello con \n ﬁ\nnestre random dalle time series (es. \nsequence di 30 giorni consecutivi e un vettore contenente i valori dei successivi \n7 giorni come target).  \nIn alternativa si imposta return_sequences=True per tutti i layer creando una \nsequence-to-sequence. Per l'addestramento si usano random windows con la \nstessa lunghezza del target. \n21",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#21": "RNN - Training\nQuali sono le maggiori dif\n ﬁ\ncoltà nel training di una RNN e come puoi \naffrontarle?\n22",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#22": "RNN - Training\nQuali sono le maggiori dif\n ﬁ\ncoltà nel training di una RNN e come puoi \naffrontarle?  \nLe due maggiori problematiche sono l'instabilità dei gradienti e la short-term \nmemory limitata. I problemi peggiorano in presenza di sequenze molto lunghe.  \nPer affrontarli si usano learning rate più bassi, funzioni di attivazioni che \nsaturano ed eventualmente gradient clipping, layer normalization o dropout ad \nogni step. Per la short-term memory, si impiegano celle LSTM o GRU.\n23",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#23": "RNN - LSTM\nRappresenta l'architettura LSTM gra\n ﬁ\ncamente.\n24",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#24": "RNN - 1d conv\nPerché vorresti impiegare una 1d conv all'interno di una RNN?\n25",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#25": "RNN - 1d conv\nPerché vorresti impiegare una 1d conv all'interno di una RNN?  \nUna RNN opera sequenzialmente: per calcolare l'output al tempo t, deve prima \ncalcolare gli output degli step precedenti. Questo rende impossibile \nparallelizzare l'elaborazione.  \nLa 1d conv non mantiene uno stato tra elaborazioni successive perciò e \nfacilmente parallelizzabile. Non essendo ricorrente, è meno affetta da gradienti \ninstabili.  \nPiù 1d conv possono processare l'input riducendo la risoluzione temporale \n(downsampling) permettendo di analizzare time series molto lunghe.  \nInfatti la WaveNet analizza time series impiegando solo 1d conv.\n26",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#26": "RNN - Scenario\nQuale architettura NN impiegheresti per classi\n ﬁ\ncare video? \n27",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#27": "RNN - Scenario\nQuale architettura NN impiegheresti per classi\n ﬁ\ncare video?  \nPrendiamo un frame per secondo e lo diamo in input a una rete \nconvoluzionale. L'output della CNN è passato in input a una sequence-to-\nvector RNN, il cui output è passato a una layer softmax, ottenendo una \ndistribuzione di probabilità sulle classi.  \nLa funzione di costo può essere una cross entropy.  \nPer usare l'audio si possono impiegare layer 1d conv, per ridurre la risoluzione \nda migliaia di audio frames per secondo a 1 solo per secondo, così da \nsincronizzarsi rispetto ai frame, e concatenare l'output con l'input alla \nsequence-to-vector.\n28",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#28": "RNN - Sketch dataset\nAddestra un modello per la classi\n ﬁ\ncazione per il Sketch-RNN dataset \ndisponibile dentro Tensor\n ﬂ\now.\n29\n",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#29": "RNN - Sketch dataset\nAddestra un modello per la classi\n ﬁ\ncazione per il Sketch-RNN dataset \ndisponibile dentro Tensor\n ﬂ\now. \nDOWNLOAD_ROOT = \n \"http://download.tensorflow.org/data/\"\nFILENAME = \n \"quickdraw_tutorial_dataset_v1.tar.gz\"\nfilepath = keras.utils.get_file(FILENAME,\n                                DOWNLOAD_ROOT + FILENAME,\n                                cache_subdir=\n \"datasets/quickdraw\"\n ,\n                                extract=\n True\n)\nquickdraw_dir = Path(filepath).parent\ntrain_files = \n sorted\n([str(path) \n for\n path \nin\n quickdraw_dir.glob(\n \"training.tfrecord-*\"\n )])\neval_files = \n sorted\n([str(path) \n for\n path \nin\n quickdraw_dir.glob(\n \"eval.tfrecord-*\"\n )])\nwith \nopen\n(quickdraw_dir / \n \"eval.tfrecord.classes\"\n ) \nas\n test_classes_file:\n    test_classes = test_classes_file.readlines()\n    \nwith \nopen\n(quickdraw_dir / \n \"training.tfrecord.classes\"\n ) \nas\n train_classes_file:\n    train_classes = train_classes_file.readlines()\nassert\n train_classes == test_classes\nclass_names = [name.strip().lower() \n for\n name \nin\n train_classes]\nsorted\n(class_names)\n30",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#3": "1d convolution per le sequenze: esempio\nIl modello include una \n 1d conv \n che opera una sorta di \n downsampling\n  delle \nsequenze in input di un fattore 2 impiegano uno stride 2. Il kernel è più grande \ndello stride perciò tutta l'informazione verrà considerata.  \nRiducendo la lunghezza in input sarà più facile per la GRU riconoscere pattern \npiù lunghi.  \nmodel = keras.models.Sequential([\n    keras.layers.Conv1D(filters=\n 20\n, kernel_size=\n 4\n, strides=\n 2\n, \npadding=\n \"valid\"\n,\n                        input_shape=[\n None\n, \n1\n]),\n    keras.layers.GRU(\n 20\n, return_sequences=\n True\n),\n    keras.layers.GRU(\n 20\n, return_sequences=\n True\n),\n    keras.layers.TimeDistributed(keras.layers.Dense(\n 10\n))\n])\nmodel.\ncompile\n(loss=\n\"mse\"\n, optimizer=\n \"adam\"\n, \nmetrics=[last_time_step_mse])\nhistory = model.fit(X_train, Y_train[:, \n 3\n::\n2\n], epochs=\n 20\n,\n                    validation_data=(X_valid, Y_valid[:, \n 3\n::\n2\n]))\n•\nNota: Avendo kernel di dimensione 4, è opportuno ignorare i primi 3 step nei valori target, e \nfare dowsampling dei target di un fattore 2.\n4",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#30": "RNN - Sketch dataset\nAddestra un modello per la classi\n ﬁ\ncazione per il Sketch-RNN dataset disponibile dentro Tensor\n ﬂ\now. \ndef \nparse\n(\ndata_batch\n ):\n    feature_descriptions = {\n        \n \"ink\"\n: tf.io.VarLenFeature(dtype=tf.float32),\n        \n \"shape\"\n: tf.io.FixedLenFeature([\n 2\n], dtype=tf.int64),\n        \n \"class_index\"\n : tf.io.FixedLenFeature([\n 1\n], dtype=tf.int64)\n    }\n    examples = tf.io.parse_example(data_batch, feature_descriptions)\n    flat_sketches = tf.sparse.to_dense(examples[\n \"ink\"\n])\n    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), \n -1\n, \n3\n])\n    lengths = examples[\n \"shape\"\n][:, \n0\n]\n    labels = examples[\n \"class_index\"\n ][:, \n0\n]\n    \nreturn\n sketches, lengths, label\n s\ndef \nquickdraw_dataset\n (\nfilepaths\n , \nbatch_size\n =\n32\n, \nshuffle_buffer_size\n =\nNone\n,\n                      \n n_parse_threads\n =\n5\n, \nn_read_threads\n =\n5\n, \ncache\n=\nFalse\n)\n:\n    dataset = tf.data.TFRecordDataset(filepaths\n ,\n                                      num_parallel_reads=n_read_threads\n )\n    \nif\n cache\n:\n        dataset = dataset.cache(\n )\n    \nif\n shuffle_buffer_size\n :\n        dataset = dataset.shuffle(shuffle_buffer_size\n )\n    dataset = dataset.batch(batch_size\n )\n    dataset = dataset.\n map\n(parse, num_parallel_calls=n_parse_threads\n )\n    \nreturn\n dataset.prefetch(\n 1\n)\n31",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#31": "RNN - Sketch dataset\nAddestra un modello per la classi\n ﬁ\ncazione per il Sketch-RNN dataset disponibile dentro Tensor\n ﬂ\now. \ntrain_set = quickdraw_dataset(train_files, shuffle_buffer_size=\n 10000\n)\nvalid_set = quickdraw_dataset(eval_files[:\n 5\n]\n)\ntest_set = quickdraw_dataset(eval_files[\n 5\n:]\n)\ndef \ndraw_sketch\n (\nsketch\n, \nlabel\n=\nNone\n)\n:\n    origin = np.array([[\n 0\n., \n0\n., \n0\n.]]\n)\n    sketch = np.r_[origin, sketch\n ]\n    stroke_end_indices = np.argwhere(sketch[:, \n -1\n]==\n1\n.)[:, \n0\n]\n    coordinates = np.cumsum(sketch[:, :\n 2\n], axis=\n 0\n)\n    strokes = np.split(coordinates, stroke_end_indices + \n 1\n)\n    title = class_names[label.numpy()] \n if\n label \nis \nnot \nNone \nelse \n\"Try to guess\"\n    plt.title(title\n )\n    plt.plot(coordinates[:, \n 0\n], -coordinates[:, \n 1\n], \n\"y:\"\n)\n    \nfor\n stroke \n in\n strokes\n :\n        plt.plot(stroke[:, \n 0\n], -stroke[:, \n 1\n], \n\".-\"\n)\n    plt.axis(\n \"off\"\n)\ndef \ndraw_sketches\n (\nsketches\n , \nlengths\n, \nlabels\n)\n:\n    n_sketches = \n len\n(sketches\n )\n    n_cols = \n 4\n    n_rows = (n_sketches - \n 1\n) // n_cols + \n 1\n    plt.figure(figsize=(n_cols * \n 3\n, n_rows * \n 3.5\n)\n)\n    \nfor\n index, sketch, length, label \n in \nzip\n(\nrange\n(n_sketches), sketches, lengths, labels)\n :\n        plt.subplot(n_rows, n_cols, index + \n 1\n)\n        draw_sketch(sketch[:length], label\n )\n    plt.show()\n32",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#32": "RNN - Sketch dataset\nAddestra un modello per la classi\n ﬁ\ncazione per il Sketch-RNN dataset disponibile dentro \nTensor\n ﬂ\now. \nfor\n sketches, lengths, labels \n in\n train_set.take(\n 1\n)\n:\n    draw_sketches(sketches, lengths, labels\n )\nlengths = np.concatenate([lengths \n for\n _, lengths, _ \n in \ntrain_set.take(\n 1000\n)]\n)\nplt.hist(lengths, bins=\n 150\n, density=\n True\n)\nplt.axis([\n 0\n, \n200\n, \n0\n, \n0.03\n]\n)\nplt.xlabel(\n \"length\"\n )\nplt.ylabel(\n \"density\"\n )\nplt.show(\n )\ndef \ncrop_long_sketches\n (\ndataset\n, \nmax_length\n =\n100\n)\n:\n    \nreturn\n dataset.\n map\n(\nlambda\n inks, lengths, labels: \n(inks[:, :max_length], labels)\n )\ncropped_train_set = crop_long_sketches(train_set\n )\ncropped_valid_set = crop_long_sketches(valid_set\n )\ncropped_test_set = crop_long_sketches(test_set\n )\n33",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#33": "RNN - Sketch dataset\nAddestra un modello per la classi\n ﬁ\ncazione per il Sketch-RNN dataset disponibile dentro \nTensor\n ﬂ\now. \nmodel = keras.models.Sequential(\n [\n    keras.layers.Conv1D(\n 32\n, kernel_size=\n 5\n, strides=\n 2\n, activation=\n \"relu\"\n)\n,\n    keras.layers.BatchNormalization()\n ,\n    keras.layers.Conv1D(\n 64\n, kernel_size=\n 5\n, strides=\n 2\n, activation=\n \"relu\"\n)\n,\n    keras.layers.BatchNormalization()\n ,\n    keras.layers.Conv1D(\n 128\n, kernel_size=\n 3\n, strides=\n 2\n, activation=\n \"relu\"\n)\n,\n    keras.layers.BatchNormalization()\n ,\n    keras.layers.LSTM(\n 128\n, return_sequences=\n True\n)\n,\n    keras.layers.LSTM(\n 128\n)\n,\n    keras.layers.Dense(\n len\n(class_names), activation=\n \"softmax\"\n )\n]\n)\noptimizer = keras.optimizers.SGD(lr=\n 1e-2\n, clipnorm=\n 1\n.\n)\nmodel.\ncompile\n(loss=\n\"sparse_categorical_crossentropy\"\n ,\n              optimizer=optimizer\n ,\n              metrics=[\n \"accuracy\"\n , \n\"sparse_top_k_categorical_accuracy\"\n ]\n)\nhistory = model.fit(cropped_train_set, epochs=\n 2\n,\n                    validation_data=cropped_valid_set\n )\ny_test = np.concatenate([labels \n for\n _, _, labels \n in\n test_set]\n )\ny_probas = model.predict(test_set)\n34",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#34": "RNN - Sketch dataset\nAddestra un modello per la classi\n ﬁ\ncazione per il Sketch-RNN dataset disponibile dentro \nTensor\n ﬂ\now. \nnp.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas)\n )\nn_new = \n 10\nY_probas = model.predict(sketches\n )\ntop_k = tf.nn.top_k(Y_probas, k=\n 5\n)\nfor\n index \nin \nrange\n(n_new)\n:\n    plt.figure(figsize=(\n 3\n, \n3.5\n)\n)\n    draw_sketch(sketches[index]\n )\n    plt.show(\n )\n    \nprint\n(\n\"Top-5 predictions:\"\n .\nformat\n(index + \n 1\n)\n)\n    \nfor\n k \nin \nrange\n(\n5\n)\n:\n        class_name = class_names[top_k.indices[index, k]\n ]\n        proba = \n 100\n * top_k.values[index, k\n ]\n        \n print\n(\n\"  {}. {} {:.3f}%\"\n .\nformat\n(k + \n1\n, class_name, proba)\n )\n    \nprint\n(\n\"Answer: {}\"\n .\nformat\n(class_names[labels[index].numpy()])\n )\nmodel.save(\n \"my_sketchrnn\"\n )\n35",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#35": "RNN - Generazione di musica\nScarica il dataset Bach chorales e scompattalo. Consiste in 382 corali composti \nda Johann Sebastian Bach. Ogni corale è lungo da 100 a 640 time steps, e ogni \nstep contiene 4 interi, dove ogni interno corrisponde alla nota su un piano. Lo 0 \nindica che che non si suona alcuna nota.  \nAddestra un modello ricorrente o convoluzionale, o entrambi, che può predire \nil successivo step (4 note), data una sequenza del corale. Usa quello modello \nper generare musica in stile Bach, ad esempio dando in input l'inizio di un \ncorale e ottenendo la predizione che userai come successivo input.  \nIn\nﬁ\nne dai un'occhiata al Google Coconet model.  \n36",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#36": "RNN - Generazione di musica\nDOWNLOAD_ROOT = \n \"https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/\"\nFILENAME = \n \"jsb_chorales.tgz\"\nfilepath = keras.utils.get_file(FILENAME,\n                                DOWNLOAD_ROOT + FILENAME,\n                                cache_subdir=\n \"datasets/jsb_chorales\"\n ,\n                                extract=\n True\n)\njsb_chorales_dir = Path(filepath).parent\ntrain_files = \n sorted\n(jsb_chorales_dir.glob(\n \"train/chorale_*.csv\"\n ))\nvalid_files = \n sorted\n(jsb_chorales_dir.glob(\n \"valid/chorale_*.csv\"\n ))\ntest_files = \n sorted\n(jsb_chorales_dir.glob(\n \"test/chorale_*.csv\"\n ))\nimport\n pandas \n as\n pd\ndef \nload_chorales\n (\nfilepaths\n ):\n    \nreturn\n [pd.read_csv(filepath).values.tolist() \n for\n filepath \n in\n filepaths]\ntrain_chorales = load_chorales(train_files)\nvalid_chorales = load_chorales(valid_files)\ntest_chorales = load_chorales(test_files)\ntrain_chorales[\n 0\n]\nnotes = set()\nfor\n chorales \n in\n (train_chorales, valid_chorales, test_chorales):\n    \nfor\n chorale \n in\n chorales:\n        \n for\n chord \nin\n chorale:\n            notes |= set(chord)\nn_notes = \n len\n(notes)\nmin_note = \n min\n(notes - {\n 0\n})\nmax_note = \n max\n(notes)\n37",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#37": "RNN - Generazione di musica\nassert\n min_note == \n 36\nassert\n max_note == \n 81\nfrom\n IPython.display \n import\n Audio\ndef \nnotes_to_frequencies\n (\nnotes\n):\n    \n# Frequency doubles when you go up one octave; there are 12 semi-tones\n    \n# per octave; Note A on octave 4 is 440 Hz, and it is note number 69.\n    \nreturn \n2\n ** ((np.array(notes) - \n 69\n) / \n12\n) * \n440\ndef \nfrequencies_to_samples\n (\nfrequencies\n , \ntempo\n, \nsample_rate\n ):\n    note_duration = \n 60\n / tempo \n # the tempo is measured in beats per minutes\n    \n# To reduce click sound at every beat, we round the frequencies to try to\n    \n# get the samples close to zero at the end of each note.\n    frequencies = np.\n round\n(note_duration * frequencies) / note_duration\n    n_samples = int(note_duration * sample_rate)\n    time = np.linspace(\n 0\n, note_duration, n_samples)\n    sine_waves = np.sin(\n 2\n * np.pi * frequencies.reshape(\n -1\n, \n1\n) * time)\n    \n# Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)\n    sine_waves *= (frequencies > \n 9\n.).reshape(\n -1\n, \n1\n)\n    \nreturn\n sine_waves.reshape(\n -1\n)\ndef \nchords_to_samples\n (\nchords\n, \ntempo\n, \nsample_rate\n ):\n    freqs = notes_to_frequencies(chords)\n    freqs = np.r_[freqs, freqs[\n -1\n:]] \n# make last note a bit longer\n    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)\n                     \n for\n melody \n in\n freqs.T], axis=\n 0\n)\n    n_fade_out_samples = sample_rate * \n 60\n // tempo \n # fade out last note\n    fade_out = np.linspace(\n 1\n., \n0\n., n_fade_out_samples)**\n 2\n    merged[-n_fade_out_samples:] *= fade_out\n    \nreturn\n merged\n38",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#38": "RNN - Generazione di musica\ndef \nplay_chords\n (\nchords\n, \ntempo\n=\n160\n, \namplitude\n =\n0.1\n, \nsample_rate\n =\n44100\n, \nfilepath\n =\nNone\n):\n    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)\n    \nif\n filepath:\n        \n from\n scipy.io \n import\n wavfile\n        samples = (\n 2\n**\n15\n * samples).astype(np.int16)\n        wavfile.write(filepath, sample_rate, samples)\n        \n return\n display(Audio(filepath))\n    \nelse\n:\n        \n return\n display(Audio(samples, rate=sample_rate))\nfor\n index \nin \nrange\n(\n3\n):\n    play_chords(train_chorales[index])\ndef \ncreate_target\n (\nbatch\n):\n    X = batch[:, :\n -1\n]\n    Y = batch[:, \n 1\n:] \n# predict next note in each arpegio, at each step\n    \nreturn\n X, Y\ndef \npreprocess\n (\nwindow\n):\n    window = tf.where(window == \n 0\n, window, window - min_note + \n 1\n) \n# shift values\n    \nreturn\n tf.reshape(window, [\n -1\n]) \n# convert to arpegio\ndef \nbach_dataset\n (\nchorales\n , \nbatch_size\n =\n32\n, \nshuffle_buffer_size\n =\nNone\n,\n                 \n window_size\n =\n32\n, \nwindow_shift\n =\n16\n, \ncache\n=\nTrue\n):\n    \ndef \nbatch_window\n (\nwindow\n):\n        \n return\n window.batch(window_size + \n 1\n)\n    \ndef \nto_windows\n (\nchorale\n):\n        dataset = tf.data.Dataset.from_tensor_slices(chorale)\n        dataset = dataset.window(window_size + \n 1\n, window_shift, drop_remainder=\n True\n)\n        \n return\n dataset.flat_map(batch_window)\n    chorales = tf.ragged.constant(chorales, ragged_rank=\n 1\n)\n    dataset = tf.data.Dataset.from_tensor_slices(chorales)\n    dataset = dataset.flat_map(to_windows).\n map\n(preprocess)\n    \nif\n cache:\n        dataset = dataset.cache()\n    \nif\n shuffle_buffer_size:\n        dataset = dataset.shuffle(shuffle_buffer_size)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.\n map\n(create_target)\n    \nreturn\n dataset.prefetch(\n 1\n)\n39",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#39": "RNN - Generazione di musica\ntrain_set = bach_dataset(train_chorales, shuffle_buffer_size=\n 1000\n)\nvalid_set = bach_dataset(valid_chorales)\ntest_set = bach_dataset(test_chorales)\nn_embedding_dims = \n 5\nmodel = keras.models.Sequential([\n    keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,\n                           input_shape=[\n None\n]),\n    keras.layers.Conv1D(\n 32\n, kernel_size=\n 2\n, padding=\n \"causal\"\n , activation=\n \"relu\"\n),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv1D(\n 48\n, kernel_size=\n 2\n, padding=\n \"causal\"\n , activation=\n \"relu\"\n, dilation_rate=\n 2\n),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv1D(\n 64\n, kernel_size=\n 2\n, padding=\n \"causal\"\n , activation=\n \"relu\"\n, dilation_rate=\n 4\n),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv1D(\n 96\n, kernel_size=\n 2\n, padding=\n \"causal\"\n , activation=\n \"relu\"\n, dilation_rate=\n 8\n),\n    keras.layers.BatchNormalization(),\n    keras.layers.LSTM(\n 256\n, return_sequences=\n True\n),\n    keras.layers.Dense(n_notes, activation=\n \"softmax\"\n )\n])\nmodel.summary()\noptimizer = keras.optimizers.Nadam(lr=\n 1e-3\n)\nmodel.\ncompile\n(loss=\n\"sparse_categorical_crossentropy\"\n , optimizer=optimizer,\n              metrics=[\n \"accuracy\"\n ])\nmodel.fit(train_set, epochs=\n 20\n, validation_data=valid_set)\nmodel.save(\n \"my_bach_model.h5\"\n )\nmodel.evaluate(test_set)\n40",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#4": "Architettura WaveNet\nLe rete convolutiva \n WaveNet\n  impiega più layer 1d conv, dove ad ogni layer si \nraddoppia la lunghezza della LRF, chiamato anche \n dilatation rate.\n  In questo \nmodo ogni layer raddoppia i dati analizzati rispetto al layer precedente.  \n•\nI primi layer riconoscono pattern \n short-term\n , gli ultimi i pattern estesi.  \n•\nPer dilatation >1, i layer ignoreranno alcuni campioni all'interno del LRF che \nperò saranno considerati nei layer precedenti.  \nIl training è più rapido rispetto alle RNN non essendoci collegamenti ricorrenti.  \nL'output può essere accodato all'input successivo per fare predizione (es. \ngenerazione voce umana).\n5\nstack of conv layers",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#40": "RNN - Generazione di musica\ndef \ngenerate_chorale\n (\nmodel\n, \nseed_chords\n , \nlength\n):\n    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n    arpegio = tf.reshape(arpegio, [\n 1\n, \n-1\n])\n    \nfor\n chord \nin \nrange\n(length):\n        \n for\n note \nin \nrange\n(\n4\n):\n            next_note = model.predict_classes(arpegio)[:\n 1\n, \n-1\n:]\n            arpegio = tf.concat([arpegio, next_note], axis=\n 1\n)\n    arpegio = tf.where(arpegio == \n 0\n, arpegio, arpegio + min_note - \n 1\n)\n    \nreturn\n tf.reshape(arpegio, shape=[\n -1\n, \n4\n])\nseed_chords = test_chorales[\n 2\n][:\n8\n]\nplay_chords(seed_chords, amplitude=\n 0.2\n)\nnew_chorale = generate_chorale(model, seed_chords, \n 56\n)\nplay_chords(new_chorale)\ndef \ngenerate_chorale_v2\n (\nmodel\n, \nseed_chords\n , \nlength\n, \ntemperature\n =\n1\n):\n    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n    arpegio = tf.reshape(arpegio, [\n 1\n, \n-1\n])\n    \nfor\n chord \nin \nrange\n(length):\n        \n for\n note \nin \nrange\n(\n4\n):\n            next_note_probas = model.predict(arpegio)[\n 0\n, \n-1\n:]\n            rescaled_logits = tf.math.log(next_note_probas) / temperature\n            next_note = tf.random.categorical(rescaled_logits, num_samples=\n 1\n)\n            arpegio = tf.concat([arpegio, next_note], axis=\n 1\n)\n    arpegio = tf.where(arpegio == \n 0\n, arpegio, arpegio + min_note - \n 1\n)\n    \nreturn\n tf.reshape(arpegio, shape=[\n -1\n, \n4\n])\n41",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#41": "RNN - Generazione di musica\nnew_chorale_v2_cold = generate_chorale_v2(model, seed_chords, \n 56\n, temperature=\n 0.8\n)\nplay_chords(new_chorale_v2_cold, filepath=\n \"bach_cold.wav\"\n )\nnew_chorale_v2_medium = generate_chorale_v2(model, seed_chords, \n 56\n, temperature=\n 1.0\n)\nplay_chords(new_chorale_v2_medium, filepath=\n \"bach_medium.wav\"\n )\nnew_chorale_v2_hot = generate_chorale_v2(model, seed_chords, \n 56\n, temperature=\n 1.5\n)\nplay_chords(new_chorale_v2_hot, filepath=\n \"bach_hot.wav\"\n )\nplay_chords(test_chorales[\n 2\n][:\n64\n], filepath=\n \"bach_test_4.wav\"\n )\n42",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#5": "6\n1\n2\n3\n4\nhttps://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio\nNella \n WaveNet\n  l'output layer ha la \nstessa dimensionalità temporale \ndell'input.  \nIl singolo valore in output è prodotto \nda una \n softmax\n , perciò con \ndistribuzione sulle categorie \ndisponibili.  \nLe \ndilated convolution\n  sono simili ai \nlayer convolutivi con pooling e \nstride, ma in questo caso l'output ha \nla stessa dimensione dell'input.  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#6": "WaveNet: esempio\nImpostando il \n padding  \ncausal\n  si garantisce che l'input non conterrà dati oltre a \nquello attuale.  \nIl parametro \n dilatation_rate\n  de\nﬁ\nnisce l'architettura WaveNet.  \nL'ultimo layer è convolutivo con 10 \n ﬁ\nltri di dimensione 1 senza funzione di \nattivazione. Ogni conv layer produce una sequenza della stessa lunghezza \ndell'input, cosicché possiamo usare i target senza ridimensionarli.  \nNell'esempio manca il layer softmax impiegato nell'esempio precedente.  \nmodel = keras.models.Sequential()\nmodel.add(keras.layers.InputLayer(input_shape=[\n None\n, \n1\n]))\nfor\n rate \nin\n (\n1\n, \n2\n, \n4\n, \n8\n) * \n2\n:\n    model.add(keras.layers.Conv1D(filters=\n 20\n, kernel_size=\n 2\n, padding=\n \"causal\"\n ,\n                                  activation=\n \"relu\"\n, dilation_rate=rate))\nmodel.add(keras.layers.Conv1D(filters=\n 10\n, kernel_size=\n 1\n))\nmodel.\ncompile\n(loss=\n\"mse\"\n, optimizer=\n \"adam\"\n, metrics=[last_time_step_mse])\nhistory = model.fit(X_train, Y_train, epochs=\n 20\n,\n                    validation_data=(X_valid, Y_valid))\n7",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#7": "Deep RNN\nFinora abbiamo visto RNN con un singolo hidden layer ricorrente, uno strato \ndi input e uno di output. Le memory cell permettono di creare correlazioni \nche in\n ﬂ\nuenza step anche distanti tra loro (direzione temporale).  \nNelle Deep RNN si vogliono identi\n ﬁ\ncare correlazioni anche tra input e output \nnello stesso step (direzione input-output). Per questo si considerano più layer \nstacked \n sequence-to-sequence.  \n•\nIl primo layer produce una sequenza in output di lunghezza T, che sarà \nl'input del successivo layer.  \n•\nOgni cella perciò dipenderà dai valori  \ndel layer negli step precedente, e dai  \nvalori generati dai layer precedenti nello  \nstesso step.  \nArchitetture comuni di RNN hanno  \nlunghezza (\n numero di step\n ) nel range  \n64-2056 e profondità in 1-8.\n8\n",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#8": "Deep RNN - Keras (1)\n12-deep_rnn.ipynb\n9",
    "data_test\\rootfolder\\università\\DeepLearning\\13-RNN 2-sbloccato.pdf#9": "Deep RNN - Keras (2)\nIn alternativa alla classe GRU possiamo operare uno stacking impiegando \nSequential:  \nmodel = keras.models.Sequential([\n    keras.layers.SimpleRNN(\n 20\n, return_sequences=\n True\n, input_shape=[\n None\n, \n1\n]),\n    keras.layers.SimpleRNN(\n 20\n, return_sequences=\n True\n),\n    keras.layers.SimpleRNN(\n 1\n)\n])”\nNota\n : ricordati di impostare return_sequences=\n True\n per ogni layer (tranne \nl'ultimo se ci interessa in output solo l'ultimo valore), altrimenti l'output del \nlayer sarà 2D (solo l'ultimo valore) e si crea un mismatch con l'input atteso in \n3D dal successivo layer.\n10",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nAttention mechanisms e Transformers\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#1": "Sommario\nBeam search  \nAttention mechanism  \nMulti-head attention  \nSelf-attention  \nTransformers  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#10": "Beam search (2)\nLa complessità è pari a \n O\n(\nk·\n|\nY\n|·\nT'\n)\n, dove \n T'\n è il numero massimo di token \ndella sequenza in output, e \n Y\n è il vocabolario.  \nAl contrario dell'approccio greedy, la beam search permette di scegliere alcuni \ntoken meno probabili, sebbene la frase nel suo complesso generi accuracy \nmigliori.  \nUna ricerca esaustiva di tutte le possibili combinazioni richiederebbe \ncomplessità \n O\n(|\nY\n|\nT'\n).\n11",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#11": "Attention cues\nIl meccanismo si ispira a studi di neuroscienze cognitive, dove si tenta di dare \nattenzione solo ad una parte degli stimoli generati dal sistema di visione.  \n•\nle \nnonvolitional cues\n  (\nkeys\n) sono legate alla visibilità dell'oggetto \nnell'ambiente (es. tazza di caffè rossa su un tavolino grigio),  \n•\nle \nvolitional cue\n  (o \nquery\n ) dipendono dal task che stiamo seguendo (es. \nleggere un libro su un tavolo).  \nSe abbiamo dei \n sensory inputs\n  da analizzare, la \n query\n  interagisce con le \n keys \nper selezionare gli input più corretti.  \nL'\nattention pooling\n  aggrega gli input per generare l'output.\n12\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#12": "Attention pooling e Keras\nCi sono vari modi di implementare l'attention pooling. Qui diamo un esempio \nbasato sul modello di regressione Nadaraya-Watson kernel.  \nGeneriamo un dataset arti\n ﬁ\nciale con questo modello:  \ncon epsilon generato con distribuzione normale media 0 e varianza 0.5, e 50 \nistanze di training e test.  \nclass \nNonlinearData\n (\nd2l\n.\nDataModule\n ):\n    \ndef \n__init__\n (\nself\n, \nn\n, \nbatch_size\n ):\n        \n self\n.save_hyperparameters()\n        f = \n lambda\n x: \n2\n * tf.sin(x) + x**\n 0.8\n        \n self\n.x_train = tf.sort(tf.random.uniform((n,\n 1\n)) * \n5\n, \n0\n)\n        \n self\n.y_train = f(\n self\n.x_train) + tf.random.normal((n,\n 1\n))\n        \n self\n.x_val = tf.\n range\n(\n0\n, \n5\n, \n5.0\n/n)\n        \n self\n.y_val = f(\n self\n.x_val)\n    \ndef \nget_dataloader\n (\nself\n, \ntrain\n):\n        arrays = (\n self\n.x_train, \n self\n.y_train) \n if\n train \nelse\n (\nself\n.x_val, \n self\n.y_val)\n        \n return \nself\n.get_tensorloader(arrays, train)\nn = \n50\ndata = NonlinearData(n, batch_size=\n 10\n)\n13\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#13": "Attention pooling e Keras (2)\nGra\nﬁ\nchiamo gli esempi di training (cerchi), il ground truth senza rumore \n(curva blu) la funzione generata per la prediction (tratteggiata rossa).  \nProviamo con l'estimator più facile: \n average pooling\n  sui dati di input:  \ny_hat = tf.repeat(tf.reduce_mean(data.y_train), n)\nplot_kernel_reg(y_hat)\ndef \nplot_kernel_reg\n (\ny_hat\n):\n    d2l.plot(data.x_val, [data.y_val, y_hat.numpy()], \n 'x'\n, \n'y'\n, legend=[\n 'Truth'\n, \n'Pred'\n],\n             xlim=[\n 0\n, \n5\n], ylim=[\n -1\n, \n5\n])\n    d2l.plt.plot(data.x_train, data.y_train, \n 'o'\n, alpha=\n 0.5\n);\n14",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#14": "Attention pooling e Keras (3)\nNel seguente nonparametric attention pooling chiamato \n Nadaraya-Watson \nkernel regression \n pesiamo gli output in base alla posizione degli input.  \ndove K è il kernel. Generalizzandolo (non serve ora studiare i dettagli del \nregressore) possiamo de\n ﬁ\nnire un qualsiasi \n attention pooling\n  nel seguente \nmodo:  \ndove \n x\n è la \n query\n , e (\nx\ni\n,y\ni\n) e la coppia \n chiave-valore\n . Perciò ogni valore \n y\ni\n è \npesato e si può pensare come una distribuzione di probabilità sull'insieme \nchiavi-valore.  \n15\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#15": "Attention pooling e Keras (4)\nGra\nﬁ\ncando l'output del nuovo modello otteniamo:  \ndef \ndiff\n(\nqueries\n, \nkeys\n):\n    \nreturn\n tf.reshape(queries, (\n -1\n, \n1\n)) - tf.reshape(keys, (\n 1\n, \n-1\n))\ndef \nattention_pool\n (\nquery_key_diffs\n , \nvalues\n):\n    attention_weights = tf.nn.softmax(- query_key_diffs**\n 2\n/\n2\n, axis=\n1\n)\n    \nreturn\n tf.matmul(attention_weights, values), attention_weights\ny_hat, attention_weights = attention_pool(\n    diff(data.x_val, data.x_train), data.y_train)\nplot_kernel_reg(y_hat)\n16\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#16": "Attention pooling e Keras (5)\nAnalizzando i pesi generati dell'attention pooling, con le \n query\n  come \nvalidation inputs\n  e \nkeys\n come \n training inputs\n , notiamo come all'avvicinarsi dei \nvalori tra \n query\n  e \nchiave\n , i pesi sono più signi\n ﬁ\ncativi:  \nd2l.show_heatmaps([[attention_weights]],\n                  xlabel=\n 'Sorted training inputs'\n ,\n                  ylabel=\n 'Sorted validation inputs'\n )\n17\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#17": "Attention Scoring functions\nL'output dell'\n attention mechanism\n  possiamo valutarlo con una \n softmax\n  e \ninterpretarlo come distribuzione di probabilità sui valori che sono in paio con \nle chiavi.  \n18\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#18": "Multi-head attention\nL'attention mechanism potrebbe richiedere di analizzare dipendenze su vari \nintervalli (short e long-range) all'interno delle sequenze. Invece di un singolo \npooling, possiamo generare \n h\n proiezioni lineari indipendenti. Gli \n h\n output \nsono concatenati e passati ad una combinazione lineare \n ﬁ\nnale per produrre \nl'output. Ognuna delle \n h \nattention pooling\n  è chiamato \n head\n .\n19\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#19": "Self-attention e positional encoding\nSupponiamo che in input all'attention mechanism diamo una sequenza di \ntokens. I tokens rappresentano perciò sia le query, le chiavi e i valori. Ogni \nquery è relativa e tutte le coppie chiave-valore e genera un output. Per tale \nmotivo si parla di \n self-attention\n . \nSi può dimostrare facilmente che le CNN e i self-attention possono essere \nimplementati con computazioni parallele, sebbene sequenze molto lunghe \npenalizzano molto i self-attention.  \nPossiamo aggiungere informazioni aggiuntive, come quelle associate alla \nposizione, alla rappresentazione in input del self-attention, poiché durante i \ncalcoli queste informazioni vengono ignorate, a differenza delle RNN.\n20",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#2": "Introduzione\nIn una architettura \n encoder-decoder,\n  durante la traduzione di un testo notiamo \ncome alcune parole generate dal decoder dipendano da poche parole in input \nal encoder. Se le frasi sono molte lunghe, una RNN fa fatica a identi\n ﬁ\ncare tali \ndipendenze.  \nGli \nattention mechanism \n introdotti nel 2014 da Bahdanau et al.\n(1)\n risolvono in \nparte le limitazioni della memoria delle RNN, arrivando a processare frasi di \n30 parole circa.  \nGli attention mechanism sono alla base dell'architettura \n Transformers\n , che è \nlo stato dell'arte nel campo dell'NLP in molti task, es. machine language \ntranslation, conversational chatbots, e per migliorare le performance dei \nsearch engines.  \nL'obiettivo degli \n attention mechanism \n è assegnare un livello di importanza alle \nfeatures e sfruttarlo per agevolare il raggiungimento di un certo task. \n3 (1) https://arxiv.org/abs/1409.0473",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#20": "Attention mechanism e Encoder-decoder (1)\nNell'architettura \n encoder-decoder con \n attention mechanism\n , oltre all'ultimo \nhidden state propagato dal encoder al decoder (non visibile nel disegno), \ninviamo al decoder tutti i valori generati in output dal encoder\n . \n•\nAd ogni step, il \n decoder\n  calcola una combinazione lineare dei valori ottenuti \nin output dal encoder così da determinare su quale parola porre l'attenzione \nal successivo step.  \n•\nIl peso \n  è riferito al \n i\n-esimo output, allo step \n t\n-esimo...\n α\n(\nt\n,\ni\n)\n21\nNell'esempio, se  è \nmaggiore di  e , \nallora il decoder \nassegnerà maggiore \nattenzione al termine \n\"milk\" nello step corrente .\nLa restante elaborazione \ncoincide l'architettura \noriginale.α(3,2)\nα(3,0)α(3,1)Questa con ﬁgurazione \nspeci ﬁca di attention \nmechanism è anche \nchiamata:  \nBahdanau attention .  \n \nDato che concatena gli \noutput del encoder con gli \nhidden state, si chiama \nanche: concatenative \nattention , o additive \nattention .",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#21": "Attention mechanism e Encoder-decoder (2)\nI valori \n  sono generati da una rete neurale chiamata \n alignment model  \n(o \nattention layer)\n  addestrata con il resto del encoder-decoder.  \n•\nConsiste in una \n time-distributed Dense layer\n  con un singolo nodo, che \nriceve tutti gli output dal encoder, concatenati con l'hidden state del decoder \nestratti dallo step precedente.  \n•\nIl layer produce una serie di valori e\n (3,0)\n, e\n(3,1)\n, etc; che indicano \n quanto ogni \noutput è allineato con l'hidden state precedente\n . La \nsoftmax\n  normalizza tali \nvalori.\nα\n(\nt\n,\ni\n)\n22\n rappresenta l'hidden \nstate del decoder .\nLa rete densa richiede il \ncalcolo di n2 parametri, \nsupponendo n la \nlunghezza delle frasi in \ninput e output. Ma se non \nabbiamo frasi lunghissime \nla complessità è ancora \npraticabile. h(2)",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#22": "Image captioning\nIn questo task occorre generare un testo signi\n ﬁ\ncativo in linguaggio naturale \nche descrive una immagine. In altre parole dobbiamo dotare l'algoritmo di \ncapacità di \"\n comprensione\"\n . \nUsiamo un \n encoder-decoder\n , dove il \n decoder\n  sfrutta l'\n attention mechanism\n . \nL'\nencoder\n  è una CNN, e le features sono estratte dal layer convolutivo. \nL'\nattention mechanism\n  avrà perciò informazione posizionale codi\n ﬁ\ncata \nnell'input. Il \n decoder\n  usa lo stato precedente, il token generato in precedenza \ne un context vector per generare il nuovo token.\n23 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#23": "Image caption e Visual Attention\nIl \ncontext vector\n  è generato dall'\n attention mechanism \n a partire dalle features \ndella CNN nell'encoder. Esso rappresenta i pesi per ogni location spaziale \ndell'output dell'encoder (\n visual attention\n ).  \nAd ogni step il decoder usa l'attention model per identi\n ﬁ\ncare le giusta \nporzione dell'immagine da analizzare per poi per generare la frase.\n24\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#24": "Explainability\nNel ML con \n explainability\n  si intende la capacità del modello di descrivere il \nsuo comportamento in termini comprensibili all'uomo.  \n•\nInterpretability\n  è un concetto simile, ma legato alle relazioni causa-effetto \ndel modello, e perciò sulla capacità di stimare un certo output in base a una \ncerta con\n ﬁ\ngurazione di input. Si può avere interpretability senza \nexplainability.  \nUtile quando si vuole comprendere un certo output, eventualmente errato.  \n•\nEs. l'output \"un lupo che si muove sulla neve\" prodotto quando c'è un cane \ncome input può dipendere dal fatto che il modello si focalizza sulla presenza \ndella neve per classi\n ﬁ\ncare l'animale.  \nI \nmodelli DL \n sono molto complessi e spesso \n dif\nﬁ\ncilmente esplorabili\n . \nUn tentativo è creare modelli interpretabili (es. alberi di decisione) a partire \ndagli output di un modello non interpretabile\n(3)\n, e usarli per costruire le \nmotivazioni di un certo output.\n25 (3) https://arxiv.org/abs/1602.04938",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#25": "Architettura Transformer - motivazioni\nComputazionalmente, i modelli di attention e le \nCNN sono più veloci rispetto all RNN. I Transformer \nsono unicamente basati su tali modelli.  \nIn \"Attention is all you need\"\n(4)\n, un team di Google \npropose l'architettura \n Transformer\n , dove il task della \ntraduzione dei testi si affronta senza RNN, ma \nprincipalmente con \n layer embedding\n , \ndense layers\n  e \ndi \nnormalization\n .  \nInizialmente proposti nel task \n seq2seq\n  sul testo, \nsono stati poi usati in svariati altri domini, es. \nvisione, speech, reinforcement learning.  \nL'encoder\n  mappa le sequenze in input in una \nrappresentazione continua latente che incapsula \ntutte le informazioni rilevanti della sequenza.  \nI multi-head attention creano associazioni tra una \nparola e le altre con un sistema di pesi.\n26\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#26": "Architettura Transformer - (1)\nAd alto livello possiamo notare uno stack di layer \nmultipli che si ripetono (\n N\n volte). Ognuno di questi \nmacro-layer ha sotto layer.  \nNell'encoder si ha un \n multi-head self-attention\n  e un \npositionwise feed-forward network\n .  \nNell'\n encoder self-attention\n , queries, keys a values \nsono ottenuti dall'output del layer precedente. In \nmodo simile alla ResNet, abbiamo connessioni \nresidue.  \nLo stack del decoder oltre layer simili all'encoder \nabbiamo un ulteriore layer \n encoder-decoder \nattention\n  nel mezzo, che prende in input l'output \ndel layer precedente nel decoder, e keys e values \nottenuti dall'encoder. \n27\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#27": "Architettura Transformer - (2)\nNel decoder self-attention, queries, keys e values \nsono ottenuti dal layer precedente.  \nOgni posizione nel decoder interessa tutte le \nposizioni viste \n ﬁ\nno alla posizione corrente. Infatti \nnel training i dati sono noti, ma in produzione \npossiamo generare token che dipendono solo dai \ntoken già generati.  \nLa \npositionwise feed-forward network\n  è composta \nda 2 layer FC e prende in input (batch size, number \nof time steps/sequence length in tokens, number of \nhidden units/feature dimension) e produce in output \n(batch size, number of time steps, ffn_num_outputs).  \nI transfomer mantengono la proprietà \n auto-\nregressive\n , cioè l'output dipende linearmente dai \nvalori prodotti in precedenza e da un termine \nstocastico.\n28\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#28": "Architettura Transformer e NLP: dettagli (1)\n29 (4) https://arxiv.org/abs/1706.03762\nL'input si pre-processa come prima, ottenendo \nuna\n rappresentazione in uno spazio a 512 \ndimensioni\n  (cioè uno shape [batch size, max \ninput sentence length, 512]) mediante \n word \nembeddings\n . \nL'output del decoder ha sempre forma di \ndistribuzione di probabilità ([batch size, max \noutput sentence length, vocabulary length])  \nIl \ndecoder\n  prende in input la frase target \ntraslata di 1 posizione.  \nAd ognuno dei \n N\n livelli, l'output del \n encoder  \nè inviato in input al \n encoder-decoder attention  \nnel corrispondete livello del \n decoder\n .EncoderDecoder",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#29": "Architettura Transformer e NLP: dettagli (2)\nIn produzione ancora una volta l'output del decoder (una nuova parola) verrà \naccodata all'input del decoder allo step successivo.\n30 (4) https://arxiv.org/abs/1706.03762\nSia encoder sia decoder, oltre agli layer \nembedding, hanno \n 5\nN skip connections\n , \nognuna seguita da una layer di \nnormalizzazione\n . \nLe \npositionwise feed-forward\n  network sono \nreti MLP\n  tradizionali con 2 Dense layer \nciascuna, il primo layer con attivazione \nReLU, il secondo senza attivazione. Il \n layer \ndi output\n  è una layer denso con softmax.  \nTutti i layer sono \n time-distributed\n , cosicché \nogni parola è trattata indipendentemente \ndalle altre.\n×\nEncoderDecoder",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#3": "Introduzione\nNell'esempio sono evidenziate features ricavate dall'\n attention mechanism \n che \nmettono in correlazione features anche molto distanti tra loro.\n4\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#30": "Architettura Transformer e NLP: dettagli (3)\nMa se la generazione delle parole è indipendente una dall'altra, e non \nabbiamo RNN, come può funzionare?\n31 (4) https://arxiv.org/abs/1706.03762\nIl modulo \n multi-head attention\n  codi\n ﬁ\nca ogni \nrelazione di una parola con tutte le altre nella \nstessa frase, in modo da evidenziale le \nrelazioni più importanti (\n self-attention\n ). \n•\nEs. In “They welcomed the Queen of the \nUnited Kingdom”, il termine queen sarà più \nlegato cone \n united\n  e \nkingdom\n  rispetto a \n they \ne \nwelcomed\n . \nIl modulo \n masked multi-head attention\n  si \ncomporta in modo simile, ma si limita a \nconsiderare la parola precedente.  \nIl \nmulti-head attention\n  del decoder analizza le \nparole nella frase in input e si focalizza sui \ntermini più importanti per la traduzione (es. \n\"Queen\").",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#31": "Architettura Transformer e NLP: dettagli (5)\nMa se la generazione delle parole è indipendente una dall'altra, come può \nfunzionare?\n32 (4) https://arxiv.org/abs/1706.03762\nI \npositional embeddings\n , che sono dati in \ninput al \n encoder\n  e \ndecoder\n  insieme agli \nembedding tradizionali, \n rappresentano la \nposizione di un termine rispetto agli altri in \nuna certa frase\n .  \nSono aggiunti ai \n word embedding\n  poiché il \nmulti-head attention laye\n r ignora posizione \ne ordine delle parole nella frase, come pure \ngli altri layer  essendo tutti \n layer time-\ndistributed\n . \n ",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#32": "Keras: Transformer\nIn Keras una versione di Attention basata su \n scaled dot-product\n  è \nimplementata in keras.layers.Attention.  \nencoder_outputs = Z\nZ = decoder_in\nfor\n N \nin \nrange\n(\n6\n):\n    Z = keras.layers.Attention(use_scale=\n True\n, causal=\n True\n)([Z, Z])\n    Z = keras.layers.Attention(use_scale=\n True\n)([Z, encoder_outputs])\noutputs = keras.layers.TimeDistributed(\n    keras.layers.Dense(vocab_size, activation=\n \"softmax\"\n ))(Z)\n33 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#33": "Demo Transformers e NLP\nhttps://transformer.huggingface.co/  \n34 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#4": "Richiamo: Architetture encoder-decoder\nSi può combinare una rete \n sequence-to-vector\n  (\nencoder\n ) con una \n vector-to-\nsequence\n  (\ndecoder\n ) ottenendo una rete \n encoder-decoder\n . \n•\nUn \nencoder\n  può rappresentare una frase in un linguaggio in un singolo \nvettore che viene impiegato poi dal \n decoder\n  per generare la frase in diverso \nlinguaggio. \n5\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#5": "Encoder/Decoder in Keras (1)\nL'interfaccia \n encoder\n  può prendere in input una sequenza di lunghezza \nvariabile X.  \nclass \nEncoder\n(\ntf\n.\nkeras\n.\nlayers\n.\nLayer\n):\n   \ndef \n__init__\n (\nself\n):\n        super().\n __init__\n ()\n    \n# Later there can be additional arguments (e.g., length excluding padding)\n    \ndef \ncall\n(\nself\n, \nX\n, *\nargs\n):\n        \n raise\n NotImplementedErro\n r\nIl \ndecoder\n  prende l'output dei decoder per tramutarlo nello stato.  \nclass \nDecoder\n(\ntf\n.\nkeras\n.\nlayers\n.\nLayer\n):\n   \ndef \n__init__\n (\nself\n):\n        super().\n __init__\n ()\n    \n# Later there can be additional arguments (e.g., length excluding padding)\n    \ndef \ninit_state\n (\nself\n, \nenc_outputs\n , *\nargs\n):\n        \n raise\n NotImplementedError\n    \ndef \ncall\n(\nself\n, \nX\n, \nstate\n):\n        \n raise\n NotImplementedError\n6",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#6": "Encoder/Decoder in Keras (2)\nL'architettura completa:  \nclass \nEncoderDecoder\n (\nd2l\n.\nClassifier\n ):\n   \ndef \n__init__\n (\nself\n, \nencoder\n, \ndecoder\n):\n        super().\n __init__\n ()\n        \n self\n.encoder = encoder\n        \n self\n.decoder = decoder\n    \ndef \ncall\n(\nself\n, \nenc_X\n, \ndec_X\n, *\nargs\n):\n        enc_outputs = \n self\n.encoder(enc_X, *args, training=\n True\n)\n        dec_state = \n self\n.decoder.init_state(enc_outputs, *args\n )\n        \n # Return decoder output only\n        \n return \nself\n.decoder(dec_X, dec_state, training=\n True\n)[\n0\n]\n7",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#7": "Esempio: Machine Translation (1)\nIn questo caso input e output sono sequenze di lunghezza variabile. La \nsequenza in input è tradotta in una rappresentazione nascosta/latente \n ﬁ\nxed-\nshape.  \nLa sequenza in output è generata \n token-by-token\n : data l'attuale sequenza in \ninput, e i token precedenti generati in output. Durante l'addestramento il \ntoken da generare sarà estratto dai dati ground-truth. L'\n hidden state \ndell'\nencoder\n  viene dato in input ad ogni step di decoding. L'output generato \nsarà il nuovo input del decoder nello step successivo.  \nNota: se ignoriamo \n l'encoder\n , il \ndecoder\n  corrisponde ad un \n language model\n . \nNell'esempio abbiamo frasi tokenizzate, dove <eos> corrisponde a end-of-\nsequence. Ad ogni istanze iniziale, si impiega un tag <bos> per indicare \nl'inizio della sequenza\n8\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#8": "Esempio: Machine Translation (2)\nL'encoder\n  può essere implementato con una RNN (es. GRU) uni o bi-\ndirezionale.  \nL'output layer del \n decoder\n  sarà una FC che genera la distribuzione di \nprobabilità sui token in output.  \nLa \nloss\n sarà una basata sulla \n cross-entropy\n . \nUsualmente si usano sequenze di padding per frasi di lunghezza variabile, in \ninput e output. Tali padding non intervengono nel calcolo della loss.\n9\n",
    "data_test\\rootfolder\\università\\DeepLearning\\14-Attention e Autoencoders 1-sbloccato.pdf#9": "Beam search (1)\nNell'architettura precedente il token generato è quello con più alta \nprobabilità, \n ﬁ\nno a quando non è generato il token <eos>. Seguiamo una \nstrategia \n greedy\n , \nbasata sui passati token generati e la variabile di contesto \n c\n, \nche rappresenta la frase in input:  \nNella \n beam search\n  scegliamo i \n k\n token candidati più probabili. \nSuccessivamente teniamo in considerazioni i \n k\n token per la generazione del \nnuovo token, e così via.\n10\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nAutoencoders\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#1": "Sommario\nLanguage models: recenti sviluppi  \nAutoencoders  \nStacked Autoencoders  \nFashion MNIST dataset  \nVisualizzazione con t-SNE  \nUnsupervised training con Stacked autoencoders  \nConvolutional Autoencoders  \nRecurrent Autoencoders  \nDenoising Autoencoders  \nSparse Autoencoders  \nVariational Autoencoders  \nSemantic interpolation",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#10": "Rappresentazioni latenti\nLatent representation learning\n  (LRL), o \n Latent variable modeling \n (LVM), è una \ntecnica di apprendimento automatico che tenta di inferire le variabili latenti \nda misurazioni empiriche da variabili osservabili. Tali variabili latenti non \npossono essere misurate direttamente e quindi devono essere dedotte.  \nUna o più variabili latenti costituiscono congiuntamente uno \n spazio latente\n  o \nuna\n rappresentazione latente\n . Questa rappresentazione è solitamente una \nforma \n compatta\n  dello spazio impiegato per rappresentare le misurazioni \nempiriche, cioè consiste in un numero di variabili latenti inferiore alla \ndimensionalità delle misurazioni.\n11 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#11": "Autoencoders\nGli \nautoencoders\n  apprendono \n rappresentazioni latenti\n  dei dati senza \nl'impiego di approcci supervisionati.  \nInoltre possono essere impiegati per il \n unsupervised pretraining\n , e per \ngenerare casualmente nuovi dati \n che risultano simili a dati già visti in \nprecedenza (es. visi di persone), sebbene non sempre realistici.  \n•\nCon le più recenti \n Generative adversarial networks\n  (\nGANs\n ), che spesso \nincludono anche moduli di autoencoders, suddividono il processo in 2 parti: \ngenerazione e discrimazione. In questi casi il realismo è maggiore.  \n•\nhttps://thispersondoesnotexist.com/  \nhttps://thisrentaldoesnotexist.com/  \nhttps://github.com/jantic/DeOldify    \nInoltre le GAN possono incrementare la risoluzione delle immagini, \naggiungere colore alle immagini b/w, photo editing come rimpiazzare oggetti, \nconvertire un disegno in una foto realistica, predire il successo frame in un \nvideo, creare/incrementare dataset per l'addestramento, etc.\n12 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#12": "Rappresentazione dei dati ef\n ﬁ\nciente\nUn \nautoencoder\n  può avere una architettura piuttosto comune, es. MLP, dove \ninput e output hanno hanno medesima dimensione.  \n•\nNel seguente esempio l'\n hidden layer\n  consiste in 2 soli nodi, mentre l'\n output \ne\n l'input layer \n di 3 nodi. Lo scopo del \n decoder\n  (\noutput layer\n ) è ricostruire \nl'input a partire dalla rappresentazione creata dall'\n encoder\n .  \n•\nSe la rappresentazione dell'encoder ha meno dimensioni rispetto all'input, \nl'\nautoencoder\n  si chiama \n undercomplete\n . \n•\nLa\n loss di ricostruzione\n  valuta la differenza dell'output generato rispetto \nall'input.\n13 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#13": "Autoencoders\nSe l'\nautoencoder \n usa \nattivazioni lineari\n  e la \n MSE\n come funzione di costo, \nallora otteniamo un modello simile alla \n Principal Component Analysis \n (\nPCA\n). \nNel seguente esempio proiettiamo istanze da un dataset 3d in 2d.  \nfrom\n tensorflow \n import\n keras\nencoder = keras.models.Sequential([keras.layers.Dense(\n 2\n, input_shape=[\n 3\n])])\ndecoder = keras.models.Sequential([keras.layers.Dense(\n 3\n, input_shape=[\n 2\n])])\nautoencoder = keras.models.Sequential([encoder, decoder])\nautoencoder.\n compile\n(loss=\n\"mse\"\n, optimizer=keras.optimizers.SGD(lr=\n 0.1\n))\nPossiamo addestrarlo e impiegarlo per ottenere le rappresentazioni latenti:  \nhistory = autoencoder.fit(X_train, X_train, epochs=\n 20\n)\ncodings = encoder.predict(X_train)\n14 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#14": "Stacked Autoencoders\nGli \nstacked autoencoders\n  (o \ndeep autoencoders\n ) sono autoencoders \norganizzati su più layer, spesso in modo speculare.  \n•\nNon è mai consigliato creare autoencoders troppo complessi per non \npenalizzare il grado di generalizzazione su istanze in input non presenti nel \ndataset di training, su cui il modello non è capace di determinare attivazioni \nsigni\nﬁ\ncative.  \nNel caso \n MNIST\n  possiamo creare una architettura con 784 inputs, 100 nodi \nnel primo hidden layer, 30 nodi in quello centrale, un altro da 100 e l'output \nlayer.\n15 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#15": "Scaled Exponential Linear Units\nLa funzione di attivazione \n Scaled Exponential Linear Units\n  (\nSELU\n ) \nè simile alla \nELU ed è de\n ﬁ\nnita nel seguente modo:  \n \n \nLa SELU non si annulla per valore < 0, a differenza della ReLU.  \nSi può ipotizzare che la SELU implementi un ulteriore tipo di normalizzazione \n\"interna\" che supporti l'invarianza tra media e varianza tra i layer, oltre alle \ndue normalizzazioni già note:  \n•\nInput normalization (\n es. quando scaliamo i dati in ingresso)  \n•\nBatch normalization\nf\n(\nx\n)\n=\nλ\nx\n,\nif \nx\n>\n0\nf\n(\nx\n)\n=\nλ\nα\n(\ne\nx\n−\n1\n)\n altrimenti\n16\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#16": "Keras: Stacked Autoencoders\nL'implementazione è simile a una MLP. Nell'esempio usiamo una funzione di \nattivazione SELU, e invece delle MSE impieghiamo la \n binary cross-entropy\n  loss  \nper accelerare la convergenza.  \nstacked_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[\n 28\n, \n28\n]),\n    keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n),\n    keras.layers.Dense(\n 30\n, activation=\n \"selu\"\n),\n])\nstacked_decoder = keras.models.Sequential([\n    keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n, input_shape=[\n 30\n]),\n    keras.layers.Dense(\n 28\n * \n28\n, activation=\n \"sigmoid\"\n ),\n    keras.layers.Reshape([\n 28\n, \n28\n])\n])\nstacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\nstacked_ae.\n compile\n(loss=\n\"binary_crossentropy\"\n ,\n                   optimizer=keras.optimizers.SGD(lr=\n 1.5\n))\nhistory = stacked_ae.fit(X_train, X_train, epochs=\n 10\n,\n                         validation_data=[X_valid, X_valid])\n17 (13) https://arxiv.org/pdf/1706.02515.pdf",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#17": "`\nPer comprendere se l'output è corretto è utile visualizzarlo. Nel caso del \ndataset Fashion MNIST si ha:  \ndef \nplot_image\n (\nimage\n):\n    plt.imshow(image, cmap=\n \"binary\"\n )\n    plt.axis(\n \"off\"\n)\ndef \nshow_reconstructions\n (\nmodel\n, \nn_images\n =\n5\n):\n    reconstructions = model.predict(X_valid[:n_images])\n    fig = plt.figure(figsize=(n_images * \n 1.5\n, \n3\n))\n    \nfor\n image_index \n in \nrange\n(n_images):\n        plt.subplot(\n 2\n, n_images, \n 1\n + image_index)\n        plot_image(X_valid[image_index])\n        plt.subplot(\n 2\n, n_images, \n 1\n + n_images + image_index)\n        plot_image(reconstructions[image_index])\nshow_reconstructions(stacked_ae)\n18 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#18": "t-Distributed Stochastic Neighbourh \nt-Distributed Stochastic Neighbourh Embedding (t-SNE)\n  è un algoritmo non \nsupervisionato usato per la visualizzazione dei dati.  \nBasato su una tecnica di riduzione della dimensionalità non lineare che punta \na raggruppare punti simili tra loro in spazi con poche dimensioni preservando \nla struttura dei dati originali.  \nSfrutta la distribuzione t-Student per il calcolo della similarità tra 2 punti nello \nspazio ridotto e sulla Kullback–Leibler divergence.  \nÈ poco affetto dagli outliers.\n19 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#19": "Visualizzare un dataset con Autoencoders\nSebbene esistano tecniche avanzate di riduzione della dimensionalità e la \nvisualizzazione dei dati, gli \n autoencoders\n  sono capaci di ridurre notevolmente \nle dimensioni di un dataset con molti istanze e molte features. Perciò \npossiamo sfruttarlo per generare input verso approcci più tradizionali, anche \ndi visualizzazione.  \nSfruttiamo \n t-distributed stochastic neighbor embedding\n  (\nt\n-\nSNE\n) implementato \nin Scikit-Learn per la visualizzazione 2d.  \nfrom\n sklearn.manifold \n import\n TSNE\nX_valid_compressed = stacked_encoder.predict(X_valid)\ntsne = TSNE()\nX_valid_2D = tsne.fit_transform(X_valid_compressed)\nplt.scatter(X_valid_2D[:, \n 0\n], X_valid_2D[:, \n 1\n], c=y_valid, s=\n 10\n, cmap=\n\"tab10\"\n)\n20 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#2": "Language Models: recenti sviluppi (1)\nELMo\n(6)\n Embeddings from Language Models: rappresentazioni contestuali \nottenute da un approccio \n Deep bidirectional language model (biLM) \naddestrato su larghi dataset testuali. Gli stati generati dalla rete sono associati \nai testi in modo da creare rappresentazioni latenti.   \nULMFiT\n(7)\n Universal Language Model Fine-tuning: basato su \n self-supervised \nlearning\n  con una architettura \n LSTM\n  a 3 layer dove sono richiesti meno dati (es. \n100 istanze) per l'addestramento sfruttando il transfer learning. State-of-the-art \nper la classi\n ﬁ\ncazione NLP.\n3(6) https://arxiv.org/abs/1802.05365  \n(7) https://arxiv.org/abs/1801.06146  \n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#20": "Fashion MNIST: Autoencoders e t-SNE\nFashion MNIST sottoposto a \n autoencoders\n  e \nt-SNE\n :\n21 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#21": "Unsupervised training con Stacked autoencoders\nSeguendo la \n ﬁ\nloso\nﬁ\na del \n transfer learning\n , possiamo addestrare un \nautoencoder\n  su un grande dataset di dati \n unlabeled\n , e \nriutilizzare i parametri \nottenuti nei primi layer \n con un dataset più limitato di dati \n labeled\n  nel task \nprincipale di interesse.  \n•\nDati \n unlabeled\n  si trovano facilmente sul web, es. immagini, testi, mentre i \ndati labeled sono molto preziosi poiché richiedono molte ore-uomo per \ncreare valori target.\n22 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#22": "Autoencoders: Tying weights (1)\nPer \nautoencoders\n  simmetrici è possibile creare \n vincoli\n  tra i valori dei parametri \nnei layer speculari (\n tying weights\n ) in modo da dimezzare i parametri da \nstimare durante l'apprendimento.  \nIn Keras costruiamo un Dense layer per impiegare i pesi di un layer \nprecedente; attenzione: occorre trasporli prima di impiegarli nella decodi\n ﬁ\nca. \nclass \nDenseTranspose\n (\nkeras\n.\nlayers\n.\nLayer\n):\n    \ndef \n__init__\n (\nself\n, \ndense\n, \nactivation\n =\nNone\n, **\nkwargs\n):\n        \n self\n.dense = dense\n        \n self\n.activation = keras.activations.get(activation)\n        super().\n __init__\n (**kwargs\n )\n    \ndef \nbuild\n(\nself\n, \nbatch_input_shape\n ):\n        \n self\n.biases = \n self\n.add_weight(name=\n \"bias\"\n, initializer=\n \"zeros\"\n,\n                                      shape=[\n self\n.dense.input_shape[\n -1\n]])\n        super().build(batch_input_shape\n )\n    \ndef \ncall\n(\nself\n, \ninputs\n):\n        z = tf.matmul(inputs, \n self\n.dense.weights[\n 0\n], \ntranspose_b\n =\nTrue\n)\n        \n return \nself\n.activation(z + \n self\n.biases)\n23 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#23": "Autoencoders: Tying weights (2)\nLa costruzione della rete impiega i nuovi layer per legarli con i precedenti:  \ndense_1 = keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n)\ndense_2 = keras.layers.Dense(\n 30\n, activation=\n \"selu\"\n)\ntied_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[\n 28\n, \n28\n]),\n    dense_1,\n    dense_2\n])\ntied_decoder = keras.models.Sequential([\n    DenseTranspose(dense_2, activation=\n \"selu\"\n),\n    DenseTranspose(dense_1, activation=\n \"sigmoid\"\n ),\n    keras.layers.Reshape([\n 28\n, \n28\n])\n])\ntied_ae = keras.models.Sequential([tied_encoder, tied_decoder])\n24 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#24": "Greedy layerwise training\nInvece di addestrare tutti i layer contemporaneamente possiamo farlo uno step \nalla volta, aggiungendo un layer dopo aver addestrato il precedente (\n greedy \nlayerwise training\n ). \nDopo il primo step codi\n ﬁ\nco tutto il dataset per mezzo del primo autoencoder \n(\nphase 1\n ). Uso il nuovo dataset per addestrare un secondo autoencoder (\n phase \n2\n). In\nﬁ\nne metto tutti i layer insieme (\n phase 3\n ) \n•\nTale tecnica è attualmente poco popolare a causa di tecniche più recenti.\n25 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#25": "Convolutional Autoencoders\nLe architetture di \n autoencoders\n  viste non sono adatte per le immagini, cioè \ninput con grandi dimensionalità.  \nLe \nconvolutional autoencoders\n  impieghiamo dei \n layer convoluzionali \n per \nridurre la dimensionalità\n  incrementando la profondità del modello durante la \ncodi\nﬁ\nca. \nIl \ndecoder\n  deve fare l'inverso: ridurre la profondità ed aumentare la risoluzione \n(\nupsampling\n ). Si impiegano \n transpose convolutional layers\n  che operano in \nmodo inverso alle convolution layer tradizionali.  \nEcco un esempio per Fashion MNIST:  \nconv_encoder = keras.models.Sequential([\n    keras.layers.Reshape([\n 28\n, \n28\n, \n1\n], input_shape=[\n 28\n, \n28\n]),\n    keras.layers.Conv2D(\n 16\n, kernel_size=\n 3\n, padding=\n \"same\"\n, activation=\n \"selu\"\n),\n    keras.layers.MaxPool2D(pool_size=\n 2\n),\n    keras.layers.Conv2D(\n 32\n, kernel_size=\n 3\n, padding=\n \"same\"\n, activation=\n \"selu\"\n),\n    keras.layers.MaxPool2D(pool_size=\n 2\n),\n    keras.layers.Conv2D(\n 64\n, kernel_size=\n 3\n, padding=\n \"same\"\n, activation=\n \"selu\"\n),\n    keras.layers.MaxPool2D(pool_size=\n 2\n)\n]\n)\n...\n26 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#26": "Convolutional Autoencoders\nconv_decoder = keras.models.Sequential([\n    keras.layers.Conv2DTranspose(\n 32\n, kernel_size=\n 3\n, strides=\n 2\n, padding=\n \"valid\"\n,\n                                 activation=\n \"selu\"\n,\n                                 input_shape=[\n 3\n, \n3\n, \n64\n]),\n    keras.layers.Conv2DTranspose(\n 16\n, kernel_size=\n 3\n, strides=\n 2\n, padding=\n \"same\"\n,\n                                 activation=\n \"selu\"\n),\n    keras.layers.Conv2DTranspose(\n 1\n, kernel_size=\n 3\n, strides=\n 2\n, padding=\n \"same\"\n,\n                                 activation=\n \"sigmoid\"\n ),\n    keras.layers.Reshape([\n 28\n, \n28\n])\n])\nconv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n27 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#27": "Recurrent Autoencoders\nPer dati \n time series\n  abbiamo visto come le RNN sono una valida alternativa alle \nFC. \nI \nrecurrent autoencoder \n hanno un \n encoder\n  tipicamente \n sequence-to-vector \n che \n\"comprime\" l'input in una rappresentazione vettoriale, mentre il decoder è \nvector-to-sequence\n . \nIl seguente \n autoencoder\n  processa sequenze di qualsiasi lunghezza, con 28 \ndimensioni considerate per singolo step. L'input possono essere immagini \nFashion MNIST che saranno processate una riga di pixel alla volta.  \n•\nIl\n RepeatVector layer \n del decoder garantisce che l'input vector al decoder sarà \ninviato per intero ad ogni step.  \nrecurrent_encoder = keras.models.Sequential([\n    keras.layers.LSTM(\n 100\n, return_sequences=\n True\n, input_shape=[\n None\n, \n28\n]),\n    keras.layers.LSTM(\n 30\n)\n])\nrecurrent_decoder = keras.models.Sequential([\n    keras.layers.RepeatVector(\n 28\n, input_shape=[\n 30\n]),\n    keras.layers.LSTM(\n 100\n, return_sequences=\n True\n),\n    keras.layers.TimeDistributed(keras.layers.Dense(\n 28\n, activation=\n \"sigmoid\"\n ))\n])\nrecurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])\n28 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#28": "Denoising Autoencoders (1)\nNelle \n denoising autoencoders\n(14)\n in input abbiamo immagini a cui \naggiungiamo del rumore, e in output ci sono le versioni originali: stiamo \naddestrando la rete a \n rimuovere il rumore\n .  \n•\nIl rumore può essere gaussiano, oppure con un random switch-off degli input \n(es. tramite tecniche simili al Dropout).\n29 (14) https://jmlr.csail.mit.edu/papers/v11/vincent10a\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#29": "Denoising Autoencoders (2)\nCodi\nﬁ\nca e output con Fashion MNIST  \ndropout_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[\n 28\n, \n28\n]),\n    \nkeras.layers.Dropout(\n 0.5\n),\n    keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n),\n    keras.layers.Dense(\n 30\n, activ\n                       “    keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n),\n    keras.layers.Dense(\n 30\n, activation=\n \"selu\"\n)\n])\ndropout_decoder = keras.models.Sequential([\n    keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n, input_shape=[\n 30\n]),\n    keras.layers.Dense(\n 28\n * \n28\n, activation=\n \"sigmoid\"\n ),\n    keras.layers.Reshape([\n 28\n, \n28\n])\n])\ndropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])\n30 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#3": "Self-supervised learning\nCon \nself-supervised learning  \nsi intende l'addestramento di una modello in assenza di \nun dataset suf\n ﬁ\ncientemente grande in termini di valori target riguardo il task di \ninteresse principale.  \nIn tali casi si sfruttano le stessi istanze presentate in input per creare dei nuovi target \nsecondari, distinti da quello iniziale, ma comunque af\n ﬁ\nni. In tal modo la rete può \nidenti\n ﬁ\ncare alcune features salienti impiegabili nel task principale (\n knowledge transfer \nprocess\n ).  \n•\nEsempi di task secondari sono\n : identi\n ﬁ\ncare relazioni sostantivo-verbo o frase-\naggettivo (dominio NLP); due immagini, una ruotata, ed aspettarsi l'angolo di \nrotazione in output alla rete (dominio immagini).  \nSebbene i dataset secondari siano più facili da costruire, non sono suf\n ﬁ\ncienti per \nrisolvere il problema principale. ma riducono il tempo totale necessario per la fase di \ntraining del task principale. Una ulteriore fase di addestramento su un dataset ridotto \n(es. quello disponibile inizialmente) rendono la rete ef\n ﬁ\ncace anche sul task di interesse \nprimario.  \nÈ fondamentale scegliere un task secondario che, durante l'addestramento, generi un \nsottoinsieme di features utili anche per il task principale.  \nAttenzione: è un approccio distinto dal \n unsupervised pretraining\n .\n4",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#30": "Sparse Autoencoders (1)\nNegli \n sparse autoencoders \n introduciamo un termine nella funzione di costo che \nfavorisce un numero limitato di nodi \"attivi\" nel layer di coding\n , cioè quello che \nè associato allo spazio che stiamo costruendo.  \n•\nIn altre parole, forziamo la rete a rappresentare ogni input con poche attivazioni, \ne perciò \n ogni nodo attivo rappresenterà un numero limitato di feature molto \nsigni\nﬁ\ncative\n . \nCon la funzione di attivazione \n sigmoid\n , che pone una sorta di vincolo sulle \ncodi\nﬁ\nche in [0,1], e con la \n ℓ\n1\n regularization\n  al layer di coding, otteniamo il \nseguente codice Keras:  \nsparse_l1_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[\n 28\n, \n28\n]),\n    keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n),\n    keras.layers.Dense(\n 300\n, activation=\n \"sigmoid\"\n ),\n    \nkeras.layers.ActivityRegularization(l1=\n 1e-3\n)\n  # vedi lucido seguente\n])\nsparse_l1_decoder = keras.models.Sequential([\n    keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n, input_shape=[\n 300\n]),\n    keras.layers.Dense(\n 28\n * \n28\n, activation=\n \"sigmoid\"\n ),\n    keras.layers.Reshape([\n 28\n, \n28\n])\n])\nsparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])\n31 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#31": "Sparse Autoencoders (2)\nIl layer \n ActivityRegularization\n  restituisce gli stessi input, ma ha l'effetto \ncollaterale di aggiungere una\n  training loss che coincide con la somma dei valori \nassoluti dei suoi input\n . In questo modo forziamo la rete, sia a produrre \ncodi\nﬁ\nche vicine allo 0\n , sia a ricostruire l'output corretto; perciò avremo \ncodi\nﬁ\nche con pochi valori, ma molto signi\n ﬁ\ncativi, diversi da 0.  \nUn modo alternativo è \n misurare una sorta di \"sparsity\" calcolata durante \nl'apprendimento\n  e, se si discosta da un valore target, \n penalizziamo la rete\n . La \nricaviamo con l'\n attivazione media\n  per ogni nodo nel coding layer nell'intero \ntraining batch, che avrà una dimensione suf\n ﬁ\nciente per stimare correttamente \ntali valori.  \nSuccessivamente introduciamo la \n sparsity loss\n  che penalizza i nodi troppo \nattivi, o i nodi non suf\n ﬁ\ncientemente attivi.  \n•\nEs. Se l'average per un nodo è 0.3, e la target sparsity è 0.1, penalizziamo in \nmodo da ridurre l'attivazione aggiungendo ad esempio l'\n errore quadratico  \n(0.3-0.1)2  alla funzione di cost.  \n•\nUna alternativa migliore è usare \n Kullback–Leibler (KL)\n , che deriva dei gradienti \npiù signi\n ﬁ\ncativi interpretando le 2 attivazioni come distribuzioni di probabilità.\n32 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#32": "Sparsity loss\nSparsity loss\n  ricavata con diverse metriche:\n33 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#33": "Keras: Sparse Autoencoders\nSparse autoencoders con la KL-divergence:  \nK = keras.backend\nkl_divergence = keras.losses.kullback_leibler_divergence\nclass \nKLDivergenceRegularizer\n (\nkeras\n.\nregularizers\n .\nRegularizer\n ):\n    \ndef \n__init__\n (\nself\n, \nweight\n, \ntarget\n=\n0.1\n):\n        \n self\n.weight = weight\n        \n self\n.target = target\n    \ndef \n__call__\n (\nself\n, \ninputs\n):\n        mean_activities = K.mean(inputs, axis=\n 0\n)\n        \n return \nself\n.weight * (\n            kl_divergence(\n self\n.target, mean_activities) +\n            kl_divergence(\n 1\n. - \nself\n.target, \n 1\n. - mean_activities))\n        \n..\n.\nkld_reg = KLDivergenceRegularizer(weight=\n 0.05\n, target=\n 0.1\n)\nsparse_kl_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[\n 28\n, \n28\n]),\n    keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n),\n    keras.layers.Dense(\n 300\n, activation=\n \"sigmoid\"\n ,”\n                       activity_regularizer=kld_reg)\n])\nsparse_kl_decoder = keras.models.Sequential([\n    keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n, input_shape=[\n 300\n]),\n    keras.layers.Dense(\n 28\n * \n28\n, activation=\n \"sigmoid\"\n ),\n    keras.layers.Reshape([\n 28\n, \n28\n])\n])\nsparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])\n34 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#34": "Sparse Autoencoders e attivazioni\nDopo la fase di training su Fashion MNIST notiamo come circa il 70% delle \nattivazioni è prossima a 0, e che gran parte dei neuroni (90%) ha attivazione \nmedia tra 0.1 e 0.2.\n35 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#35": "Variational Autoencoders (1)\nI \nvariational autoencoders \n sono molto diffusi. Sono distinti dai precedenti \npoiché sono in parte \n probabilistici\n , cioè una parte dell'output è generato in \nmodo random, e \n generativi\n , cioè possono generare nuove istanze che \nsembrano campionate dal training set. \n36 (15) https://arxiv.org/abs/1312.6114\nHanno una architettura simile agli altri \nautoencoders, ma all'interno \nl'encoder produce un vettore \n codi\nﬁ\nca \nmedia  \n e un vettore \n deviazione \nstandard  \n.  \nL'\neffettiva codi\n ﬁ\nca\n della istanza in \ninput sarà generata per mezzo di una \ndistribuzione gaussiana con tali \nparametri.  \nDurante il training la loss tende a \nraggruppare le codi\n ﬁ\nche in modo da \ngenerare una \"nuvola gaussiana\" di \npunti.\nμ\nσ",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#36": "Variational Autoencoders (2)\nLa \nfunzione di costo\n  consiste in due loss: la \n reconstruction loss \n che impone \nche l'output sia fedele all'input, e una \n latent loss \n che spinge ad avere \ncodi\nﬁ\nche come se fossero campionate da una distribuzione gaussiana, de\n ﬁ\nnita \nper mezzo della KL-divergence.  \n37 (15) https://arxiv.org/abs/1312.6114\nLa forma analitica contiene dettagli \nper limitare l'informazione trasmessa \nal coding layer, ma sempli\n ﬁ\ncando si \nottiene la seguente \n latent loss\n : \nK \nè la dimensione delle codi\n ﬁ\nche e \n i \nindica l'i-esima componente della \ncodi\nﬁ\nca.  \n•\nImpiegando la log(\n ) invece di \n  si \nottiene \n più stabilità\n .\nσ\n σ\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#37": "Keras: Variational Autoencoders (1)\nIn Keras creiamo un \n Sampling\n  layer che campiona una istanza dalla distribuzione \ngaussiana  \nclass \nSampling\n (\nkeras\n.\nlayers\n.\nLayer\n):\n    \ndef \ncall\n(\nself\n, \ninputs\n):\n        mean, log_var = inputs\n        \n return\n K.random_normal(tf.shape(log_var)) * K.exp(log_var / \n 2\n) + mean\nNon avendo un modello strettamente sequenziale usiamo le \n Functional API\n  di Keras, \nadatte per architetture particolari, ad esempio con topologie non lineari, pesi condivisi \ntra layer, o input e output multipli.  \nNel codice del \n encoder\n  con Functional API notiamo la rappresentazione esplicita dei \ndati ricavati dalla rete (es. \n z, codings_mean, codings_log_var\n  etc):  \ncodings_size = 1\n 0\ninputs = keras.layers.Input(shape=[\n 28\n, \n28\n])\nz = keras.layers.Flatten()(inputs)\nz = keras.layers.Dense(\n 150\n, activation=\n \"selu\"\n)(z)\nz = keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n)(z)\ncodings_mean = keras.layers.Dense(codings_size)(z)  \n # \nμ\ncodings_log_var = keras.layers.Dense(codings_size)(z)  \n # \nγ\ncodings = Sampling()([codings_mean, codings_log_var])\nvariational_encoder = keras.Model(\n    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n38 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#38": "Keras: Variational Autoencoders (2)\nCreiamo il \n decoder\n , in questo caso potevamo usare anche l'approccio Keras \nSequential.  \ndecoder_inputs = keras.layers.Input(shape=[codings_size])\nx = keras.layers.Dense(\n 100\n, activation=\n \"selu\"\n)(decoder_inputs)\nx = keras.layers.Dense(\n 150\n, activation=\n \"selu\"\n)(x)\nx = keras.layers.Dense(\n 28\n * \n28\n, activation=\n \"sigmoid\"\n )(x)\noutputs = keras.layers.Reshape([\n 28\n, \n28\n])(x)\nvariational_decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])\nCreiamo il modello e de\n ﬁ\nniamo la \n latent_loss\n  e \nreconstruction_loss\n , e \naddestriamo con \n RMSprop\n  optimizer, adatto in questa con\n ﬁ\ngurazione:  \n_, _, codings = variational_encoder(inputs)\nreconstructions = variational_decoder(codings)\nvariational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])\nlatent_loss = \n -0.5\n * K.\nsum\n(\n    \n1\n + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n    axis=\n -1\n)\nvariational_ae.add_loss(K.mean(latent_loss) / \n 784\n.)\nvariational_ae.\n compile\n(loss=\n\"binary_crossentropy\"\n , optimizer=\n \"rmsprop\"\n )\nhistory = variational_ae.fit(X_train, X_train, epochs=\n 50\n, batch_size=\n 128\n,\n                             validation_data=[X_valid, X_valid])\n39 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#39": "Generare immagini stile Fashion MNIST\nGeneriamo nuove istanze campionando in modo causale dalla distribuzione \ngaussiana:  \ncodings = tf.random.normal(shape=[\n 12\n, codings_size])\nimages = variational_decoder(codings).numpy(\n )\nLe istanze in output, un po' fuzzy, sono abbastanza verosimili:\n40 ...\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#4": "Self-supervised learning - esempio\nNel dominio delle immagini possiamo considerare come task secondari quelli \nil cui obiettivo è ricostruire una immagine manipolata, es. distorta, ruotata.  \nNel task \n patches\n , estraiamo più segmenti dall'immagine e cerchiamo di \ndeterminare la relazione tra essi (es. posizione relativa tra 2 segmenti).  \n•\nEs\n. prendiamo una patch \n X\n a caso dall'immagine, ed otteniamo le 8 patches \nche la circondano \n Y\ni\n. Usiamo coppie di patches (\n X,Y\ni\n) come input per \ndeterminare la posizione della patch \n Y\ni\n. Oppure diamo in input tutte le 9 \npatches in ordine random e chiediamo alla rete di \"risolvere il puzzle\".\n5\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#40": "Variational Autoencoders e semantic interpolation\nInvece di interpolare due immagini nel \"dominio dei pixel\", possiamo \ninterpolare nel dominio latente \n costruito dall'\n autoencoder\n . \n•\nDeriviamo la rappresentazione dal coding layer di due immagini in input, \ninterpoliamole e decodi\n ﬁ\nchiamole.  \ncodings_grid = tf.reshape(codings, [\n 1\n, \n3\n, \n4\n, codings_size])\nlarger_grid = tf.image.resize(codings_grid, size=[\n 5\n, \n7\n])\ninterpolated_codings = tf.reshape(larger_grid, [\n -1\n, codings_size])\nimages = variational_decoder(interpolated_codings).numpy()\n41 ...\nLe immagini nel box sono \nquelle originali, quelle \nsenza sono l'interpolazione \ndi quelle adiacenti.",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#5": "Language Models: recenti sviluppi (2)\nGPT\n(8)\n sfrutta il \n unsupervised pretraining\n  con una  architettura \n Transform\n  con \nstack di 12 moduli, addestrata su un dataset esteso con tecniche \n self-\nsupervised\n .  \n•\nNecessita di un \n ﬁ\nne-tuned training per impiegarla su task speci\n ﬁ\nci (es. \nclassi\n ﬁ\ncazione, misura di similarità, question answering).  \n•\nGPT-2\n(9)\n è una versione estesa con 1.5 miliardi di parametri, con modelli \ndisponibili online.  \n•\nGPT-3\n  è estesa a 175 miliardi di parametri. Le APIs sono disponibili ma \nl'accesso è previa veri\n ﬁ\nca.\n6(8) https://bit.ly/38FfBQ7  \n(9) https://bit.ly/3oGLu0i   https://github.com/openai/gpt-2",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#6": "Language Models: recenti sviluppi (3)\nGPT-2 output\n7(8) https://bit.ly/38FfBQ7  \n(9) https://bit.ly/3oGLu0i   https://github.com/openai/gpt-2\n",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#7": "Language Models: recenti sviluppi (4)\nBERT\n(10)\n Bidirectional Encoder Representations from Transformers: sviluppata \nda Google, simile alla GPT, impiega \n self-supervised pretraining\n  con approccio \nbidirezionale. È stata pre-addestrata su due task:  \n•\nOgni parola in una frase ha il 15% di probabilità di essere \n mascherata\n . Il \ncompito della rete è di indovinarla.  \n•\nDate due frasi, predire se sono consecutive.  \nAltri approcci recenti usano CNN con \n masked 2d-conv\n  per il task di \ntrasformazione sequence-to-sequence\n(11)\n, o RNN dove ogni nodo risulta \nindipendente dall'altro, garantendo apprendimenti su sequenze molto più \nlunghe\n(12)\n.\n8(10) https://arxiv.org/abs/1810.04805  \n(11) https://arxiv.org/abs/1808.03867(12) https://arxiv.org/abs/1803.04831  ",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#8": "Rappresentazione dei dati ef\n ﬁ\nciente\nRiusciresti a memorizzare queste due sequenze?  \n•\n40, 27, 25, 36, 81, 57, 10, 73, 19, 68  \n•\n50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14\n9 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\15-Attention e Autoencoders 2-sbloccato.pdf#9": "Rappresentazione dei dati ef\n ﬁ\nciente\nRiusciresti a memorizzare queste due sequenze?  \n•\n40, 27, 25, 36, 81, 57, 10, 73, 19, 68  \n•\n50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14  \nSe riconosci il pattern \"tutti i numeri pari dal 50 al 14\" ti sarà più facile \nricordare la seconda.\n10 ...",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nGenerative Adversarial Networks\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#1": "Sommario\nApprendimento discriminativo e generativo  \nGeneratie adversarial networks (GANs)  \nDeep Convolutional Generative Adversarial Networks",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#10": "GAN e Keras: Generatore e Discriminatore\n   \nfor\n epoch \nin \nrange\n(num_epochs):\n        timer = d2l.Timer()\n        metric = d2l.Accumulator(\n 3\n)  \n# loss_D, loss_G, num_examples\n        \n for\n (X,) \nin\n data_iter:\n            batch_size = X.shape[\n 0\n]\n            Z = tf.random.normal(\n                mean=\n 0\n, stddev=\n 1\n, shape=(batch_size, latent_dim))\n            metric.add(update_D(X, Z, net_D, net_G, loss, optimizer_D),\n                       update_G(Z, net_D, net_G, loss, optimizer_G),\n                       batch_size)\n        \n # Visualizzazione dei dati generati\n        Z = tf.random.normal(mean=\n 0\n, stddev=\n 1\n, shape=(\n 100\n, latent_dim))\n        fake_X = net_G(Z)\n        animator.axes[\n 1\n].cla()\n        animator.axes[\n 1\n].scatter(data[:, \n 0\n], data[:, \n 1\n])\n        animator.axes[\n 1\n].scatter(fake_X[:, \n 0\n], fake_X[:, \n 1\n])\n        animator.axes[\n 1\n].legend([\n \"real\"\n, \n\"generated\"\n ])\n        \n # Visualizzazione delle loss\n        loss_D, loss_G = metric[\n 0\n] / metric[\n 2\n], metric[\n 1\n] / metric[\n 2\n]\n        animator.add(epoch + \n 1\n, (loss_D, loss_G))\n    \nprint\n(\nf\n'loss_D \n {loss_D\n:.3f\n}\n, loss_G \n {loss_G\n:.3f\n}\n, '\n          \n f\n'\n{metric[\n 2\n] / timer.stop()\n :.1f\n}\n examples/sec'\n )\n11",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#11": "GAN e Keras: Generatore e Discriminatore\nSpeci\n ﬁ\nchiamo gli iperparametri per fare \n ﬁ\ntting di una distribuzione gaussiana:  \nlr_D, lr_G, latent_dim, num_epochs = \n 0.05\n, \n0.005\n, \n2\n, \n20\ntrain(net_D, net_G, data_iter, num_epochs, lr_D, lr_G,\n      latent_dim, data[:\n 100\n].numpy())\n> \nloss_D \n0.693\n, loss_G \n 0.693\n, \n333.2\n examples/sec\n12\n",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#12": " Deep Convolutional Generative Adversarial \nNelle GAN abbiamo visto come i campioni generati provengano perloppiù da \ndistribuzioni uniformi o normali, che sono poi trasformati in istanze che \ncorrispondono alle distribuzioni di un certo dataset di dati reali.  \nPer generare campioni più complessi (es. immagini fotorealistiche) sono \nnecessarie architetture più complesse come le \n Deep Convolutional GANs \n(DCGAN)\n . \n13",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#13": "DCGAN - Keras (1)\nIl dataset è la collezione di Pokemon sprites, ottenuto da pokemondb.  \nimport\n tensorflow \n as\n tf\n!\npip install d2l==\n 1.0.0\na1.post0\nfrom\n d2l \nimport\n tensorflow \n as\n d2\nl\nd2l.DATA_HUB[\n 'pokemon'\n ] = (d2l.DATA_URL + \n 'pokemon.zip'\n ,\n                           \n 'c065c0e2593b8b161a2d7873e42418bf6a21106c'\n )\ndata_dir = d2l.download_extract(\n 'pokemon'\n )\nbatch_size = \n 256\npokemon = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir, batch_size=batch_size, image_size=(\n 64\n, \n64\n)\n)\nRidimensiono ogni immagini in 64x64. I valori sono in [0,1], mentre il generatore usa la \n tanh\n e \ngenera campioni con pixel in [-1,1]. Normalizziamo i dati con media e deviazione standard pari \na 0.5.  \ndef \ntransform_func\n (\nX\n):\n    X = X / \n 255\n.\n    X = (X - \n 0.5\n) / (\n0.5\n)\n    \nreturn\n X\ndata_iter = pokemon.\n map\n(\nlambda\n x, y: (transform_func(x), y),\n                        num_parallel_calls=tf.data.experimental.AUTOTUNE)\ndata_iter = data_iter.cache().shuffle(buffer_size=\n 1000\n).prefetch(\n    buffer_size=tf.data.experimental.AUTOTUNE)\n14",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#14": "DCGAN - Keras (2)\nd2l.set_figsize(figsize=(\n 4\n, \n4\n))\nfor\n X, y \nin\n data_iter.take(\n 1\n):\n    imgs = X[:\n 20\n, :, :, :] / \n 2\n + \n0.5\n    d2l.show_images(imgs, num_rows=\n 4\n, num_cols=\n 5\n)\nIl generatore deve mappare una \n noise variabile  \n e un vettore di dimensione \n d\n ad una  \nimmagine 64x64.  \nUsiamo la \n Conv2DTranspose\n  per incrementare  \nla risoluzione in input, seguita da una \n batch normalization  \ne attivazione ReLU.  \nclass \nG_block\n(\ntf\n.\nkeras\n.\nlayers\n.\nLayer\n):\n    \ndef \n__init__\n (\nself\n, \nout_channels\n , \nkernel_size\n =\n4\n, \nstrides\n=\n2\n, \npadding\n=\n\"same\"\n,\n                 **\n kwargs\n):\n        super().\n __init__\n (**kwargs)\n        \n self\n.conv2d_trans = tf.keras.layers.Conv2DTranspose(\n            out_channels, kernel_size, strides, padding, use_bias=\n False\n)\n        \n self\n.batch_norm = tf.keras.layers.BatchNormalization()\n        \n self\n.activation = tf.keras.layers.ReLU()\n    \ndef \ncall\n(\nself\n, \nX\n):\n        \n return \nself\n.activation(\n self\n.batch_norm(\n self\n.conv2d_trans(X)))\nz\n∈\nℝ\nd\n15\n",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#15": "DCGAN - Keras (3)\nDi default abbiamo\n  kernel 4x4, stride 2x2 e same padding.  \nCon un input 16x16, il generatore raddoppia larghezza e altezza dell'input.  \nx = tf.zeros((\n 2\n, \n16\n, \n16\n, \n3\n))  \n# creiamo un dato sintetico\ng_blk = G_block(\n 20\n)\ng_blk(x).shape\n> TensorShape([2, 32, 32, 20]\n )\nSe usiamo un kernel 4x4, stride 1x1 e zero padding, con un input 1x1, l'output avrà \nlarghezza e altezza incrementati di 3.  \nx = tf.zeros((2, 1, 1, 3)\n )\n# padding=\"valid\" corresponds to no padding\ng_blk = G_block(\n 20\n, strides=\n 1\n, padding=\n \"valid\"\n)\ng_blk(x).shape\n> TensorShape([2, 4, 4, 20])\n16\n",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#16": "DCGAN - Keras (4)\nIl \ngeneratore\n  consiste in 4 blocchi base che incrementano ampiezza e altezza \nda 1 a 32. Inizialmente mappa le variabili latenti in 64x8 canali, e poi \ndimezza i canali ogni volta. In\n ﬁ\nne, un\n  transposed convolution layer \n genera \nl'output raddoppiando la dimensione a 64x64 e riducendo i canali a 3 per \nrispettare l'output desiderato. La funzione di attivazione \n tanh\n è usata per \ngenerare output in (-1,1).  \nn_G = \n64\nnet_G = tf.keras.Sequential([\n    \n# Output: (4, 4, 64 * 8)\n    G_block(out_channels=n_G*\n 8\n, strides=\n 1\n, padding=\n \"valid\"\n),\n    G_block(out_channels=n_G*\n 4\n), \n# Output: (8, 8, 64 * 4)\n    G_block(out_channels=n_G*\n 2\n), \n# Output: (16, 16, 64 * 2)\n    G_block(out_channels=n_G), \n # Output: (32, 32, 64)\n    \n# Output: (64, 64, 3)\n    tf.keras.layers.Conv2DTranspose(\n        \n 3\n, kernel_size=\n 4\n, strides=\n 2\n, padding=\n \"same\"\n, use_bias=\n False\n,\n        activation=\n \"tanh\"\n)\n])\n17",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#17": "Richiami: Leaky ReLU\nLa leaky ReLU è  utile per affrontare il dying ReLU.  \nalphas = [\n 0\n, \n.2\n, \n.4\n, \n.6\n, \n.8\n, \n1\n]\nx = tf.\nrange\n(\n-2\n, \n1\n, \n0.1\n)\nY = [tf.keras.layers.LeakyReLU(alpha)(x).numpy() \n for\n alpha \nin\n alphas]\nd2l.plot(x.numpy(), Y, \n 'x'\n, \n'y'\n, alphas)\n18\n",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#18": "DCGAN - Keras (5)\nIl blocco base del discriminatore è un convolution layer seguito da \n batch \nnormalization\n  (tranne per l'input layer) e leaky ReLU activation. Gli \niperparametri sono simili a quelli impiegati al blocco generatore.  \nclass \nD_block\n(\ntf\n.\nkeras\n.\nlayers\n.\nLayer\n):\n    \ndef \n__init__\n (\nself\n, \nout_channels\n , \nkernel_size\n =\n4\n, \n                 \n strides\n=\n2\n, \npadding\n=\n\"same\"\n, \nalpha=\n0.2\n, **kwargs):\n        super().\n __init__\n (**kwargs)\n        \n self\n.conv2d = tf.keras.layers.Conv2D(out_channels, kernel_size,\n                                             strides, padding,  \n                                      use_bias=\n False\n)\n        \n self\n.batch_norm = tf.keras.layers.BatchNormalization()\n        \n self\n.activation = tf.keras.layers.LeakyReLU(alpha)\n    \ndef \ncall\n(\nself\n, \nX\n):\n        \n return \nself\n.activation(\n self\n.batch_norm(\n self\n.conv2d(X))\n )\nx = tf.zeros((\n 2\n, \n16\n, \n16\n, \n3\n))\nd_blk = D_block(\n 20\n)\nd_blk(x).shape\n> TensorShape([2, 8, 8, 20])\n19",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#19": "DCGAN - Keras (6)\nPer un input shape 16x16 e un kernel 4x4 e stride 2 e same padding:  \nn_D = \n64\nnet_D = tf.keras.Sequential([\n    D_block(n_D), \n # Output: (32, 32, 64)\n    D_block(out_channels=n_D*\n 2\n), \n# Output: (16, 16, 64 * 2)\n    D_block(out_channels=n_D*\n 4\n), \n# Output: (8, 8, 64 * 4)\n    D_block(out_channels=n_D*\n 8\n), \n# Outupt: (4, 4, 64 * 64)\n    \n# Output: (1, 1, 1)\n    tf.keras.layers.Conv2D(\n 1\n, kernel_size=\n 4\n, use_bias=\n False\n)\n]\n)\nx = tf.zeros((\n 1\n, \n64\n, \n64\n, \n3\n))\nnet_D(x).shape\n> TensorShape([1, 1, 1, 1]) # Predizione: Singolo valore\n20\n",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#2": "Apprendimento discriminativo e generativo\nFinora abbiamo trattato il \n discriminative learning\n , cioè un apprendimento \ncapace di distinguere le differenti istanze, cioè le relative caratteristiche, e \nclassi\n ﬁ\ncarle, o fare predizione. In molti task arriviamo a livelli di accuratezza \ncomparabili a quelli umani.  \nCi sono altri casi in cui vogliamo analizzare grossi dataset senza labels per \ncreare un modello che ne descrive le caratteristiche. Con tale modello \npossiamo creare esempi di dato \n sintetici\n  che assomigliano a quelli reali. Tale \napproccio si chiama \n generative learning\n . \n•\nEs. le reti ricorrenti sono un esempio di un modello discriminativo che può \nessere impiegato anche per generare nuove istanze.\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#20": "Richiami: Adam Optimization\nAdam (Adaptive Moment Estimation)  \nè una combinazione di Momentum \noptimization e RMSProp\n . \n \n \n \n \n \ndove \n T\n indica l'iterazione corrente  \nRispetto al Momentum, nella prima espressione si introduce il decay dei gradienti \ncon  \nLa 3\na\n e 4\na\n espressione sono utili per incrementare il valore di \n m\n ed \ns\n all'inizio del \ntraining, essendo i valori iniziali pari a 0.\nm\n←\nβ\n1\nm\n+\n(\n1\n−\nβ\n1\n)\n∇\nΘ\nJ\n(\nΘ\n)\ns\n←\nβ\n2\ns\n+\n(\n1\n−\nβ\n2\n)\n∇\nΘ\nJ\n(\nΘ\n)\n⊗\n∇\nΘ\nJ\n(\nΘ\n)\nm\n←\nm\n1\n−\nβ\nT\n1\ns\n←\ns\n1\n−\nβ\nT\n2\nΘ\n←\nΘ\n−\nη\n⋅\nm\n⊘\ns\n+\nϵ\nβ\n1\n21Momentum :  \n \nRMSProp :  \n \n \n \n \n \nRMSProp : m←β⋅m+η∇ΘJ(Θ)\ns←βs+(1−β)∇ΘJ(Θ)⊗∇ΘJ(Θ)\nΘ←Θ−η∇ΘJ(Θ)⊘s+ϵ",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#21": "DCGAN - Keras (7)\nRispetto alle GAN usiamo lo stesso \n learning rate\n  per il generatore e \ndiscriminatore essendo architetture simili. Portiamo \n  in Adam da 0.9 (spesso \nusato come default) a 0.5.  \nDecrementiamo lo \n smooth\n  del momentum, la weighted moving average \nesponenziale dei passati gradienti, per tenere traccia più puntuale delle \nvariazioni rapide dei gradienti a causa dell'instabilità creata dal discriminatore-\ngeneratore.  \ndef \ntrain\n(\nnet_D\n, \nnet_G\n, \ndata_iter\n , \nnum_epochs\n , \nlr\n, \nlatent_dim\n ,\n          \n device\n=d2l.try_gpu()):\n    loss = tf.keras.losses.BinaryCrossentropy(\n        from_logits=\n True\n, reduction=tf.keras.losses.Reduction.SUM)\n    \nfor\n w \nin\n net_D.trainable_variables:\n        w.assign(tf.random.normal(mean=\n 0\n, stddev=\n 0.02\n, shape=w.shape))\n    \nfor\n w \nin\n net_G.trainable_variables:\n        w.assign(tf.random.normal(mean=\n 0\n, stddev=\n 0.02\n, shape=w.shape))\n    optimizer_hp = {\n \"lr\"\n: lr, \n\"beta_1\"\n : \n0.5\n, \n\"beta_2\"\n : \n0.999\n}\n    optimizer_D = tf.keras.optimizers.Adam(**optimizer_hp)\n    optimizer_G = tf.keras.optimizers.Adam(**optimizer_hp)\nβ\n1\n22",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#22": "DCGAN - Keras (8)\n    animator = d2l.Animator(xlabel=\n 'epoch'\n, ylabel=\n 'loss'\n,\n                          xlim=[\n 1\n, num_epochs], nrows=\n 2\n, figsize=(\n 5\n, \n5\n),\n                          legend=[\n 'discriminator'\n , \n'generator'\n ]\n)\n    animator.fig.subplots_adjust(hspace=\n 0.3\n)\n    \nfor\n epoch \nin \nrange\n(\n1\n, num_epochs + \n 1\n):\n \n       timer = d2l.Timer()\n        metric = d2l.Accumulator(\n 3\n) \n# loss_D, loss_G, num_examples\n        \n for\n X, _ \nin\n data_iter:\n            batch_size = X.shape[\n 0\n]\n            Z = tf.random.normal(mean=\n 0\n, stddev=\n 1\n,\n                                 shape=(batch_size, \n 1\n, \n1\n, latent_dim))\n            metric.add(d2l.update_D(X, Z, net_D, net_G, loss,  \n                                                           optimizer_D),\n                       d2l.update_G(Z, net_D, net_G, loss, optimizer_G),\n                       batch_size)\n23",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#23": "DCGAN - Keras (9)\n        \n # Visualizziamo i dati generti\n        Z = tf.random.normal(mean=\n 0\n, stddev=\n 1\n, \n                                        shape=(\n 21\n, \n1\n, \n1\n, latent_dim))\n        \n # Normalizziamo i dati generati in (0,1)\n        fake_x = net_G(Z) / \n 2\n + \n0.5\n        imgs = tf.concat([tf.concat([fake_x[i*\n 7\n+j] \nfor\n j \nin \nrange\n(\n7\n)],\n                                    axis=\n 1\n)\n                          \n for\n i \nin \nrange\n(\nlen\n(fake_x) // \n 7\n)], axis=\n 0\n)\n        animator.axes[\n 1\n].cla()\n        animator.axes[\n 1\n].imshow(imgs)\n        \n # Visualizziamo le loss\n        loss_D, loss_G = metric[\n 0\n] / metric[\n 2\n], metric[\n 1\n] / metric[\n 2\n]\n        animator.add(epoch, (loss_D, loss_G)\n )\n    \nprint\n(\nf\n'loss_D \n {loss_D\n:.3f\n}\n, loss_G \n {loss_G\n:.3f\n}\n, '\n          \n f\n'\n{metric[\n 2\n] / timer.stop()\n :.1f\n}\n examples/sec on  \n                                      \n {\nstr\n(device._device_name)}\n '\n)\n24",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#24": "DCGAN - Keras (10)\nlatent_dim, lr, num_epochs = \n 100\n, \n0.0005\n, \n40\ntrain(net_D, net_G, data_iter, num_epochs, lr, latent_dim)\n> loss_D 0.217, loss_G 3.687, 2310.5 examples/sec on /GPU:\n 0\n25\n",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#3": "Generative adversarial networks\nNel 2014 sono state introdotte le \n Generative adversarial networks (GAN)\n , un \nmodello che sfrutta un approccio \n discriminativo\n  per generare modelli \ngenerativi:  \n•\nL'idea è che un modello generativo è buono se non riusciamo a distinguere i \ndati generati da quelli reali.  \nDal punto di vista statistico corrisponde ad un \n 2-sample test\n : misurare se due \nsequenze di istanze \n X\n= {\nx\n1\n, ..., \nx\nn\n} e \nX'\n= {\nx'\n1\n, ..., \nx'\nn\n} sono ottenute dalla stessa \ndistribuzione.  \nNelle GAN tale test è usato dal modello generativo per adattarsi a creare \nistanze sempre più simili ai casi reali.  \n•\nIn pratica, cerchiamo di \"bidonare\" il classi\n ﬁ\ncatore reale/fake. \n4",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#4": "Generative adversarial networks (GANs)\nL'architettura include un \n generative network\n , nel nostro caso una deep \nnetwork, che ha lo scopo di generare istanze simili a quelle reali (es. segnale \ndi voce umana, immagini di visi). Il \n discriminative network\n  cerca di \ndistinguere dati reali da quelli generate (o fake).  \nIl \ndiscriminator\n  è implementato come un classi\n ﬁ\ncatore binario che produce \nuno scalare per ogni input \n x \n(es. una FC con 1 layer e funzione di attivazione \nsigmoid\n  per convertire lo scalare in probabilità). Assumiamo che la label \ncorrispondente sia 1 per una istanza da dati reali, 0 per una fake creata dal \ngeneratore.  \nIl generatore mira a generare una immagine più  \nvicina possibile alle immagini reali, e per ottenere  \ndal discriminatore il relativo output corrispondente  \na \"il dato e' real\".\n5\n",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#5": "Generative adversarial networks (GANs)\nIl \ndiscriminatore\n  mira a distinguere immagini generate da immagini reali minimizzando \nla \ncross-entropy loss:  \n \ndove \n D\n(x) = 1/(1 + \n e\n-o\n) è la probabilità ottenuta con la \n sigmoid\n  a partire dallo scalare \n o.  \nCollezionando in modo casuale \n  (es. con distribuzione normale), dove \n  riveste il \ncompito di \n variabile latente,\n  il compito del \n generatore\n  è di bidonare il discriminatore per \nclassi\n ﬁ\ncare \n x'=G(z)\n  come \"dato reale\", cioè vogliano D(G(z)) ≈ 1.  \nIn altre parole, dato un discriminatore D, aggiorniamo i parametri del generatore per \nmassimizzare la \n cross-entropy loss \n quando y=0, cioè \n dato fake\n : \n \nSe il generatore si comporta in modo ottimale, D(x') è circa 1, cosicché la loss è vicina \nallo 0, e perciò i gradienti sono assai ridotti per generare progressi per il discriminatore. \nMinimizzeremo perciò la seguente loss:  \n \nche è il feed x'=G(z) nel discriminatore dando il label 1.  \nmin\n D\n{\n−\ny\n log \nD\n(\nx\n)\n−\n(\n1\n−\ny\n)\n log\n(\n1\n−\nD\n(\nx\n)\n)\n}\nz\n∈\nℝ\nD\nz\nmax\n G\n{\n−\n(\n1\n−\ny\n)\n log \n(\n1\n−\nD\n(\nG\n(\nz\n)\n)\n)\n}\n=\nmax\n G\n{\n−\n log \n(\n1\n−\nD\n(\nG\n(\nz\n)\n)\n)\n}\nmin\n G\n{\n−\ny\n log \n(\nD\n(\nG\n(\nz\n)\n)\n)\n}\n=\nmin\n G\n{\n−\n log \n(\nD\n(\nG\n(\nz\n)\n)\n)\n}\n6",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#6": "GAN e Keras (1)\nGeneriamo dati con un modello gaussiano:  \nX = tf.random.normal((1000, 2), 0.0, 1\n )\nA = tf.constant([[1, 2], [-0.1, 0.5]]\n )\nb = tf.constant([1, 2], tf.float32\n )\ndata = tf.matmul(X, A) + \n b\nOtteniamo una gaussiana traslata in modo arbitrario con media \n b\n e covarianza \nA\nT\nA\n. \nd2l.set_figsize(\n )\nd2l.plt.scatter(data[:100, 0].numpy(), data[:100, 1].numpy())\n ;\nprint(f'The covariance matrix is\\n{tf.matmul(A, A, transpose_a=True)}'\n )\n> The covariance matrix i\n s\n> [[1.01 1.95\n ]\n> [1.95 4.25]\n ]\nbatch_size = \n 8\ndata_iter = d2l.load_array((data,), batch_size)\n7\n",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#7": "GAN e Keras: Generatore e Discriminatore\nIl generatore è un semplice layer lineare.  \nnet_G = tf.keras.layers.Dense(2\n )\nPer il discriminatore usiamo una MLP a 3 layer:  \nnet_D = tf.keras.models.Sequential(\n [\n    tf.keras.layers.Dense(5, activation=\"tanh\", input_shape=(2,))\n ,\n    tf.keras.layers.Dense(3, activation=\"tanh\")\n ,\n    tf.keras.layers.Dense(1\n )\n]\n)\nDe\nﬁ\nniamo una funzione per aggiornare il \n discriminatore\n : \ndef \nupdate_D\n (\nX\n, \nZ\n, \nnet_D\n, \nnet_G\n, \nloss\n, \noptimizer_D\n ):\n    batch_size = X.shape[\n 0\n]\n    ones = tf.ones((batch_size,)) \n # Labels corrispondenti ai dati reali\n    zeros = tf.zeros((batch_size,)) \n # Labels corrispondenti ai dati fake\n    \n# Ignoriamo i gradienti per `net_G` all'interno di GradientTape\n    fake_X = net_G(Z)\n    \nwith\n tf.GradientTape() \n as\n tape:\n        real_Y = net_D(X)\n        fake_Y = net_D(fake_X)\n        loss_D = (loss(ones, tf.squeeze(real_Y)) + loss(\n            zeros, tf.squeeze(fake_Y))) * batch_size / \n 2\n    grads_D = tape.gradient(loss_D, net_D.trainable_variables)\n    optimizer_D.apply_gradients(\n zip\n(grads_D, net_D.trainable_variables))\n    \nreturn\n loss_D\n8",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#8": "GAN e Keras: Generatore e Discriminatore\nIl generatore sarà aggiornato in modo simile. Riutilizziamo la cross-entropy \nloss ma cambiamo la label dei dati fake da 0 a 1  \ndef \nupdate_G\n (\nZ\n, \nnet_D\n, \nnet_G\n, \nloss\n, \noptimizer_G\n ):\n    batch_size = Z.shape[\n 0\n]\n    ones = tf.ones((batch_size,))\n    \nwith\n tf.GradientTape() \n as\n tape:\n        fake_X = net_G(Z)\n \n       fake_Y = net_D(fake_X)\n       loss_G = loss(ones, tf.squeeze(fake_Y)) * batch_size\n    grads_G = tape.gradient(loss_G, net_G.trainable_variables)\n    optimizer_G.apply_gradients(\n zip\n(grads_G, net_G.trainable_variables))\n    \nreturn\n loss_G\nSia il discriminatore sia il generatore operano una\n  logistic regression binaria \ncon cross-entropy loss. Usiamo \n Adam\n  per rendere smooth il processo di \ntraining. Ad ogni iterazione, prima aggiorniamo il discriminatore e poi il \ngeneratore. \n9",
    "data_test\\rootfolder\\università\\DeepLearning\\16-GAN-sbloccato.pdf#9": "GAN e Keras: Generatore e Discriminatore\ndef \ntrain\n(\nnet_D\n, \nnet_G\n, \ndata_iter\n , \nnum_epochs\n , \nlr_D\n, \nlr_G\n, \nlatent_dim\n , \ndata\n):\n    loss = tf.keras.losses.BinaryCrossentropy(\n        from_logits=\n True\n, reduction=tf.keras.losses.Reduction.SUM)\n    \nfor\n w \nin\n net_D.trainable_variables:\n        w.assign(tf.random.normal(mean=\n 0\n, stddev=\n 0.02\n, shape=w.shape))\n    \nfor\n w \nin\n net_G.trainable_variables:\n        w.assign(tf.random.normal(mean=\n 0\n, stddev=\n 0.02\n, shape=w.shape))\n    optimizer_D = tf.keras.optimizers.Adam(learning_rate=lr_D)\n    optimizer_G = tf.keras.optimizers.Adam(learning_rate=lr_G)\n    animator = d2l.Animator(\n        xlabel=\n \"epoch\"\n, ylabel=\n \"loss\"\n, xlim=[\n 1\n, num_epochs], nrows=\n 2\n,\n        figsize=(\n 5\n, \n5\n), legend=[\n \"discriminator\"\n , \n\"generator\"\n ])\n    animator.fig.subplots_adjust(hspace=\n 0.3\n)\n   ...\n10",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nRecommender Systems\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#1": "Sommario\nMovieLens dataset  \nAutoRec  \nImplicit feedback (richiami)ù  \nNeural Collaborative Filtering (NCF)  \nCaser e Sequence-aware Recsys  \nFactorization Machines e Deep FM",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#10": "Neural Collaborative Filtering for Personalized Ranking\nL'output del penultimo layer di entrambe le reti è concatenato è dato in input \nal NeuMF layer:\n11\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#11": "Sequence-aware recommender systems\nSpesso gli utenti operano una sequenza di azioni nei servizi online il cui \nordine temporale può essere signi\n ﬁ\ncativo nel processo di raccomandazione.  \nIl modello \n Caser \n (Convolutional sequence embedding recommendation \nmodel) sfrutta le CNN, in particolare \n horizontal\n  e \nvertical\n  convolutional \nnetworks, per identi\n ﬁ\ncare rispettivamente pattern sequenziali \n union-level\n  e \npoint-level\n  di tipo short-term.  \nI pattern \n point-level\n  identi\n ﬁ\ncano l'in\n ﬂ\nuenza di un item all'interno di una \nsequenza verso un certo item target. L'union-level analizza l'in\n ﬂ\nuenza di varie \nazioni fatte sul valore target (es. l'acquisto di latte e burro può implicare \nl'acquisto di farina).  \nI bisogni di lungo termine sono rappresentati nei layer FC \n ﬁ\nnali.\n12",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#12": "Sequence-aware recommender systems\nSupponiamo che ogni utente u sia associato ad una sequenza di items \n. Se prendiamo i passati \n L\n items, possiamo costruire una \nmatrice che rappresenta le interazioni passati con tali items rispetto al time \nstep \nt\n. \nDove \n  rappresenta sempre lo spazio di embedding e \n q\ni\n indica la \n i\n-\nma riga. \n  è usata per ottenere i bisogni transienti dell'utente \n u\n per \nil time step \n t\n, ed è l'input per i successivi convolutional layers:  \n•\nL'horizontal layer ha \n d \nﬁ\nltri orizzontali \n . \n•\nIl vertical layer ha d' \n ﬁ\nltri verticali  \nDopo una serie di operatori convoluzionali e di pooling otteniamo gli output \n e \n :\nS\nu\n=\n(\nS\nu\n1\n,\n⋯\n,\nS\nu\n|\nS\nu\n|\n)\nQ\n∈\nℝ\nn\n×\nk\nE\n(\nu\n,\nt\n)\n∈\nℝ\nL\n×\nk\nF\nj\n∈\nℝ\nh\n×\nk\n,\ni\n≤\nj\n≤\nd\n,\nh\n=\n{\n1,\n⋯\n,\nL\n}\nG\nj\n∈\nℝ\nL\n×\n1\n,\ni\n≤\nj\n≤\nd\n′ \no\n∈\nℝ\nd\no\n′ \n∈\nℝ\nd\n′ \n13\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#13": "Sequence-aware recommender systems\nGli output sono concatenati e dati in input ad una MLP per ricavarne \nrappresentazioni ad alto livello:  \nL'output \n  indica i bisogni a breve termine dell'utente.  \nI bisogni a lungo termine dell'utente sono ricavati:  \ndove \n  è una ulteriore embedding matrix, e  \n  è la \n user \nembedding matrix\n  per i bisogni a lungo termine. \n  e \n  sono la \nu\n-ma riga e \n i\n-ma riga rispettivamente di \n P\n e \nV\n.\nz\n∈\nℝ\nk\nV\n∈\nℝ\nn\n×\n2\nk\nP\n∈\nℝ\nm\n×\nk\np\nu\n∈\nℝ\nk\nv\ni\n∈\nℝ\n2\nk\n14\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#14": "Sequence-aware recommender systems\nL'architettura generale di Caser è così rappresentata:\n15\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#15": "Addestramento e architetture sequenziali\nIn modo simile all'addestramento RNN, in presenza di dati con timestamp che \nrappresentano azioni tra utenti e items (es. l'utente ha lasciato un rating su un \nﬁ\nlm), possiamo costruire un dataset di addestramento creando sequenze di \ndimensione prede\n ﬁ\nnita, ad esempio:\n16\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#16": "Factorization Machines\nLe FM sono algoritmi supervisionati che possono essere impiegati in contesti \ndi classi\n ﬁ\ncazione, regressione e ranking. Si ispirano a modelli di regressione \nlineare, modelli di MF e Support vector machines con kernel polinomiali.  \nMostrano vantaggi in caso di dataset sparsi riducendo notevolmente il tempo \ndi addestramento. Inoltre individuano più facilmente correlazioni signi\n ﬁ\ncative \ntra i dati.  \nSe indichiamo con \n  il vettore delle feature per una certa istanza, e con \ny la label numerica associata (es. 4.5 oppure click/no-click), formalizziamo il \nmodello in questo modo:  \ndove \n  è il bias globale, \n  sono i pesi per la i-ma variabile, \n sono i feature embeddings, e \n v\ni\n è la i-ma riga di \n V\n, <v\n i\n,v\nj\n> è il \nprodotto vettoriale tra i 2 vettori è modella l'interazione tra la \n i\n-ma e \n j\n-ma \nfeature.\nx\n∈\nℝ\nd\nw\n0\n∈\nℝ\n w\n∈\nℝ\nd\nV\n∈\nℝ\nd\n×\nk\n17\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#17": "Factorization Machines\nNell'espressione precedente si può notare una prima componente che \nrappresenta il modello di regressione lineare, mentre il secondo estende un \nmodello di MF:  \nSe la feature \n i\n rappresenta un item, e la feature \n j\n un utente, il terzo termine è il \nprodotto scalare tra i due embedding, uno dell'utente ed uno dell'item. \n18\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#18": "Deep Factorization Machines\nIn alcuni scenari l'approccio lineare delle FM non è suf\n ﬁ\nciente per \nrappresentare correlazioni e patterns complessi. Ma è possibile integrare \napprocci \"deep\" nel FM per rappresentare interazioni tra features nei dati.  \nNel \nDeepFM\n  la componente FM e deep sono combinate in modo \n parallelo\n . La \nFM è simile all'architettura originale. La deep è implementata con una MLP. \nL'input/embeddings delle 2 componenti è il medesimo, l'output è \n sommato  \nper creare la predizione \n ﬁ\nnale.  \nLa DeepFM si ispira allearchitetture RecSys chiamate \n wide & deep\n . In tali \narchitetture la predizione combina due pipeline:  \n•\nla \nmemorizzazione\n  mira a rappresentare co-occorrenze frequenti tra items o \nfeatures nei dati storici. Si implementa con un modello lineare (es. logistic \nregression)  \n•\nla \ngeneralizzazione\n  punta a implementare la \"transitività\" delle correlazioni, \ncioè esplorare combinazioni signi\n ﬁ\ncative tra features che non sono state mai \nincontrate nel passato. La pipeline è generalmente basata su una MLP.\n19",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#19": "Deep Factorization Machines\nSupponiamo che l'output della FM sia \n . Indichiamo con \n  il vettore \ndelle feature latenti del campo \n i\n-mo.  \nL'input della componente deep è la concatenazione degli embeddings di tutti \ni campi associati alle \n f\n feature categoriche date in input:  \nLa rete neurale è cosi de\n ﬁ\nnita: \nL'output \n  è combinato con il precedente per generare l'output \n ﬁ\nnale:  \n \n̂\ny\n(\nF\nM\n)\ne\ni\n∈\nℝ\nk\n̂\ny\n(\nD\nN\nN\n)\n̂\ny\n=\nσ\n(\nh\na\nt\ny\n(\nD\nN\nN\n)\n+\n̂\ny\n(\nD\nN\nN\n)\n)\n20\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#2": "Motivazioni\nI \nsistemi di raccomandazione\n  sono strumenti chiave in molti scenari: e-\ncommerce, siti per la fruizione di musica e video (es. Spotify, Net\n ﬂ\nix), app \nstores, pubblicità, etc.  \n•\nAlcune conferenze internazionali speci\n ﬁ\nche nel settore (es. RecSys) \nattraggono i maggiori players che fanno a gara per aggiudicarsi i migliori \nricercatori.  \nSupponiamo nel resto dei lucidi che alcuni argomenti sia già noti dai \nprecedenti corsi:  \n•\nCollaborative \n ﬁ\nltering  \n•\nExplicit e Implicit feedback  \n•\nRecommendation tasks (es. rating vs top-n vs sequence aware \nrecommendation\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#20": "Deep Factorization Machines\nL'architettura DeepFM è la seguente:\n21\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#3": "MovieLens dataset\nIl dataset più popolare nel mondo accademico \n RecSys\n . Ne esistono diverse \nversioni in base alla quantità di dati contenuti.  \n•\nIn \nMovieLens 100K\n  sono contenuti 100.000 ratings espressi in una scala da 1 \na 5, da 943 utenti su 1682 \n ﬁ\nlm. Ogni utente ha espresso rating su almeno 20 \nﬁ\nlm. Il formato del dataset è \n csv\n. \n•\nhttp://\n ﬁ\nles.grouplens.org/datasets/movielens/ml-100k.zip  \nTecniche quali \n Matrix Factorization\n  sono state in in grado di individuare \npatterns chiave per ottenere migliori risultati rispetto ad approcci più \ntradizionali. Ma si limitano a catturare patterns e correlazioni di tipo lineare. \n4",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#4": "MovieLens dataset\nMovieLens\n  100K\n  vs \n1M\n5\n",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#5": "AutoRec\nIn \nAutoRec\n  si impiega un paradigma di Collaborative Filtering basato su \nautoencoders. Invece di rappresentare la matrice user-ratings in un spazio \nlatente, o di impiegare le stesse istanze di input anche per l'output come nel \ncaso degli autoencoders visti in precedenza, si segue un approccio alternativo:  \n•\nin \ninput\n  si hanno un le interazioni utente-item osservate  \n•\nin \noutput\n  ci si aspetta l'intera matrice delle interazioni utente-item  \nEsistono architetture AutoRec \n user-based \n e \nitem-based\n . Qui vedremo le \nseconde ma è facile immaginare le prime per analogia.\n6",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#6": "(Item-based) AutoRec\nIndichiamo con \n  la i-ma colonna della matrice dei ratings. I valori di rating \nsconosciuti saranno 0.  \nLa rete AutoRec la possiamo de\n ﬁ\nnire formalmente:  \n \ndove f e g sono funzioni di attivazione, W e V matrici di pesi, \n  e \nb\n sono \nbiases, \n  la ricostruzione della i-ma colonna.  \nLa funzione da ottimizzare è la seguente:  \n \ndove il primo modulo considera solo i \n ratings\n  noti.\nR\n*\ni\nh\n(\nR\n*\ni\n)\n=\nf\n(\nW\n⋅\ng\n(\nV\n⋅\nR\n*\ni\n+\nμ\n)\n+\nb\n)\nμ\nh\n(\nR\n*\ni\n)\nargmin\nW\n,\nV\n,\nμ\n,\nb\nM\n∑\ni\n=\n1\n|\n|\nR\n*\ni\n−\nh\n(\nR\n*\ni\n)\n|\n|\n2\n+\nλ\n(\n|\n|\nW\n|\n|\n2\nF\n+\n|\n|\nV\n|\n|\n2\nF\n)\n)\n7",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#7": "Richiami: Implicit Feedback\nI \nrating espliciti\n  (es. valutazioni da 1 a 5) sono generalmente scarsi nei servizi \ndi raccomandazione. Inoltre valori mancanti di rating possono essere \nerroneamente interpretati, es.: forme di feedback negativi invece di rating che \ndevono essere ancora speci\n ﬁ\ncati. \nSi tendono a sfruttare altre fonti che possono essere interpretate come forme di \nimplicit feedback\n . \n•\nEs. clicks, acquisti, visite, wish lists.\n8",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#8": "Neural Collaborative Filtering for Personalized Ranking\nIl \nNeural Collaborative Filtering (NCF)  \nframework con implicit feedback \nsfrutta la capacità di \n non-linearità \n delle reti neurali.  \nÈ composto da 2 reti, una basata su Generalized Matrix Factorization, l'altra \nconsiste in una MLP.  \nL'output delle 2 reti è concatenato per generale la predizione \n ﬁ\nnale. Se in \nAutoRec puntavamo a predire i rating, NCF produce una lista di \nraccomandazioni con score associato ad ogni item della lista.\n9",
    "data_test\\rootfolder\\università\\DeepLearning\\17-RecSys-sbloccato.pdf#9": "Neural Collaborative Filtering for Personalized Ranking\nLa \nGMF\n  è un approccio di MF implementato con reti neurali. L'input è il \nprodotto element-wise (Hadamard product) tra le rappresentazioni latenti degli \nutenti e degli item:  \nDove \n p\nu\n e \nq\ni\n sono rispettivamente la u-ma riga di \n P\n e q-ma riga di \n Q\n, dove \n e \n . L'output è la previsione di score dell'utente \n u\n per \nl'item \n i\n. \nLa \nMLP\n prende in input le rappresentazioni degli utenti e item, ignorando lo \nspazio latente della GMF. Lo scopo è individuare correlazioni aggiuntive con \noperazioni non lineari.\nP\n∈\nℝ\nm\n×\nk\nQ\n∈\nℝ\nn\n×\nk\n10\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#0": "Deep Learning  \nUniversità Roma Tre  \nDipartimento di Ingegneria  \nAnno Accademico 2022 - 2023  \nDeep Learning e Natural Language Processing\n1",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#1": "Sommario\nDL e NLP: motivazioni  \nword2vec  \nskip-gram  \nCBOW  \nGloVe  \nfastText  \nBERT",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#10": "word2vec: skip-gram (training)\nCi poniamo l'obiettivo di massimizzare la probabilità, cioè minimizzare la \nfunzione:  \nSe impieghiamo lo SGD, usiamo sequenze brevi per stimare il gradiente \nstocastico e aggiornare il modello. La stima è basta sul gradiente del logaritmo \ndella probabilità condizionata data una coppia \n w\no\n e \nw\nc\n. \nUna volta terminato l'apprendimento, i vettori \n v\ni\n sono tipicamente impiegati \ncome \n embedding\n  associati ad un termine.\n11\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#11": "word2vec: Continuous Bag of Words (CBOW)\nSimile allo skip-gram ma assume che le parole contestuali generico la parola \ncentrale.  \nEssendoci più parole contestuali, i vettori sono mediati. La probabilità \ncondizionata di generare un termine \n  dati i termini contestuali \n  è \nla seguente:  \nSe consideriamo una sequenza di lunghezza T abbiamo:\nw\nc\n w\no\n1\n,\n⋯\n,\nw\no\n2\nm\n12\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#12": "word2vec: recap\nDiagramma riassuntivo dei 2 modelli:\n13\nCBOW model Skip-gram model\nt-word embedding t-word embeddingmatrix  \nVxdmatrix\ndxV",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#13": "Word Embedding with Global Vectors (GloVe)\nLe co-occorrenze tra termini rappresentano informazioni importanti per \ncostruire gli embeddings. Indichiamo con \n q\nij\n la probabilità condizionata \n P(w\n j\n|\nw\ni\n)\n nel modello \n skip-gram\n : \nLa parola \n w\ni\n può presentarsi molte volte in un corpus. Tutte le parole \ncontestuali che co-occorrono con \n w\ni\n creano un multiset, dove \n x\nij\n indica il \nnumero di volte che la parola \n w\nj \nco-occorre con \n w\ni\n. La loss function è:  \nIndichiamo con \n x\ni\n il numero di parole contestuali dove compare wi come \nparola centrale, e avendo \n p\nij\n=x\nij\n/x\ni\n, otteniamo:\n14\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#14": "Word Embedding with Global Vectors (GloVe)\nLa sommatoria interna è la cross-entropy tra la probabilità condizionata \n q\nij \nrelativa alla predizione generata dal modello, e \n p\nij\n ottenuta analizzando le \nstatistica dell'intero corpus.  \nPer ridurre la complessità computazionale (soprattutto per generare \n q\nij\n) e per \nmitigare gli effetti generate dai termini che compaiono di rado nel corpus ma \nche possono assumere importanza elevata dalla cross entropy, il modello \nGloVe introduce alcune varianti.  \nLa nuova \n loss function\n  è la seguente:  \ndove si introducono ad ogni parola sono associati 2 bias, \n b\ni\n per le parole \ncentrali e \n c\ni\n per le parole impiegate nel contesto; il primo e ultimo termine nel \ntermine a quadrato sono il termine di loss, e \n h(x\nij\n)\n genera un peso associato al \ntermine di loss.\n15\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#15": "fastText model\nCi sono relazioni morfologiche comuni tra molti vocaboli, es., tra \n help\n e \nhelps, \nhelped, helping\n ; tra \ndog\n e \ndogs\n e tra \n cat\n e \ncats\n; tra \nboy\n e \nboyfriend\n  e tra \n girl\n e \ngirlfriend\n . Modelli come skip-gram ignorano queste relazioni, poiché ognuno \ndi questi termini è rappresentato da un vettore distinto.  \nIl modello \n fastText\n  usa \nsubword embeddings\n , dove ogni \n subword\n  è un \n n-gram \ndi caratteri. Ad ogni subword è associato un vettore.  \n•\nPer esempio, la parola \"where\" genera le subwords “<wh”, “whe”, “her”, \n“ere”, “re>” impiegando una \n ﬁ\nnestra di lunghezza 3.  \nLa rappresentazione di un termine \n v\nw\n sarà la somma delle sue subwords \n z\ng\n: \nIl resto del modello è basato su skip-gram.\n16\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#16": "Modelli context-indipendent e context-sensitive\nNei modelli precedenti, data una parola, il vettore generato non dipende dal \ncontesto attuale (approccio \n context-independent\n ). Termini polisemici o \nrelazioni semantiche del linguaggio naturale saranno perciò ignorate.  \nModelli come \n ELMo\n  combinano le rappresentazioni intermedie ottenute da \nLSTM bidirezionali per ottenere una rappresentazione che dipende dalla \nsequenza in input (approccio \n context-sensitive\n ).  \n•\nLa rappresentazione così ottenuta è solitamente combinata con quella \nottenuta in modo context-independent (es. tramite GloVe) nei task successivi. \nIl modello impiegato da ELMo deve essere speci\n ﬁ\nco per il task che si andrà \nad affrontare, e perciò rimarrà costante.  \nPer evitare di avere diversi modelli per ogni task, GPT pre-addestra un \nlanguage model che sarà usato per rappresentare sequenze testuali. I \nparametri saranno poi \n ﬁ\nne-tuned\n  in base all'ouput del task successivo. GPT è \nbasato su Transformers. Il contesto analizzato da GPT sarà limitato alla parte \nantecedente al termine attuale, perciò non si analizza il contesto a destra del \ntermine. \n17",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#17": "Bidirectional Encoder Representations from Transformers (BERT)\nBERT combina i due approcci appena descritti, rappresentando l'intero \ncontesto mediante un approccio bidirezionale.  \nÈ basato su Transformer encoders pre-addestrati. Un output layer speci\n ﬁ\nco per \nil task da affrontare sarà di volta in volta addestrato da zero. \n18\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#18": "Bidirectional Encoder Representations from Transformers (BERT)\nL'input di BERT può essere una singolo testo o coppie di testi.  \nOltre agli \n positional\n  embedding, si impiegano anche \n segment\n  e \ntoken  \nembeddings. Infatti, a differenza delle RNN, i Transformer richiedono tecniche \nspeci\n ﬁ\nche per rappresentare internamente l'ordine relativo in cui i termini \ncompaiono tra loro. Tali embedding sono ricavati durante la fase di training.\n19\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#19": "Bidirectional Encoder Representations from Transformers (BERT)\nCome pretraining (auxiliary) task si impiega il \n Masked Language modeling\n . \nDato un corpus testuale, il 15% dei tokens saranno selezionati in modo \nrandom per il task di predizione. Al loro posto sarà presente un tag <mask>, \nes: \n•\n“this movie is great” becomes “this movie is <mask>”  \nUn ulteriore auxiliary task speci\n ﬁ\nco nello scenario in cui si hanno 2 testi in \ninput è il \n Next sentence prediction\n . Dal corpus si estraggono coppie di frasi \nconsecutive, e altrettante coppie di frasi che non sono consecutive. Il task è di \nclassi\n ﬁ\ncazione binaria.\n20",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#2": "DL e NLP \nDurante l'apprendimento di tecniche ML abbiamo spesso bisogno di grosse \nmoli di dati \n labelled\n  per implementare approcci supervisionati.  \nAlcune architetture DL hanno la capacità di riconoscere pattern e \ncaratteristiche anche complesse in tali dati, ma dataset adeguati per \nl'addestramento non sono disponibili.  \nPer tale motivo sono stati proposti vari approcci come il \n self-supervised \nlearning\n , per analizzare dati un modo non supervisionato (\n auxiliary task, es. \npredire una parte mancante del testo) e costruire rappresentazioni utili per \nsupportare l'apprendimento (tipicamente supervisionato) in task più speci\n ﬁ\nci.  \nAvendo un dataset di testo, l'input può essere costruito impiegando singole \nparole o n-grams formati da lettere, utili per catturare informazioni \nmorfologiche delle parole. L'output è tipicamente una rappresentazione \nvettoriale associata ad ogni parola (\n embedding\n ), indipendente dal contesto in \ncui sarà presente in seguito.\n3",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#20": "Bidirectional Encoder Representations from Transformers (BERT)\nBERT raggiunge prestazioni elevate su numero categorie di tasks, es.:  \n•\nsingle text classi\n ﬁ\ncation \n (e.g., sentiment analysis),  \n•\ntext pair classi\n ﬁ\ncation\n  (e.g., date due domande di Quora determinare se sono \nsimili o no),  \n•\nquestion answering\n ,  \n•\ntext tagging\n  (e.g., named entity recognition)\n21",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#3": "Esempio di auxiliary task\n4\ninputsliding-window\noutput (training set)\n  ",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#4": "Esempio di embeddings\nEmbeddings relativi a termini che identi\n ﬁ\ncano 115 nazioni estratti da un \ncorpus testuale, rappresentati su un piano 2d.\n5   \n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#5": "Esempio di operazioni su embeddings\nEssendo vettori, possiamo fare operazioni sugli embeddings, es:  \n•\nvector(“paris”)−vector(“france”)+vector(\"germany\")  \nImpiegando il modello di embeddings \n GloVe\n  addestrato sul testa estatto da \nWikipedia otteniamo:  \n•\nberlin: 0.8015347  \n•\nparis: 0.7623165     \n•\nmunich: 0.7013252     \n•\nleipzig: 0.6616945    \n•\ngermany: 0.6540700 \n6   ",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#6": "DL e NLP \nLe rappresentazioni pretrained ottenute con approcci non supervisionati sono \nsuccessivamente impiegate su architetture di DL in base al task da risolvere.\n7\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#7": "word2vec\nIl modello impiega 2 reti: \n skip-gram\n  e \ncontinuos bag of words\n  (CBOW).  \nIl training è basato sulla stima delle probabilità condizionate di predire una \ncerta parola in base a termini che occorrono nel suo intorno. Si segue sempre \nun approccio non supervisionato.\n8",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#8": "word2vec: skip-gram\nAssume che un termine può generare il testo circostante in una sequenza.  \nSupponiamo di considerare la sequenza \n “the”, “man”, “loves”, “his”, “son”\n ; e \nconsiderare il termine \n loves\n  con parola centrale, e una \n ﬁ\nnestra di 2 termini \nintorno al termine centrale.  \nIl modello skip-gram valuta la seguente probabilità condizionata:  \nSe assumiamo che i termini siano generati in modo indipendente tra loro, \npossiamo riscriverla:\n9\n",
    "data_test\\rootfolder\\università\\DeepLearning\\18-NLP-sbloccato.pdf#9": "word2vec: skip-gram\nOgni parola con indice \n i\n ha associati 2 vettori d-dimensionali, \n  e \n. Il primo impiegato quando la parola è usata centralmente, l'altro \nquando la parola appare nel contesto.  \nLa probabilità di generare un certo termine contestuale con indice \n o\n dato il \ntermine centrale con indice \n c\n è de\n ﬁ\nnita mediante una operazione softmax nel \nseguente modo:  \nData una sequenza di testo lunga \n T\n, dove \n  indica la parola posizionata allo \nstep \nt\n, e assumendo che le parole contestuali siano generate in modo \nindipendente tra loro, per una \n ﬁ\nnestra di lunghezza \n m\n, la probabilità di \ngenerare tutti i termini contestuali è de\n ﬁ\nnita nel seguente modo:\nv\ni\n∈\nℝ\nd\nu\ni\n∈\nℝ\nd\nw\n(\nt\n)\n10\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#0": "!1Introduzione",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#1": "Cos’è la Fisica?La Fisica è la disciplina che si propone di fornire una spiegazione a tutti i fenomeni naturali\n!2\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#10": "Misura delle grandezze fisicheEsempio: per misura della larghezza L di una lavagna occorre confrontare la larghezza della lavagna con uno standard di misura delle lunghezze: \n!11L{}=LL⎡⎣⎤⎦Risultato del confrontoGrandezza fisica da misurareLunghezza standard• Se [L]=metro            → {L} = 3,5    [L]=m   →   L = 3,5 m • Se [L]=centimetro    → {L} = 350     [L]=cm   →   L = 350 cm • Se [L]=piede             → {L} = 11,5    [L]=ft     →   L = 11,5 ft • Se [L]=pollice           → {L} = 138    [L]=in     →  L = 138 in La grandezza è sempre la stessa, ma cambiano sia la parte numerica che quella relativa allo standard di misura utilizzato",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#11": "Misura delle grandezze fisicheLa misura è identificata da due elementi: • La parte numerica (numero)  {L} • Lo standard usato (l’unità di misura) [L] \n!12L={L}[L]Devono essere specificati entrambi!!!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#12": "Dimensioni delle grandezze fisicheGrandezze principali (che useremo nel corso) • Lunghezza L, Tempo T, Massa M, Intensità di corrente I\n!13e ( alcune) grandezze derivate: • Superficie S=[L2], V olume V=[L3] • Frequenza F=[1/T]=[T-1]  • Velocità V=[L/T]=[LT-1], accelerazione A=[L/T2]=[LT-2] • Tensione elettrica V=[ML2I-1T-3]• Grandezza generica  [X]=[MαLβTγI𝛿] 𝛼,𝛽,𝛾,𝛿 sono dette dimensioni della grandezza fisica",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#13": "Dimensioni nelle formuleOgni formula ﬁsica è una relazione tra grandezze ﬁsiche → sono due relazioni, una sui numeri e una sulle unità di misura\n!14",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#14": "Unità di misura (standard di misura)Gli standard devono soddisfare i criteri: • Essere stabili nel tempo • Essere precisi • Essere “facilmente” riproducibili in ogni parte del mondo (universo)\n!15Dal 20 maggio 2019 si utilizzano nuove definizioni",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#15": "Unità di tempo: il secondoScelta di un fenomeno periodico:  •Giorno solare medio. Diviso in  - 24 ore, 60 minuti primi, 60 minuti secondo - 1 giorno = 86400 secondi  (minuti secondi) • 1967: un secondo corrisponde a 9.192.631.770 oscillazioni dell’isotopo di Cesio 133 tra lo stato fondamentale e il suo primo stato eccitato (invariato al 20/5/2019)!16\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#16": "Unità di lunghezza: il metroProdotto della rivoluzione francese (1795)•Deﬁnizione originale– 1 metro = 1/10 000 000 della distanza tra polo nord ed equatore •Deﬁnizione successiva (1889): distanza tra due tacche di una sbarra di platino-iridio (campione di Sèvres)•1983: Lo standard di tempo è ben deﬁnito; la velocità della luce è una costante universale:– 1 metro = distanza percorsa dalla luce in 1/299 792 458 secondi(invariato al 20/5/2019)!17\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#17": "Unità di corrente: l’ampereFino al 20/5/2019 L’intensità di corrente che, se mantenuta in due conduttori lineari paralleli di lunghezza infinita e sezione trascurabile, posti a un metro di distanza l’uno dall’altro nel vuoto, produce tra questi una forza pari a 2×10-7 newton per ogni metro di lunghezza. Oggi:  L’ampere sarà definito dal valore numerico della carica elementare fissato a 1,602176634×10-19 coulomb e sarà realizzato attraverso speciali circuiti che contano gli elettroni.!18\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#18": "Unità di massa: il kilogrammoProdotto della rivoluzione francese (1795) Intenzione: 1 kg = massa di 1 dm3 di acqua a 4 gradi centigradi Fino al 20/5/2019 Definizione: 1kg =  massa di un cilindro campione di platino iridio di 39 mm di altezza e 39 mm di diametro!19\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#19": "Unità di massa: il kilogrammoOggi:  Sarà ridefinito in termini della costante di Planck, sarà realizzato attraverso una speciale bilancia elettromagnetica (detta bilancia di Kibble) e non sarà più necessario riferirsi al campione di Sèvres. il chilogrammo diventa la massa controbilanciata da un certa quantità di corrente, dove entra in gioco la costante di Planck.\n!20\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#2": "Cos’è la Fisica?La Fisica è la disciplina che si propone di fornire una spiegazione a tutti i fenomeni naturali\n!3Fino al XVII secolo la Fisica era considerata come filosofia della natura (spinta più da considerazioni filosofiche)Il senso moderno del termine è stato introdotto da Galileo Galilei, partendo dalla definizione di Metodo Scientifico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#20": "Sistema Metrico DecimaleUn insieme di unità di misura costituisce un sistema: Sistema MKS: metro, kilogrammo, secondo (rinominato in SI nel 1970: Sistema Internazionale) Sistema cgs: centimetro, grammo, secondo Sistema metrico decimale: i multipli ed i sottomultipli sono potenze di 10: Multipli prefisso  sottomultipli prefisso 10 deca (da)  10-1 deci   (d) 102 etto (h)  10-2 centi  (c) 103 kilo  (k)                 10-3 milli  (m) 106 mega (M)  10-6 micro  (µ) 109 giga (G)  10-9 nano (n) Esempi: 1 mm, 2 µm, 5 ns, 20 km, 4 hg!21",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#21": "Esempio\n!22Una macchina percorre una curva semicircolare di raggio R=50 m con una velocità di v = 20 m/s. Calcolare l’accelerazione della macchina.\nRisultato: l’accelerazione vale: Analisi dimensionale: [a]=[LT-2]Suggerimento: l’accelerazione (a) si misura in m/s2. La formula da usare è una delle seguenti:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#22": "Esercizio\n!23Determinare quanti secondi ci sono in un anno solare;Quanto pesa un metro cubo di acqua?Enrico Fermi amava dire che faceva lezioni che duravano tipicamente un microsecolo. A quanti minuti corrisponde un microsecolo?365.25×24×60×60=31,556,7361dm3→1kg1m3=1000dm3→1000kg100×365.25×24×60=52,594,560 minuti in un secoloUn microsecolo corrisponde a 52.59456 minuti ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#23": "Lorenzo RinaldiDipartimento di Fisica e Astronomialorenzo.rinaldi@unibo.ithttps://www.unibo.it/sitoweb/lorenzo.rinaldi/\n!24",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#3": "Il Metodo Scientifico-SperimentaleAlla base del metodo Scientifico c’è l’Esperimento: i processi della Natura sono schematizzati in Modelli da verificare sperimentalmente\n!4\n...tra le sicure maniere di conseguire la verità è l’anteporre l’esperienza a qualsivoglia discorso, non sendo possibile che una sensata esperienza sia contraria al vero... ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#4": "Il Metodo Scientifico-SperimentaleNessun modello teorico risulta essere valido universalmente Le teorie risultano essere valide entro ben determinati limiti esempio:  •piccole distanze: serve la “teoria dei quanti” •elevate velocità: serve la “teoria della relatività” \n!5",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#5": "Il Metodo Scientifico-SperimentaleLe teorie fisiche sono validate tramite osservazioni sperimentali Gli esperimenti devono essere realizzati per determinare con precisione (MISURARE) in maniera RIPRODUCIBILE le grandezze fisiche.\n!6Le grandezze Fisiche sono quantità che servono per descrivere i fenomeni naturali in maniera oggettiva (esempio: tempo, spazio, massa,…) \n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#6": "Grandezze Fisiche\n!7Grandezza fisica: proprietà o caratteristica di un oggetto o di un fenomeno che può essere quantificata (→ misurata)\nEsempi: \nlunghezze, durate, velocità, forza, temperatura, pressioneodori, intelligenza, bello, brutto…\nControesempi: \n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#7": "Grandezze principali e derivate Lunghezza e V olume • Il volume V di un cubo di lato L: V=L3\n!8\nL In un viaggio di T=1 h, ho percorso L=100 km spostandomi ad una velocità v=100 km/h • 3 grandezze: durata, distanza, velocità •1 relazione tra le grandezze v=L/Tlunghezza e tempo sono grandezze principali V olume e velocità sono grandezze derivate",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#8": "Grandezze principali e derivate\n!9In Fisica ci sono 7 grandezze principali, tutte le altre sono derivabili da esselunghezza tempo massa temperatura intensità di corrente elettrica intensità luminosa quantità di sostanzaMECCANICAELETTROMAGNETISMO",
    "data_test\\rootfolder\\università\\FisicaGenerale\\01-introduzione.pdf#9": "Misura delle grandezze fisicheMisura: processo di determinazione di una grandezza fisica Operativamente: misura=confronto della grandezza che ci interessa con uno standard (una misura campione di quel tipo di grandezza)Le grandezze Fisiche sono definite in Modo Operativo: il modo di misurare la grandezza ne fissa la definizione Le grandezze Fisiche sono definite da tutte le possibili operazioni di misurazione\n!10",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#0": "VETTORI  CdS Ingegneria Informatica A.A. 2019/20",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#1": "!2Grandezze fisiche•Grandezze scalari: completamente definite da un numero ed una unità di misura –Esempi: distanza, lunghezza, periodo, pressione, temperatura •Grandezze vettoriali: completamente definite da 3 numeri e da una unità di misura o da un numero, una unità di misura, una direzione ed un verso –Esempi: spostamenti, forze, velocità, accelerazione, campi elettrici e magnetici, … •Grandezze tensoriali: definite da più di 3 numeri ed una unità di misura –Esempi: momento d’inerzia, matrice di rotazione, …",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#10": "!11Proprietà associativa della somma\n⃗a+⃗c",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#11": "!12Differenza tra vettori•Definizione:OABOAB−⃗bvettore opposto (stesso modulo e direzione, ma con verso opposto)⃗d=⃗a−⃗b=⃗a+(−⃗b)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#12": "Somma e differenza\n!13⃗a⃗d=⃗a−⃗b⃗b⃗c=⃗a+⃗b",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#13": "!14Moltiplicazione per uno scalare•Si può definire come moltiplicazione tra un numero naturale n ed un vettore     come una somma ripetuta:•Generalizzando, si può definire come  moltiplicazione tra un numero reale λ ed un vettore      come vettore di direzione pari ad      modulo pari a            e verso concorde con     se             , verso opposto se    È un vettore!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#14": "!15Moltiplicazione per scalare: proprietà•La moltiplicazione per uno scalare gode delle proprietà commutative, associative e distributive sia rispetto agli scalari che ai vettori:•Inoltre:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#15": "!16Prodotto scalareAssocia a due vettori arbitrari uno scalare:θa⋅b=abcosϑ\na⋅b=abb\na⋅b=aba",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#16": "!17                   : casi notevoli•Vettori in direzione opposta:a⋅b=abcosϑ•Vettori paralleli:a⋅b=ab>0•Vettori ortogonali:a⋅b=0•La componente: –Sia      un versorea⋅ˆu=aˆucosϑ==acosϑ=au",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#17": "!18Prodotto scalare: proprietà•Il prodotto scalare gode della proprietà commutativa, distributiva sulla somma:•Quadrato di un vettore:DEFINIZIONE  DI MODULO!  a⋅b=b⋅aa⋅b+c()=a⋅b+a⋅cλa⋅b()=λa()⋅b=a⋅λb()   a⋅a=a2=a2=a2  ⇒a=a⋅a",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#18": "!19Moduli di somme e di differenze\n   a+b=a+b()2=a+b()⋅a+b()=  =a⋅a+a⋅b+b⋅a+b⋅b   a+b=a2+b2+2abcosϑ   a−b=a−b()2=a−b()⋅a−b()=  =a⋅a−a⋅b−b⋅a+b⋅b   a−b=a2+b2−2abcosϑ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#19": "!20Prodotto vettore•Associa a due vettori un terzo vettore:\nModulo Direzione ⊥ piano dei vettori Verso: regola della mano destraModulo: area del parallelogrammaVerso convenzionale",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#2": "!3Stazione: 2.2 km in direzione nord-est",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#20": "!21Prodotto vettore•Associa a due vettori un terzo vettore:Modulo Direzione ⊥ piano dei vettori Verso: regola della mano destra\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#21": "!22Prodotto vettore: proprietà•Il prodotto vettore (o vettoriale) gode della proprietà anticommutativa e distributiva sulla somma: •Il prodotto vettore non gode della proprietà associativa: •Caso notevole:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#22": "!23Doppio prodotto misto\nProprietà:V=a∧b⋅c=a∧b()⋅ch=c⋅versa∧b() a∧b⋅c=b∧c⋅a=c∧a⋅b a∧b⋅c=a⋅b∧c",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#23": "!24Sistemi di riferimento•I vettori sono entità astratte, indipendenti da come sono rappresentate.AB•Per convenienza pratica i vettori si descrivono bene utilizzando il concetto di SISTEMA DI RIFERIMENTO, costituito in estrema sintesi da un punto privilegiato detto origine e da un insieme di vettori campione (vettori di base)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#24": "!25Spazio unidimensionale•Ogni vettore può essere scritto come:O In uno spazio unidimensionale ogni vettore può essere espresso come uno scalare (la componente) moltiplicato il versore dell’asse (sempre lo stesso).a+b=auˆu+buˆu=au+bu()ˆua=a⋅a=auˆu⋅auˆu=au2(ˆu⋅ˆu)=au",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#25": "!26Spazio bidimensionale: vettori nel piano•Scelgo 2 assi ortogonali x,y: \nOXYˆi⋅ˆj=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#26": "Esempio di spazio bi-dimensionale\n!27\n(C; 4)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#27": "!28Spazio tridimensionale\n•Scelgo 3 assi ortogonali x,y,z: ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#28": "!29Vettori di base nello spazio\n1ˆˆˆˆˆˆ=⋅=⋅=⋅kkjjii0ˆˆˆˆˆˆ=⋅=⋅=⋅ikkjjiˆi∧ˆi=ˆj∧ˆj=ˆk∧ˆk=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#29": "!30Operazioni nella rappresentazione cartesiana\na⋅b=ca⋅b=(axˆi+ayˆj+azˆk)⋅(bxˆi+byˆj+bzˆk)==axbxˆi⋅ˆi+axbyˆi⋅ˆj+axbzˆi⋅ˆk+aybxˆj⋅ˆi+aybyˆj⋅ˆj+aybzˆj⋅ˆk++azbxˆk⋅ˆi+azbyˆk⋅ˆj+azbzˆk⋅ˆk==axbx+ayby+azbz=c",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#3": "!4Vettore nel piano\nABModuloDirezioneVersoVettore libero 1 direzione nello spazio 1 verso 1 modulo (intensità)Prototipo: vettore spostamento",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#30": "!31Prodotto vettoriale\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#31": "Esercizio A•Sianoˆˆˆˆˆˆ21322aijkbijk=−+=−+−!!1.Trovare i moduli 2.Trovare il vettore somma ed il vettore differenza 3.Calcolare  4.Calcolare  5.Trovare l’angolo compreso!3232,23cabdab=+=−!!!!!!abλ=⋅!!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#32": "Esercizio Nel piano XY, la componente x di un vettore v vale -25, quella y +40. Quanto vale il modulo del vettore? Quanto vale l’angolo compreso fra v e l’asse delle ascisse? \n!33",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#33": "!34Esercizio 1•Sia1.Trovare i moduli 2.Trovare l’angolo compreso 3.Trovare il vettore somma ed il vettore differenza 4.Trovare un vettore perpendicolare ad entrambi",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#34": "!35Esercizio 3•Una barca naviga in direzione Nord-Est per 15 km, successivamente vira in direzione Sud e prosegue per 10 km, quindi vira nuovamente in direzione Ovest e percorre altri 5 km. Trovare la distanza percorsa e la distanza dal punto di partenza.NESO",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#35": "Esercizio Nella somma a+b = c il vettore a ha modulo 12 e forma un angolo di 40° rispetto al semiasse positivo delle ascisse, mentre il vettore c ha modulo 15 ed è diretto con un angolo di 20° in senso antiorario rispetto al semiasse negativo delle ascisse. Calcolare il modulo e la direzione (rispetto al semiasse positivo delle ascisse) di b. \n!36",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#36": "Esercizio Dati nel piano cartesiano i punti A = (1, 1), B = (3, 4) e  C = (5, 2), determinare il valore dell’angolo formato dai segmenti CA e CB e l’area del triangolo ABC. \n!37",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#37": "EsercizioDeterminare il volume del parallelepipedo individuato dai vettori   ˆˆˆˆˆˆˆ2,3,32ajkbjcjkιι=−+=−=−+−!!!\n!38",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#38": "Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it www.unibo.it/docenti/lorenzo.rinaldi\n!39",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#4": "!5Versore•Versore: vettore di modulo unitario, adimensionaleUn versore individua un asse orientatoAB",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#5": "I versori dove non te li aspetti\n!6",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#6": "!7LA componente ed IL componente\nvu = v cosθla componente\n(vu = v cosθ u) il componenteLA componente è una grandezza scalare!IL componente è un vettore (il vettore componente lungo una direzione)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#7": "!8Algebra dei vettori•I vettori liberi costituiscono un’algebra –È definita l’operazione somma tra due vettori –È definita l’operazione di moltiplicazione tra un vettore ed uno scalare •Inoltre: sono definiti un prodotto esterno ed uno interno –Prodotto scalare: –Prodotto vettoriale:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#8": "!9Somma tra due vettori•Prototipo: somma tra due vettori spostamentoABCD\nRegola del parallelogramma: Il vettore somma è dato dalla diagonale (C-A) del  Parallelogramma costruito  con i vettori (B-A) e (C-B)B≡C⃗c=⃗a+⃗b=(D−A)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\02-vettori.pdf#9": "!10Proprietà commutativa della somma•La somma gode della proprietà commutativa: \n•È un risultato sperimentale, non teorico, valido nel nostro ambiente. Ci sta dicendo che lo spazio fisico in cui viviamo è in buona approssimazione uno spazio euclideo.",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#0": "CINEMATICA CdS Ingegneria InformaticaA.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#1": "\u00002Modello base•Punto materiale: –Punto geometrico –Dotato di una proprietà chiamata massa •Valido per la descrizione del moto di ogni oggetto, quando le dimensioni dello stesso non sono importanti e possono essere trascurate",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#10": "\u000011Velocità scalare, vettoriale, versore tangente\nNella rappresentazione intrinseca: v(t)=limΔt→0P(t+Δt)−P(t)Δt=dPdt v(t)=s(t)=limΔt→0s(t+Δt)−s(t)Δt⎯⎯→⎯→Δ0t)()()()(lim0tvtsttsttst==Δ−Δ+=→Δ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#11": "\u000012Velocità: derivata del vettore posizione\nxyzP(t)\nNella rappresentazione cartesiana:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#12": "\u000013Derivata di un vettore⃗a=⃗a(t)=B(t)−A(t)d⃗adt=limΔt→0⃗a(t+Δt)−⃗a(t)Δtd⃗adt è un vettored⃗adt=limΔt→0⃗a(t+Δt)−⃗a(t)Δt⃗a(t)⃗a(t+Δt)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#13": "\u000014Regole di derivazione\nDimostrabili tramite la rappresentazione cartesiana dei vettori",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#14": "se a(t)=λ costante   ⇒da2dt=0 per ipotesida2dt=da⋅a()dt=dadt⋅a+a⋅dadt=2a⋅dadt≡0⇒a⊥dadt\n\u000015Esempi e dimostrazioni•Tutte le relazioni si dimostrano facilmente nella rappresentazione cartesiana:•Caso notevole: vettore di modulo costante.\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#15": "\u000016Cinematica: Riassunto•Il moto è sempre un fenomeno relativo\nMoto di un punto (P) rispetto ad un sistema di riferimento (SR)TraiettoriaDescrizione cartesianaEquazioni  parametricheVettore posizionexyz",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#16": "\u000017Velocità e descrizione intrinseca\nxyzOΩss: ascissa/coordinata curvilinea\nVelocità scalare istantanea\nVelocità vettoriale  istantanea\nRappresentazione cartesianaRappresentazione intrinsecaversore tangente alla traiettoria",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#17": "\u000018Accelerazione scalare media ed istantanea•Analogamente a quanto fatto per la variazione della posizione, si introduce il concetto di accelerazione per descrivere le variazioni di velocità •Data la velocità scalare istantanea   Accelerazione scalare mediaAccelerazione istantanea   a(t)=limΔt→0am(t,t+Δt)=limΔt→0v(t+Δt)−v(t)Δt=dvdt=!v   a(t)=dvdt=!v=d2sdt2=!!s  am⎡⎣⎤⎦=a⎡⎣⎤⎦=ΔvΔt⎡⎣⎢⎤⎦⎥=LT−1/T⎡⎣⎤⎦=LT−2⎡⎣⎤⎦→(m/s2)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#18": "\u000019Accelerazione vettorialeAccelerazione mediaAcc. Istantanea !a=limΔt→0!am=limΔt→0!v(t+Δt)−!v(t)Δt",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#19": "\u000020Esercizio 1•Il movimento di un punto dello spazio è descritto dal vettore posizione: •Trovare la velocità vettoriale e scalare •Trovare l’accelerazione vettoriale •Calcolare l’angolo tra il vettore velocità e quello accelerazione e spiegare il risultato ottenuto.\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#2": "•La terra non ruota solo su se stessa: ruota intorno al Sole a una velocità superiore a 110.000 km/h.\nQual è la nostra VELOCITÀ?Vi sembra di essere seduti immobili mentre ascoltate la lezione?\n\u00003•Il pianeta ruota su se stesso, il che significa che in realtà viaggiamo verso est a una velocità che può raggiungere i 1600 km/h .\n•Il Sole e il Sistema Solare viaggiano nello spazio alla folle velocità di 2 milioni di km/hQual è la nostra vera VELOCITÀ? ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#20": "\u000021Esercizio 2•In un piano xy, un punto materiale si muove seguendo le leggi: •Trovare il vettore posizione •Trovare la velocità scalare al tempo t=10s •Mostrare che l’accelerazione è costante\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#21": "\u000022Rapp. Intrinseca: versore normale\nTraiettoria circolare\nΔ̂utΔs⟶α,Δs→0d̂utds=d̂utdŝun",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#22": "\u000023Componenti intrinseche dell’accelerazione\nCirconferenza osculatrice (nel piano osculatore)ρ = raggio di curvatura (funzione di s)Espressione intrinseca",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#23": "\u000024Rappresentazione intrinseca del moto•Traiettoria:•Legge oraria:•Versore tangente: •Versore normale: •Versore binormale: Terna intrinseca  di versori  Ortonormali  •Raggio di curvatura: •Velocità: •Accelerazione: •Legge oraria:   →!v=\"s=vx2+vy2+vz2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#24": "\u000025Classificazione dei moti - I1. Moto a velocità costante:\nxyzOMoto rettilineo  uniforme",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#25": "\u000026Classificazione dei moti - II2. Velocità costante in direzione\nxyzOEsempio: Moto uniformemente  accelerato",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#26": "\u000027Classificazione dei moti - III3. Moto a modulo di velocità costanteEsempio: Moto circolare uniformeMoto uniformemente curvo\nxyzOΩs",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#27": "\u000028Classificazione dei moti - IV4. Moto senza vincoli sulla velocitàMoto curvo varioxyzOΩs",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#28": "\u000029Osserviamo la realtà che ci circonda …Perché le curve in autostrada sono sempre molto dolci (→ hanno un raggio di curvatura di centinaia di metri), mentre in campagna mi trovo anche curve molto secche (a 90° in pochi metri)?Perché NON ESISTONO curve in autostrada con raggio inferiore a diverse centinaia di metri, ad eccezione dei raccordi per i caselli, dove, se non si rallenta opportunamente, è facile finire fuori strada?Perché i progettisti delle tratte ferroviarie dell’alta velocità considerano sempre traiettorie con raggi di curvatura di qualche km, quando in stazione ci sono curve con raggi di curvatura di qualche decina di metri?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#29": "\u000030Espressioni cartesiane\n an=!s2ρ→ρ=!s2an",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#3": "\u00004Cos’è il moto?•Il moto è sempre un fenomeno relativo•Moto di una macchina rispetto ad una strada•Moto di un aereo rispetto alle nuvole, al terreno•Moto di un pianeta rispetto alle stelle ﬁsse•Moto di un sistema osservato rispetto all’osservatoreESEMPIMoto di un punto (P) rispetto ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#30": "\u000031Problemi di cinematica•Problema DIRETTO della cinematica: dato il vettore posizione, trovare velocità ed accelerazione: •Problema INVERSO della cinematica: data l’accelerazione (o la velocità), trovare velocità e vettore posizione !at() noto ⇒ !vt()=?!rt()=?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#31": "\u000032Problema inverso•Tipico problema: nota la velocità:\nL’analisi illustra che esistono ∞3 soluzioni (moti diversi)La richiesta che il sistema di equazioni abbia  una sola soluzione richiede l’introduzione di altri dati:  le condizioni iniziali",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#32": "\u000033Esempio di problema inversoCostanti arbitrarieCondizioni iniziali: Soluzioneunivoca",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#33": "\u000034Esempio: problema inverso unidimensionale•ES:Sia                  , trovare il moto x(t).Soluzione: txk=-2k=0k=-1k=+1Moltitudine di moti diversi!Condizioni iniziali:  x(0)=0Un moto particolareSoluzione: k=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#34": "\u000035Esempio•Un punto materiale si muove lungo l’asse x con una accelerazione data da •Sapendo che le condizioni iniziali sono •Trovare velocità e posizione ad ogni istante di tempo",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#35": "\u000036Soluzione•Velocità:• Posizione:dv adt→=→dv∫=adt∫",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#36": "\u000037Esercizio 1 La posizione di un punto materiale è individuata dal vettore posizione con t  espresso in secondi ed r in metri. Determinare la velocità e l’accelerazione ad ogni istante di tempo, la terna di versori intrinseca ed il raggio di curvatura della traiettoria per t=0 s.\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#37": "\u000038Esercizio 2In un certo istante, un punto materiale è in moto lungo un arco di circonferenza. Sapendo che rispetto ad un certo SR, la velocità e l’accelerazione valgono  e determinare la velocità scalare, l’accelerazione tangenziale, il raggio di curvatura della traiettoria e la normale al piano in cui avviene il moto. \n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#38": "\u000039Moti nel piano\nXYP1y(t)Ox(t)Equazioni parametriche\nEquazione della traiettoria",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#39": "\u000040Moto rettilineo uniforme\nXYP1y(t)Ox(t)Equazioni parametricheVelocità ed accelerazioneda x=x0+v0xt→t=x−x0v0xintercettapendenza",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#4": "\u00005Scelta del sistema di riferimento•Lo stesso oggetto può essere descritto in modo diverso a seconda del SR:Moto della lavagna (e di tutti noi):•Ferma rispetto a noi (SR della stanza)•Moto circolare per chi ci osserva dalla luna (SR lunare; velocità circa 1200 km/h)•Moto + complesso per chi ci osserva dal Sole (SR eliocentrico; velocità circa 108000 km/h)•Moto ancora più complesso per chi ci osserva dal centro della Galassia!Scegliamo un SR a seconda di cosa si muove e di come vogliamo descrivere il moto",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#40": "\u000041Moto dei gravi•Caduta di un corpo sulla superficie terrestre\nXYy(t)Ox(t)costantealtoAsse orizzontaleCondizioni iniziali",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#41": "\u000042Moto dei gravi: soluzione\n•Traiettoria:→y=ax2+bx+c",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#42": "\u000043Caduta dei graviOggetto che cade da fermo da un’altezza hCaso particolare con condizioni iniziali (con t0=0): {⃗r0=ĥ𝚥⃗v0=⃗0{x0=0y0=hv0x=0v0y=0{vx(t)=0vy(t)=−gt{x(t)=0y(t)=h−g2t2traiettoria: linea retta (asse y)XYO",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#43": "\u000044Caduta dei gravi{vx(t)=0vy(t)=−gt{x(t)=0y(t)=h−g2t2\nXYOTempo di caduta (da altezza h):y(tc)=0h−g2t2c=0tc=2hgVelocità d’impatto al suolo⃗v(tc)=−gtĉ𝚥⃗v(tc)=−g2hĝ𝚥=−2gĥ𝚥",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#44": "\u000045Moto dei gravi:  generale•La traiettoria è una parabolaXYy(t)Ox(t)altoAsse orizzontaleCoordinate del punto di massimo della parabola?In quale punto dell’asse x atterra ? (y=0)A che istante e con che velocità ci arriva?Rappresentazione intrinseca:velocità e accelerazione?terna di versori intrinseca?raggio di curvatura?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#45": "\u000046Coordinate Polari piane\nxyPvettore posizione del punto Pin coordinate cartesiane⃗r=x̂ı+ŷ𝚥\n{x=rcosφy=rsinφpotremmo usare un’altra coppia di scalari: + distanza r dall’origine e angolo 𝜑 rispetto ad asse x̂ı̂𝚥φrtrasformazioni delle coordinater=x2+y2φ=arctanyx",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#46": "\u000047Coordinate Polari piane\nxyP{x=rcosφy=rsinφ̂ı̂𝚥φrr=x2+y2φ=arctanyxversori in coordinate polari pianêur=(̂ur⋅̂ı)̂ı+(̂ur⋅̂𝚥)̂𝚥=cosφ̂ı+sinφ̂𝚥⃗r=x̂ı+ŷ𝚥̂uφ=(̂uφ⋅̂ı)̂ı+(̂uφ⋅̂𝚥)̂𝚥=−sinφ̂ı+cosφ̂𝚥̂ur̂uφsi veriﬁca facilmented̂urdφ=̂uφd̂uφdφ=−̂urcambiano durante il moto!α=φ+π2cosα=−sinφsinα=cosφ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#47": "\u000048Coordinate polari cilindriche\nxyzPϕzrP’̂ur̂uφ̂uz\n̂ur̂uz{x=rcosφy=rsinφz=zr=x2+y2φ=arctanyxz=ẑur=cosφ̂ı+sinφ̂𝚥uφ=−sinφ̂ı+cosφ̂𝚥̂uz=̂k̂uφterna ortogonalêur=̂uφ∧̂k",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#48": "\u000049Moto circolare\nxyP(t)ascissa curvilinea s (con origine sull’asse x)s=RφTraiettoria circolare di raggio R centrata nell’origine di un SdR cartesianoRarco di circonferenzaφΩs[0≤s≤2πR]{x(φ)=Rcosφy(φ)=RsinφNel SdR cartesiano⃗r(φ)=Rcosφ̂ı+Rsinφ̂𝚥⃗r(s)=Rcos(sR)̂ı+Rsin(sR)̂𝚥|⃗r|=R\nla posizione dipende solo dall’angolo 𝜑⃗r(φ)=R̂urs(t)=Rφ(t)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#49": "\u000050Cinematica del moto circolare⃗r(φ(t))=Rcosφ(t)̂ı+Rsinφ(t)̂𝚥=R̂ur⃗v(φ(t))=d⃗rdt=−R·φsinφ̂ı+R·φcosφ̂𝚥=R·φ̂uφ⃗a(φ(t))=d⃗vdt==(−R··φsinφ−R·φ2cosφ)̂ı+(R··φcosφ−R·φ2sinφ)̂𝚥==R··φ(−sinφ̂ı+cosφ̂𝚥)−R·φ2(cosφ̂ı+sinφ̂𝚥)==R··φ̂uφ+R·φ2(−̂ur)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#5": "\u00006Sistema di riferimento cartesianoTraiettoria Luogo dei punti dello spazio per cui passa un corpo P=P(t)\nxyz\n= Descrizione cartesianaEquazioni  parametricheOVettore posizione\nr⎡⎣⎤⎦=x⎡⎣⎤⎦=y⎡⎣⎤⎦=z⎡⎣⎤⎦=L⎡⎣⎤⎦→(m)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#50": "\u000051Cinematica del moto circolareGrandezze angolari:velocità angolareω=·φaccelerazione angolareα=·ω=··φ⃗v=R·φ̂uφ=Rω̂uφ=Rω̂k∧̂ur=(ω̂k)∧(R̂ur)=⃗ω∧⃗rvettore velocità angolarêuφ=̂k∧̂ur⃗v=⃗ω∧⃗r⃗ω=ω̂k⃗a=Rα̂uφ+Rω2(−̂ur)=⃗α∧⃗r−ω2⃗rvettore accelerazione angolare⃗α=α̂k⃗a=ddt(⃗ω∧⃗r)=d⃗ωdt∧⃗r+⃗ω∧d⃗rdt=ur=̂uφ∧̂k\n⃗at=⃗α∧⃗r⃗an=⃗ω∧⃗v=⃗ω∧(⃗ω∧⃗r)=⃗α∧⃗r+⃗ω∧⃗v=⃗α∧⃗r+⃗ω∧(⃗ω∧⃗r)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#51": "\u000052Cinematica del moto circolareGrandezze angolari:velocità angolareω=·φ=ddt(sR)=·sR=vRaccelerazione angolareα=·ω=ddt(·sR)=··sRangoloφ=sR⃗v=Rω̂uφ=·ŝuφ⃗a=Rα̂uφ+Rω2(−̂ur)=··suφ+·s2R(−̂ur)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#52": "\u000053Cinematica del moto circolare⃗r=R̂ur⃗v=R·φ̂uφ=Rω̂uφ⃗a=R··φ̂uφ+R·φ2(−̂ur)=xyφR̂ur̂uφ=Rα̂uφ+Rω2(−̂ur)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#53": "\u000054Moto circolare uniforme⃗r=R̂ur⃗v=Rω̂uφ=⃗ω∧⃗rx̂uryφR̂uφ⃗a=−Rω2(̂ur)=−ω2⃗r=⃗ω∧(⃗ω∧⃗r)velocità costante in modulo ma varia continuamente in direzioneω=·φ=costanteα=·ω=0\naccelerazione (centripeta) costante in modulo ma varia continuamente in direzione",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#54": "Moti periodici•Un fenomeno è detto periodico se, a partire da un istante qualsiasi t, le sue caratteristiche si ripresentano inalterate dopo un certo intervallo di tempo T, detto periodo. •Quantità caratteristiche: –       ,  periodo fondamentale; –         , frequenza (numero di T contenuti nell’unità di tempo); –          , pulsazione (numero di giri compiuti nell’unità di tempo sulla traiettoria chiusa) υ=1Tω0=2πTTmin\n\u000055 !r(t+nT)=!r(t)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#55": "Esempio di moto periodicoMoto circolare uniforme:→v=costantexy !r•In coordinate cartesiane:Tutte le equazioni:hanno la stessa famiglia di soluzioni:\u000056\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#56": "\u000057Soluzione generale•Problema di base:Ipotesi di soluzione:f+ω2f=0→",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#57": "\u000058Moto oscillatorio armonicoTraiettoria Equazione oraria \nx+l-l",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#58": "\u000059Moto armonico: condizioni inizialiSia dato un moto armonico di pulsazione ω e condizioni iniziali x(0)=x0 e v(0)=v0. Trovare la legge oraria.Soluzione:  Equazione del moto armonico:Soluzione generale:Velocità:Accelerazione:Impongo le condizioni iniziali:x(0)=Acos(φ0)=x0x(0)=−ωAsin(φ0)=v0→⎧⎨⎪⎩⎪",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#59": "\u000060Esercizio•Dati due moti armonici di pulsazione ω nel piano con condizioni iniziali:\nTrovare leggi orarie e traiettoriaMoto A xA0()=x0!xA0()=0⎧⎨⎪⎩⎪yA0()=y0!yA0()=0⎧⎨⎪⎩⎪Moto B xB0()=x0!xB0()=0⎧⎨⎪⎩⎪yB0()=0!yB0()=ωx0⎧⎨⎪⎩⎪",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#6": "\u00007TraiettoriaLuogo dei punti dello spazio per cui passa un corpo (entità unidimensionale)P=P(t)xyzOP1=P(t1)P2=P(t2)Equazione parametrica della traiettoria:ParametriVettore spostamentor⎡⎣⎤⎦=L⎡⎣⎤⎦→(m)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#60": "Moti relativi\n\u000061\nP(')(')POOOPO−=−+−\n()rrOOʹʹ=+−!!Posizioner!rʹ!\n''PPOrrr=+!!\"'Or!‘‘‘‘‘‘‘\nSS’S: sistema di riferimento fermoS’: sistema di riferimento mobile\nSS’",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#61": "Trasformazione della velocità (opz)\n\u000062Velocità''Orrr=+!!!ˆˆˆˆˆˆ(')(')''''''(')rPOxiyjzkPOOOxiyjzkOO=−=++==−+−=+++−!ˆˆˆ'(')''''''ˆˆˆ()(')(')rPOxiyjzkPOOOxiyjzkOO=−=++==−+−=+++−!\nPr!rʹ!\n'Or!’’’’’’’ˆˆˆ'''''''xiyjzk=++v!\"\"\"ˆˆˆxiyjzk=++v!\"\"\"ˆˆˆˆˆˆ'('''''')'''ˆˆˆ'''''''''drdxiyjzkddjdkxiyjzkxyzdtdtdtdtdtι++==+++++!\"\"\"ˆˆˆ'''ddjdkdtdtdtιQuanto valgono                          ?\n!v=d!rdt=d!r'dt+d!rO'dt=d!r'dt+!vO'",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#62": "Formule di Poisson (opz)•Quindi:\n\u000063ˆ'ddtιDerivata di un vettore di modulo costanteˆˆ''ˆˆˆ'''ddajbkdtdtιιι⊥=+drrdtω==×v!!!!Vista nel moto circolare uniforme. E’ generalizzabile !Formule di Poisson: esiste un unico       per cui:ˆ'ˆ'ˆ'ˆ'ˆ'ˆ'ddtdjjdtdkkdtιωιωω⎧=×⎪⎪⎪=×⎨⎪⎪=×⎪⎩!!!ω!ˆˆˆ''''''ˆˆˆ'(')'(')'(')ˆˆˆ('''''')'ddjdkxyzdtdtdtxyjzkxyjzkrιωιωωωιω++==×+×+×==×++=×!!!!!!ω!Descrive la rotazione di S’ rispetto ad S: asse + velocità angolare",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#63": "Trasformazione della velocità (opz)•Posizione:\n\u000064''Orrr=+!!!ˆˆˆ'''''''xiyjzk=++v!\"\"\"ˆˆˆxiyjzk=++v!\"\"\"•Velocità:•Trasformazione:•Velocità di trascinamento:•Un punto fermo in S’ si muove di velocità     in STv!Addizione delle velocità!v=!v'+!ω×!r'+!vO'!v=d!rdt=d!r'dt+d!rO'dt=d!r'dt+!vO'=!v'+!ω×!r'+!vO'!vT=!ω×!r'+!vO'!v=!v'+!vT",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#64": "Trasformazione dell’accelerazione (opz)\n\u000065Accelerazioneˆˆˆˆˆˆ'''''''axiyjzkaxiyjzk=++=++!!\"\"\"\"\"\"\"\"\"\"\"\"'ˆˆˆˆˆˆˆˆˆˆˆˆ('''''''''''')('''''''''''')Oxiyjzkxiyjzkxiyjzkxiyjzka=++++++++++++=!\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"ˆˆˆˆˆˆˆˆˆ('''''')'(')''''('''''')'xiyjzkxiyjzkxiyjzkωωωωω++=×+×+×=×++=×v!!!!!!\"\"\"\"\"\"\"\"\"\"\"\"NB:()ˆˆˆ'(')'ˆˆˆˆ''''diddiidtdtdtωιωιωωιωωι×===×+×=×+××!\"!!!!!\"\"\"\"\n!v=\"xˆi+\"yˆj+\"zˆk=\"x'ˆi'+\"y'ˆj'+\"z'ˆk'+x'ˆ\"i'+y'ˆ\"j'+z'ˆ\"k'+!vO'!v'=\"x'ˆi'+\"y'ˆj'+\"z'ˆk'!a=d!vdt=ddt(\"x'ˆi'+\"y'ˆj'+\"z'ˆk'+x'ˆ\"i'+y'ˆ\"j'+z'ˆ\"k'+!vO')=\nx'ˆ!!i'+y'ˆ!!j'+z'ˆ!!k'==x'(!\"ω×ˆι'+!ω×!ω×ˆι'())+y'(!\"ω×ˆj'+!ω×!ω×ˆj'())+z'(!\"ω×ˆk'+!ω×!ω×ˆk'())==!\"ω×(x'ˆi'+y'ˆj'+z'ˆk')+!ω×!ω×(x'ˆi'+y'ˆj'+z'ˆk')()=!\"ω×!r'+!ω×!ω×!r'()",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#65": "Trasformazione dell’accelerazione\n\u000066Accelerazioneˆˆˆˆˆˆ'''''''axiyjzkaxiyjzk=++=++!!\"\"\"\"\"\"\"\"\"\"\"\"()''2'''odaarradtωωωω==+×+×+××+vv!!!!!!!!!!!\"()'''Toarraωωω=×+××+!!!!!!!\"Accelerazione di trascinamento:Un punto fermo in S’ si muove di accelerazione     in STa!'2''TCOTaaaaaaω=+×+=++v!!!!!!!!2'COaω=×v!!!Accelerazione di Coriolis:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#66": "SR in moto rettilineo uniforme\n\u000067\n''Orrr=+!!!\nxyzx’y’z’'Ov!\n'aa=!!P(t)O’O00COTaa==!!!!\n()''2'''COTCOTOaaaaaarraωωωω=++=×=×+××+v!!!!!!!!!!!!!!\"\nTrasformazioni di Galileo!vO'=costante,!ω=!0x(t)=x'(t)+vO'ty(t)=y'(t)z(t)=z'(t)!v(t)=!v'(t)+!vO'=vx(t)=vx'(t)+vO'vy(t)=vy'(t)vz(t)=vz'(t)⎧⎨⎪⎩⎪!vT=!vO'\n!v=!v'+!vT!vT=!vO'+!ω×!r'",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#67": "Lorenzo RinaldiDipartimento di Fisica e Astronomialorenzo.rinaldi@unibo.itwww.unibo.it/docenti/lorenzo.rinaldi\n\u000068",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#68": "Argomenti opzionali\n\u000069",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#69": "\u000070Velocità areolare\nA(t)=limΔt→0ΔSΔtαΔt→0⎯→⎯⎯π−β[A(t)]=[rv]=[L2T−1]→(m2/s) !A=12P−O()∧!v=12!r∧!v",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#7": "\u00008Rappresentazione intrinseca\nxyzOΩss: ascissa curvilineaDescrizione intrinseca: -Geometria della traiettoria -Origine Ω, verso della traiettoria  -Coordinata curvilinea s(t)s(t)⎡⎣⎤⎦=L⎡⎣⎤⎦→(m)origine della traiettoriaverso",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#70": "\u000071Accelerazione Areolare•Velocità areolare•Accelerazione areolare   costante in direzione à il moto si svolge su un piano   costante à                    MOTO CENTRALE à                    MOTO RETTILINEOClassiﬁcazione dei moti",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#71": "SR in rotazione uniforme\n\u000072\nxy  x’y’O=O’Pr\n'Trrωω=×=×v!!!!!\n'rr=!!\n()'2'COTCOTaaaaaarωωω=++=×=××v!!!!!!!!!!!Un punto fermo in S’ ha accelerazione                                  in S()Tarωω=××!!!!\n''Orrr=+!!!\n()''2'''COTCOTOaaaaaarraωωωω=++=×=×+××+v!!!!!!!!!!!!!!\"\n!v=!v'+!vT!vT=!vO'+!ω×!r'\n!v=!v'+!ω×!r!rO'=!0,!ω=costante",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#72": "Esercizio•Nei pressi di un incrocio a 90° tra due strade si urtano due macchine che viaggiavano rispettivamente a 40 km/h e 50 km/h. Determinare la velocità relativa dell’urto (velocità di una macchina come misurata da un osservatore solidale con l’altra) quando: –L’urto è frontale –L’urto è un tamponamento –L’urto avviene tra due macchine che viaggiavano su due strade a 90° tra loro.\n\u000073",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#73": "Caso 1: tamponamento\n\u000074\n150/kmh=v\n240/kmh=vx’y’z’xyz!v2=!v'2+!vO'=40km/h ˆι!vO'=!v1=50km/h ˆι!v'2=!v2−!vO'=!v2−!v1=−10km/hˆι",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#74": "Caso 2: urto frontale\n\u000075\n150/vkmh=\n240/vkmh=x’y’z’xyz!v2=!v'2+!vO'=−40km/h ˆι!vO'=!v1=50km/h ˆι!v'2=!v2−!vO'=!v2−!v1=−90km/hˆι",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#75": "Caso 3: urto a 90 gradi\n\u000076\n150/vkmh=\n240/vkmh=x’y’z’xyz!v2=!v'2+!vO'=40km/h ˆk!vO'=!v1=50km/h ˆι!v'2=!v2−!vO'=!v2−!v1=−50ˆι+40ˆk()km/h!v'2=502+402=64km/h",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#76": "Esercizio•Su una giostra costituita da una piattaforma rotante si trova un bambino con in mano una pallina. La giostra ruota con una velocità angolare pari a 0.5 s-1 quando, il bambino, che si trova a 4 m dall’asse di rotazione, lancia la pallina con una velocità iniziale pari a 3 m/s. Calcolare la velocità che ha la pallina per un osservatore solidale con il terreno quando il bambino lancia la pallina: –Verso l’asse di rotazione della giostra –In direzione radiale –In orizzontale a 90° dalla direzione radiale.\u000077",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#77": "Impostazione della soluzione\n\u000078\nxy  x’y’O=O’r\nvʹ!\n'vvrω=+×!!!!\nCaso 2:Caso 3:5(/)vms=!!rO'=!0,!ω=costante=0.5ˆk!r=!ʹr=4ˆι(m)\n!v=−3ˆι+0.5⋅4ˆk∧ˆι=−3ˆι+2ˆjCaso 1:!ʹv=3ˆk(m/s)\n!v=3ˆk+0.5⋅4ˆk∧ˆι=3ˆk+2ˆj!ʹv=−3ˆι(m/s)\n!ʹv=3ˆj(m/s)\n!v=3ˆj+0.5⋅4ˆk∧ˆι=5ˆj!v=13 (m/s)!v=13 (m/s)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#78": "Esercizio •Calcolare i moduli delle velocità e dell’accelerazione di un corpo fermo sulla superficie terreste a 45° di latitudine rispetto ad un SR con origine nel centro della terra e assi rivolti verso le stelle fisse.\n\u000079",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#8": "\u00009Velocità scalare media ed istantanea\nVelocità scalare istantanea\nVelocità scalare mediavm⎡⎣⎤⎦=v⎡⎣⎤⎦=ΔsΔt⎡⎣⎢⎤⎦⎥=L/T⎡⎣⎤⎦=LT−1⎡⎣⎤⎦→(m/s)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\03-cinematica.pdf#9": "\u000010Velocità vettoriale media ed istantanea\nVelocità vettoriale media Velocità vettoriale Istantanea",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#0": "Moti in SR NON INERZIALI CdS Ingegneria Informatica A.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#1": "LAURA FABBRI  -\nMoti in SR in moto relativo: cinematica\n!7Cinematica: movimento è un concetto relativo, legato al SR scelto.ES: oggetto lasciato cadere sul vagone di un treno in moto:  - Cade lungo la verticale per un osservatore sul treno,  - Compie una traiettoria parabolica per osservatore a terra.Entrambi i moti sono veri rispetto al loro SR.  Cambia la descrizione di posizione, velocità…. Un SR può essere solo più “conveniente” computazionalmente\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#10": "LAURA FABBRI  -\nCosa misura una bilancia  in ascensore?\n!50\nAscensore fermo:Ascensore in salita con      costante. Se l’ascensore sale, un corpo fermo in esso sentirà una forza fittizia diretta come  Ascensore in discesa con      costante. Se l’ascensore scende, un corpo fermo in esso sentirà una forza fittizia diretta come  Caso limite: caduta libera→P→/u1D445/u1D463’’",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#2": "LAURA FABBRI  -\nMoti in SR in moto relativo: dinamica\n!11Due principi fondamentali:•Tutti i sistemi di riferimento inerziali sono equivalenti;•Nei SRI le leggi della fisica sono le stesse e per il secondo principioCosa succede se studio il moto in un SR NON INERZIALE?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#3": "LAURA FABBRI  -\nMoti in SR Non inerziali\n!14\nEs: treno in moto con velocità costante. Ragazzo seduto sul treno con un cubetto di ghiaccio sul vassoio. Due SR: S solidale a un osservatore a terra    S’ solidale con l’osservatore sul trenoIn S: sul cubetto non agisce nessuna forza -> si muove con la stessa velocità del SRIn S’: sul cubetto non agisce nessuna forza -> è fermo nel SR ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#4": "LAURA FABBRI  -\nMoti in SR Non inerziali\n!19\nSe treno in moto decelera improvvisamente….In S’ il cubetto vola fuori dal vassoio come se fosse sottoposto a una forza in avanti. È reale?Forza reale: attrito esercitato tra treno e binari, che ha coinvolto tutti gli oggetti solidali al treno in moto. Forza non ha agito sugli oggetti sul treno non solidali ad esso. Moto improvviso non dovuto a forze sull’oggetto ma a forze sul SR che non è più inerziale",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#5": "LAURA FABBRI  -\nSistemi di riferimento non inerziali\n!23•Esiste una classe di sistemi di riferimento in cui NON vale il secondo principio della dinamica: sistemi di riferimento non inerziali •I SR non inerziali sono tutti quelli in moto accelerato rispetto ad un SRI. Es: veicolo in partenza, veicolo in frenata, piattaforma rotante….•Nel SR non inerziale compaiono forze dette fittizie dovute all’accelerazione del nuovo SR.•In un SR non inerziale possiamo scrivere il secondo principio a patto di usare come risultante delle forze sia quelle reali che quelle fittizie",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#6": "LAURA FABBRI  -\nForze fittizie\n!30\n‘‘‘‘‘‘‘SS’\nForza di CoriolisForza centrifuga→/u1D439′\u0000=/u1D45A→/u1D44E′\u0000(/u1D461)=/u1D45A(→/u1D44E−→/u1D44E/u1D450/u1D45C−→/u1D44E/u1D461)S’: sistema di riferimento mobileS: sistema di riferimento fermoUn osservatore in S’ direbbe che sul corpo agisce una forza        tale che:Corpo in S sente una forza reale \nForza fittizia",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#7": "LAURA FABBRI  -\nForza centrifuga\n!35\n-In S (SRI) solidale alla strada agisce una forza reale: forza centripeta;-Oggetti dentro la macchina non sentono l’azione dell’attrito fra ruote e strade e tendono a mantenere il moto rettilineo per il primo principio.  -In S’ (SR NON I) solidale alla macchina: osservatore dentro la macchina si sente spinto verso l’esterno dalla forza centrifuga: •Forza fittizia; •Stesso modulo e direzione della forza centripeta ma verso oppostoForza a cui è soggetto un corpo in moto curvilineo: es macchina in curva",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#8": "LAURA FABBRI  -\nForza di Coriolis\n!40Piattaforma che ruota con velocità angolare costante e corpo lanciato radialmente con velocità iniziale non nulla.In S SRI solidale al terreno moto della pallina rettilineo uniforme poichè non agiscono forze (primo principio).In S’ SR non I solidale alla piattaforma: pallina risente della forza fittizia di CoriolisyxˆjˆiForza a cui è soggetto un corpo in moto in un sistema di riferimento in rotazione\nTraiettoria circolare verso destra rispetto osservatore in S’→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′\u0000\n→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′\u0000=−2/u1D45A(/u1D714^/u1D458)×(/u1D463^/u1D456)=−2/u1D45A/u1D714/u1D463^/u1D457",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-MotiNonIneriziali.pdf#9": "LAURA FABBRI  -\nForza di Coriolis\n!45\n•Le masse d’aria si spostano dall’alta pressione H alla bassa pressione L: vento di ciclone; •H e L separate di 1000 km; •Emisfero settentrionale: correnti d’aria tendono verso L deviando a destra; •Vortice ciclonico che ruota in senso antiorario nell’emisfero nord e in senso orario nell’emisfero sudResponsabile di molti fenomeni visibili: •Sbilanciata usura dei binari dei treni orientati secondo i meridiani: treno da nord a sud usura maggiormente il binario di destra; •Moto dei gravi su lunghe distanze (missili…); •Circolazione dei venti→/u1D439/u1D450/u1D45C=−2/u1D45A→/u1D714×→/u1D463′\u0000",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#0": "Forza: dinamometro•Definizione operativa della forza. •Dinamometro: strumento graduato contente una molla ideale, elastica, deformabile.\n!1\n0\n01\n02\n03Calibrazione del dinamometro tramite peso campione: unità kg-forza",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#1": "Modello del filo inestensibile•Filo ideale senza massa, in grado di trasportare una forza (TENSIONE) senza allungarsi.\n!2\n01\n01\n01\n01\nIl filo è in grado di trasportare una tensione.  Il dinamometro si allinea al filo.Ciò che misura un dinamometro è un vettore: -Direzione (del filo) -Verso (il filo tira) -Intensità (scala graduata)La forza è un vettore",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#10": "Esercizio 2•Un acrobata, stando nel punto di mezzo di una fune lunga 18 m, esercita una forza di 700 N e fa abbassare la fune di 1.5 m rispetto alle estremità. Determinare la tensione T della fune.\n!11\nP!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#11": "Esercizio 3•Una sfera di peso 4 kg-f si ferma tra due piani inclinati di 30° e 60°. Determinare le reazioni vincolari delle superfici.\n!12\nP!\nP!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#2": "03\nCome funziona un dinamometro?•Il dinamometro misura una forza       esterna generando una forza         tale che\n!3\n03\nF!F−!dinFkl=−Δ!!\"\"Legge di HookeestF!dinF!\n0estdinFF+=!!!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#3": "Natura vettoriale delle forze\n!4\n02\n03\n021F!2F!3F!23FF+!!1230FFF++=!!!!In condizioni statiche! (Macchina di Atwood)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#4": "Quiete, equilibrio e statica\n!5Equilibrio: se un sistema (insieme di punti o di corpi) inizialmente quiete in un dato SdR, pur soggetto a forze rimane in quiete, allora esso si trova in uno stato di equilibrio.Quiete: un punto (o un corpo) è in quiete in un dato SdR, se il punto (o ogni punto del corpo) ha una velocità nulla in ogni istante di tempo (è e rimane fermo). Assenza di velocità!\nStatica: studio delle forze nei sistemi in stato di equilibrioEquilibrio stabile: piccole variazioni nel sistema portano a piccoli spostamenti dalla posizione di equilibrio Equilibrio instabile: piccole variazioni nel sistema portano a grandi spostamenti\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#5": "Statica del punto materiale•Risultato sperimentale: il punto è in quiete se:\n!61F!2F!\n3F!1234RFFFF=+++!!!!!\n4F!\n12340RFFFF=+++=!!!!!!Risultante delle forze applicate al puntoCondizione necessaria per l’equilibrio di un punto materiale è che si annulli la risultante        di tutte le forze ad esso applicate.R!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#6": "Studio statico delle forzeFORZA PESO\n!7\n01!P!FdinIdea: applicare ad un corpo una forza tramite il dinamometro, adattando verso, direzione e modulo fino a raggiungere l’equilibrio!Fdin+ EQ ⇒!R=0!R=!Fdin+ ?\nAd ogni punto materiale posto in prossimità della superficie terrestre risulta applicata una forza diretta lungo la verticale, verso il basso, con intensità dipendente dal corpo materiale.!P=−!Fdin",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#7": "REAZIONE VINCOLARE\n!8\n!P!RV!P+ EQ ⇒!R=!P+!RV!RV=−!P\n!F\nQuando la superficie di un corpo materiale C, giungendo a contatto con la superficie di un corpo materiale V (vincolo) esercita su tale superficie una forza perpendicolare F, determina una deformazione di V che esercita a sua volta su C una forza RV uguale e contraria ad F   㱺  RV: normale alla superficie, uscente e di modulo dipendente dalla forza applicata F  CV!RV",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#8": "!9Un vincolo impedisce alcuni movimenti del corpo considerato e ne consente altri (es.: rotaia treno, cardine porta, piano su cui è appoggiato un oggetto, ecc.). Per impedire i movimenti vietati dei corpi, i vincoli debbono esercitare sui corpi delle forze, dette forze vincolari o reazioni vincolari.Le forze vincolari sono a priori sconosciute, in quanto debbono adeguarsi alle circostanze per neutralizzare le forze attive che potrebbero causare movimenti vietati.\nVincolo",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica-integrazione.pdf#9": "Vincoli ideali o lisci•Vincolo ideale o liscio: vincoli che non offrono resistenza apprezzabile quando le forze tendono a produrre degli spostamenti tangenziali rispetto alla loro superficie\n!10\nPF!VR!\nPF!VR!•In caso contrario, se c’è resistenza ai movimenti tangenziali, parleremo di vincolo scabro (forze d’attrito)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#0": "DINAMICA CdS Ingegneria InformaticaA.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#1": "Concetto di forza\n\u00002Grandezza ﬁsica vettoriale (intensità, direzione, verso e punto di applicazione): vettore applicatoLe forze possono produrre variazioni dello stato di moto degli oggetti su cui agisconoLe forze possono deformare i corpi su cui agisconoLe forze possono compensarsi, determinando situazioni di equilibrioLe forze si presentano sempre in coppia: derivano sempre da interazioni tre i corpi, che esercitano forze l’uno sull’altro",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#10": "Formulazione esplicita del 2° principioNewton: “La forza è uguale alla massa per l’accelerazione.\" \n\u000011\nIn un sistema di riferimento inerziale, la forza complessiva (totale, risultante) che agisce su un corpo materiale di massa m è tale che:Fma=!!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#11": "Unità di misura della forza\n\u0000122o Principio Unità di misura della massa nel sistema internazionale: chilogrammo (kg) Prototipo: cilindro di platino-iridio c/o Bureau International des Poids et Mèsures a Sèvres dal 22/5/2019 nuova definizione basata sulla costante di PlankUnità di misura della forza nel sistema internazionale: Newton (N) Corrisponde alla forza che, agendo su una massa di 1 kg le imprime un’accelerazione di 1 m/s2Unità di misura della forza nel sistema tecnico: chilogrammo-forza (kgf) È il peso del cilindro di cui sopra,nei luoghi in cui g=9,80665 m/s2, detto valore “standard”Per convenzione\nDerivata per definizione\n1kgf9.80665N;1N0.101972kgf==Per convenzione\n!F=m!a\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#12": "Forza peso: misura della massa inerzialeN corpi con pesi\n\u000013\na!!P29,8 m/sag==!12,,,NPPP!!!…12Naaag====!!!…12,,,Naaa!!!…cadono con accelerazionig=!Pmg=!!Osservazione sperimentale valida (con opportune approssimazioni) in ogni punto della Terra.Approssimazioni: ignoro gli attriti, la forma non sferica della terra, considero di essere in un SRI",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#13": "Misura della massa inerziale\n\u000014Presa una massa campione      ho anche un peso campionecmccPmg=!!\nPmg=!!cP!cRPλ=!!ccPRPPλ==!!!!cccPmgmmgmPλ===!!!!Condizione di equilibrio:cPRPλ==!!!\nccPmmP=!!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#14": "Principi fondamentali•Il secondo principio NON è una definizione di forza\n\u000015•SdR: Inerziale•La forza è ciò che indica il dinamometro•La massa è una proprietà dei corpi•L’accelerazione è una caratteristica cinematicaFma=!!•In ogni SRI vale:Fma=!!\n''SSaa=!!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#15": "Indipendenza delle azioni simultanee\n\u000016\nTTFma=!!11Fma=!!22Fma=!!12FF=+=!!()12Tmaama=+=!!!2a!1a!\nOgni forza produce un effetto indipendentemente dalla presenza di altre forze.L’effetto complessivo è dato dalla risultante di tutte le forze applicate.",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#16": "Relazione tra moto e cause•Tutti i problemi di determinazione del moto di un corpo a partire dalle forze che agiscono sono problemi inversi di cinematica\n\u000017Fma=!!Fam=!!nototrovare (),  ()atrt=v!!!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#17": "Moto circolare uniforme\nnF!Rappresentazione intrinseca della forza\nMoto rettilineo\n\u000018\nˆtuˆnuF!tF!\nˆˆtnttnnFFFfufu=+=+!!!ˆˆ()ttnnFmamauau==+!!2forza tangenteforza centripetattnnfmafmamR===v00tnffR≠=→=+∞200/tnnffRmf=≠→=vˆˆttnnaauau=+!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#18": "Moto circolare uniforme\n\u000019\nF!r!v!drrdtω==×v!!!!costanterRωω===v!!!22costanteaRRωω====vv!!!??2nnFmafmamRω===!!\nv!T!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#19": "Caduta dei graviGrave: punto materiale o oggetto in moto a causa del suo peso\n\u000020\nz\nhPmg=!!ˆkProblema: studiare la caduta di un grave di massa m che parte da fermo da una quota hˆˆPmgmgkmzk==−=!!\"\"zg→=−!!0()(0)()tztzgdtʹ→=+−∫!!()ztgt→=−!200()(0)(')'''2ttgztzztdthgtdtht→=+=−=−∫∫!Legge oraria:2()2gztht=−Velocità:()ztgt=−!Tempo di caduta:2()0hhhzttg=→=vmax=v(th)=2gh",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#2": "Concetto di forza\n\u00003Forze di contattomacroscopicamente sono associate ad un contatto tra corpi interagenti (es. spinta di un oggetto, forze elastiche)Forze a distanzaLe interazioni avvengono senza contatto (forza peso, forze elettriche e magnetiche)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#20": "Tutti i corpi cadono nello stesso modo\n\u000021Tempo di caduta:2()0hhhzttg=→=\n11Pmg=!!22Pmg=!!33Pmg=!!1ag=!!2ag=!!3ag=!!vmax=v(th)=2gh",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#21": "Un punto materiale inizialmente (per t=0 s)  fermo in y=0  è soggetto ad una accelerazione pari a                         nell’intervallo di tempo 0 < t < 𝜏 ,                              nell’intervallo di tempo 𝜏 < t < 2𝜏  e a(t) = 0 per t >2𝜏, con a0 = 0.5 m/s2 e 𝜏 = 2 s.                                      Determinare la velocità e la posizione nell’istante t = 4𝜏.             \nEsercizio\n\u000022()()otatyaτ==!!()(2)otatyaτ==−!!v(4τ)=a0τ=1m/sy(4τ)=3a0τ2=6m",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#22": "Piano Inclinato liscio\n\u000023\nP!\nVR!tP!nP!sintPPα=!\nαcosnPPα=!hcosVnNRPPα===!!\n\u000023|⃗PT|=Psinα=mgsinα=maa=gsinαcostante:moto unif. accel.Lunghezza del pianoL=hsinαs(t)=s0+vot+12at2L=hsinα=12gsinαt2v(t)=v0+att=2Lgsinα=2hgsin2αv(t)=gsinα2hgsin2α=2ghs0=0v0=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#23": "Forza elastica / Legge di Hooke•k costante elastica della molla. [k]=[MT-2]\n\u000024\n03\n0\nXF!\nF!0F=!!ˆ()Ffxι=!(0)0f=0,()0xfx><0,()0xfx<>ˆFkxι=−!()fxx\nFkr=−!!0()Fkrr=−−!!!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#24": "Oscillatore armonico unidimensionale\n\u000025\n0\nmˆFkxι=−!ˆaxι=!\"\"Fmakxmx=→−=!!\"\"0mxkx→+=!!0kxxm+=!!2pongo  0kmω=>20xxω+=!!\nx+l-l\n0(0)cos()xlφ=\n0()cos()xtltωφ=+kmω=\n000arctanxφω=−v()0220lxω=+v22mTkππω==SRIEquazione oraria ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#25": "Regime delle piccole oscillazioni•Osservazione: ogni sistema in prossimità di un punto di equilibrio stabile si comporta come un oscillatore armonico\n\u000026ˆ()Ffxι=!()fxx\n()0fx=Punti di equilibrioAB()0Bfxʹ>xB punto instabile\n()0Afxʹ<xA punto stabile\n()2()()()()()AAAAfxfxfxxxOxxʹ+−+−!()()AAxxfxkxx→⎯⎯⎯→−−Moto oscillatorio attorno al punto di equilibrio stabile xA2():;2()AAkfxmTmmfxωπʹ−===ʹ−",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#26": "Pendolo sempliceGalileo: osservazione del moto del lampadario nel Duomo di Pisa\n\u0000271.Ampiezza max a DX = SX2.Il periodo del pendolo (T) è  indipendente dall’ampiezza massima3.Il periodo non dipende dalla massa ma solo dalla lunghezza del ﬁlo\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#27": "Pendolo semplice\n\u000028\nMetodo: 1.“Inquadrare” il problema 2.Scrivere la F = ma  3.Individuare il SdR migliore  4.Scrivere le equazioni parametriche 5.Integrare 6.Calcolare le costanti arbitrarie\n0v!Ol\nC\nθslθ=\ngmP!!=VR!RgmF!!!+=\nˆtuˆnu21ˆˆtnasusuρ=+!\"\"\"\n0(0)(0)0(0)(0)lslslρθθ=====v!!ˆˆsinttmsumguθ=−!!sin0glθθ+=!!()2ˆˆcosnVnsmumgRulθ=−+!2cosVmlmgRθθ+=!\nam!=\nPiccole oscillazioni (sinθ ≅ θ )0glθθ+=!!\n()0()singlttglαθαωω⎧=⎪=⎨=⎪⎩v\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#28": "Pendolo semplice II\n\u0000292cosVRmlmgθθ=+!()0()singlttglαθαωω⎧=⎪=⎨=⎪⎩v()2221122()cos,cos11sintttθαωωθθαω=−=−!\"()()222222223122cos1sin1sinVRmltmgtmgtαωωαωααω=+−=+−Durante il moto, la reazione vincolare cambia. ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#29": "Nota storica•Le oscillazioni di un pendolo hanno costituito un primo sistema meccanico per misurare il tempo\n\u000030Esercizio pratico per casa:Costruire un pendolo e misurare l’accelerazione di gravitàElementi: punto ﬁsso, ﬁlo, massa, cronometro, metro\nL22/TLgππω==\n224LgTπ→=22/TLgππω==\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#3": "Forze fondamentali\n\u00004\nLa maggior parte delle forze sono riconducibili alla forza elettromagnetica •Forze di contatto (attrito, viscosità, reazioni vincolari) •Forze elastiche •Forze chimiche (molecolari e biologiche) Ad oggi sappiamo che esistono 4 forze fondamentali della natura",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#30": "Forza di attrito statico\n\u000031\nP!VR!\n03\nF!Se il corpo NON si sposta nonostante la forza orizzontale introduciamo una nuova forza di attrito: l’attrito staticoASF!Caratteristiche: E’ una forza di contatto; di entità NON nota a priori.E’ una caratteristica delle superﬁci (secche, non lubriﬁcate) Ma non dipende all’area di contatto !Dipende da tutte le forze agenti sui corpi.Quando esiste in condizioni statiche, annulla sempre la risultante.Per ogni situazione esiste un valore massimo della forza. \nVincolo ruvido!vincoli o superﬁciNON ideali",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#31": "Forza di attrito statico\n\u000032\nP!VR!\n03\nF!ASF!0ASFF+=!!!maxmax:ASASASFFF∃≤!maxASSFNµ=N: forza perpendicolare alle superfici      forza di carico µS: coefficiente di attrito staticoVNRP==!!Tipicamente:0.011Sµ<<",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#32": "Piano inclinato ruvidoProblema: sapendo che                , qual è il valore massimo di α per cui il corpo NON si muove?\n\u000033\nP!\nVR!tP!nP!sintPPα=!\nαcosnPPα=!hSe il corpo non si muove nonostante la presenzadi una forza non bilanciata                     allora esiste una forza di attrito staticosintPPα=!ASF!0tASPF+=!!!cosVnNRPPα===!!maxcosASSSFNPµµα==maxtASASPFF==!!maxsincosASASSPFFPαµα→===!sintancosSαµαα→==0,5Sµ=arctan0,463646...0,46Sradαµα→==→=26,565...27α→==°\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#33": "Importanza dell’attrito statico\n\u000034\nASF!,av!!\nPF!ASF!\nASF!VR!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#34": "Importanza dell’attrito statico\n(/)(/)1SSrocciametallogommaasfaltoµµ≈≪Indipendente dall’area di contattoASF!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#35": "EsercizioUn mattone è appoggiato su una scanalatura rettilinea ruvida inclinata di un angolo α=35° rispetto ad un piano orizzontale e raccordato nel punto B con un pavimento orizzontale. Le due superfici hanno lo stesso coefficiente di attrito cinetico µc = 0,4. All’istante t = 0 il mattone viene lasciato in quiete da una altezza h = 3 m (punto A). Studiare il moto del mattone calcolando la velocità massima e la lunghezza totale del percorso.\n\u000036\nαhABC\nmax?vLABBC=+\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#36": "Esercizio – Passo 1\n\u000037\nαhAB\nP!\nVR!tP!nP!ADF!ˆιa!iADtFFPma=+=∑!!!!ˆsintPmgαι=!ˆˆcosADCCFNmgµιµαι=−=−!ˆaxι=!\"\"(sincos)ADtCFPmamxmgmgαµα+=→→=−!!!\"\"2(sincos)2,41 m/sCxgaαµα=−==!!()(0)(')'xtxxtdtat=+=∫!!!!2()(0)(')'2txtxxtdta=+=∫!x0,/sinABxxhα==\n222:()2,08 s 2sinsinBBBBthxhtxtataaαα==→===max2:()25,02 m/sBBBBxxtataaxa====v!/sin5,23 mBxhα==",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#37": "Esercizio – Passo 2\nDistanza percorsa: \u000038C\nˆιADF!\nP!VR!v!BiADtFFPma=+=∑!!!!0tP=!!ˆˆADCCFNmgµιµι=−=−!ADtCFPmamxmgµ+=→→=−!!!\"\"23,92 m/sCxgaµ=−=−=−!!()(0)(')'Bxtxxtdtat=+=−∫v!!!!2()(0)(')'2Btxtxxtdtta=+=−∫v!()0Cxt=→!/1,28 sCBta==v8,45 mBCDxx=+=xxC=vBtC−atC22=vB22a=3,22 m",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#38": "Esercizio•  Una pallina di massa M=0,2 kg è ferma tra una superficie verticale ed un piano inclinato di un angolo α=15°, come mostrato in figura. Determinare le reazioni vincolari della superficie verticale e del piano inclinato.\n\u000039\nα2VR!1VR!1tan0,52550,526VRmgNNα===…2/cos2,03..2,03VRmgNNα===",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#39": "Un punto materiale inizialmente (per t=0 s)  fermo in y=0  è soggetto ad una accelerazione pari a                         nell’intervallo di tempo 0 < t < 𝜏 ,                              nell’intervallo di tempo 𝜏 < t < 2𝜏  e a(t) = 0 per t >2𝜏, con a0 = 0.5 m/s2 e 𝜏 = 2 s.                                      Determinare la velocità e la posizione nell’istante t = 4𝜏.             \nEsercizio\n\u000040()()otatyaτ==!!()(2)otatyaτ==−!!v(4τ)=a0τ=1m/sy(4τ)=3a0τ2=6m",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#4": "Galileo Galilei (1564-1642)Qual è il moto di un corpo non soggetto ad alcuna forza?\n\u00005\n!P!RV!v=costSe riusciamo ad eliminare tutti gli attriti PRINCIPIO DI INERZIA",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#40": "EsercizioUn proiettile di massa M viene sparato orizzontalmente da un cannone fermo posto su una altura che si eleva di h=50 m rispetto alla pianura circostante. Determinare: 1)il modulo v  della velocità con cui si deve sparare il proiettile affinché colpisca un bersaglio nella pianura e che dista orizzontalmente dal cannone di D=250 m; 2)l’angolo con cui il proiettile colpisce il bersaglio;  3)la velocità scalare del proiettile quando colpisce il bersaglio.\n\u000041vf=D2g2h+2gh=84m/stanα=vyvx=2hD=0,4⇒α=21,8°v0=Dg2h=78,3m/s",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#41": "EsercizioUna molla ideale, di costante elastica k, è sospesa in verticale tramite un aggancio in alto. Ad un certo istante (t=0) si applica una massa m all’altro estremo della molla, che viene quindi lasciata libera. Trovare il moto del punto nella direzione verticale. In presenza di un piccolo attrito, dove si fermerà il punto?\n\u000042\nxzBOPbz\neF!\nPF!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#42": "EsercizioIl sistema meccanico in ﬁgura è costituito da tre corpi uguali di massa m, un ﬁlo inestensibile ed una superﬁcie ruvida con coefﬁciente di attrito statico 0.6 e coefﬁciente di attrito cinetico 0.4. Determinare: 1) se il sistema è in condizioni di staticità; 2) la tensione nel ﬁlo; 3) cosa succede se il corpo 3 è eliminato dal sistema.\n\u000043\n3\n2\n1\nˆTmgι=!ˆPmgj=−!ASF!max2ASASSSFFNmgµµ<==!Statica ?0ASTF+=!!!maxASASTFF=<!!?21.2cmgmgmgµ→<=1. Si, il sistema è in equilibrio statico. max1.2ASASFmgFmg=<=!ˆTmgι=!3. maxASASTFF=<!!?0.6cmgmgmgµ→<=No: il sistema non è statico e si muove",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#5": "Primo Principio della Dinamica\n➡criterio cinematico per stabilire quando su di un punto materiale non agiscono forze. \n\u00006\nSe in un dato sistema di riferimento la risultante delle forze applicate ad un punto materiale è nulla allora il punto materiale o rimane in quiete o si muove di moto rettilineo uniforme.Il moto è relativo:Si muove rispetto a cosa? \nSistema di riferimento inerziale \nFormulazione moderna Esiste almeno un sistema di riferimento, detto “inerziale” (SRI), rispetto al quale un qualunque punto materiale che sia sufficientemente lontano da tutti gli altri corpi, o rimane in quiete o si muove di moto rettilineo uniforme.“Principia”  di Newton:\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#6": "Classe di Sistemi di Riferimento Inerziali\n\u00007Sia dato un punto su cui non agiscono forze in un SRI   S:  il punto si muove di moto rettilineo uniforme in S:      = costante\nxyzx’y’z’\n''aaSS=!!P(t)O’Ov!v!SdR S’ in moto rettilineo uniforme\nS’ è un sistema di riferimento inerzialeTrasformazioni di Galileo!vO'=costante,!ω=!0!vO'x(t)=x'(t)+vO'xty(t)=y'(t)+vO'ytz(t)=z'(t)+vO'zt!v(t)=!v'(t)+!vO'vx(t)=vx'(t)+vO'xvy(t)=vy'(t)+vO'yvz(t)=vz'(t)+vO'z⎧⎨⎪⎩⎪!v'=!v−!vO'=costante",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#7": "Esiste un SRI privilegiato?S ed S’ sono due SRI: come posso distinguerli sperimentalmente operando solo all’interno di un SRI ?\n\u00008\n''aaSS=!!\nR: No, non esiste un SRI privilegiato\nPrincipio di relatività galileiano Tutte le leggi della fisica si scrivono nello stesso modo in ogni sistema di riferimento inerziale.\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#8": "Approssimazioni di SRI1.Sistema solidale alla terra (SR principale in statica) 2.Sistema con origine nel centro della terra e assi rivolti verso le “stelle fisse”  3.Sistema con origine nel centro del Sole e assi rivolti verso le stelle fisse 4.Sistema con origine nel centro della nostra galassia e assi rivolti verso le galassie più lontane \u00009()'2oCOTaarraaaaωωωωʹʹʹʹʹ=+×+×+××+=++v!!!!!!!!!!!!!\"22221 d,6370 km,0,035 m/sTTRarRTπω⎛⎞=====⎜⎟⎝⎠622356 d1 y,15010 km,0,0059 m/sTTRarω=====i22200 Ma,26000 al,0,00000000025 m/sTTRarω====\n29.8 m/sg=",
    "data_test\\rootfolder\\università\\FisicaGenerale\\04-dinamica.pdf#9": "Principi fondamentali\n\u000010\n2o Principio Un qualunque punto materiale che sia sottoposto ad una o più forze ha un’accelerazione vettorialmente proporzionale alla risultante di tali forze.\namF!!=CausaEffettoRisulta essere: -Positiva -Indipendente da posizione e velocità -Proprietà additiva dei corpi12Tmmm=+Massa inerziale ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#0": "LAVORO ed ENERGIA CdS Ingegneria Informatica A.A. 2019/20\n1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#1": "Lavoro ed Energia: definizioni intuitive•Lavoro: caratteristica di una forza di operare uno spostamento •L’energia è la capacità di produrre lavoro •Il lavoro è il processo attraverso il quale una certa quantità di energia si trasferisce da un corpo a un altro. •Ingredienti per una definizione più rigorosa di Lavoro: forza e movimento",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#10": "Lavoro di una forza elastica\n11\nEsempio: lavoro compiuto da una molla compressa da l1 fino all’ espansione l2δℒ=⃗F⋅d⃗l=(−kx̂ı)⋅(̂ıdx)=−kxdx(̂ı⋅̂ı)=−kxdxℒ1,2=∫x2x1⃗F⋅d⃗l=−k∫x2x1xdx−k[x22]x2x1=−k2x22+k2x21=−k2(l2−l0)2+k2(l1−l0)2ℒ1,2=−k2(x22−x21)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#11": "Lavoro della forza peso\n12\nSARA VALENTINETTI  -\nStessa conclusione se al posto del piano inclinato abbiamo un profilo curvo.Lavoro infinitesimoLavoro totale\n𝑧1𝑧2 ℒ1,2=mghh = differenza di quota a cui si porta il punto\n𝑑𝑙𝑧1𝑧2Esempio: punto materiale di massa m scivola su un piano liscio inclinato di un angolo  da un punto P1 a un punto P2 a differenza di quota hδℒ=⃗F⋅d⃗l=(−mĝk)⋅(̂ıdx+̂kdz)==−mg(̂k⋅̂ı)−mg(̂k⋅̂k)=−mgdzℒ1,2=∫P2P1⃗F⋅d⃗l=−mg∫z2z1dz=−mg(z2−z1)=mgh>0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#12": "Proprietà additiva dei lavori\n13Punto materiale soggetto a N forze, equivale a un punto soggetto alla risultante delle forzeLavoro infinitesimo di ciascuna forza:Lavoro infinitesimo totale:Date n forze Fi , applicate allo stesso punto P, che si muove lungo una propria curva  dal punto A al punto B,  il lavoro complessivo è dato da….ℓLo spostamento è lo stesso per ogni forza perché agiscono tutte sulla stessa particella che compie un tratto di traiettoria.\nSomma dei lavori delle singole forze.δℒ=⃗F⋅d⃗lδℒtot=δℒ1+δℒ2+...=⃗F1⋅d⃗l+⃗F2⋅d⃗l+...=(⃗F1+⃗F2+...)⋅d⃗l=(∑i⃗Fi)⋅d⃗l=⃗R⋅d⃗lℒℓtot=∫BAℓ⃗R⋅d⃗l=∫BAℓ(∑i⃗Fi)⋅d⃗l=∫BAℓ(∑i⃗Fi⋅d⃗l)=∑i∫BAℓ⃗Fi⋅d⃗l=∑iℒℓi",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#13": "Potenza di una forzaDef: capacità di produrre lavoro per unità di tempo\n14•Per un punto materiale:Nuova definizione di lavoroLavoro compiuto da una forza per unità di tempo durante un intervallo di tempo infinitesimo P=δℒdtP=δℒdt=⃗F⋅d⃗ldt=⃗F⋅d⃗ldt=⃗F⋅⃗vP=⃗F⋅⃗vδℒ=Pdt⟹ℒ=∫Pdt",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#14": "Analisi dimensionale\n15LavoroL⎡⎣⎤⎦=F⋅ds⎡⎣⎤⎦=N⋅m⎡⎣⎤⎦=kg⋅ms2⋅m⎡⎣⎢⎤⎦⎥=MLT−2L⎡⎣⎤⎦⇒L⎡⎣⎤⎦=ML2T−2⎡⎣⎤⎦Unitá di misura: SI-MKS  Joule(J)=N⋅mPotenzaP⎡⎣⎤⎦=LΔt⎡⎣⎢⎤⎦⎥=F⋅dsΔt⎡⎣⎢⎤⎦⎥=N⋅ms⎡⎣⎢⎤⎦⎥=kg⋅ms2⋅m⋅1s⎡⎣⎢⎤⎦⎥=MLT−2LT−1⎡⎣⎤⎦⇒P⎡⎣⎤⎦=ML2T−3⎡⎣⎤⎦Unitá di misura: SI-MKS  Watt(W)=Joule/s",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#15": "Esercizio\n16Determinare la potenza istantanea sviluppata durante la caduta su un piano inclinato di un angolo  alto h da un punto A in cima al piano ad un punto B in fondo al piano da un punto materiale di massa m.α",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#16": "Teorema delle Forze Vive\n17\nEs: Corpo in moto con velocità  su piano orizzontale liscio contro molla. Corpo comprime molla perdendo velocità. Molla esercita forza tale che  e  opposti e       v⃗Fdxℒ<0•Lavoro: scalare legato alla forza e allo spostamento •Maxwell: “il lavoro è l’atto con cui viene realizzata una modificazione (deformazione o spostamento) nella configurazione di un sistema materiale contro le forze che a questa modificazione si oppongono” •Il lavoro è una forma di energia. Es: macchina che compie lavoro trasferisce energia da un corpo all’altro.",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#17": "Teorema delle Forze Vive\n18•Lavoro: scalare legato alla forza e allo spostamento •Maxwell: “il lavoro è l’atto con cui viene realizzata una modificazione (deformazione o spostamento) nella configurazione di un sistema materiale contro le forze che a questa modificazione si oppongono” •Il lavoro è una forma di energia. Es: macchina che compie lavoro trasferisce energia da un corpo all’altro.\nAlla fine del moto il corpo è fermo e molla compressa esercita forza che tende a ridistenderla, in grado di rimettere in moto il corpo. In questo caso  e  hanno stesso verso e     ⃗Fdxℒ>0Relazione fra velocità e lavoroSperimentalmente  ⃗vfinale=−⃗viniziale",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#18": "Teorema delle Forze Vive\n19Descrive il lavoro compiuto da un sistema di forze qualunque (attive, vincolari, interne, esterne, di interazione o apparenti), su un sistema meccanico qualunque (puntiforme, esteso, rigido, non rigido, vincolato, ecc.). Teorema delle forze vive per il punto materiale:Lavoro compiuto da tutte le forze per spostare corpo da A a B lungo un tratto di traiettoriaSostituisco la definizione di d⃗lProprietà delle derivate principio: risultante di tutte le forzeℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅d⃗ld⃗l=⃗vdt⟹ℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅⃗vdtℒA,B=∫BA⃗F⋅d⃗l=∫BAmd⃗vdt⋅⃗vdt=∫BAm12dv2dtdt=12m∫BAdv2=12m[v2]BA=12mv2B−12mv2A",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#19": "Teorema delle Forze Vive\n20Il lavoro compiuto dalla risultante delle forze che agiscono su un sistema meccanico qualunque, nel passaggio da una configurazione A ad un’altra B, è uguale alla corrispondente variazione dell’energia cinetica di tale sistema.Se  forza ha accelerato il corpo compiendo un lavoro positivoℒ>0⟹vB>vA→Se forza ha decelerato il corpo compiendo un lavoro negativoℒ<0⟹vB<vA→Energia Cinetica: 1. Ha le dimensioni del lavoro       2. Non è  mai negativa  (T>=0)[𝑇]=[12𝑚𝑣2]=[𝑀𝐿2𝑇−2]→JouleT=12mv2ℒA,B=12mv2B−12mv2A=TB−TA",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#2": "Lavoro ed Energia: MacchineUna macchina è un dispositivo vincolato capace di spostare il punto di applicazione di una forza, chiamata “resistente”, sfruttando un’altra forza chiamata “motrice”.\nUna macchina “vantaggiosa” sposta il punto di applicazione di una forza resistente utilizzando una forza motrice di modulo più piccolo.carrucolapiano inclinatoleva",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#20": "Energia Potenziale\n21\nLavoro sul corpo (teorema delle forze vive):Corpo in moto su un piano orizzontale liscio contro una molla ideale •velocità iniziale del carrello v0,  •velocità finale nulla poiché comprime una molla che esercita una forza opposta allo spostamento del corpo provocandone l’arresto.ℒcorpo=Tfin−Tin=12mv2fin−12mv2in=0−12mv20<0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#21": "Energia Potenziale\n22•Molla inizialmente in quiete si comprime per effetto di una forza premente.  •Chi produce la forza compressiva è il carrello e l’entità della compressione è una misura della forza agente.  •Forza reagente della molla è uguale e opposta alla forza premente.Lavoro sulla molla (teorema delle forze vive):   \nDal punto di vista della molla…\nℒmolla=Tfin−Tin=12mv2fin−12mv2in=12mv20−0=−ℒcorpo>0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#22": "Energia Potenziale\n23•Corpo in ragione della velocità compie un lavoro positivo sulla molla comprimendola; •Energia di un corpo: possibilità di un corpo di compiere un lavoro positivo; •Energia del carrello in moto si trasferisce gradualmente alla molla; •Quando il carrello si ferma, tutta la sua energia cinetica iniziale è trasferita alla molla compiendo un lavoro positivo su di essa; •Molla immagazzina l‘energia del corpo comprimendosi; •Molla poi rilascia gradualmente l’energia immagazzinata distendensosi e imprimendo al corpo una velocità uguale e contraria: restituisce energia cinetica al carrello; •energia totale immagazzinata dalla molla ridiventa interamente energia cinetica",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#23": "Energia Potenziale\n24\n0Lavoro forza elastica:Molla compressa di una certa quantità a ad un certo tempo t>0Teorema forze vive:Uguagliando:Energia iniziale: cineticaEnergia totale istantanea durante la compressioneLavoro che sarebbe in grado di fornire la molla ridistendendosi -> misura dell’energia propria immagazzinata dalla molla: Energia potenzialeLa somma dell’energia cinetica e di quella potenziale si conserva IN QUESTO moto.ℒel=Tfin−Tin=12mv2−12mv20ℒel=∫finin⃗Fel⋅d⃗l=∫finin(−kx̂ı)⋅(̂ıdx)=∫finin−kxdx=−k[x22]finin=−kx2212mv2−12mv20=−kx22⟹12mv2+kx22=12mv20kx22",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#24": "Esercizio\n25Un blocco di ghiaccio è in moto su una salita inclinata di  Sapendo che all’inizio la sua velocità è pari a v = 9 m/s e che il coefficiente di attrito dinamico è pari a , di quanto si sposta lungo il piano inclinato il blocco di ghiaccio prima di fermarsi?α=6∘μc=0.07",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#25": "Esercizio\n26Un blocco P di massa m = 3 kg si muove di moto rettilineo su un piano orizzontale scabro nella direzione dell’asse di una molla non deformata, di cui va a colpire uno degli estremi, mentre l’altro è bloccato a un supporto verticale fisso. La molla, di costante elastica k = 300 N/m, viene compressa di  Sapendo che il coefficiente di attrito dinamico fra P e il piano è , determinare: 1) I lavori compiuti durante tale compressione dalla forza elastica e dalla forza di attrito; 2) Il modulo della velocità di P nel momento in cui colpisce la molla. δ=8cmμc=0.25",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#26": "Esercizio\n27Un cubetto P di massa m scivola lungo il segmento AB disposto lungo un piano inclinato di un angolo  rispetto alla direzione orizzontale. Il coefficiente di attrito dinamico passa dal valore massimo di ½ alla sommità A al valore 0 alla base B secondo una legge del tipo  dove e k sono costanti positive e s è la distanza da A di un generico punto di AB. Sapendo che  e che P è partito da fermo in A, calcolare il modulo v della sua velocità all’istante in cui arriva in B in termini di  e della variazione di quota h fra A e B.Ah𝛼B",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#27": "Alcuni concetti matematici\n28•Derivate parziali: primo e secondo ordine, miste… •Differenziali; •Campi: scalari, vettoriali…",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#28": "Derivate parziali\n29Se una funzione esiste per ogni valore della variabile nel dominio, derivate parziali al primo ordine:Se le derivate parziale al primo ordine esistono per ogni valore della variabile nel dominio, derivate parziali al secondo ordine:\nDerivate parziali miste (l’ordine non influenza)𝜕𝑧2Es: ∂f(x,y,z)∂xx0,y0,z0=limΔx→0f(x0+Δx,y0,z0)Δx∂f(x,y,z)∂yx0,y0,z0=limΔy→0f(x0,y0+Δy,z0)Δy∂f(x,y,z)∂zx0,y0,z0=limΔy→0f(x0,y0,z0+Δz)Δz∂2f(x,y,z)∂x∂y,∂2f(x,y,z)∂y∂z,∂2f(x,y,z)∂x∂zf(x,y,z)=x3−y2+3z",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#29": "DifferenzialiSia  una funzione a 3 variabili. Quanto varia il valore della funzione se ci spostiamo da un punto  a un punto infinitamente vicino  ?f(x0+dx,y0+dy,z0+dz)=f(x0,y0,z0)+∂f∂xP0dx+∂f∂yP0dy+∂f∂zP0dzDifferenzialedF=f(x0+dx,y0+dy,z0+dz)−f(x0,y0,z0)=∂f∂xdx+∂f∂ydy+∂f∂zdzPiù ordini successivi\n30",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#3": "Definizione di lavoro infinitesimo\n4\nP1P2\nxyzOLavoro infinitesimo compiuto da  durante uno spostamento infinitesimo   la quantità scalare:⃗Fd⃗lPer definire lavoro infinitesimo compiuto da una forza:In un intervallo di tempo   i, punto si sposta da P1 a P2 :    ΔtΔ⃗r=⃗r2−⃗r1-Regione di spazio in cui agisce  -Punto P si muove lungo linea curva   ⃗FℓSe  piccolo,             tangente ΔtΔ⃗r→d⃗l=̂utdlLavoro infinitesimo  perché non è un differenziale esatto (in generale non dipende solo dagli estremi in cui si integra).δLδℒ=⃗F⋅d⃗lΔ⃗rℓ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#30": "CampiCampo scalare: una grandezza scalare funzione delle coordinate spaziali U(x,y,z) definita ovunque dentro una certa regione di spazio. Superficie di livello: luogo geometrico dei punti dove la funzione scalare assume un valore costante prefissato  U(x,y,z) = costante -> infinite superficiCampo vettoriale: un vettore applicato funzione delle coordinate spaziali               definito ovunque dentro una certa regione di spazioLinee di forza: una o più linee sempre tangenti al vettore del campo. Le linee di forza sono più fitte dove il modulo del vettore è maggiore.31",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#31": "Campi di forze conservativi\n32In generale il lavoro di una forza per spostare un punto materiale su un tratto AB di traiettoria dipende dalla traiettoriayzx0AB..12Per il teorema delle forze vive:Le velocità agli estremi sono diverse a seconda che si percorra la curva 1 o la 2.ℒ1(A,B)=∫BA1⃗F⋅d⃗lℒ2(A,B)=∫BA2⃗F⋅d⃗l⟹ℒ1(A,B)≠ℒ2(A,B)ℒ1(A,B)=12m(vB)2−12m(vA)2ℒ2(A,B)=12m(v′\u0000B)2−12m(v′\u0000A)2⟹vB≠v′\u0000B⟹vA≠v′\u0000A",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#32": "Campi di forze conservativi\n33Campo di forza conservativo: forza posizionale che, spostando il suo punto di applicazione da A a B, punti qualunque del dominio di esistenza, compie un lavoro che è indipendente dalla particolare traiettoria seguita, ma dipendente soltanto dagli estremi A e B. \nℒA,B=∫BA⃗F⋅d⃗lℒ1(A,B)=ℒ2(A,B)=ℒ3(A,B)=...=ℒA,B",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#33": "Campi di forze conservativi: 1a proprietà\n34\nAB12Campo conservativo:\n1a Proprietà\nLavoro su una curva chiusa di una forza conservativa (circuitazione) è nulloCondizione necessaria (se il campo è conservative allora la circuitazione è nulla) e sufficiente (se la circuitazione è nulla allora il campo è conservativo)ℒ1(A,B)=∫BA1⃗F⋅d⃗lℒ2(A,B)=∫BA2⃗F⋅d⃗lℒA,B=∫BA1⃗F⋅d⃗l=∫BA2⃗F⋅d⃗l⟹∫BA1⃗F⋅d⃗l−∫BA2⃗F⋅d⃗l=0∫BA1⃗F⋅d⃗l+∫AB2⃗F⋅d⃗l=0⟹ℒ=∮⃗F⋅d⃗l\nℒ=∮⃗F⋅d⃗l",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#34": "Campi di forze conservativi: 2a proprietà \n35 funzione scalare definita in ogni punto dello spazio legata al valore della forza in quell punto. Fissata a meno di una costante additiva arbitraria: se  soddisfa la relazione anche  lo faU=U(x,y,z)U(x,y,z)U′\u0000=U(x,y,z)+kDifferenziale esatto di una funzione scalare  è un campo scalare Analisi: integrale fra A e B di un differenziale esatto è la differenza della primitiva fra B e A.Scelgo arbitrariamente un punto in cui   (origine)U=0yzx0PU funzione solo del punto non della traiettoria∫BA1⃗F⋅d⃗l=∫BA2⃗F⋅d⃗l⟹ℒA,B=∫BA⃗F⋅d⃗lℒA,B=∫BA⃗F⋅d⃗l=∫BAdU=U(B)−U(A)ℒA,B=U(B)−U(A)=[U′\u0000(B)−k]−[U′\u0000(A)−k]=U′\u0000(B)−U′\u0000(A)U(x,y,z)=∫P(x,y,z)0⃗F⋅d⃗l=U(P)−U(0)=U(P)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#35": "Campi di forze conservativi: 2a proprietà \nEsiste una  funzione scalare U(P), dipendente solo dalla posizione e dalla forza, detta potenziale tale che2a Proprietàyzx0BA..123Percorso AB: A->O->B\nℒA,B=∫BA1⃗F⋅d⃗l=∫0A2⃗F⋅d⃗l+∫03B⃗F⋅d⃗l=−∫A02⃗F⋅d⃗l+∫03B⃗F⋅d⃗l==−[U(A)−U(0)]+[U(B)−U(0)]=U(B)−U(A)ℒA,B=U(B)−U(A)36",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#36": "Energia potenzialeAl posto di U(P) si preferisce introdurre V(P)=−U(P)\n37•V(P) misura la capacità che ha il punto P di produrre lavoro quando il punto materiale ritorna all’origine.2a ProprietàEsiste una funzione scalare V(P), dipendente solo dalla posizione e dalla forza, detta energia potenziale tale cheLe prime due proprietà devono essere mutualmente dimostrabili.ℒA,B=U(B)−U(A)=V(A)−V(B)V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗l",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#37": "Forze conservative 3a proprietà\n38Campo conservativo è un differenziale esattoPer definizioneFxdx+Fydy+Fzdz=−∂V∂xdx−∂V∂ydy−∂V∂zdzdV=∂V∂xdx+∂V∂ydy+∂V∂zdzUguagliandoδℒ=⃗F⋅d⃗l=Fxdx+Fydy+Fzdz=dU=−dV",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#38": "Forze conservative 3a proprietà\n39Operatore vettoriale (operatore simbolico)  nabla\n3a ProprietàLa forza è col segno meno il gradiente dell’energia potenziale NB: l’operatore nabla non è un vettore, è un operatore che agisce sulle funzioni, come la derivata o l’integrale. Il risultato dell’operazione dipende al tipo di funzione a cui è applicato. ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#39": "Operatore Nabla\n40\nNabla:Gradiente di una funzione scalare\nDivergenza di un campo vettoriale\nRotore di un campo vettoriale\nÈ un vettoreÈ uno scalareÈ un vettoreÈ un operatore",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#4": "Se chiamo   la componente della forza lungo la tangente allo spostamento allora  Ft=Fcosθ\nDefinizione di lavoro infinitesimo\n5Lavoro infinitesimo compiuto da una forza:Il lavoro infinitesimo è il prodotto dello spostamento per la componente della forza lungo lo spostamentoSe la forza è  allo spostamento:        ⊥δℒ=0Es:\nNB:definizioni valgono per qualsiasi forza, non è detto sia quella che causa il moto!δℒ=⃗F⋅d⃗l=|⃗F||d⃗l|cosθ=Fdlcosθδℒ=Ftdlδℒpeso=0δℒforza⃗F≠0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#40": "Significato dell’operatore gradienteL’operatore gradiente restituisce un vettore diretto lungo la direzione in cui aumenta più velocemente la funzione scalare.\n41Campo scalare\nxy\nSuperfici (linee) di livello\nVettore applicato!\nDiretto dove f(x,y) aumenta e       alle superfici di livello⊥",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#41": "Forze conservative 4a proprietà\n423a proprietàRotoreSostituisco la prima nella seconda:Proprietà delle derivate parziali seconde per funzioni continue e derivabili:∂2V∂x∂y=∂2V∂y∂x∂2V∂x∂z=∂2V∂z∂x∂2V∂y∂z=∂2V∂z∂y𝜕𝑧",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#42": "Forze conservative 4a proprietà\n4a pr oprietà:  se il campo è conservativo il suo rotore é nulloCondizione necessaria e sufficiente affinché un campo di forze sia conservativo è che il rotore si annulli in tutti i punti del campo.Modo facile e pratico per verificare se un campo è conservativo:𝜕𝑧\n43",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#43": "ℒ=∮⃗F⋅d⃗lRiepilogo: Forze conservative\n44\n1a Proprietà\n2a ProprietàEsiste una funzione scalare V(P) (=-U(P)), detta energia potenziale, tale che\nℒA,B=V(A)−V(B)\n3a Proprietà\n4a Proprietà\nTutte le proprietà sono simultaneamente necessarie e sufficienti (la verifica di una implica tutte le altre)Forze posizionali il cui lavoro non dipende mai dal percorso ma solo dal punto di partenza e dal punto di arrivo.",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#44": "Calcoli di energia potenziale\n45yz\nxP(t)O1Data una forza conservativa, trovare l’energia potenziale\n2AB\nV(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗lℒ0,P=ℒ1(0,P)=ℒ2(0,P)=ℒ(0,A,B,P)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#45": "Calcoli di energia potenziale\n46\n1. Scelgo un percorso arbitrario su una spezzata2. Applico la definizione di energia potenziale sul percorso sceltoIn coordinate cartesiane:V(P)=−U(P)=−ℒ0,P=−∫P0⃗F⋅d⃗l=∫0P⃗F⋅d⃗l",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#46": "47Esercizio1.15Calcolare l’energia elettrostatica di una sfera di raggioRin cui ` e distribuita uniformemente una carica condensit` a⇢costante. (R:4⇡⇢2R515\"0)1.16In una certa regione di spazio sono presenti i due campi vettoriali~E1=K1xˆı+K2y2ˆ|+K1zˆke~E2=K2xyˆı+K2x2ˆ|. Determinarea) il gradiente della grandezza~E1·~E2(R: (2K1K2+2K21)xyˆı+(K1K2x2+1K22X2y)ˆ|);b) quale dei due campi pu essere considerato elettrostatico (R:~E1);1.17Si consideri il campo~F(x, y, z)=\u00002xˆı\u0000z2ˆ|\u0000ayzˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=2);b) il potenziale'generato dal campo~F(R:'=x2+yz2);c) la densit` a di carica⇢che genera il campo~F(R:⇢=\u00002✏0(y+ 1))1.18Si consideri il campo~F(x, y, z)=2xˆı\u0000zˆ|\u0000ayˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=1);b) il potenziale'generato dal campo~F(R:'=yz\u0000x2);c) la densit` a di carica⇢che genera il campo~F(R:⇢=\u00002✏0)1.19Sia dato il campo~E(x, y, z)=↵(4xˆı+zˆ|+yˆk).a) Veriﬁcare che~E` e conservativo; (R: veriﬁcare che~r⇥~E= 0)b) calcolare il ﬂusso di~Eattraverso un cubo di spigoloLcon un vertice nell’origine del sistema diriferimento e tre spigoli posizionati sui tre semiassi positivi; (R:\u0000=4↵L3)c) calcolare la carica totale contenuta nel cubo, utilizzando il teorema di Gauss sia in forma integrale chedi↵erenziale (R:Q=4↵\"0L3)2 Elettrostatica dei conduttori2.1Una sfera conduttrice di raggior1=5 cm porta una caricaQ1=+10\u00006C. Un guscio sferico di materialeconduttore, concentrico alla prima sfera, di raggio internor2=10cm e raggio esternor3=12cm ` e caricato conuna caricaQ2=10Q1. Nell’ipotesi che il sistema sia nel vuoto, calcolare:a) la densit` a di carica superﬁciale\u00002sulla superﬁcie interna del guscio sferico (R:\u00002\u0000Q14⇡r22=\u00008·10\u00006C/m);b) la di↵erenza di potenziale tra i due conduttori. (R:\u0000V=Q4⇡\"0r2\u0000r1r1r2= 15kV)V",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#47": "Esercizio   Sia dato un punto materiale di massa M su cui agisce una forza conservativa di energia potenziale:                                Sapendo che le costanti α e β sono positive, determinare:   1) l’espressione della forza;   2) le dimensioni e le unità di misura delle costanti α e β;    3) l’accelerazione del corpo quando passa per il punto P(0,L,L).\n48\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#48": "Conservazione dell’energia meccanica\n49Sistema meccanico con: -Vincoli ideali -Forze attive conservativeTeo. forze viveCampi conservativiUguagliando:Energia meccanica:E=T+VTeorema della conservazione dell’energia meccanica: Per un sistema meccanico sottoposto a vincoli tutti ideali ed a forze non vincolari tutte conservative, l’energia meccanica E si conserva, ossia la somma fra l’energia cinetica T e  l’energia potenziale totale V, rimane costante durante il moto. \nDimensionalmente:                    JouleE⎡⎣⎤⎦=T⎡⎣⎤⎦=V⎡⎣⎤⎦NB: A e B sono punti sulla traiettoria, l’energia si conserva lungo la traiettoria\nℒA,B=V(A)−V(B)\nℒA,B=T(B)−T(A)ℒA,B=T(B)−T(A)=V(A)−V(B)⟹T(A)+V(A)=T(B)+V(B)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#49": "Conservazione dell’energia meccanica\n50\nx\nx\nE1E2Corpo 1: Stato liberox1x≥x1x2x3Corpo 2: Stato legatox2≤x≤x3Curva nera:  V(x) energia potenzialeIn una certa regione di spazio E è costante Se V aumenta  T diminuisce  e viceversaMoto possibile solo nelle regioni di spazio in cui                        per def di TE≥V",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#5": "Definizione di lavoro\n6\nAB\nxyzOIl lavoro totale compiuto dalla forza su un punto materiale in un intervallo di tempo in cui il punto si sposta da A a B è la somma di tutti i lavori infinitesimi:d⃗l1d⃗l2d⃗l3\nIl lavoro compiuto da una generica forza, il cui punto di applicazione P si sposta da A a B lungo una linea , è l’integrale esteso a tale linea del prodotto scalare fra la forza  e lo spostamento infinitesimo :⃗Fℓ⃗Fd⃗lℓℒ=∑iδℒ=∑i⃗Fi⋅d⃗liℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#50": "Esempi: forza elastica\n51Verifichiamo se è conservativa:  ?⃗∇∧⃗F=0\nForza elastica:\nLa forza elastica è conservativa⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂Fy∂z−∂Fz∂y)+̂𝚥(∂Fz∂x−∂Fx∂z)+̂k(∂Fx∂y−∂Fy∂x)==̂ı(∂(ky)∂z−∂(kz)∂y)+̂𝚥(∂(kz)∂x−∂(kx)∂z)+̂k(∂(kx)∂y−∂(ky)∂x)=⃗0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#51": "Potenziale elastico\n52yzxP(t)OABV(P) calcolata sul percorso OP: O(0,0,0)→A(x,0,0)→B(x,y,0)→P(x,y,z)\nV(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0Fxdx−∫(x,y,0)(x,0,0)Fydy−∫(x,y,z)(x,y,0)Fzdz==∫(x,0,0)0kxdx+∫(x,y,0)(x,0,0)kydy+∫(x,y,z)(x,y,0)kzdz==kx22+ky22+kz22=k2(x2+y2+z2)=k|⃗r2|2V(P)=k2(x2+y2+z2)=k|⃗r2|2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#52": "Esempi: forza pesoForza peso:\n53\nLa forza peso è conservativaVerifichiamo se è conservativa:  ?⃗∇∧⃗F=0⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂Fy∂z−∂Fz∂y)+̂𝚥(∂Fz∂x−∂Fx∂z)+̂k(∂Fx∂y−∂Fy∂x)==̂ı(−∂(−mg)∂y)+̂𝚥(∂(−mg)∂x)+0̂k=⃗0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#53": "Potenziale gravitazionale\n54yzxP(t)OAB𝑉(𝑃)=𝑚𝑔𝑧\nV(P) calcolata sul percorso OP: O(0,0,0)→A(x,0,0)→B(x,y,0)→P(x,y,z)V(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0Fxdx−∫(x,y,0)(x,0,0)Fydy−∫(x,y,z)(x,y,0)Fzdz==∫(x,y,z)(x,y,0)mgdz=mgz",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#54": "Esempi: forza costanteForza costante:\n55\nUna forza costante è conservativaVerifichiamo se è conservativa:  ?⃗∇∧⃗F=0⃗∇∧⃗F=det̂ı̂𝚥̂k∂∂x∂∂y∂∂zFxFyFz=̂ı(∂fy∂z−∂fz∂y)+̂𝚥(∂fz∂x−∂fx∂z)+̂k(∂fx∂y−∂fy∂x)=⃗0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#55": "Potenziale di una forza costante\n56yzxP(t)OAB𝑉(𝑃)=−𝑓𝑥𝑥−𝑓𝑦𝑦−𝑓𝑧𝑧\nV(P)=−∫P0⃗F⋅d⃗l=−∫(x,0,0)0fxdx−∫(x,y,0)(x,0,0)fydy−∫(x,y,z)(x,y,0)fzdz==−fx∫(x,0,0)0dx−fy∫(x,y,0)(x,0,0)dy−fz∫(x,y,z)(x,y,0)dz=−fxx−fyy−fzz",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#56": "Esempi: campo centrale  a simmetria sfericaForza centrale a simmetria sferica:\n57Verifichiamo se è conservativa:\nTutti i campi centrali a simmetria sferica sono conservativixyz\nO funzione scalare della sola posizione   è un’energia potenziale se è possibile trovare una funzione scalare t.c  (forza è conservativa).F(r)drF(r)dr=−dVF(r)dr=−dV⟹F(r)=−dV/drd⃗l=̂u⊥(dl⊥)+̂ur(dr)δℒ=⃗F⋅d⃗l=F̂ur⋅(̂u⊥dl⊥+̂urdr)=F(ur⋅̂u⊥dl⊥+ur⋅̂urdr)=Fdrd⃗l=(dl⊥)̂u⊥+(dlr)̂ur=0=1⃗F(⃗r)=F(r)̂ur\nℒA,B=∫BAF(r)dr=−∫BAdV=V(rB)−V(rA)AB",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#57": "•sono arrivato qua •(mancano le animazioni)\n58",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#58": "Lavoro di una forza di attrito dinamico\n59Lavoro lungo la traiettoria 2:\nBLavoro lungo la traiettoria 1:Lavoro da A a B della forza di attrito dinamico:1\nATutte le forze di attrito (dinamico, viscoso) NON sono mai conservative⃗F=−μcN̂ut=−μcN⃗vvℒ1(A,B)=∫BA1⃗F⋅d⃗l=∫BA1(−μcN̂ut)⋅(̂utdl)2=−μcN∫BA1dl=−μcNLA1B<0ℒ2(A,B)=∫BA2⃗F⋅d⃗l=∫BA2(−μcN̂ut)⋅(̂utdl)=−μcN∫BA2dl=−μcNLA2B<0LA1B≠LA2B⟹ℒ1(A,B)≠ℒ2(A,B)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#59": "Lavoro di forze conservative e non\n60\nTeo. Forze vive ℒtot=T(B)−T(A)Lavoro totale ℒtot=ℒcons+ℒncCampi conservativi ℒcons=V(A)−V(B)Il lavoro delle forze non conservative è dato dalla variazione dell’energia meccanica totaleIn presenza di forze d’attrito, generalmente, si ha ℒnc<0⟹E(B)<E(A)Forze dissipativePunto materiale soggetto ad una forza totale: somma di 2 contributi ℒA,B=∫BA⃗F⋅d⃗l=∫BA(⃗Fcons+⃗Fnc)⋅d⃗l=∫BA⃗Fcons⋅d⃗l+∫BA⃗Fnc⋅d⃗lT(B)−T(A)=V(A)−V(B)+ℒncℒnc=[T(B)+V(B)]−[T(A)+V(A)]=E(B)−E(A)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#6": "Graficamente\n7\nAB\nOIn un piano in cui rappresentiamo   in funzione dell’ascissa curvilinea , sia  che  sono funzioni della particolare traiettoria:   e  variano cambiando il percorso da A a B. Fissata una certa traiettoria…FtsFtssAsBFtssAsBIl lavoro infinitesimo in un tratto di s è pari all’area tratteggiatadlδℒ=Ftdlℓ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#60": "Esercizio•Un carrello viene lanciato con una velocità iniziale v lungo un binario orizzontale che poi presenta un avvolgimento circolare verticale di raggio R = 4 m. Calcolare, nell’ipotesi di assenza di attriti,  il minimo valore vmin che deve essere dato alla velocità v affinché il carrello compia il “giro della morte” senza staccarsi dai binari.\n61\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#61": "EsercizioUn punto materiale di massa m=30 g è inizialmente fermo su di un profilo circolare liscio di raggio R=20 cm ad una altezza H=R/2 rispetto al piano orizzontale. Scendendo lungo il profilo il punto incontra in A un piano orizzontale liscio su cui è vincolata in B una molla di costante elastica  k =0,1 kg/s2, inizialmente a riposo. Determinare: a)le componenti tangenziale (aT) e centripeta (aN)  dell’accelerazione del punto nel punto iniziale; b)la reazione vincolare nel punto A; c)la compressione massima della molla. \n62\nmRKA\nR\nB",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#62": "EsercizioUna cassa, di massa M=7 kg è  inizialmente in moto su un piano orizzontale liscio con una velocità di v =8 m/s ad una distanza D =6 m da un piano ruvido inclinato di  α=15° rispetto alla direzione orizzontale. Sapendo che la cassa si ferma dopo aver percorso L = 8 m sul piano inclinato, determinare  a)il coefficiente di attrito dinamico del piano inclinato,  b)il lavoro fatto dalla forza di attrito sul piano inclinato,  c)indicare (motivando la risposta) se, raggiunta la quota massima la cassa ridiscende il piano o si ferma.\n63\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#63": "EsercizioUn corpo di massa M = 12 kg scende da un piano inclinato di α=30° rispetto ad una direzione orizzontale. Sapendo che il corpo parte da fermo, che si abbassa di una quota h = 2 m, che il piano è ruvido e con un coefficiente di attrito dinamico µd=0,2, determinare la sua velocità finale.\n64",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#7": "Graficamente\n8\nAB\nOIn un piano in cui rappresentiamo   in funzione dell’ascissa curvilinea , sia  che  sono funzioni della particolare traiettoria:   e  variano cambiando il percorso da A a B. Fissata una certa traiettoria…FtsFtssAsBFtssAsB\nIl lavoro totale è pari all’area sotto la curva compresa fra i due estremi fra cui si sposta il punto materialeℒ=∫BAFtdlℓ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#8": "Esempi\n91.\nAB\ncostante in modulo, direzione e verso ℓℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l=∫BAℓFtdl=Ft∫BAℓdl=Ftℓ2. costante in moduloFt=|⃗F|cosθ=Fcosθℒℓ(A,B)=∫BAℓ⃗F⋅d⃗l=∫BAℓFcosθdl=Fcosθ∫BAℓdl=FℓcosθIn generale in coordinate cartesiane: forza posizionale⃗F(x,y,z)=Fx(x,y,z)̂ı+Fy(x,y,z)̂𝚥+Fz(x,y,z)̂kd⃗l=dx̂ı+dŷ𝚥+dẑkIntegrale generalmente non scomponibile!\nAB\n𝜗𝜗𝜗𝜗ℓℒ=∫BAℓ⃗F(x,y,z)⋅d⃗l=∫BAℓ[Fx(x,y,z)dx+Fy(x,y,z)dy+Fz(x,y,z)dz]",
    "data_test\\rootfolder\\università\\FisicaGenerale\\05-lavoro-e-energia.pdf#9": "Esercizio\n10Calcolare il lavoro della forzacon k e h costanti che agisce sul piano (x,y) sulle traiettorie: 1)Lungo un segmento rettilineo che congiunge l’origine con un punto A=(a,b); 2)Lungo l’arco di parabola OA avente vertice nell’origine e per asse l’asse x.xyOA",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#0": "Terzo Principio della Dinamica CdS Ingegneria Informatica A.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#1": "Sviluppo1)Modello del punto materiale troppo povero per descrivere tutta la realtà; 2)Dinamica dei sistemi di punti materiali; 3)Riscrittura  della  in modo opportuno; 4)Terzo principio della dinamica⃗F=m⃗a\n2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#10": "Derivate rispetto al tempo\nRappresenta TUTTE le forze REALI che agiscono sul punto i-esimoPossiamo distinguere tra le forze dovute agli altri punti del sistema  (forze INTERNE al sistema) e forze dovute a tutto ciò che non è il sistema (forze ESTERNE al sistema, dovute all’ambiente). Analogamente per i momenti→𝑄=𝑁∑𝑖=1→𝑞𝑖=𝑁∑𝑖=1𝑚𝑖→𝑣𝑖𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1𝑑→𝑞𝑖𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖→𝑃𝑜=𝑁∑𝑖=1→𝑝𝑖=𝑁∑𝑖=1𝑚𝑖→𝑟𝑖∧→𝑣𝑖𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1𝑑→𝑝𝑖𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1→𝑟𝑖∧→𝐹𝑖\n11",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#11": "Forze interne ed esterneTipiche forze interne: vincoli tra punti materiali, fili, sbarre interne al sistema, molle o sistemi di attrazione/repulsione tra punti del sistema Tipiche forze esterne: forze peso, vincoli tra il sistema e l’esterno, tensioni tra il sistema e l’esterno\nPiano verticaleInterneEsterne\nPiano orizzontale\nPiano verticale\n12",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#12": "Separazione tra forze interne ed esterne\nPer un sistema isolato si ha:Attenzione:  risultato parziale→𝐹𝐸𝑆𝑇=0, →𝑀𝐸𝑆𝑇=0𝑑→𝑄𝑑𝑡=→𝐹𝐼𝑁𝑇𝑑→𝑃𝑜𝑑𝑡=→𝑀𝐼𝑁𝑇𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖=𝑁∑𝑖=1(→𝐹𝐼𝑁𝑇𝑖+→𝐹𝐸𝑆𝑇𝑖)=𝑁∑𝑖=1→𝐹𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝐹𝐸𝑆𝑇𝑖=→𝐹𝐼𝑁𝑇+→𝐹𝐸𝑆𝑇𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1(→𝑀𝐼𝑁𝑇𝑖+→𝑀𝐸𝑆𝑇𝑖)=𝑁∑𝑖=1→𝑀𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝑀𝐸𝑆𝑇𝑖=→𝑀𝐼𝑁𝑇+→𝑀𝐸𝑆𝑇\n13",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#13": "Verifiche sperimentaliQuanto valgono nei sistemi isolati?Studio il sistema Terra-Luna o Giove-suoi satelliti o altri sistemi:\nRisultato sperimentale nuovo: nei sistemi isolati si osserva sempre: Nei sistemi isolati la quantità di moto e il momento angolare del sistema sono costanti nel tempo.𝑑→𝑄𝑑𝑡=→𝐹𝐼𝑁𝑇𝑑→𝑃𝑜𝑑𝑡=→𝑀𝐼𝑁𝑇\n𝑑→𝑄𝑑𝑡=→0𝑑→𝑃𝑜𝑑𝑡=→0⟹→𝐹𝐼𝑁𝑇=→0, →𝑀𝐼𝑁𝑇=014",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#14": "Sistema isolato semplice\nLe due forze interne agiscono su una retta d’azione che passa per i due punti materiali\n e : forze interne al sistema di due punti⃗F1⃗F2\nO\n→𝐹𝐼𝑁𝑇=→0→→𝐹1+→𝐹2=→0⟹→𝑀𝐼𝑁𝑇=→𝑟1∧→𝐹1+→𝑟2∧→𝐹2=→0→→𝑟1∧→𝐹1+→𝑟2∧(−→𝐹1)=→0→→𝑟1∧→𝐹1−→𝑟2∧→𝐹1=(→𝑟1−→𝑟2)∧→𝐹1=→0(→𝑟1−→𝑟2)∥→𝐹115→𝐹2=−→𝐹1⃗F1⃗F2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#15": "Terzo principio della dinamicaOgni volta che un corpo (A) esercita una forza su un altro corpo (B), il secondo esercita sul primo una forza vettorialmente opposta e con la stessa retta d’azione.Formulazione storica\n16",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#16": "Terzo principio della dinamica•Col secondo principio prevediamo il moto di un punto materiale sulla base della forza agente su di esso:  •Per avere una forza  occorre almeno un altro corpo che agisca sul punto materiale •Il secondo principio dice come si muove il punto materiale soggetto ad una forza ma non cosa succede al corpo che tale forza la provoca  serve il terzo principio→𝐹=𝑚→𝑎⃗F→17",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#17": "Terzo principio della dinamica  per sistemi di punti materiali•Per ogni punto si suppone di poter distinguere fra le forze agenti sul punto i-esimo quella dovuta al punto j-esimo •Si soppone valere sempre la sovrapposizione degli effetti cioè se  è la forza che 2 esercita su 1 e  è la forza che 3 esercita su 1 allora  •Se valgono queste condizioni allora il terzo principio è estendibile a N corpi applicandolo ad ogni possibile coppia di punti→𝐹1,2→𝐹1,3→𝐹1=→𝐹1,2+→𝐹1,3→𝐹𝑖=𝑁−1∑𝑗=1→𝐹𝐼𝑁𝑇𝑖,𝑗+→𝐹𝐸𝑆𝑇𝑖Sul punto i-esimo agiscono tutte le forze interne dovute agli altri N-1 punti e le forze esterneSe agiscono solo forze interne: il sistema è isolato  →𝐹𝐸𝑆𝑇𝑖=→0⟹𝑑→𝑄𝑑𝑡=018",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#18": "Terzo principio della dinamicaOgni volta che un corpo (A) esercita una forza su un altro corpo (B), il secondo esercita sul primo una forza vettorialmente opposta e con la stessa retta d’azione.Formulazione storicaFormulazione alternativaSe in un SRI, osserviamo che su un corpo (A) si esercita una forza allora esisterà almeno un altro corpo (B) responsabile di tale forza. Su questo corpo B agirà una forza vettorialmente opposta a quella su A e con la stessa retta d’azione.NB: le due forze sono applicate in due punti di applicazione diversi ovvero I due corpi!19",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#19": "Terzo principio, formulazione modernaSemplice, diretto, modernoSu sistemi isolati\nNulli per il terzo principio (sperimentale)Nulli in un sistema isolatoQuantità di moto e momento angolare si conservano per sistemi isolati.In un Sistema di Riferimento Inerziale,  e calcolato rispetto ad un polo O qualunque si conservano per sistemi isolati.→𝑄→𝑃0 𝑑→𝑄𝑑𝑡=→0𝑑→𝑃𝑜𝑑𝑡=→0⟹→𝐹𝐼𝑁𝑇=→0, →𝑀𝐼𝑁𝑇=0\n20",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#2": "Quantità di moto di un punto materialeSi definisce la quantità di moto di un punto come:Se la massa è costante:Secondo principio:Se la massa è variabile: quale delle due è corretta?oppure[→𝑞]=[𝑚→𝑣]=[𝑀𝐿𝑇−1]→𝑘𝑔∙𝑚𝑠→𝐹=𝑚→𝑎=𝑚𝑑→𝑣𝑑𝑡=𝑑(𝑚→𝑣)𝑑𝑡\n→𝐹=𝑑→𝑞𝑑𝑡→𝐹=𝑑→𝑞𝑑𝑡=𝑑(𝑚→𝑣)𝑑𝑡=𝑑𝑚𝑑𝑡→𝑣+𝑚𝑑→𝑣𝑑𝑡3",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#20": "Conseguenze del terzo principio2 corpi su un piano orizzontale tenuti insieme da una molla compressa tramite un filo ideale\n21\nTerzo principio: poiché il sistema è isolatoIn diverse circostanze è possibile ottenere dei risultati di dinamica SENZA conoscere le forze in gioco\n→𝑄𝑖𝑛𝑖𝑧=→0Tagliando il filo i corpi si muovono per effetto della di moto rettilineo uniforme in direzione opposta→𝐹=𝑚→𝑎 →𝑄𝑓𝑖𝑛=𝑚1→𝑣1+𝑚2→𝑣2→𝑄𝑖𝑛𝑖𝑧=→𝑄𝑓𝑖𝑛→→0=𝑚1→𝑣1+𝑚2→𝑣2→→𝑣2=−𝑚1𝑚2→𝑣1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#21": "Urti CdS Ingegneria Informatica A.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#22": "UrtiSi ha un urto quando due corpi, che si muovono a velocità diverse, interagiscono (p.es. vengono a contatto) e, in un intervallo di tempo molto breve (rispetto al contesto), modificano sostanzialmente le proprie velocità.\n23\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#23": "Forze d’urto – forze impulsive\n24\nForze impulsive",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#24": "Urti collineari di punti materiali\n25\ne = 0 : urto perfettamente anelastico e = 1 : urto perfettamente elasticoEmpiricamente Prima dell’urtoDopo l’urto\nNB.: Trattasi di relazioni tra le componenti dei vettori lungo l’asse x, le quali includono il segno.v0,1x−v0,2x>0→𝑄𝑖𝑛𝑖𝑧=→𝑄𝑓𝑖𝑛𝑣1,𝑥−𝑣2,𝑥=−𝑒(𝑣01,𝑥−𝑣02,𝑥)0≤𝑒≤1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#25": "Urti collineari di punti materiali\n26\nConservazione della quantità di moto (e del momento angolare).\nRelazione fra le velocità\nm1 = m2\ne = 0\nUrto anelastico\nm1 = m2\ne = 1\nUrto elastico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#26": "Energia cineticaFacendo un po’ di conti … :\ne = 1\nE = costante T=12m1v1x2+12m2v2x2T0=12m1v01x2+12m2v02x2\nIn un urto perfettamente elastico l’energia cinetica si conserva\ne = 0\nΔE ≤  0 In un urto perfettamente anelastico l’energia cinetica diminuisce27",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#27": "Urti in sistemi non isolatiSe gli urti avvengono in sistemi non isolati a causa della presenza di forze esterne o vincoli esterni, il terzo principio (formulazione conservativa) non è sempre applicabileSe l’urto è quasi istantaneo, sono molto più importanti le forze impulsive e si può trascurare l’effetto della forza peso. Si ha una quasi conservazione di quantità di moto e momento angolare tra prima e dopo l’urto. Vale in generale per forze esterne LIMITATE.Se le forze esterne hanno una direzione definita, si ha la conservazione della quantità di moto nelle direzioni perpendicolari.\nEsempio: urto di due palloni che si scontrano in aria. E’ presente una forza esterna: quella peso.\n28",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#28": "Urti: riassunto\n29",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#29": "EsercizioUn corpo di massa m=1 kg è in moto rettilineo uniforme ad una velocità v=10 m/s, su un piano liscio, quando entra in una regione permanendovi per t=0.1 s in cui perde velocità scalare. All’uscita della regione il corpo ha una velocità di v=9 m/s. Determinare:  1)la forza media che ha frenato il corpo,  2)il lavoro della forza frenante e  3)il coefficiente di attrito se si tratta di una forza di attrito cinetico. \n30",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#3": "Situazioni di massa variabile•Moto di una goccia d’acqua che cade in presenza di vapor d’acqua saturo  à la massa aumenta •Moto di un aereo in condizioni di tempo brutto con formazione di ghiaccio sulle ali à la massa aumenta •Moto di un razzo che si muove bruciando carburante à la massa diminuisce •Relatività: la massa dipende dalla velocità: •Dato sperimentale: la forza varia con la massa!È più generale della \nm(v)=m01−vc()2→𝐹=𝑑→𝑞𝑑𝑡4",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#30": "EsercizioDue punti materiali di massa m1=1 kg e m2=3 kg sono uniti da un filo inestensibile che risulta sempre in tensione. Sapendo che i due punti si muovono su un piano ideale senza attrito, che costituiscono un sistema isolato e che il punto 1 ha equazioni del moto date da :    (nelle unità del SI) trovare la tensione del filo e l’accelerazione del punto 2. \n31",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#31": "EsercizioDa una pistola con canna lunga L=15 cm esce un proiettile di massa m=5 g con velocità v=180 m/s. Trovare la forza media che ha spinto il proiettile dentro la canna e il tempo che impiega il proiettile a percorrere la canna della pistola dal momento dello sparo.\n32",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#32": "EsercizioDue corpi A e B di massa 2 kg si scontrano fra loro. Le velocità prima dell’urto sono   Dopo l’urto Tutte le velocità sono date in metri al secondo. Qual è la velocità finale di B? Quanta energia cinetica guadagna o perde nell’urto il corpo B? L’urto è elastico? →𝑣𝐴,𝑖=15^𝑖+30^𝑗→𝑣𝐵,𝑖=−10^𝑖+5^𝑗→𝑣𝐴,𝑓=−5^𝑖+20^𝑗\n33",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#33": "EsercizioUna palla di stucco con una massa di 5 g ed una velocità v1 = 4 m/s compie una collisione diretta e perfettamente anelastica con una palla da biliardo inizialmente ferma e che ha una massa di 500 g. Determinare la velocità comune delle due palle dopo l’urto e le energie cinetiche prima e dopo l’urto dei diversi corpi.  - trascurare gli effetti di rotolamento -\n34",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#34": "EsercizioUna pallina di gomma, di massa m=20 g, viene lasciata cadere in verticale da una altezza h=100 cm misurata rispetto ad un pavimento orizzontale. La pallina rimbalza esattamente in verticale e raggiunge una altezza di h' = 90 cm.  Qual è il coefficiente di restituzione del pavimento? A che altezza arriverà il successivo rimbalzo?\n35",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#35": "EsercizioDue carrelli, di massa rispettivamente M=50 kg e 2M si muovono uniti su un binario orizzontale rettilineo ad una velocità costante v=10 m/s. Tra i due carrelli, tenuti uniti da un gancio, vi è un respingente (molla) compresso di 25 cm e di costante elastica k=80000 N/m. Se ad un certo punto il gancio si rompe, trovare le velocità finali dei due carrelli.\n36",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#36": "EsercizioUn proiettile di massa mP = 4 kg viene sparato in orizzontale da un cannone posto su un carrello e avente una massa complessiva di MC = 3 000 kg. Sapendo che la velocità di uscita del proiettile è di vP = 350 m/s, determinare la velocità iniziale di rinculo del cannone.\n37",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#37": "Esercizio (pendolo balistico)Un proiettile, di massa m e velocità v diretta in orizzontale, colpisce in modo totalmente anelastico un peso di massa M appeso al soffitto tramite un filo inestensibile. A seguito dell’urto il peso inizia una oscillazione. Trovare la relazione tra la velocità del proiettile e la massima altezza del peso rispetto alla sua posizione di riposo.\n38",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#38": "Esercizio Un corpo di 2 kg viene spinto contro una molla di costante elastica pari a 200 N/m fino a comprimerla di 15 cm. Lasciato andare, la molla lo spinge su una superficie orizzontale fino a che non si arresta dopo un percorso di 75 cm. Qual e’ il coefficiente di attrito dinamico tra blocco e superficie?\n3939",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#39": "EsercizioDue sferette di masse m1 e m2, vincolate a muoversi su un piano verticale, sono collegate ad uno stesso punto fisso O attraverso due fili flessibili inestensibili, entrambi di lunghezza l e massa trascurabile (vincoli ideali). Inizialmente la sferetta m2 è in posizione di equilibrio stabile, mentre la sferetta m1 con il filo teso è trattenuta ad una quota h rispetto alla posizione di m2. In seguito, m1 viene lasciata libera di muoversi e va a urtare m2. Nell’ipotesi che l’urto sia istantaneo e completamente anelastico, calcolare:   1) il modulo v1 della velocità con cui m1 urta m2;   2) la quota massima h’ raggiunta dal sistema    dopo l’urto e   3) la perdita di energia cinetica.\n40\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#4": "ImpulsoL’azione di una forza in un intervallo di tempo dt provoca una variazione infinitesima della quantità di moto\nImpulso:Viceversa: da una variazione infinitesima della quantità di moto si può risalire alla forza agente.⃗ℐ=∫t2t1⃗Fdt=∫t2t1d⃗q=⃗q(t2)−⃗q(t2)=Δ⃗q[⃗ℐ]=[Δ⃗q]=[MLT−1]5",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#40": "EsercizioUn sistema meccanico, che si trova inizialmente fermo ad una altezza h = 1,2 m dal pavimento, è costituito da una pallina di massa m1 = 10 g collocata in equilibrio (instabile) sopra una pallina di massa m2 = 5m1. A un certo istante, il sistema viene lasciato libero di cadere. Assumendo che ogni urto sia perfettamente elastico e trascurando le dimensioni delle palline, determinare:  1)l’altezza a cui rimbalza la pallina più leggera;  2)la velocità con cui arriva a terra la seconda pallina dopo l’urto.\n41",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#41": "EsercizioUna pallina di massa 2m viene lanciata verso l’alto da una quota z=0 ad una velocità v=10 m/s esattamente nello stesso istante in cui un’altra pallina di massa m, posta ad una quota h=5 m viene lasciata cadere sulla verticale della prima pallina.  1) Se l’urto tra le palline e’ elastico, quanto tempo impiega la prima pallina ad arrivare a terra? 2) Se l’urto e’ completamente anelastico, quanto tempo ci mettono le palline ad arrivare a terra?    (considerare g=10 m/s2)\n42",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#5": "Teorema dell’impulsoForze impulsive: forze che agiscono per un periodo di tempo limitato\nPrimo principio  con la quantità di motoSe m è costante    costante    Se m costante e     costante    Teorema dell’impulso: l’impulso di una forza applicata ad un punto materiale provoca la variazione della sua quantità di moto.Forma integrale del secondo principio della dinamica:  nota la forza anche la variazione della quantità di moto è nota; nota la variazione della quantità di moto è nota la forza media che ha agito nell’intervallo di tempo dt.⃗ℐ=∫t2t1⃗Fdt=Δ⃗q\n⃗ℐ=∫t2t1⃗Fdt=Δ⃗q=m(⃗v2−⃗v1)6",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#6": "⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)Momento angolare\nxyz\nO\nP\nPunto materiale di massa m con velocità  ⃗vMomento angolare o  momento della quantità di moto rispetto al polo O: \nRispetto al polo F: P\nF\nOsservazione: il vettore quantità di moto è un vettore applicato nel punto P\n7⃗pF=(⃗r−⃗rF)∧⃗q",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#7": "Momento angolare nel piano\nY\nO\nVelocità: componente radiale più tangenziale\nIl momento angolare: - Dipende dalla velocità trasversa, non da quella radiale - È un vettore  al piano definito da  e  - È diverso da zero solo quando c’è una rotazione - È costante in un moto circolare uniforme⊥→𝑟→𝑣velocità angolare\n8⃗v=⃗vr+⃗vt=vr̂ur+vt̂ut=·r̂ur+r·φ̂ut̂ur̂utφ⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)⃗p0=⃗r∧⃗q=m(r̂ur)∧(·r̂ur+r·φ̂ut)=mr2·φ(̂ur∧̂ut)=mr2·φ̂k·φ=dφdt=ω",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#8": "d⃗p0dt=⃗r∧⃗F=⃗M0Derivata del momento angolareDerivando:La derivata del momento angolare é uguale al momento della forza agente sul punto materiale rispetto allo stesso polo.Il momento delle forze è nullo se: -La forza agente è nulla (punto isolato da altri corpi) -Vettore posizione e forza sono paralleli  Se il momento delle forze è nullo, il momento angolare è costante in modulo direzione e verso: la traiettoria giace su un piano. 9⃗p0=⃗r∧⃗q=m(⃗r∧⃗v)d⃗p0dt=d(⃗r∧⃗q)dt=d⃗rdt∧⃗q+⃗r∧d⃗qdt=⃗v∧⃗q+⃗r∧⃗F",
    "data_test\\rootfolder\\università\\FisicaGenerale\\06-terzo-principio-e-urti.pdf#9": "Sistemi di punti materialiUn insieme di N punti materiali di masse mi costituisce un sistema di punti materiali \nxyz\nOSRI\n12iDef: massa del sistema di punti materiali:\nNM=mii=1N∑Def: Quantità di moto del sistema di punti materiali: \nDef: Momento della quantità di moto (o momento angolare): (momento risultante del sistema)10⃗P0=N∑i=1⃗pi=N∑i=1⃗ri∧⃗qi=N∑i=1mi⃗ri∧⃗vi",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#0": "Dinamica dei Sistemi CdS Ingegneria Informatica A.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#1": "Equazioni cardinali \n2Dal principio di indipendenza delle azioni simultanee: le forze ed i momenti interni rimangono nulli anche in presenza di forze e momenti delle forze esterni.6 equazioni scalari! Descrivono esattamente: 1.Il moto di un punto 2.Il moto di 2 punti 3.Il moto di un corpo rigido𝑑→𝑄𝑑𝑡=𝑁∑𝑖=1→𝐹𝑖=𝑁∑𝑖=1→𝐹𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝐹𝐸𝑆𝑇𝑖=→𝐹𝐼𝑁𝑇+→𝐹𝐸𝑆𝑇𝑑→𝑃𝑜𝑑𝑡=𝑁∑𝑖=1→𝑀𝑖=𝑁∑𝑖=1→𝑀𝐼𝑁𝑇𝑖+𝑁∑𝑖=1→𝑀𝐸𝑆𝑇𝑖=→𝑀𝐼𝑁𝑇+→𝑀𝐸𝑆𝑇Equazioni cardinali della dinamica dei sistemiChe cosa descrivono per un sistema generico di N punti materiali?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#10": "Teorema del momento angolare\n11A cosa sono dovute le variazioni del momento angolare totale di un sistema di punti?Consideriamo un polo O’ mobile (non necessariamente il CM)\nO\nO’\nDerivando:=𝑁∑𝑖=1𝑚𝑖→𝑣𝑖∧→𝑣𝑖−𝑁∑𝑖=1𝑚𝑖→𝑣𝑂′\u0000∧→𝑣𝑖+𝑁∑𝑖=1𝑚𝑖(→𝑟𝑖−→𝑟𝑂′\u0000)∧→𝑎𝑖==𝑁∑𝑖=1𝑚𝑖→𝑣𝑖∧→𝑣𝑖−→𝑣𝑂′\u0000∧𝑁∑𝑖=1𝑚𝑖→𝑣𝑖+𝑁∑𝑖=1𝑚𝑖(→𝑟𝑖−→𝑟𝑂′\u0000)∧→𝑎𝑖Quantità di moto totale del sistemaMomento delle forze agenti sul sistema rispetto polo O’Nullo perché prodotto vettoriale fra vettori paralleli⃗PO′\u0000=N∑i=1⃗pi=N∑i=1mi⃗r′\u0000i∧⃗vi=N∑i=1mi(⃗ri−⃗rO′\u0000)∧⃗vid⃗PO′\u0000dt=N∑i=1mid[(⃗ri−⃗rO′\u0000)∧⃗vi]dt==N∑i=1mi(⃗vi−⃗vO′\u0000)∧⃗vi+N∑i=1mi(⃗ri−⃗rO′\u0000)∧⃗ai=−→𝑣𝑂′\u0000∧→𝑄+→𝑀𝑂′\u0000",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#11": "Teorema del momento angolare\n12O\nO’\nEstensione della seconda equazione cardinale al caso di un polo mobile:  seconda equazione cardinale generalizzataUsando il primo teorema del centro di massa−→𝑣𝑂′\u0000×𝑀→𝑣𝐶𝑀+→𝑀𝑂′\u0000=−𝑀→𝑣𝑂′\u0000×→𝑣𝐶𝑀+→𝑀𝑂′\u0000𝑑→𝑃𝑂′\u0000𝑑𝑡=−→𝑣𝑂′\u0000×→𝑄+→𝑀𝑂′\u0000=",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#12": "Teorema del momento angolare: se il polo O’ è fisso nel SRI o coincide con il CM, l’evoluzione nel tempo del momento angolare è determinata dal momento risultante delle forze esterne.Teorema del momento angolare\n13Il secondo termine è nullo quando: 1- O’ è fermo nel SRI 2- il CM è fermo nel SRI 3- il polo O’ coincide con il CM 4- \nSempre, anche  quando il CM si muove!\nIn uno di questi casi𝑑→𝑃𝑂′\u0000𝑑𝑡=→𝑀𝑂′\u0000−𝑀→𝑣𝑂′\u0000×→𝑣𝐶𝑀\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#13": "Equazioni cardinali\n14\nDescrivono il moto di un sistema di N punti materiali attraverso il suo CMSistema di equazioni non completo: non si può descrivere il moto di N punti con sole 2 equazioni vettoriali, ma queste forniscono una indicazione globale su come si muove il CM e l’evoluzione del momento angolare calcolato rispetto al CM.Per un sistema di punti materialiEquazioni cardinali:  moto di 1 punto, 2 punti, corpo rigido",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#14": "Energie di un sistema di punti\n15Osservazione: la forza ed il lavoro sono grandezze additive Anche l’energia (cinetica, potenziale, meccanica) è una grandezza additiva.Definiamo energia cinetica di un sistema:\nDefiniamo energia potenziale di un sistema soggetto solo a forze conservative interne o esterne:\nAnalogamente definiremo Energia Meccanica di un sistema:\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#15": "Teorema di König\n16\nUsiamo coordinate intrinseche: \nEnergia cinetica come calcolata nel SR del CM (SR intrinseco)Energia cinetica nel SRI di un punto di massa M  con velocità pari a quella del CM\nTCM=\n⃗Q′\u0000=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#16": "T=T′\u0000+TCMTeorema di König\n17Energia cinetica nel SR del CM (SR intrinseco)Energia cinetica di un punto di massa M con velocità pari a quella del CM\nTeorema di König: l’energia cinetica di un sistema di punti materiali in moto rispetto ad un punto O è, istante per istante, uguale alla somma dell’energia cinetica del sistema rispetto al CM (T’) più l’energia che possiederebbe in quell’istante rispetto ad O il CM se in esso fosse concentrata tutta la massa (TCM).\n()T′\u0000=0TCM=12Mv2CMT′\u0000=N∑i=112miv′\u00002i",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#17": "Sistema di punti soggetti a forza peso\n18O\nCM\nRicordando la definizione di CM:\n⟹𝑀→𝑟𝐶𝑀=∑𝑁𝑖=1𝑚𝑖→𝑟𝑖",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#18": "Sistema di punti soggetti a forza peso\n19O\nCM\nUn sistema di punti soggetto alla forza peso si comporta come un unico punto materiale coincidente con il CM avente massa M\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#19": "Esercizio\n20\nUn proiettile è lanciato con una velocità di 20 m/s ad un angolo di 30° rispetto l’orizzontale. Nel corso della sua traiettoria esplode suddividendosi in due frammenti, uno dei quali ha massa doppia rispetto quell’altro. I due frammenti colpiscono il suolo nello stesso istante. Il frammento di massa minore colpisce il suolo a 20 m dal punto di lancio. In quale punto colpisce il suolo il secondo frammento?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#2": "Equazioni cardinali -Per N punti materiali servono N equazioni vettoriali del tipo  quindi 3N equazioni scalari; -Le equazioni cardinali sono al massimo 6 equazioni scalari  mancano 3N-6 equazioni scalari che diano informazioni mancanti (es: vincoli che legano fra loro i punti come nel caso dei corpi rigidi)→𝐹=𝑚→𝑎⟹Per N punti materiali le equazioni cardinali forniscono solo informazioni parziali:  non forniscono informazioni sul singolo punto ma danno informazioni collettive.  Che cosa descrivono le equazioni cardinali per un sistema di N punti materiali?  È possibile trovare un elemento del sistema che sia descritto dalle equazioni cardinali? 3",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#20": "Sistemi continui\n21Sistemi non puntiformi: insiemi “densi” di punti àsistemi continui (estesi). Per tali sistemi la grandezza (dimensione lineare) è importante.  Possiamo caratterizzarli attraverso una nuova quantità geometrica:      Volume V     [L3] àm3Anche un sistema continuo è dotato della proprietà Massa del Sistema:          Massa M     [M] àkg\nM=∫dm=∫Vρ(⃗r)dτDef: densità volumetrica puntuale (locale) di massa: \ndm,dτρ(⃗r)=dmdτdm=ρ(⃗r)dτDef: densità volumetrica media di massa: \nM,τ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#21": "Legame tra sistemi di punti e sistemi estesi\n22\nSistema di punti\nSistema esteso\nUn sistema continuo può essere pensato come un sistema di N punti materiali, con Nà+∞ \nM=∫dm=∫Vρ(⃗r)dτρ(⃗r)=dmdτ\nM=∫dm=∫Vρ(⃗r)dτ∫f(⃗r,⃗v)dm=∫Vf(⃗r,⃗v)ρ(⃗r)dτ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#22": "Esempio: centro di massa\n23\nSistema di punti\nSistema continuo\nEsempio: cubo omogeneo di lato L\nxzy⃗rCM=∫V⃗rρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫V⃗rρ(⃗r)dτMxCM=∫Vxρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vxρ(⃗r)dτMyCM=∫Vyρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vyρ(⃗r)dτMzCM=∫Vzρ(⃗r)dτ∫Vρ(⃗(r)dτ=∫Vzρ(⃗r)dτM",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#23": "SISTEMI PIANI\n24Se un sistema continuo volumetrico ha una dimensione sempre costante allora può essere trattato come un sistema continuo pianoEsempi: foglio di carta, lastra metallica, tavola di legno, muro\nDef: densità superficiale media di massa: \nDef: densità superficiale puntuale (locale): \nDimensionalmente:\nSe il sistema esteso ha uno spessore costante pari a D:\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#24": "¯λ=MLSistemi lineari\n25Se un sistema continuo volumetrico ha due dimensioni sempre costanti allora può essere trattato come un sistema continuo lineareEsempi: corda, filo, sbarra, palo, colonna, pilastroDef: densità lineare media: \nDef: densità lineare puntuale (locale): \n[¯λ]=[ML−1]kg/m",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#25": "Esercizio\n26Una sbarra di lunghezza L è collocata lungo l’asse x con un estremo nell’origine (0<x<L). Determinare la coordinata x del CM sapendo che la sbarra ha una densità lineare pari a:\nxL0Caso 1:\nCaso 2:\nCaso 3:\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#26": "Esercizio\n27Trovare le coordinate del CM di un triangolo rettangolo isoscele di lato L e densità superficiale σ costante.\nyxO\ndx\nVerificare che \n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#27": "Corpi rigidi\n28\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#28": "Moto del corpo rigido\n29Sistema di N=1 punto \n3 variabili dinamicheSistema rigido di N=2 punti \n6 variabili dinamiche dei punti - 1 vincolo = 5 variabili dinamiche indipendenti\nSistema rigido di N=3 punti 3x3=9 variabili dei punti - 3 vincoli = 6 variabili indipendenti\nSistema rigido di N>3 punti Ogni punto in più introduce 3 variabili dinamiche del punto e 3 vincoli\nNel caso del corpo rigido il moto è descrivibile da sole 6 equazioni.\n6 variabili dinamiche indipendenti",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#29": "Quali variabili dinamiche?\n30La descrizione completa ne richiede 6. Ho la libertà di scegliere quali.\nABCon le 6 variabili così definite posso descrivere la posizione del corpo rigido nello spazio. Sono convenienti dal punto di vista della dinamica?\nSuggerimento: 3 coordinate del CM + 3 variabili angolari6 eq. in 6 incogniteEsempio:  •3 coordinate del punto A + 3 coordinate del punto B – 1 vincolo sulla distanza AB = 5 variabili. •1 angolo di rotazione attorno all’asse AB\nEquazioni  cardinali per sistema di punti",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#3": "Centro di Massa\n4O\nCM\nSia dato un sistema di N punti materiali descritti in un sistema di riferimento inerziale, si definisceCentro di massa:\n3mmL\nL/43L/4CM\nPunto geometrico definito dal vettore posizione   “interno al sistema”, ma non necessariamente appartenente al sistema. E’ una caratteristica del sistema di punti e non del sistema di riferimento usato.→𝒓𝑪𝑴",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#30": "Moto generico di un corpo rigido\n31Due possibili moti indipendenti:\n2.Moto rotatorio puro attorno ad un asse passante per il CM che è fisso    Tutti i punti compiono un moto circolare attorno all’asse istantaneo di rotazione\nVale ancora:Due possibili moti indipendenti:1.Moto traslatorio puro.   - Tutti i punti hanno la stessa velocità (del CM)  - Traiettorie dei punti sono tutte parallele  - Moto descritto dalla prima equazione cardinale\nCM\n Il moto più generico possibile è un moto roto-traslatorio, dove il CM si muove seguendo la prima equazione cardinale ed il corpo fa un moto rotatorio attorno ad un asse istantaneo di rotazione e solo se l’asse di rotazione passa per il CM il moto è descritto dalla seconda equazione cardinale. ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#31": "Moto di un corpo rigido\n32\nEquazioni cardinali per i sistemi sono separate per il moto del CM e per l’evoluzione del momento angolare.Prima equazione cardinale analoga a  per il punto materiale. Ben nota.→𝐹=𝑚→𝑎Seconda equazione cardinale è la vera novità per il moto dei corpi estesi. La studiamo in dettaglio nel caso più semplice: il CM non ha moto traslatorio e utilizzo il sistema di riferimento intrinseco (moto rotatorio puro)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#32": "Moto rotatorio puro\n33\nScelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.\nUnica equazione cardinale utile:                        per il 3o teorema del CM\nCM\nCon il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare  ⃗ωIl sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Legge di trasformazione delle velocità tra due sistemi di riferimento in moto relativo⃗vi=⃗v′\u0000i+⃗vO′\u0000+ω∧⃗r′\u0000i",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#33": "Moto rotatorio puro\n34\nScelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.\nUnica equazione cardinale utile:                        per il 3o teorema del CM\nCM\nCon il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare \nIl sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Nulli perché i due sistemi di riferimento si muovono reciprocamente di solo moto rotatorio.⃗vi=⃗v′\u0000i+⃗vO′\u0000+ω∧⃗r′\u0000i",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#34": "Moto rotatorio puro\n35\nScelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.\nUnica equazione cardinale utile:                        per il 3o teorema del CM\nCM\nCon il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare \nIl sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’ perché  per la scelta del sistema S’ →𝑟𝑖=→𝑟′\u0000𝑖→𝑟𝑂′\u0000=→𝑟𝐶𝑀=0⃗vi=⃗v′\u0000i+⃗vO′\u0000+ω∧⃗r′\u0000i=ω∧⃗ri",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#35": "Moto rotatorio puro\n36\nScelgo un SRI dove il CM è l’origine (Sistema intrinseco) e suppongo il CM fermo.\nUnica equazione cardinale utile:                        per il 3o teorema del CM\nCM\nIn generale  è un vettore la cui direzione NON coincide con →𝑷𝑪𝑴→𝝎Con il CM fisso, l’unico moto possibile è una rotazione attorno a un asse fisso passante per il CM con velocità angolare \nIl sistema intrinseco S’ ha origine nel CM ed è solidale  con il corpo rigido: tutti i punti del corpo rigido sono fermi in S’Momento angolare per sistemi di punti materiali.Momento angolare per sistemi estesi.⃗vi=⃗v′\u0000i+⃗vO′\u0000+ω∧⃗r′\u0000i=ω∧⃗ri⃗PCM=∫V⃗r∧⃗vρdτ=∫V⃗r∧(⃗ω∧⃗r)ρdτ⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#36": "Momento angolare di un sistema rigido\n37\nProprietà del doppio prodotto vettoriale:2)  ⃗ri(⃗ω⋅⃗ri)=(xîı+yî𝚥+zîk)⋅(xiωx+yiωy+ziωz)=1) ⃗ωr2i=ωxr2îı+ωyr2î𝚥+ωzr2îk⃗ri=(xîı+yî𝚥+zîk)\n=̂ı(ωxx2i+ωyxiyi+ωzxizi)+̂𝚥(ωxxiyi+ωyy2i+ωzyizi)+̂k(ωxxizi+ωyyizi+ωzz2i)⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)⃗PCM=N∑i=1mi⃗ri∧(ω∧⃗ri)=N∑i=1mi⃗ωr2i−N∑i=1mi⃗ri(⃗ω⋅⃗ri)⃗a∧⃗b∧⃗c=⃗b(⃗a⋅⃗c)−⃗c(⃗a⋅⃗b)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#37": "Momento angolare di un sistema rigido\n38Sostituisco le espressioni trovate in precedenza=N∑i=1mi(ωxr2îı+ωyr2î𝚥+ωzr2îk)+−N∑i=1mi[̂ı(ωxx2i+ωyxiyi+ωzxizi)++̂𝚥(ωxxiyi+ωyy2i+ωzyizi)++̂k(ωxxizi+ωyyizi+ωzz2i)]⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)=",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#38": "Momento angolare di un sistema rigido\n39            =̂ı𝑁∑𝑖=1𝑚𝑖[(𝜔𝑥𝑟2𝑖−𝜔𝑥𝑥2𝑖−𝜔𝑦𝑥𝑖𝑦𝑖−𝜔𝑧𝑥𝑖𝑧𝑖)]++̂𝚥𝑁∑𝑖=1𝑚𝑖[(𝜔𝑦𝑟2𝑖−𝜔𝑥𝑥𝑖𝑦𝑖−𝜔𝑦𝑦2𝑖−𝜔𝑧𝑦𝑖𝑧𝑖)]+̂k𝑁∑𝑖=1𝑚𝑖[(𝜔𝑧𝑟2𝑖−𝜔𝑥𝑥𝑖𝑧𝑖−𝜔𝑦𝑦𝑖𝑧𝑖−𝜔𝑧𝑧2𝑖)]Raccolgo tutti i termini diretti lungo lo stesso versore⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)=",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#39": "Momento angolare di un sistema rigido\n40\nSi è sostituito: 𝑟2𝑖−𝑥2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑥2𝑖=𝑦2𝑖+𝑧2𝑖𝑟2𝑖−𝑦2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑦2𝑖=𝑥2𝑖+𝑧2𝑖𝑟2𝑖−𝑧2𝑖=(𝑥2𝑖+𝑦2𝑖+𝑧2𝑖)−𝑧2𝑖=𝑥2𝑖+𝑦2𝑖E ordino secondo le componenti di →𝜔⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)=",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#4": "Centro di Massa\n5Centro di massa:\nEquazione vettoriale  corrisponde a 3 equazioni scalari⇒𝑥𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑥𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑥𝑖𝑦𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑦𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑦𝑖𝑧𝐶𝑀=∑𝑁𝑖=1𝑚𝑖𝑧𝑖∑𝑁𝑖=1𝑚𝑖=1𝑀𝑁∑𝑖=1𝑚𝑖𝑧𝑖",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#40": "Momento angolare di un sistema rigido\n41\nCompaiono dei termini uguali nelle posizioni simmetriche. ⃗PCM=N∑i=1⃗ri∧mi⃗vi=N∑i=1mi⃗ri∧(ω∧⃗ri)=",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#41": "Momento angolare di un sistema rigido\n42\nIn generale  è un vettore la cui direzione NON coincide con →𝑷𝑪𝑴→𝝎I: tensore d’inerzia Matrice 3x3 simmetrica\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#42": "Momento d’inerzia\n43\nin generale non sono paralleli.\nproblema agli autovalori/autovettoriI=I0100010001⎛⎝⎜⎜⎜⎞⎠⎟⎟⎟In casi particolari il tensore d’inerzia è diagonale e proporzionale al tensore unitario\nIndipendentemente dalla sua forma, per un corpo rigido generico esistono tre direzioni (detti assi principali d’inerzia) per cui  : →𝑷∥→𝝎→𝑷=𝝀→𝝎Esempi: - Sfera di raggio R e massa M:    \n              - Cubo di lato L e massa M:    \n⃗P=I⃗ω=λ⃗ω(I−1λ)⃗ω=0→(I−1λ)=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#43": "Momento d’inerzia\n44problema agli autovalori/autovettoriè la matrice d’inerzia simmetrica  esistono sempre 3 autovalori e 3 autovettori che diagonalizzano la matrice𝐼 →𝐼=𝐼𝑥𝑥000𝐼𝑦𝑦000𝐼𝑧𝑧,= momenti principali d’inerzia Per tale matrice  sono gli assi principali d’inerzia.Ixx,Iyy,Izẑı,̂𝚥,̂k(I−1λ)⃗ω=0→(I−1λ)=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#44": "Momento d’inerzia\n45Se l’asse z è un asse principale d’inerzia allora quando l’asse di rotazione coincide con l’asse z (velocità angolare solo lungo l’asse z) si ha:\nPer sistemi di punti materialiPer sistemi estesi⃗P=I⃗ω=Ixx000Izz000Izz(00ω)=Izzω̂k⃗P=Izzω̂kIzz=∫V(x2+y2)ρdτ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#45": "Rotazioni attorno all’asse z:⃗P=Iω̂k\n46z\nxy\nPrendo un sistema di N punti materiali simmetrico rispetto all’asse z in moto rotatorio con velocità  attorno ad un asse coincidente con l’asse di simmetria. →𝜔Sistemi simmetrici rispetto ad un asse hanno nell’asse di simmetria un asse principale\nSe l’asse z è un asse principale d’inerzia allora quando l’asse di rotazione coincide con l’asse z si ha con →𝑃=𝐼𝑧𝑧→𝜔=𝐼𝑧𝑧𝜔^𝑘 𝐼𝑧𝑧=∑𝑁𝑖=1𝑚𝑖(𝑥2𝑖+𝑦2𝑖)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#46": "Rotazioni attorno all’asse ⃗P=Iω̂k\n47Per un sistema di N punti materiali simmetrico rispetto all’asse z\nI    (cvd)→𝑃=𝐼→𝜔=𝐼𝑥𝑥𝐼𝑥𝑦0𝐼𝑥𝑦𝐼𝑦𝑦000𝐼𝑧𝑧00𝜔^𝑘=𝐼𝑧𝑧𝜔^𝑘z\nxy\nPer un sistema di N puntiPer un sistema esteso\nIzz=∫V(x2+y2)ρdτ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#47": "Dinamica rotazionale\n48Dinamica rotazionale:\nAnaloga a :\nStessa struttura, stesse soluzioni. in generale è una variabile dinamica vettoriale descritta da 3 variabili scalari di tipo angolare che possono essere:  •2 variabili per indicare la direzione del vettore •1 variabile per l’intensità della velocità angolare.→𝜔𝑑→𝑃𝐶𝑀𝑑𝑡=→𝑀𝐸𝑆𝑇𝐶𝑀→𝑃=𝐼→𝜔𝑑→𝑣𝐶𝑀𝑑𝑡=→𝐹𝐸𝑆𝑇𝑀⟹𝑑→𝑣𝐶𝑀=→𝐹𝐸𝑆𝑇𝑀𝑑𝑡⇒→𝑣𝐶𝑀=𝑡∫0→𝐹𝐸𝑆𝑇𝑀𝑑𝑡+→𝑣0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#48": "Dinamica rotazionale\n49\nCaso più semplice: moti con asse di rotazione fisso (z): →𝜔=𝜔^𝑘\n diretto lungo l’asse z→𝑀𝐸𝑆𝑇𝐶𝑀=𝑀𝐸𝑆𝑇𝐶𝑀^𝑘𝐼𝑧𝑧𝑑𝜔𝑑𝑡=𝑀𝐸𝑆𝑇𝐶𝑀→𝑑𝜔𝑑𝑡=𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧⟹𝑑𝜔=𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧𝑑𝑡⇒Il momento d’inerzia rappresenta per la dinamica rotazionale ciò che la massa rappresenta nel moto traslatorio: fornisce l’inerzia del corpo rigido ad essere messo in moto rotatorio.𝜗(𝑡)=𝑡∫0𝜔(𝑡)𝑑𝑡+𝜗0𝜔(𝑡)=𝑡∫0𝑀𝐸𝑆𝑇𝐶𝑀𝐼𝑧𝑧𝑑𝑡+𝜔0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#49": "Esempio\n50Due punti, di uguale massa m, legati da un filo lungo 2R, ruotano nel piano orizzontale e sono soggetti ad un momento delle forze MEST costante diretto in modo perpendicolare al piano del moto.\nθ(t)\nyx =2𝑚(𝑅𝑐𝑜𝑠𝜃^𝑖)∧(−˙𝜃𝑅𝑠𝑒𝑛𝜃^𝑖)+(𝑅𝑐𝑜𝑠𝜃^𝑖)∧(˙𝜃𝑅𝑐𝑜𝑠𝜃^𝑗)+(𝑅𝑠𝑒𝑛𝜃^𝑗) ∧(−˙𝜃𝑅𝑠𝑒𝑛𝜃^𝑖)+(𝑅𝑠𝑒𝑛𝜃^𝑗) ∧(˙𝜃𝑅𝑐𝑜𝑠𝜃^𝑗)=⃗v1=d⃗r1dt=−·θRsinθ̂ı+·θRcosθ̂𝚥⃗v2=d⃗r2dt=−d⃗r1dt=−⃗v1⃗PCM=m⃗r1∧⃗v1+m⃗r2∧⃗v2=m⃗r1∧⃗v1+m(−⃗r1)∧⃗(−v1)=2m⃗r1∧⃗v1=2m⃗r1∧⃗v1=2m(Rcosθ̂ı+Rsinθ̂𝚥)∧(−R·θsinθ̂ı+R·θcosθ̂𝚥)==2𝑚˙𝜃𝑅2(𝑐𝑜𝑠2𝜃+𝑠𝑒𝑛2𝜃)^𝑘=2𝑚˙𝜃𝑅2^𝑘",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#5": "Primo teorema del Centro di Massa\n6Velocità del Centro di massa:\nCentro di massa:\nDerivando:\nRicordando:⟹⟹",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#50": "Esempio\n51Due punti, di uguale massa m, legati da un filo lungo 2R, ruotano nel piano orizzontale e sono soggetti ad un momento delle forze MEST costante diretto in modo perpendicolare al piano del moto.\nθ(t)\nyx→𝑃𝐶𝑀=𝐼→𝜔⟹2𝑚˙𝜃𝑅2^𝑘=𝐼→𝜔⟹{𝐼=2𝑚𝑅2→𝜔=˙𝜃^𝑘Caso  MEST =0  ⟹\n𝑑𝑃𝐶𝑀𝑑𝑡=𝑀𝐸𝑆𝑇→𝑃𝐶𝑀=2𝑚˙𝜃𝑅2^𝑘Seconda equazione cardinaleCaso  MEST=cost  ⟹\n  ˙𝜃(𝑡)=˙𝜃0+𝛼𝑡𝜃(𝑡)=𝜃0+˙𝜃0𝑡+12𝛼𝑡2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#51": "Momenti d’inerzia di solidi\n52Sbarra omogenea di massa M e lunghezza L: \nI=λx2dx−L2L2∫=λx33⎡⎣⎢⎤⎦⎥−L2L2=λ2L33⋅8=MLL33⋅4=ML212Disco omogeneo di raggio R e massa M: \nσ=MS=MπR2,dS=2πrdrI=σr22πrdr0R∫=2πσr44⎡⎣⎢⎤⎦⎥0R=2πMπR2R44=MR22Piastra rettangolare omogenea di lati a e b:\nσ=MS=Mab,dS=dxdy\n-a/2a/2b/2-b/2-L/2L/2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#52": "Teorema di Huygens-Steiner\n53Calcoliamo il momento d’inerzia rispetto ad un asse passante a distanza D                            dal CM (asse lungo z) per un sistema rigido di N punti materiali.\nCMxyy’x’z’z\nPer definizioneIntroduco il SR intrinseco\nIl momento d’inerzia rispetto ad un asse qualunque è sempre pari al momento d’inerzia calcolato rispetto ad un asse parallelo a quello dato ma passante per il CM aumentato della quantità MD2 con D distanza tra i due assi.\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#53": "Teorema di König per corpi rigidi\n54Energia cinetica di un sistema di punti materialiVelocità dei punti nel sistema del CM\nαd\nT=T'+TCM=12mivi'2i∑+12MvCM2\nEnergia cinetica di rotazioneEnergia cinetica di traslazioneCome si calcola l’energia cinetica totale di un corpo rigido?Ipotesi semplificata: corpo in rotazione istantanea attorno a un asse passante per il CM diretto lungo z.",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#54": "Statica dei corpi rigidi•Quando un corpo rigido è in condizioni statiche? (ànon si muove)\n55\nEquazioni cardinali della Dinamica dei sistemiR: Quando ogni punto del corpo è e rimane fermo!                      il corpo non trasla e non ruota!\nControllo forze e momenti esterni e questo garantisce che il corpo resti fermo per il 1°, 2° e 3° principio!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#55": "Macchina di AtwoodDiscutere il moto dei due oggetti 1 e 2 appesi tra loro su una carrucola tramite un filo ideale nel caso: 1) la carrucola sia ideale; 2) la carrucola sia reale. \n56\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#56": "EsercizioUn’asta omogenea di sezione trascurabile, di massa m e lunghezza l giace su un piano orizzontale liscio inizialmente ferma ed incernierata in uno degli estremi. Ad un certo istante un punto materiale di massa 2m che si muove con velocità v0 urta in modo totalmente anelastico e perpendicolarmente l’asta nel suo centro. Calcolare le espressioni:  1)Della velocità angolare del sistema dopo l’urto; 2)Della reazione vincolare che agisce sul sistema dopo l’urto.57",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#57": "EsercizioUna forza costante di 1960 N applicata tangenzialmente al bordo di un disco di raggio R=100 cm ne fa variare la velocità angolare da 4 s-1 a 2 s-1 in 30 s. Determinare: -il momento d’inerzia della ruota attorno al suo asse;  -il modulo della variazione del momento angolare nei 30 sec considerati;  -l’angolo descritto dalla ruota in questo intervallo di tempo -l’energia cinetica persa.\n58",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#58": "EsercizioUn disco omogeneo di massa M = 0.4 kg e raggio R = 10 cm viene appoggiato in verticale su un piano inclinato di 30° rispetto l’orizzontale. Sapendo che il disco scende rotolando senza strisciare, determinare la velocità di traslazione del disco dopo aver compiuto 2 m sul piano inclinato.\n59",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#59": "EsercizioDue volani assimilabili a due dischi aventi massa e raggio rispettivamente di M1 = 187,5 kg, R1 = 80 cm, M2 = 120 kg e R2 = 50 cm ruotano attorno allo stesso asse fisso orizzontale coincidente con il loro asse di simmetria con velocità angolari di  e . Ad un certo istante I due volani vengono messi a contatto. Calcolare la velocità angolare finale trascurando gli effetti transienti.𝜔1=33 𝑟𝑎𝑑/𝑠𝜔2=2𝜔1\n60",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#6": "Secondo teorema del Centro di Massa\n7Accelerazione del Centro di massa:\nPrima equazione cardinale→𝑎𝐶𝑀=𝑑→𝑣𝐶𝑀𝑑𝑡=𝑑(→𝑄𝑀)𝑑𝑡=1𝑀𝑑→𝑄𝑑𝑡=1𝑀→𝐹𝐸𝑆𝑇\nAnalogia formale  (e sostanziale) con: \nLa 1a equazione cardinale descrive il moto di un punto fittizio che è il CM. Se il sistema non è soggetto a forze esterne, il CM si muove con velocità costante. ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#60": "EsercizioUna Colonna di marmo di massa M = 600 kg ha la forma di un parallelepipedo a base quadrata di lato L = 30 cm e altezza h = 2.5 m ed è appoggiata in vertical su un piano ruvido inclinato di un angolo  rispetto l’orizzontale. Schematizzando la colonna come una figura piana che appoggia sul piano inclinator nei punti A e B distanti L determinare: 1)Il valore Massimo dell’angolo che permette la stabilità 2)La forza di attrito statica necessaria alla stabilità 3)Il minimo valore del coefficiente di attrito statico necessario per tenere ferma la colonna se 𝛼𝛼=5°\n61\nAB",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#61": "EsercizioDue punti materiali di massa M ruotano nel piano (x,y) attorno all’origine seguendo le equazioni del moto: Determinare le forze esterne ed i momenti delle forze esterne che agiscono sul sistema al tempo t=0.  \n62θ(t)=α2t2+ϖ0t",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#62": "EsercizioUn disco di massa M = 0.5 kg, raggio R = 0.2 m e spessore trascurabile ha densità superficiale . Supponendo che il disco sia disposto orizzontalmente e ruoti attorno ad un asse verticale passante per il suo centro con velocità angolare  = 4 rad/s, calcolare l’energia cinetica del sistema.σ=kr⃗ω\n63",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#63": "Esercizio\n64Una sbarra omogenea di massa M e lunghezza L è appesa al soffitto tramite un filo collegato al suo centro di massa. La sbarra si muove in un piano orizzontale (x,y) e il filo esercita un debole momento delle forze dato da                          .       Calcolare il periodo del movimento.\nxy\nθ\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#7": "Sistema di riferimento del CM\n8\nPosizione del CM rispetto al CMVelocità del CM rispetto al CM\nCalcoliamo la posizione del CM nel sistema intrinsecoIl CM definisce un punto importante per capire la dinamica del sistema. La prima equazione cardinale riguarda il moto di questo punto.  Che cosa descrive la seconda equazione cardinale?E’ conveniente introdurre un nuovo sistema di riferimento S’ (in generale NON inerziale) che esalti il ruolo del CM: SR Intrinseco con origine coincidente col CM.\nO\nCM=O’\n→𝑟𝑖\n→𝑟𝐶𝑀",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#8": "Terzo teorema del centro di massa\n9Riscriviamo il momento angolare nel SRI usando il sistema intrinseco:\n=𝑁∑𝑖=1𝑚𝑖(→𝑟′\u0000𝑖+→𝑟𝐶𝑀)∧(→𝑣′\u0000𝑖+→𝑣𝐶𝑀)Sostituendo:=𝑁∑𝑖=1𝑚𝑖→𝑟′\u0000𝑖∧→𝑣′\u0000𝑖+𝑁∑𝑖=1𝑚𝑖→𝑟′\u0000𝑖∧→𝑣𝐶𝑀+𝑁∑𝑖=1𝑚𝑖→𝑟𝐶𝑀∧→𝑣′\u0000𝑖+𝑁∑𝑖=1𝑚𝑖→𝑟𝐶𝑀∧→𝑣𝐶𝑀=𝑁∑𝑖=1𝑚𝑖→𝑟′\u0000𝑖∧→𝑣′\u0000𝑖+(𝑁∑𝑖=1𝑚𝑖→𝑟′\u0000𝑖)∧→𝑣𝐶𝑀+→𝑟𝐶𝑀∧(𝑁∑𝑖=1𝑚𝑖→𝑣′\u0000𝑖)+(𝑁∑𝑖=1𝑚𝑖)→𝑟𝐶𝑀∧→𝑣𝐶𝑀=momento angolare del sistema calcolato rispetto al SR intrinseco⃗P′\u0000CM=𝑀⟹𝑀→𝑟𝐶𝑀∧→𝑣𝐶𝑀Momento angolare di un punto di massa M situato nel CM Nulli per dimostrazione precedente⃗P0=N∑i=1⃗pi=N∑i=1mi⃗ri∧⃗vi",
    "data_test\\rootfolder\\università\\FisicaGenerale\\07-dinamica-sistemi.pdf#9": "Terzo teorema del centro di massa\n10\nSpin o momento angolare intrinseco\nTerzo teorema del centro di massa: il momento angolare rispetto ad un polo O di un sistema di punti materiali è in ogni istante uguale alla somma del momento angolare del sistema calcolato nel sistema di riferimento del centro di massa e del momento angolare rispetto allo stesso polo O di un punto materiale di massa pari alla massa totale M del sistema collocato nel CM.⃗P0=⃗P′\u0000CM+M⃗rCM∧⃗vCM=⃗P′\u0000CM+⃗rCM∧⃗Q",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#0": "Campo Gravitazionale CdS Ingegneria Informatica A.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#1": "Moto dei pianeti\n2Meccanica diventa disciplina coerente dopo un’accurata e attendibile descrizione del moto dei pianeti: moto in assenza di attriti studiabile per lungo tempo -> metodo scientifico facilmente applicabile: Comprensione del moto -> previsione del moto -> verifica sperimentale.Principali risultati grazie a : -Tycho Brahe (1546-1601): misura di precisione delle posizioni dei pianeti -Johannes Kepler (1571-1630): formulazione leggi empiriche sui moti dei pianeti a partire dai dati di Brahe\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#2": "Leggi di Keplero1.I pianeti descrivono orbite piane, ellittiche, di cui il Sole occupa uno dei due fuochi. 2.Il raggio vettore che unisce il centro del Sole con il centro del pianeta descrive aree uguali in tempi uguali. 3.I quadrati dei tempi che i pianeti impiegano a percorrere le loro orbite sono proporzionali al cubo del semiasse maggiore dell’orbita.3\na2T3=costante",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#3": "Gravitazione universale\n4•Cosa fa girare i pianeti? •Moto può avvenire anche in assenza di forza (principio di inerzia), ma serve una “spinta” centripeta per mantenere il corpo in traiettoria curva. •Newton: pianeti si muovono sottoposti alla forza di gravità che è la stessa che fa cadere i corpi a Terra. •Che forma ha questa forza?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#4": "5Velocità areolare\nA(t)=limΔt→0ΔSΔtαΔt→0⎯→⎯⎯π−β[A(t)]=[rv]=[L2T−1]→(m2/s) !A=12P−O()∧!v=12!r∧!v",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#5": "Gravitazione universale\n61a legge di Keplero: il moto avviene su un piano.Velocità areolare2a legge di Keplero: la velocità areolare è costante in modulo.\n2o principio dinamica ⃗A=12(P−O)∧⃗v=12⃗r∧⃗vd⃗Adt=12ddt(⃗r∧⃗v)=12(d⃗rdt∧⃗v+⃗r∧d⃗vdt)=12(⃗v∧⃗v+⃗r∧⃗a)=12⃗r∧⃗a=⃗0Campo centrale a simmetria sferica",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#6": "Gravitazione universale\n73a legge di Keplero:Moto dei pianeti può essere schematizzato come moto circolare uniforme \nStessa struttura di quanto ipotizzato dalla 2a leggeDallo studio dei moti celesti:  con M=massa attorno a cui ruota m     GM=4π2kCostante di gravitazione universaleG=6,672⋅10−11N⋅m2kg2a2T3=costanteT=2πω→ω=2πT⃗a(t)=⃗at+⃗an=··ŝut+v2ρ̂un=v2ρ̂unT2=kR3⃗Fcentripeta=m⃗ac=mv2R̂un=mω2R̂un=m4π2T2R̂un⟹⃗Fcentripeta=m4π2T2R̂un=m4π2kR3R̂un=−m4π2kR2̂ur",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#7": "Legge di gravitazione universale\n8\nUn qualsiasi punto materiale P1 di massa m1 esercita su un qualunque altro punto materiale P2 di massa m2 una forza gravitazionale F12 diretta secondo la congiungente di P1 con P2, sempre attrattiva, in modulo direttamente proporzionale al prodotto delle due masse e inversamente proporzionale al quadrato della distanza fra P1 e P2. •Per il terzo principio della dinamica se P1 esercita una forza su P2 allora P2 esercita una forza  su P1 uguale e contraria •Sul sistema agiscono due forze di risultante nulla ma applicate in punti di applicazione diversi -> il moto è uno solo •La forza gravitazionale è conservativa poiché è un campo centrale a simmetria sferica -> esiste un potenziale gravitazionale ⃗F12⃗F21conˆr=P2−P1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#8": "Energia potenziale gravitazionale\n9Campo conservativo\nCostante arbitrariaScelgo r0→∞⇒V(∞)=−Gm1m2r0=0V(A)=−Gm1m2rAEnergia potenziale gravitazionale",
    "data_test\\rootfolder\\università\\FisicaGenerale\\08-gravitazione.pdf#9": "Velocità di fuga\n10\nVelocità di fuga: velocità minima che occorre imprimere ad un corpo per far si che si allontani da un altro corpo senza ricadervi.Corpo in R si allontana in modo che arrivi all’infinito con velocità nullaConservazione dell’energia meccanica\n12mvfuga2−GmMR=0⇒vfuga=2GMRG",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#0": "1 Elettrostatica CdS Ingegneria Informatica A.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#1": "2Fenomeni elettriciFenomeni elettrici (e magnetici) noti dall’antichità\nTeoria completa dei fenomeni elettrici (e magnetici) nella seconda metà XIX secolo: Volta, Ampère, Faraday, Maxwell, Ørsted \n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#10": "11Elettrizzazione per contatto\nAC++++++++12Q+AB++++++++12Q+12Q+++++++++Fino a che punto possiamo suddividere (separare) la carica elettrica?\nLimite della Natura la più piccola carica elettrica osservata fino ad ora in natura è quella dell’elettrone (-) e del protone (+)Cariche elettriche frazionar ie della carica elementari sono s tate ipotizzate  (quark confinati all’interno di protoni e neutroni) ma MAI osservate fino ad ora",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#11": "12La carica elettricaUnità di misura della carica elettrica nel Sistema Internazionale:  C  (Coulomb) Carica dell’elettrone:   qe= −1.6 × 10-19 C   Carica del protone:      qp= +1.6 × 10-19 C Limite sperimentale:                                                               \u0000\u0000\u0000\u0000|qe|\u0000|qp||qp|\u0000\u0000\u0000\u0000<⇡10\u000021",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#12": "13La carica elettrica - esempiCarica degli elettroni in una goccia d’acqua (1g)  Ne=(Np)=3×1023     |Qe|=(|Qp|)=5×104 C  Forza tra due cariche da 1C ad 1m di distanza 9×109 N (equivalente a 100 Titanic!!)Carica in processi triboelettrici  |Q|=10-7C (1011 elettroni)1m1C1C×100",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#13": "14Proprietà carica elettricaEsistono due tipi di cariche elettriche  •convenzionalmente positive e negative La carica elettrica è quantizzata •in natura le cariche sono multiple della carica elettrica elementare  |qe|= 1.6 × 10-19−19 C In un sistema isolato, la carica elettrica si conserva •il numero totale di cariche (negative e positive) rimane invariato ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#14": "15Interazioni tra cariche elettriche~F=m~aIpotesi iniziali (per il momento…) •Scegliamo un sistema di riferimento inerziale: -un corpo non soggetto a forze si muove con velocità costante -  •Supponiamo che ci sia il vuoto nello spazio interposto tra le cariche che interagiscono •Consideriamo solo cariche ferme (ELETTROSTATICA)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#15": "16Forza elettrostaticaBilancia di torsione (Coulomb, fine XVIII sec)\n𝜃Avvicinando la cariche q2 e q1, si arriva ad una situazione di equilibrio in cui la forza elettrica è bilanciata dalla forza di torsione del pendolo Felettrica=Ftorsione∝𝜃  Dalla misura dell’angolo 𝜃 si ricava l'intensità della forza elettrica.q1, q2 cariche  r distanza tra le cariche 𝜃 angolo di torsione|Fel|/|q1||q2|r2Sperimentalmente si osserva: ricordiamoci che la forza è un vettore…",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#16": "17Legge di Coulomb\nz\ny\nx\nq1q2SdR cartesiano ortogonaleForza esercitata dalla carica q1 sulla carica q2\nCostante dielettrica del vuoto:q1 e q2  puntiformi~F12=14⇡\"0q1q2r3~r~F12ha stessa direzione di~re verso che dipende dal segno delle cariche⃗F12=14πε0q1q2r2̂ur\n(Farad verrà introdotto in seguito)ε0=8.85×10−12C2Nm2=8.85×10−12Fm14πε0=8.99×109Nm2C2⃗r=⃗r2−⃗r1⃗r1⃗r2⃗F12=q1q24πε0⃗r2−⃗r1|⃗r2−⃗r1|3⃗F12=14πε0q1q2r3⃗r",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#17": "18Legge di Coulomb~F21=\u0000~F12III principio della dinamica (sistema isolato)Il vettore forza è applicato sulla caricaStesso segnoq1q2~r=~r2\u0000~r1~F12=14⇡\"0q1q2r3~r~F21q1q2~r=~r2\u0000~r1~F12=14⇡\"0q1q2r3~r~F21Segni opposti",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#18": "19Esercizio\n𝜃 l m,q m,q l Esercizi di Fisica Generale T2Lorenzo Rinaldi18/9/20181 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, le due palline formanoun angolo✓con la verticale. Determinare quanto vale la carica sulle due palline (nell’approssimazione dipiccoli angoli).(R:q=p16⇡\"0mgl2✓3)1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏025+15p2\u000012p330)1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1=\u00004·10\u00007C,q2=+ 2·10\u00007Ceq3=+ 1·10\u00007C, determinare l’energia elettrostatica del sistema.(R:U=\u000010q24⇡✏0a=\u00009·10\u00003J)1.4Quattro particelle con la stessa caricaQ=-1nC si trovano ai vertici di un quadrato di latol=12cm. Si calcoli:a) il modulo dell’intensit` a del campo elettrico nel centroOdel quadrato e nel punto medioMdi ciascunlato (R:EO= 0,EM=4p525q⇡✏0l2=8.93⇥102V/m);b) la di↵erenza di potenziale tra i puntiOeM;(R:\u0000V=q⇡✏0l(1 +p5/5\u0000p2)=1.12 V)c) il lavoro che si deve compiere per avvicinare le cariche e disporle ai vertici di un quadrato di latol/2.(R:L=q24⇡✏0⌃i,j>i1rij=4.06⇥10\u00007J)1.5Si consideri una carica elettrica distribuita uniformemente con densit` a di carica lineare\u0000=10\u00005C/m su diun ﬁlo di lunghezzaL=10 cm. Si calcoli il campo elettrico in un puntoAposto a distanzah=3 cm daun’estremit` a del ﬁlo, perpendicolarmente ad esso.(Ex=\u00004⇡✏0hLph2+L2,Ey=\u00004⇡✏0h(hph2+L2\u00001))1Esercizi di Fisica Generale T2Lorenzo Rinaldi18/9/20181 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, le due palline formanoun angolo✓con la verticale. Determinare quanto vale la carica sulle due palline (nell’approssimazione dipiccoli angoli).(R:q=p16⇡\"0mgl2✓3)1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏025+15p2\u000012p330)1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1=\u00004·10\u00007C,q2=+ 2·10\u00007Ceq3=+ 1·10\u00007C, determinare l’energia elettrostatica del sistema.(R:U=\u000010q24⇡✏0a=\u00009·10\u00003J)1.4Quattro particelle con la stessa caricaQ=-1nC si trovano ai vertici di un quadrato di latol=12cm. Si calcoli:a) il modulo dell’intensit` a del campo elettrico nel centroOdel quadrato e nel punto medioMdi ciascunlato (R:EO= 0,EM=4p525q⇡✏0l2=8.93⇥102V/m);b) la di↵erenza di potenziale tra i puntiOeM;(R:\u0000V=q⇡✏0l(1 +p5/5\u0000p2)=1.12 V)c) il lavoro che si deve compiere per avvicinare le cariche e disporle ai vertici di un quadrato di latol/2.(R:L=q24⇡✏0⌃i,j>i1rij=4.06⇥10\u00007J)1.5Si consideri una carica elettrica distribuita uniformemente con densit` a di carica lineare\u0000=10\u00005C/m su diun ﬁlo di lunghezzaL=10 cm. Si calcoli il campo elettrico in un puntoAposto a distanzah=3 cm daun’estremit` a del ﬁlo, perpendicolarmente ad esso.(Ex=\u00004⇡✏0hLph2+L2,Ey=\u00004⇡✏0h(hph2+L2\u00001))1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#19": "20Forza elettrica vs forza gravitazionaleForza ElettrostaticaForza GravitazionaleHanno stessa forma (entrambe dipendono dall’inverso del quadrato), ma… A. la forza elettrica è molto più intensa della forza gravitazionale B.la massa è sempre positiva (forza gravitazionale sempre attrattiva)14πε0=8.99×109 Nm2C−2G=6.67×10−11kg−1m3s−2⃗FCoulomb=14πε0q1q2r2̂ur⃗FGravitazionale=−Gm1m2r2̂ur",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#2": "3Fenomeni elettriciOsservazioni sperimentali (note da VI secolo A.C): oggetti di diversi materiali (es. vetro, plastica, ambra), dopo strofinio su panno di lana, se posti in vicinanza: •oggetti della medesima sostanza, si respingono •oggetti di sostanze diverse possono respingersi o attrarsi \nplastica\nvetro\nambra\nvetro\nplastica\nambra\nevidenza sperimentale esistenza di una forza",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#20": "21EsempioCalcolare il rapporto tra le intensità della forza elettrica e di quella gravitazionale fra un elettrone ed un protone qe= −1.6 × 10-19 C       me= 1.9 × 10-31 kg  qp= +1.6 × 10-19 C       mp= 1.7 × 10-27 kg  G= 6.77 × 10-11 Nm-2kg-2 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#21": "22Forza elettrostatica e principio di sovrapposizione\nq3q2q1Sistema di N=3 cariche puntiformiForza totale sulla carica q1 è la somma vettoriale della forza        che la carica q2  eserciterebbe su q1 se q3 fosse assente e della forza          che la carica q3  eserciterebbe su q1 se q2 fosse assente⃗F1=⃗F21+⃗F31⃗F21⃗F31⃗F31⃗F1⃗F21",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#22": "23Forza elettrostatica e principio di sovrapposizione\nq\nsistema di N cariche puntiformiForza totale sulla carica q è la somma vettoriale delle forze che le cariche qi eserciterebbero singolarmente su q se qj≠i fossero assentiqi⃗F=N∑i=1⃗Fi⃗ri⃗rivettore posizione da qi a qqj=N∑i=114πε0qqir3i⃗ri",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#23": "24Il campo elettrostaticoLa forza di Coulomb può essere riformulata utilizzando il concetto di campo di forza •una carica Q altera le proprietà dello spazio, introducendo un campo elettrico    di cui Q è la sorgente •una seconda carica q (carica esploratrice) sentirà una forza dovuta alla presenza della carica Q⃗E⃗F\n  !=lim\"V#0\"q\"V=dqdVDistribuzioni Continue di Carica (II) •!Infine se la carica è distribuita in un volume conviene descrivere la distribuzione della carica utilizzando la densità volumetrica di carica (misurata in C/m3): •!Vogliamo ora calcolare la forza esercitata da una distribuzione di carica descritta dalla densità volumetrica & su di una carica puntiforme q posta a una certa distanza. •!Un volumetto elementare dV situato nel punto P) di vettore posizionale    conterrà la carica elettrica: !r!!r!r!!\"r  dVVqr!!   dq=!!\"r()dV25!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nDistribuzioni Continue di Carica (III) •!Il volumetto dV può essere considerato come una carica puntiforme e dunque possiamo applicare a esso la legge di Coulomb: •!Per il principio di sovrapposizione, la forza totale prodotta su q dalla carica contenuta nel volume V sarà la somma dei contribuiti di tutti i volumetti infinitesimi dV: d!F=14!\"0#!$r()dVdq\"#$%$q!r%!$r3!r%!$r()!F=14!\"0q#!$r()!r%!$r3!r%!$r()dVV&'((&'((&'((26!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!r!!r!r!!\"r  dVVq!F12=14!\"0q1q2r3!r\nCampo Elettrico •!La forza di Coulomb può essere riformulata utilizzando il concetto di campo di forza. •!Possiamo pensare che la presenza di una carica elettrica q1 posta nel punto P1 alteri le proprietà dello spazio, introducendo in esso un campo elettrico. •!Poniamo una carica puntiforme Q nell’origine di una terna cartesiana di riferimento e una seconda carica puntiforme q a una certa distanza r. La forza agente su q si può scrivere: !rqQ!F!r()=14!\"0Qqr2ˆr=q14!\"0Qr2ˆr#$%&'(!E!r()\"#$%$=q!E!r()27!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!F12=14!\"0q1q2r2ˆr\nCampo Elettrico (II) •!Possiamo allora definire campo elettrico di una carica puntiforme Q il campo vettoriale: e scrivere la forza agente su di una carica q situata nel punto di raggio vettore    come:   !F!r()=q!E!r()   !E!r()=14!\"0Qr2ˆrr!\n28!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!rqQQ⃗Eq⃗E=limq→0⃗Fq⃗F=q⃗Elimite va inteso in senso “fisico”: • q è quantizzata  •possiamo trascurare i fenomeni di induzione dovuti a q",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#24": "25Campo elettrostatico di una carica puntiforme\nz\ny\nxQq⃗rIn un SdR cartesiano poniamo: •carica sorgente Q nell’origine •carica esploratrice q in posizione  •q≪Q (trascuriamo il campo elettrico generato da q)⃗r⃗F(⃗r)=14πε0qQr2̂ur⃗E(⃗r)=14πε0Qr2̂ur\ncampo elettrostatico di una carica puntiforme Qla carica q è soggetta alla forza:⃗E=q14πε0Qr2̂ur=q⃗E(⃗r)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#25": "26Campo elettrostatico di una carica puntiformeL’azione della carica Q sulla carica q viene separata in due fasi distinte: • La creazione, da parte della carica Q, di un campo elettrico          in ogni punto dello spazio; •L’accoppiamento nel punto     del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico.  Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (V olt/metro)⃗E(⃗r)⃗E(⃗r)⃗r",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#26": "27Campo elettrico di una carica puntiforme\nCampo centrale: •diretto come versore -uscente da Q positiva -entrante in Q negativa •modulo dipende solo da r ̂rIl campo elettrico è un campo vettoriale: per ogni punto dello spazio è associato un vettore\nCampo Elettrico (III) •!In questo modo l’azione della carica Q sulla carica q viene separata in due fasi distinte: –!La creazione, da parte della carica Q, di un campo elettrico in ogni punto dello spazio; –!L’accoppiamento nel punto    del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico. •!Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (Volt/metro) e le sue dimensioni sono:   !E!r()  !E!r()r!\n  E!\"#$=F!\"#$Q!\"#$=MLT%3I%1!\"#$29!!rqQDomenico Galli – Fisica Generale B – 1. Elettrostatica!\nCampo Elettrico (IV) •!Il campo elettrico è un campo vettoriale: –!A ogni punto dello spazio è associato un vettore, il vettore campo elettrico:                                   . \n30!Domenico Galli – Fisica Generale B – 1. Elettrostatica!P!!3()\"E\"#\"\"EP()!V\nIntegrale di Superficie di una Funzione Vettoriale •!Sia data una funzione vettoriale   definita in R3 e sia data una superficie % !R3; •!Suddividiamo la superficie % in un certo numero n di superfici infini-tesime &%, prendiamo su di esse i punti: e consideriamo la somma: •!Nel limite in cui le superfici &% diventano infinitesime, la somma diventa l’integrale di superficie: \nDomenico Galli – Fisica Generale B – 1. Elettrostatica!!vP1x1,y1,z1(),P2x2,y2,z2(),…,Pnxn,yn,zn()!vPi()iˆnPi()!\"i=1n#!vPi()iˆnPi()!\"i=1n#n$%!\"$0&$&&I=!vP()iˆnd\"\"''31!\nIntegrale di Superficie di una Funzione Vettoriale (II) •!La superficie % !R3, può essere definita utilizzando i parametri $ e %: •!L’integrale di superficie si calcola quindi come: \nDomenico Galli – Fisica Generale B – 1. Elettrostatica!!=P\"!3;P=P#,$(),#\"#1,#2%&'(,$\"$1,$2%&'({}!vP()iˆnd!!\"\"=d#!vP#,$()()i%P\"!\"%#&%P\"!\"%$'()*+,d$$1$2\"#1#2\"\n32!\nCampo Elettrico (III) •!In questo modo l’azione della carica Q sulla carica q viene separata in due fasi distinte: –!La creazione, da parte della carica Q, di un campo elettrico in ogni punto dello spazio; –!L’accoppiamento nel punto    del campo elettrico          con la carica q. La forza osservata sulla carica q si stabilisce per effetto dell’accoppiamento locale carica-campo elettrico. •!Nel Sistema Internazionale il campo elettrico si misura in N/C (Newton/Coulomb) o V/m (Volt/metro) e le sue dimensioni sono:   !E!r()  !E!r()r!\n  E!\"#$=F!\"#$Q!\"#$=MLT%3I%1!\"#$29!!rqQDomenico Galli – Fisica Generale B – 1. Elettrostatica!\nCampo Elettrico (IV) •!Il campo elettrico è un campo vettoriale: –!A ogni punto dello spazio è associato un vettore, il vettore campo elettrico:                                   . \n30!Domenico Galli – Fisica Generale B – 1. Elettrostatica!P!!3()\"E\"#\"\"EP()!V\nIntegrale di Superficie di una Funzione Vettoriale •!Sia data una funzione vettoriale   definita in R3 e sia data una superficie % !R3; •!Suddividiamo la superficie % in un certo numero n di superfici infini-tesime &%, prendiamo su di esse i punti: e consideriamo la somma: •!Nel limite in cui le superfici &% diventano infinitesime, la somma diventa l’integrale di superficie: \nDomenico Galli – Fisica Generale B – 1. Elettrostatica!!vP1x1,y1,z1(),P2x2,y2,z2(),…,Pnxn,yn,zn()!vPi()iˆnPi()!\"i=1n#!vPi()iˆnPi()!\"i=1n#n$%!\"$0&$&&I=!vP()iˆnd\"\"''31!\nIntegrale di Superficie di una Funzione Vettoriale (II) •!La superficie % !R3, può essere definita utilizzando i parametri $ e %: •!L’integrale di superficie si calcola quindi come: \nDomenico Galli – Fisica Generale B – 1. Elettrostatica!!=P\"!3;P=P#,$(),#\"#1,#2%&'(,$\"$1,$2%&'({}!vP()iˆnd!!\"\"=d#!vP#,$()()i%P\"!\"%#&%P\"!\"%$'()*+,d$$1$2\"#1#2\"\n32!⃗E(⃗r)=14πε0Qr2̂ur",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#27": "28Principio di sovrapposizione del campo elettricosistema di N cariche puntiformiDimostriamo cheq\nqi⃗ri⃗E⃗F=q⃗E⃗F=N∑i=1⃗Fi=qN∑i=1[14πε0qir3i⃗ri]\nprincipio di sovrapposizione del campo elettrico ⃗E=N∑i=1⃗Ei⃗Ei=14πε0qir3i⃗ri=N∑i=114πε0qqir3i⃗ri=N∑i=1q[14πε0qir3i⃗ri]==qN∑i=1⃗Ei=q⃗E",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#28": "29Distribuzioni continue di caricaSpesso la carica elettrica non è puntiforme ma può essere distribuita in un volume nello spazio, su di una superficie o lungo una linea⇢=l i m\u0000⌧!0\u0000q\u0000⌧=dqd⌧\u0000=l i m\u0000l!0\u0000q\u0000x=dqdx\u0000=l i m\u0000S!0\u0000q\u0000S=dqdSDensità volumetrica di caricaDensità superficiale di caricaDensità lineare di carica\ndS\ndl\nd𝜏dq=ρdτcarica contenuta nel volumetto d𝜏  dq=σdS(C/m3)(C/m2)(C/m)\nqτ=∭τρdτcarica contenuta nel volume 𝜏  carica contenuta sulla sup. dS  carica contenuta sulla sup S  carica contenuta sulla linea dl  carica contenuta sulla linea l   qS=∬SσdSql=∫lλdldq=λdl",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#29": "30Campo elettrostatico da distribuzioni continue\nz\ny\nx\nP⃗r−⃗r′\u0000⃗r⃗r′\u0000Campo elettrico nel punto P generato da una carica infinitesima dq (contenuta in d𝜏):dq=ρ(⃗r′\u0000)dτPer il principio di sovrapposizione  (e sostituendo al limite la somma con l’integrale)volume 𝜏d⃗E(⃗r)=dq4πε0(⃗r−⃗r′\u0000)|⃗r−⃗r′\u0000|3=ρ(⃗r′\u0000)dτ4πε0(⃗r−⃗r′\u0000)|⃗r−⃗r′\u0000|3⃗E(⃗r)=14πε0∭τρ(⃗r′\u0000)(⃗r−⃗r′\u0000)|⃗r−⃗r′\u0000|3dτ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#3": "4Elettrizzazione per strofinio (triboelettricità)In natura esistono due tipi di elettrizzazione a cui possiamo associare due tipologie di cariche elettriche Convenzionalmente: •elettrizzazione vetrosa     à carica elettrica positiva •elettrizzazione resinosa   à carica elettrica negativa • cariche dello stesso segno: forza repulsiva • cariche di segno opposto: forza attrattiva\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#30": "31Campo elettrostatico da distribuzioni continue\ndl\ndS\nd𝜏Carica distribuita  in volume 𝜏Carica distribuita  su superficie SCarica distribuita  su linea l\nWarning! formule generali da usare con attenzione: il calcolo degli integrali può risultare complesso, non fare confusione tra r (posizione del punto in cui si vuole calcolare il campo) e r’ (variabile di integrazione, relativa alla posizione delle cariche)⃗E(⃗r)=14πε0∫lλ(⃗r′\u0000)(⃗r−⃗r′\u0000)|⃗r−⃗r′\u0000|3dl⃗E(⃗r)=14πε0∭τρ(⃗r′\u0000)(⃗r−⃗r′\u0000)|⃗r−⃗r′\u0000|3dτ⃗E(⃗r)=14πε0∬Sσ(⃗r′\u0000)(⃗r−⃗r′\u0000)|⃗r−⃗r′\u0000|3dS",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#31": "32Il campo elettrico è un campo conservativo?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#32": "33PremessaFino ad ora ci siamo posti in condizioni statiche: le cariche sono ferme → ELETTROSTATICA Non abbiamo ancora studiato gli effetti delle cariche in moto   (esistono forze associate ai movimenti delle cariche?) Per il momento continuiamo la trattazione statica: il campo elettrostatico è conservativo?Andiamo a verificare una delle condizioni di conservatività dei campi ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#33": "34Circuitazione del campo elettrostaticoCalcoliamo la circuitazione del campo lungo la linea chiusa 𝛤 : circonferenza di raggio R centrata in Q \nTeorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS\"!!=!\"i!vdVV!!!\n57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV\"P{}!vSV()\"##iˆndSdVV###=$tot!v()%V!!i!v()Pi()\"Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V\nTeorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: \n58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()\"Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn\"Sfacceesterne#!!i!vdVV%%%=!viˆndSS\"%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V\nLinee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()\n59!  !E!r()\nDomenico Galli – Fisica Generale B – 1. Elettrostatica!\nAngolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido \" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr\"0,2#$%$%!=Sr2\"0,4#$%&'S!r\n60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!Qd⃗l=̂utdl\n∮Γ⃗E⋅d⃗l=∮ΓQ4πε0r2̂ur⋅̂utdl`=0\nIl campo elettrico (elettrostatico) generato da una carica puntiforme ferma è conservativo𝛤Circuitazione nullâr",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#34": "35Proprietà del campo elettrostaticoIl campo elettrostatico eredita tutte le proprietà dei campi conservativi∮Γ⃗E⋅d⃗l=0⃗∇∧⃗E=⃗0Il campo elettrostatico ha sempre circuitazione nullaIl campo elettrostatico è  irrotazionale  (non esistono linee di campo chiuse su loro stesse)Equazioni fondamentali dell’elettromagnetismo, applicate al caso statico (cariche ferme)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#35": "36Proprietà del campo elettrostaticoIl campo elettrostatico eredita tutte le proprietà dei campi conservativi\n∃ una funzione scalare V(x,y,z):⃗E=−⃗∇VV(x,y,z) è il potenziale elettrostatico ⃗E⋅d⃗l=−dVè un differenziale esattoV(A)−V(B)=∫BA⃗E⋅d⃗lL’integrale non dipende dal percorsometodo per calcolare  il potenziale, partendo dal campo elettrostaticometodo per calcolare  il campo elettrico, partendo dal potenziale ∃ una funzione scalare V(x,y,z):⃗E=−⃗∇V",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#36": "37Il potenziale elettrostaticoIl potenziale elettrostatico V(x,y,z) è una funzione scalare in ℝ3   Dato un campo elettrostatico, operativamente il potenziale si calcola integrando il differenziale esattodV=−⃗E⋅d⃗lIl potenziale è definito a meno di una costante additiva arbitraria La differenza di potenziale tra due punti è indipendente dalla costante arbitraria (è una grandezza misurabile → circuiti) integrale indefinitointegrale definitoV(A)−V(B)=∫BA⃗E⋅d⃗lV(x,y,z)=−∫⃗E⋅d⃗l+costL’unità di misura del potenziale nel S.I. è il Volt=Joule/Coulomb  (V)=(J)/(C)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#37": "38Il potenziale elettrostatico: carica puntiformeV(⃗r)=−∫⃗E⋅d⃗l+cost\nQd⃗l=̂rdr+̂u⊥dl⊥̂u⊥dl⊥d⃗l̂urdr⃗E=Q4πε01r2̂urV(⃗r)=[−∫Q4πε01r2̂ur⋅(̂urdr+̂u⊥dl⊥)]+cost=[−∫Q4πε01r2(̂ur⋅̂urdr+̂ur⋅̂u⊥dl⊥]+costCalcoliamo V dall’integrale indefinito lungo una generica curva 𝛤  =[−Q4πε0∫drr2]+costV(⃗r)=14πε0Qr+cost𝛤in genere si fissa il potenziale nullo all’infinito:=−Q4πε0(−1r)+cost=14πε0Qr+cost⃗r`1`0V(⃗r→∞)=0⇒14πε0Q(r→∞)+cost=0⇒cost=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#38": "39Il potenziale elettrostatico: carica puntiforme\nQAB⃗Ecalcoliamo la differenza di potenziale tra i punti A e BΔVAB=VA−VB=∫BA⃗E⋅d⃗l=...=Q4πε0[−1r]BA=Q4πε0(1rA−1rB)=14πε0QrA−14πε0QrBrBrAVA=V(⃗rA)=14πε0QrAVB=V(⃗rB)=14πε0QrBAssumendo il potenziale nullo all’infinito (cost=0)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#39": "40Principio di sovrapposizione del potenzialeDemo: basta usare la proprietà distributiva del prodotto vettorialeUn campo elettrostatico generato da N cariche discrete o da una distribuzione continua di carica è conservativo⃗∇∧⃗E=⃗∇∧(∑⃗Ei)=∑⃗∇∧⃗Ei=⃗0principio di sovrapposizionecampo da carica puntiforme irrotazionaleV(⃗r)=−∫⃗E⋅d⃗l=−∫(∑⃗Ei⋅d⃗l)=∑∫−⃗Ei⋅d⃗l=∑Vi(⃗r)Il potenziale elettrostatico generato da un sistema di cariche gode del principio di sovrapposizione",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#4": "5La struttura microscopica della materiaTutti i  materiali formati da atomi (e molecole) Gli atomi sono composti da •nucleo formato da protoni (carichi positivamente) e neutroni (neutri) •attorno al nucleo orbitano gli elettroni (carichi negativamente)\nLa Forza Elettromagnetica nella Fisica Moderna (II) •!La forza elettromagnetica è la forza dominante nel mondo fisico che conosciamo: –!Tiene uniti gli elettroni al nucleo negli atomi. –!Tiene uniti gli atomi nelle molecole; –!È all’origine delle forze elastiche; –!È all’origine delle forze di tensione delle funi; –!È all’origine delle forze di attrito; –!È all’origine delle forze di resistenza; –!È all’origine delle forze di tensione superficiale dei liquidi; –!È all’origine delle forze di urto; –!È all’origine delle reazioni vincolari. 9!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nLa Forza Elettromagnetica nella Fisica Moderna (III) \n10!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Non hanno origine elettromagnetica poche forze comunemente note, tra cui: –!La forza peso (forza gravitazionale); –!La forza che mantiene i pianeti sulle loro orbite (forza gravitazionale); –!La forza che tiene uniti i quark nei nuclei degli atomi (forza nucleare forte). \nLa Composizione della Materia molecolaatomonucleoelettrone\nprotoneneutronequark10 cm!810 cm!12\n10 cm!1310 cm!13(<10 cm)!1811!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nI Costituenti della Materia: le Particelle Elementari (Fermioni) \n12!Domenico Galli – Fisica Generale B – 1. Elettrostatica!1 MeV/c2 = 1.783 ! 10–30 kg  Q=23eQ=!13eu d e !e c s µ\"!µ\"t b #\"!#\"elettrone up down neutrino elettronico neutrino muonico neutrino tauonico muone tauone charm strange top bottom m = 0 m = 0 m = 0 m = 0.5 MeV/c2 m = 8 MeV/c2 m = 15 MeV/c2 \nm = 170000 MeV/c2 m = 4500 MeV/c2 m = 106 MeV/c2 m = 1800 MeV/c2 m = 1600 MeV/c2 m = 300 MeV/c2 leptoni quark Esistite subito dopo il Big Bang. Ora presenti nei raggi cosmici e negli acceleratori Q=!eMateria ordinaria \n1 e = 1.602 ! 10–19 C  \nLa materia ordinaria risulta complessivamente neutra  (stesso numero di protoni ed elettroni) Perché?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#40": "41Potenziale: sistema di N cariche puntiformisistema di N cariche puntiformi\nqi⃗riP(x,y,z)V(x,y,z)=N∑i=1Vi(x,y,z)=N∑i=114πε0qiriIl potenziale in un punto P(x,y,z) è dato dalla somma algebrica dei singoli potenziali generati dalle cariche qi singolarmente ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#41": "42Potenziale: sistemi continui di cariche\nz\ny\nx\nP(x,y,z)⃗r−⃗r′\u0000⃗r⃗r′\u0000dqCarica volumetricaCarica superficialeCarica lineare Warning! come per il campo elettrico, queste sono formule generali da usare con attenzioneV(x,y,z)=14πε0∫dq|⃗r−⃗r′\u0000|V(x,y,z)=14πε0∭τρ(⃗r′\u0000)dτ|⃗r−⃗r′\u0000|V(x,y,z)=14πε0∬Sσ(⃗r′\u0000)dS|⃗r−⃗r′\u0000|V(x,y,z)=14πε0∫lλ(⃗r′\u0000)dl|⃗r−⃗r′\u0000|",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#42": "x\nExd2−d2\n43EsempiSiano date due cariche uguali q+ posizionate sull’asse y di un SdR cartesiano a distanza d dall’origine. Determinare l’espressione del campo e del potenziale elettrostatico sull’asse x.\nx\nd\n⃗E(x,0,0)=q2πε0x(x2+d2)3/2̂ı\ny",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#43": "44EsempioDeterminare il campo ed il potenziale elettrostatico generato da un filo rettilineo indefinito su cui è depositata uniformemente una carica con densità lineare 𝜆 ⃗E=λ2πε0r̂ur ortogonale al filo",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#44": "z\nEz45EsempioDeterminare il campo elettrostatico sull’asse di un anello di raggio R su cui è depositata uniformemente una carica Q⃗E=Q4πε0z(z2+R2)32̂k",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#45": "46EsempioDeterminare il campo elettrostatico sull’asse di un disco di raggio R su cui è depositata uniformemente una carica Q⃗E=Qz2πε0R2[1|z|−1(z2+R2)12]̂k",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#46": "47EsempioDeterminare la differenza di potenziale elettrostatico tra due piani indefiniti paralleli, posti a distanza d, su cui è depositata uniformemente una densità superficiale di carica uguale ed opposta\n  +𝜎-𝜎d",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#47": "48Esempio1.7Una sottile barra di plastica ha una densit` a lineare di carica positiva\u0000uniforme. La barra ` e curvata a formadi semicerchio di raggioR. Determinare:a) il potenziale elettrostatico nel centroOdel semicerchio (V=\u00004✏0);b) il campo elettrostatico nel puntoO(~E=\u0000\u00002⇡✏0Rˆ|)1.8Calcolare il campo elettrostatico nei punti dell’assexdi un anello di raggioRuniformemente carico concaricaQ. Descrivere il moto di una caricaq(opposta aQ) e massamche si trova inizialmente ferma inun punto dell’asse vicino al centro dell’anello. (R:~E=Q4⇡✏0x(x2+R2)32ˆı, oscillatore armonico con pulsazione!=qqQ4⇡✏0mR3)1.9Calcolare il campo elettrico lungo l’assexdi un disco di raggioRcaricato uniformemente con densit` a dicarica\u0000.( R :~E=\u0000x2✏0[1|x|\u0000(x2+R2)\u000012])1.10Sia dato un guscio sferico di raggioRe di spessore trascurabile su cui ` e distribuita uniformemente una caricatotaleQ. Calcolare il campo elettrostatico ed il potenziale in tutto lo spazio, in funzione della distanzardalcentro del sistema.1.11Sia data una sfera di raggioRin cui ` e distribuita uniformemente una carica totaleQ. Calcolare il campoelettrostatico ed il potenziale in tutto lo spazio, in funzione della distanzardal centro della sfera.1.12Sia data una sfera di raggioRnel cui volume presente una carica distribuita con densit` a di volume⇢(r)=kr,conkcostante. Calcolare:a) la carica totaleQdella sfera (R:Q=⇡kR4);b) il campo elettrostatico in tutto lo spazio, in funzione della distanzardal centro della sfera (R:~E(r<R)=kr24\"0ˆr,~E(r>R)=kR44\"0r2ˆr);c) il potenziale elettrostatico in un generico punto interno della sfera a distanzardal centro (R:V(r)=k12\"0(4R3\u0000r3)).1.13Sia data un cilindro di raggioRe altezza indeﬁnita in cui ` e distribuita uniformemente una carica con densit` avolumetrica di carica⇢. Calcolare:a) il campo elettrostatico in tutto lo spazio, in funzione della distanzardall’asse del cilindro;b) il potenziale elettrostatico in tutto lo spazio, imponendo che il potenziale sia nullo sulla superﬁcie delcilindro.1.14Si consideri un volume sferico di raggioRin cui ` e presente una caricaQdistribuita con densit` a⇢(r)dipendente dalla distanza radialerdal centro della sfera. Sapendo che il campo elettrico all’interno dellasfera ha modulo costante ed ` e diretto radialmente, determinare l’espressione della densit` a di carica⇢(r). (R:⇢=Q2⇡R2r)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#48": "49Il lavoro della forza elettrostaticaSe il campo elettrostatico è conservativo ⇒ la forza elettrostatica è conservativaℒel=∫BA⃗Fel⋅d⃗l=∫BAq⃗E⋅d⃗l=q∫BA⃗E⋅d⃗l=q(VA−VB)=qΔVAB⃗Fel=q⃗EIl lavoro fatto dalla forza elettrostatica per spostare una carica q dalla posizione A alla posizione BLa forza elettrostatica (di Coulomb) è proporzionale al campo elettrico\nDato che la forza elettrostatica è conservativa, il lavoro non dipende dal percorso",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#49": "50L’energia elettrostaticaPossiamo definire l’energia potenziale elettrostatica di una carica situata in un punto dello spazio in cui è presente un potenziale VUE=qVLa variazione di energia potenziale corrisponde alla variazione di energia cinetica Tin+Uin=Tfin+Ufin⇒ΔT=−ΔUEU si misura in Joule (J) In Fisica delle Particelle si usa l’elettronvolt: (energia cinetica di una carica elementare accelerata da un V olt) 1eV = qe𝛥V =(1.6×10-19 C)×(1V)=1.6×10-19 J Forza elettrostatica conservativa ⇒ energia meccanica totale (cinetica+potenziale) si conserva        ℰ=T+UE",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#5": "6Lo strofinio produce uno spostamento di elettroni da un materiale all’altro.  Sfregando tra di loro i due materiali: •il più alto nella lista si carica ⊕ (cede elettroni) •il più basso nella lista si carica ⊝ (acquista elettroni)Serie triboelettricacuoio vetro capelli lana seta alluminio carta legno ambra gomma argento oro plastica PVC silicone teflonperché sono gli elettroni a spostarsi e non i protoni?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#50": "51Moto di una carica in un campo elettrostatico Un oggetto di massa m e carica q posto in un campo elettrostatico è soggetto alla forza elettrostatica⃗F=q⃗E=m⃗a⃗a=d2⃗rdt2=qm⃗ENote le condizioni iniziali possiamo determinare le equazioni del moto Dato che il campo elettrostatico è conservativo, si può utilizzare anche la conservazione dell’energiaΔT=−ΔUe",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#51": "52Esempio: moto carica in campo costante\n+𝜎Campo piano indefinitoDeterminare la velocità di una particella di massa m e carica q(+), inizialmente ferma (vA=0) su un piano uniformemente carico positivamente, dopo che ha percorso una distanza D\nABa=qmE=qmσ2ε0costante, moto uniformemente acceleratovB=vA+atxB=xA+vAt+12at2v2B−v2A=2a(xB−xA)vB=qmσε0DTB−TA=UA−UBTB=12mv2BTA=0UA−UB=q(VA−VB)=q∫BA⃗E⋅d⃗l==q∫BAσ2ε0dx=qσ2ε0(xB−xA)=qσ2ε0D12mv2B=qσ2ε0Dv2B=2qmσ2ε0DDin alternativa (conservazione energia)⃗E=σ2ε0̂ıx",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#52": "53Esempio: deflessione in doppio strato-𝜎+𝜎\nxy\nm, q+⃗v0=v0x̂ı⃗E=σε0̂𝚥\n𝛼Calcolare l’angolo di deflessione di una particella di massa m e carica q che attraversa con velocità iniziale v0x un doppio strato di lunghezza LL",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#53": "54EsempioTre particelle identiche, aventi massa m e carica q,  sono poste ai vertici di un triangolo equilatero di lato L. Inizialmente le cariche sono ferme. Ad un certo istante una delle tre cariche viene lasciata libera. Determinare la velocità che la carica acquista dopo aver percorso una distanza L (risolvere per m=2 kg, q=5𝜇C, L=3m)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#54": "55Integrale di superficie una funzione vettorialeSiano date in ℝ3 una funzione vettoriale e una superficie S ⃗F(x,y,z)\nnel limite N→∞ e 𝛥Si→0 , definiamo l’integrale di superficie di una funzione vettoriale\nS𝛥SîniPi⃗F(Pi)αîniSuddividiamo S in N superfici infinitesime 𝛥Si e consideriamo su di esse i punti Pi(xi,yi,zi), i corrispondenti versori      normali a 𝛥Si  N∑i=1⃗F(Pi)⋅̂niΔSi=N∑i=1F(Pi)cosαiΔSi∬S⃗F⋅̂ndSconsideriamo  la somma ⃗F(x,y,z)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#55": "56Flusso di un campo vettorialeIl concetto di flusso viene introdotto nello studio della dinamica dei fluidi Consideriamo un tubo (di sezione infinitesima) attraversato da un fluido incompressibile (es H20) con velocità     d⃗S=̂ndS⃗vIl flusso del fluido attraverso una sezione dS del tubo è definito:dΦ=⃗v⋅̂ndSNotazione alternativa:dΦ=⃗v⋅d⃗Srisolvendo il prodotto scalare:\n̂n⃗vαdSd𝛴sezione trasversa d𝛴=dS cos𝛼dΦ=vdScosα=vdΣ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#56": "57Flusso di un campo vettorialeConsiderando più tubi (di flusso) su una generica superficie S \nFlusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: \n37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=\"v!t!\"!v()=#V#t=\"v#t#t=\"v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v\nFlusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: \n38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos\"!viˆn=!vˆn1\"cos\"=vcos\"#S!v()=!v=Svcos\"=!viˆnS!ˆn!Sr!v\nFlusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: \n39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS\"\"d!=dScos\"d!!SdSd!!vd#dS!v()=vd!=vdScos\"=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) \nFlusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. \n40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) \ndSdS!viˆnd!!S!v()=!viˆndSS\"\"\nFlusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: \n37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=\"v!t!\"!v()=#V#t=\"v#t#t=\"v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v\nFlusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: \n38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos\"!viˆn=!vˆn1\"cos\"=vcos\"#S!v()=!v=Svcos\"=!viˆnS!ˆn!Sr!v\nFlusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: \n39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS\"\"d!=dScos\"d!!SdSd!!vd#dS!v()=vd!=vdScos\"=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) \nFlusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. \n40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) \ndSdS!viˆnd!!S!v()=!viˆndSS\"\"\nFlusso del campo vettoriale     attraverso la superficie S⃗vΦs(⃗v)=∬S⃗v⋅̂ndS",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#57": "58Linee di flusso di un campo vettoriale\nLinee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. \n41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u0001\u0001\nLinee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. \n42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1\nSuperfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. \n43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nAperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) \nSuperfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. \n44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nˆnˆnˆnˆnˆnˆnˆnConsideriamo la traiettoria 𝛾 di una particella del fluido  ➡  in ogni punto la traiettoria è tangente alla velocità vettoriale della particella La linea di flusso 𝛾 è una linea sempre tangente al vettore velocità delle particelle che si trovano nei punti della linea",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#58": "59Linee di flusso del campo elettricoAnche per il campo elettrico possiamo rappresentare graficamente le linee di flusso (o linee di campo) • tangenti in ogni punto al vettore campo elettrico • orientate con il verso del campo elettrico • in numero (per unità di superficie trasversale), proporzionali al modulo del campo elettrico \nTeorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS\"!!=!\"i!vdVV!!!\n57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV\"P{}!vSV()\"##iˆndSdVV###=$tot!v()%V!!i!v()Pi()\"Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V\nTeorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: \n58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()\"Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn\"Sfacceesterne#!!i!vdVV%%%=!viˆndSS\"%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V\nLinee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()\n59!  !E!r()\nDomenico Galli – Fisica Generale B – 1. Elettrostatica!\nAngolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido \" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr\"0,2#$%$%!=Sr2\"0,4#$%&'S!r\n60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#59": "Classificazione delle superfici • aperta: compatta e con bordo • chiusa: compatta e priva di bordo • orientabile: ha due facce\nLinee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. \n41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u0001\u0001\nLinee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. \n42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1\nSuperfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. \n43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nAperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) \nSuperfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. \n44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nˆnˆnˆnˆnˆnˆnˆn\nLinee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. \n41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u0001\u0001\nLinee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. \n42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1\nSuperfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. \n43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nAperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) \nSuperfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. \n44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nˆnˆnˆnˆnˆnˆnˆn\nLinee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. \n41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u0001\u0001\nLinee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. \n42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1\nSuperfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. \n43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nAperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) \nSuperfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. \n44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nˆnˆnˆnˆnˆnˆnˆn\nLinee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. \n41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u0001\u0001\nLinee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. \n42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1\nSuperfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. \n43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nAperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) \nSuperfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. \n44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nˆnˆnˆnˆnˆnˆnˆn\nLinee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. \n41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u0001\u0001\nLinee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. \n42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1\nSuperfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. \n43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nAperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) \nSuperfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. \n44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nˆnˆnˆnˆnˆnˆnˆnAperta e orientabile\nSfera: chiusa e orientabileToroide: chiusa e orientabileNastro di Möbius: aperta e non orientabileBottiglia  di Klein: chiusa e  non-orientabile60Superfici in ℝ3",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#6": "7Isolanti e conduttoriisolanti  •la carica elettrica resta localizzata  •vetro, plastica, gomma conduttori  •cariche libere di muoversi •metalli warning: classificazione un po’ riduttiva (liquidi, semiconduttori,…)                  nota: inizieremo con esempi di materiali isolanti, i conduttori saranno trattati in seguito",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#60": "61Superfici chiuse e orientabili in ℝ3Nelle superfici chiuse e orientabili, in ogni punto della superficie  possiamo distinguere la normale esterna dalla normale interna Convenzione:  per calcolare i flussi si utilizza la normale esterna   :  positivo il flusso uscente dal volume delimitato dalla superficie chiusa negativo il flusso entrante nel volume delimitato dalla superficie chiusân\nLinee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. \n41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u0001\u0001\nLinee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. \n42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1\nSuperfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. \n43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nAperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) \nSuperfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. \n44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nˆnˆnˆnˆnˆnˆnˆn̂n̂n̂n\nLinee di Flusso di un Campo Vettoriale •!Consideriamo ora la traiettoria ! di una particella di fluido: –!Essa è in ogni suo punto tangente alla velocità vettoriale della particella. •!Definiamo quindi linea di flusso ! una linea che è sempre tangente al vettore velocità delle particelle di fluido che si trovano nei punti della linea. \n41!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u0001\u0001\nLinee di Flusso di un Campo Vettoriale (II) •!Possiamo tracciare le linee di flusso tanto più fitte quanto maggiore è la velocità del fluido. •!Più precisamente possiamo tracciare le linee in modo che il numero di linee di flusso che attraversa l’unità di superficie di una sezione trasversale sia proporzionale alla velocità del fluido. \n42!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!v1!v1!v2!v2>!v1\nSuperfici Chiuse e Orientabili di R3 •!Una superficie è chiusa se è compatta e priva di bordo. •!Una superficie è orientabile se ha due facce; è non-orientabile se ha una faccia sola. \n43!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nAperta e Orientabile Chiusa e Orientabile (sfera) Chiusa e Orientabile (toro)    Aperta e Non-orientabile (nastro di Möbius) Chiusa e Non-orientabile (bottiglia di Klein) \nSuperfici Chiuse e Orientabili di R3 (II) •!Nelle superfici chiuse e orientabili si può distinguere la normale esterna dalla normale interna in ogni punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza la normale esterna   : –!Questo equivale a considerare positivo il flusso uscente dal volume delimitato dalla superficie chiusa e negativo il flusso entrante nel volume delimitato dalla superficie chiusa. \n44!Domenico Galli – Fisica Generale B – 1. Elettrostatica!\nˆnˆnˆnˆnˆnˆnˆn̂n̂n̂n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#61": "Superfici Aperte di R3 •!Nelle superfici aperte non si può distinguere la normale esterna dalla normale interna in un punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza l’orientamento     indicato dalla regola della mano destra sulla base dell’orientamento della linea di bordo: \n45!Domenico Galli – Fisica Generale B – 1. Elettrostatica!ˆn\nFlusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile •!Consideriamo ora il flusso della velocità di un fluido attraverso una superficie chiusa. •!Per semplicità consideriamo la superficie totale di un cubo. •!Consideriamo positivo il flusso uscente dal cubo e negativo il flusso entrante nel cubo. •!Se il fluido è incompressibile e non si sono al suo interno sorgenti (in cui si produce fluido) o pozzi (scarichi, in cui il fluido scompare), allora tanto fluido entra nel cubo quanto ne esce: –!Il flusso attraverso la superficie totale è nullo. –!Il cerchietto attorno al simbolo di integrale       indica che la superficie di integrazione è chiusa. 46!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot\"\"\"==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()=0532146!!!\nFlusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile (II) •!Se il flusso attraverso la superficie totale è positivo: allora dentro il cubo è presente una sorgente che produce fluido. •!Se il flusso attraverso la superficie totale è negativo: allora dentro il cubo è presente un pozzo (cioè uno scarico) in cui il fluido scompare. 47!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot\"\"\"==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()>0532146\n!tot!v()=!viˆndSStot\"\"\"==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()<0532146\nL’Operatore Divergenza \n48!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Consideriamo una funzione vettoriale della posizione P: •!Si definisce l’operatore “divergenza” come: •!L’operatore divergenza si applica a una funzione vettoriale; il risultato è uno scalare: !!=ˆı\"\"x+ˆ!\"\"y+ˆk\"\"z!v=!vP()=!vx,y,z()=vxx,y,z()ˆı+vyx,y,z()ˆ!+vzx,y,z()ˆk\nEsempio:\"vx,y,z()=x2+y2()ˆı+x2+z2()ˆ!+zˆk!V\"\"i\"v()x,y,z()=2x+1!!!!i!v=div!v=\"vx\"x+\"vy\"y+\"vz\"z!!i!v=ˆı\"\"x+ˆ!\"\"y+ˆk\"\"z#$%&'(ivxˆı+vyˆ!+vzˆk()P!!3()\"v\"#\"\"vP()!VP!!3()\"$i\"v\"#\"\"\"$i\"v()P()!!%&'('62Superfici aperte e orientabili in ℝ3Nelle superfici aperte non possiamo distinguere la normale esterna dalla normale interna Convenzione:  per calcolare i flussi attraverso una superficie aperta si utilizza l’orientamento    indicato dalla regola della mano destra sulla base dell’orientamento della linea del bordo:̂n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#62": "63L’angolo solidorl𝛼Angolo piano rapporto tra arco di circonferenza l e raggio r\nr𝛺𝛴Angolo solido rapporto tra la parte di superficie sferica 𝛴 intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera α=lr∈[0,2π[L’angolo solido si misura in steradianti (sr)Ω=Σr2∈[0,4π]dα=dlrinfinitesimoinfinitesimodΩ=dΣr2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#63": "64Il flusso del campo elettricod𝛴̂nαdS⃗Eprendendo la superficie d𝛴 ortogonale al campo elettrico:Flusso infinitesimo del campo elettrico attraverso una superficie dSdΦS(⃗E)=⃗E⋅̂ndS=EdScosα=EdΣFlusso del campo elettrico attraverso una superficie estesa SΦS(⃗E)=∬S⃗E⋅̂ndS=∬SEcosαdS=∬SEdΣdΣ=dScosα",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#64": "65Il flusso del campo elettricoConsideriamo ora una superficie chiusa contenente al suo interno una carica elettrica puntiforme q̂n\nd𝛴dSqdΦS(⃗E)=⃗E⋅̂ndS=EdScosα=EdΣFlusso attraverso l’intera superficie S  (             ):∬SdΩ=4πil flusso dipende solo dall’angolo solido perché E è radialeΦS(⃗E)=∬S⃗E⋅̂ndS=qε0Notazione per integrale su superficie chiusaFlusso infinitesimo attraverso un elemento dS:α\nΦS(⃗E)=∬SdΦS=∬S⃗E⋅̂ndS=q4πε0∬SdΩ=qε0=(q4πε0r2)(r2dΩ)=q4πε0dΩ⃗E",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#65": "66Il flusso del campo elettrico\nd𝛴2d𝛴1\nr1r2dΩ=dΣ1r21=dΣ2r22Se q è esterna alla superficie chiusa, il numero di linee di campo che entrano nella superficie è uguale al numero di linee di campo che escono dalla superficie\nd𝛴2dS2q\nd𝛴1dS1̂n1̂n2α1α2⃗E1⋅̂n1=cosα1<0⃗E2⋅̂n2=cosα2>0\ndΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(−r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)=⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2\ndΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0dΦS1(⃗E1)+dΦS2(⃗E2)==⃗E1⋅̂n1dS1+⃗E2⋅̂n2dS2=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0Flusso attraverso l’intera superficie:Flusso infinitesimo:=E1dS1cosα1+E2dS2cosα2=E1(−dΣ1)+E2dΣ2=q4πε0r21(−r21dΩ)+q4πε0r22(r22dΩ)=0ΦS(⃗E)=∬S⃗E⋅̂ndS=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#66": "67Il flusso del campo elettricoSe all’interno della superficie chiusa ci sono N cariche qi puntiformi, per il principio di sovrapposizione del campo elettrico, il flusso vale: dove QS è la carica contenuta all’interno della superficie S q3q2q5q7q6q1q8q4qN×××S𝜏(S)QS=∑iqintQS=∭τ(S)ρdτΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0Cariche discrete Cariche distribuite su continuo V olume 𝜏(S) contenuto in superficie S ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#67": "68La Legge di Gauss del campo elettricoIl flusso del campo elettrico attraverso una superficie chiusa S è uguale al rapporto tra la carica elettrica QS contenuta all’interno della superficie e la costante dielettrica ΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#68": "69EsempiDeterminare il campo elettrico generato da un filo rettilineo indefinito su cui è depositata uniformemente una carica con densità lineare 𝜆 (usando la legge di Gauss) ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#69": "70EsempiDeterminare il campo elettrico generato da un piano indefinito su cui è depositata uniformemente una carica con densità superficiale 𝜎 (usando la legge di Gauss)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#7": "8Elettrizzazione per induzione (elettrostatica)\nElettroscopio a foglieAvvicinando un corpo carico all’elettroscopio, le foglie metalliche (conduttori) si allontanano Le componenti metalliche “sentono\" la vicinanza di carica elettrica L’effetto svanisce quando si allontana la carica",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#70": "71EsempiDeterminare il campo elettrico ed il potenziale generato da un guscio sferico di raggio R su cui è depositata uniformemente una carica Q",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#71": "72EsempioSia data una sfera di raggio R contenente una carica Q distribuita uniformemente. a) Determinare il campo elettrostatico in tutto lo spazio b) Calcolare il potenziale in un generico punto  esterno alla sfera (assumendo nullo il potenziale all’infinito) c) Calcolare il potenziale in un generico punto  interno alla sfera (assumendo nullo il potenziale all’infinito) d) Calcolare la differenza di potenziale tra il centro e la superficie della sfera",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#72": "73La divergenza di un campo vettoriale\nConsideriamo il flusso di un campo  vettoriale     attraverso una superficie chiusa S che delimita un volume 𝜏⃗FΦS(⃗F)=∬S⃗F⋅̂ndSDividiamo idealmente il volume 𝜏  in due volumi 𝜏1 e 𝜏2, usando una superficie di separazione D (diaframma). Siano S1 e S2 le superfici chiuse che delimitano 𝜏1 e 𝜏2 (D⊂S1,S2)𝜏SD𝜏2𝜏1S1S2Possiamo riscrivere il flussoΦS(⃗F)=∬S1⃗F⋅̂ndS1+∬S2⃗F⋅̂ndS2̂n2̂n1i contributi al flusso attraverso D si annullano⃗F⋅̂n1D=−⃗F⋅̂n2D",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#73": "74La divergenza di un campo vettorialeSuddividendo il volume 𝜏 in N volumi 𝜏i , limitatati da altrettante superfici SiDefinizione di divergenza di un campo vettorialediv⃗F=limτi→0ΦSi(⃗F)τiΦSi(⃗F)=∬Si⃗F⋅̂nidSiΦS(⃗F)=N∑i=1ΦSi(⃗F)La divergenza è il flusso uscente per unità di volume  • è una grandezza scalare, funzione delle coordinate • può variare da punto a punto𝜏iSi⃗FS𝜏⃗∇=(∂∂x,∂∂y,∂∂z)=∂∂x̂ı+∂∂ŷ𝚥+∂∂ẑkdiv⃗F=⃗∇⋅⃗FUtilizzando l’operatore “nabla”:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#74": "75Il teorema della divergenzaIl flusso di un campo vettoriale attraverso una superficie S chiusa è pari all’integrale sul volume 𝜏 (delimitato da S !!!) della divergenza di tale campo vettoriale ∬S⃗F⋅̂ndS=∭τdiv⃗Fdτ=N∑i=1τi∬Si⃗F⋅̂nidSiτiNel limite N →∞ e 𝜏i →d𝜏, sostituiamo 𝛴→∫∫∫ ⟶∭τdiv⃗FdτΦS(⃗F)=∬S⃗F⋅̂ndS=N∑i=1∬Si⃗F⋅̂nidSiIl teorema della divergenza è una relazione tra un integrale di superficie e un integrale di volume",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#75": "76La legge di Gauss in forma localeCombiniamo il teorema della divergenza e la legge di Gauss, in presenza di una distribuzione continua di carica∭τ(S)div⃗Edτ=∭τ(S)ρε0dτdiv⃗E=ρε0∬S⃗E⋅̂ndS=∭τ(S)div⃗Edτ∬S⃗E⋅̂ndS=∭τ(S)ρε0dτLegge di GaussTeorema della divergenzaGli integrali sono sullo stesso volume",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#76": "77Significato fisico della divergenzaLa divergenza di un campo ci da un’informazione sul comportamento locale delle linee di campo le linee di campo si incontrano nei punti in cui la divergenza del campo è diversa da zero: • convergono nel punto se il valore della divergenza è negativo • divergono dal punto se il valore della divergenza è positivo In un punto in cui la divergenza è nulla, le linee di campo non si incontrano Se un campo ha divergenza sempre nulla, allora esso si definisce solenoidale",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#77": "78Significato fisico della divergenzadiv⃗E=ρε0Il campo elettrico ha divergenza non nulla solo nei punti in cui esiste una densità di carica Nel vuoto, la divergenza del campo elettrico è nulla \nz\ny\nx⃗r⃗r′\u0000In tali punti, le linee di campo si incontranodiv⃗E(⃗r′\u0000)=ρ(⃗r′\u0000)ε0div⃗E(⃗r)=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#78": "79Potenziale e legge di GaussLegge di Gauss in forma locale⃗∇⋅⃗E=ρε0⃗E=−⃗∇V⃗∇⋅(−⃗∇V)=ρε0∇2V=−ρε0Campo elettrostaticoEquazione di Poisson\nIl laplaciano del potenziale è proporzionale alla densità di carica Equazione alle derivate seconde, note le condizioni al contorno ammette un’unica soluzione∂2V∂x2+∂2V∂y2+∂2V∂z2=−ρε0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#79": "80EsempioCalcolare la divergenza del campo e il flusso attraverso una superficie sferica di raggio R centrata nell’origine ⃗F=k⃗r",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#8": "9Elettrizzazione per induzione (elettrostatica)\nElettrizzazione per induzione anche su materiali isolanti\nMicroscopicamente, le molecole della carta “risentono” la vicinanza di cariche elettriche ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#80": "81Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\09-elettrostatica.pdf#9": "10Elettrizzazione per contatto\nIn caso di contatto, parte della carica si trasferisce (e resta) sul conduttoreCaso particolare: due conduttori di stessa forma e dimensione; inizialmente A ha una carica Q+Dopo aver messo in contatto A e B, la carica si ridistribuisce in parti ugualiAB++++++++++++++++Q+\nAB++++++++12Q+12Q+++++++++\nCarica totale si conserva!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#0": " Elettrostatica dei conduttori CdS Ingegneria Informatica A.A. 2019/20",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#1": "2Materiali isolanti e conduttoriisolanti  •le carica elettrica restano localizzate, sono vincolate a muoversi all’interno delle molecole •Un campo elettrico esterno non produce movimento di cariche, se non su piccolissima scala: deformazione e orientamento delle molecole (azioni sui dipoli) conduttori  •cariche (elettroni di conduzione) libere di muoversi sul conduttore (moto su reticolo cristallino) •comportamento degli elettroni simile ad un gas •in presenza di un campo esterno o di un eccesso di carica, le cariche si redistribuiscono sul conduttore",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#10": "11Campo elettrico in prossimità della superficie dei conduttori\nIn presenza di un conduttore, le linee di campo esterne vengono deviate dalla presenza di addensamenti locali di carica sulla superficie del conduttoreVicino al conduttore le linee di campo esterne saranno sempre perpendicolari alla superficie",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#11": "12Campo elettrico in prossimità della superficie dei conduttori⃗E=ÊnCalcoliamo il flusso attraverso un cilindretto di dimensioni infinitesime • asse ortogonale a superficie conduttore • contributo al flusso solo da base esterna⃗E=0dΦ(E)=⃗E⋅̂ndS=EdSFlusso attraverso base infinitesimaCarica contenuta nel cilindro (intersezione con la superficie del conduttore)dQS=σdSapplicando la legge di GaussEdS=σε0dSE=σε0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#12": "13Teorema di Coulomb⃗E=σε0̂nIl campo elettrostatico in prossimità dei conduttori è sempre ortogonale alla superficie del conduttore ed il modulo è proporzionale alla densità superficiale di carica La densità superficiale di carica 𝜎=𝜎(x,y,z) può variare sulla superficie, di conseguenza varierà anche l’intensità del campo elettrico Il campo elettrico subisce una discontinuità nel passaggio dall’esterno all’interno del conduttore",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#13": "14Conduttori caviSulla superficie interna di un conduttore cavo  • la carica totale è nulla  • non si osservano cariche localizzate \nS⃗E=0ΦS(⃗E)=QSε0=0La prima affermazione si dimostra applicando la legge di Gauss, utilizzando la condizione che il campo elettrico interno al conduttore è nullo",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#14": "15Conduttori cavi\n-+++++----⃗E≠0⃗E=0𝛤Ipotesi (per assurdo): distribuzioni locali di carica sulla superficie interna⇒ campo all’interno della cavità non nullo ⇒ circuitazione lungo linea chiusa 𝛤 non-nulla⇒ violazione della conservatività del campo elettrostatico Sulla superficie interna di un conduttore cavo  • la carica totale è nulla  • non si osservano cariche localizzate \n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#15": "16Schermo elettrostatico\n  Se un conduttore dotato di cavità viene esposto a un campo elettrico esterno, il campo elettrico all’interno della cavità è comunque nullo e non vi sono cariche elettriche indotte sulla superficie della cavità stessa.    In altre parole il conduttore scherma l’interno della cavità dai campi elettrici all’esterno (gabbia di Faraday)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#16": "17Induzione completa\n+QQ’’=+Q+++\n++++\n+Q’=-Q--------⃗E≠0Poniamo una carica puntiforme all’interno della cavità di un conduttore neutroLa carica genera un campo con linee radiali che poi curvano per diventare perpendicolari alla superficie interna induzione completa: tutte le linee di forza si chiudono sul conduttore Sulla superficie interna si induce una carica Q’ complessivamente uguale e opposta a +QSGauss è salvo: Q+Q’=0Conduttore neutro ⇒ carica Q’’=+Q indotta sulla superficie esterna⃗E=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#17": "18Induzione completa\n+QQ’’=+QQ’=-Q+++++++++++\n++++\n+--------⃗E≠0Poniamo all’interno della cavità una generica carica (anche su un conduttore)  Un conduttore cavo trasferisce sulla propria superficie esterna una carica uguale al valore complessivo delle cariche contenute all’interno della cavità.  ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#18": "BB\n19Potenziale elettrostatico nei conduttoriADifferenza di potenziale tra due punti del conduttoreVA−VB=∫BA⃗E⋅d⃗l=0⃗E=0A⃗E⊥d⃗l⇒VA=VB∀A,B\nTutti i punti del conduttore sono equipotenziali  (la differenza di potenziale tra due qualsiasi punti del conduttore è sempre nulla)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#19": "20Potenziale di un conduttore sfericoUn conduttore carico (con carica Q), di forma sferica di raggio R è equivalente ad un guscio sferico uniformemente caricoCampo elettrico (calcolato con legge di Gauss):⃗E(r<R)=0⃗E(r>R)=14πε0Qr2̂urPer simmetria, la densità superficiale di carica deve essere uniforme (altrimenti avrei campi elettrici tangenti)\nRQ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#2": "3Premesse~F=m~a•Scegliamo un sistema di riferimento inerziale: -un corpo non soggetto a forze si muove con velocità costante -  •Supponiamo che ci sia il vuoto nello spazio interposto tra i conduttori e le eventuali cariche esterne •Lavoriamo con conduttori solidi (es. metalli) •Poniamoci in condizioni di ELETTROSTATICA",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#20": "21Potenziale di un conduttore sfericoCalcolo del potenziale in un generico punto a distanza r dal centro della sfera (assumendo V∞=0)V(r)=V(r)−V(∞)=∫∞r⃗E⋅d⃗rEsternamente (come carica puntiforme)V(r>R)=∫∞r⃗E⋅d⃗r=∫∞r14πε0Qr2dr=Q4πε0[−1r]∞r=14πε0QrV(r<R)=∫∞r⃗E⋅d⃗r=∫Rr⃗E(r<R)⋅d⃗l+∫∞R⃗E(r≥R)⋅d⃗l=InternamenteE(r)rRV(r)rRDiscontinuità del campo⃗E(r>R)=14πε0Qr2̂urCostante!=0+∫∞RQ4πε01r2dr=Q4πε0[−1r]∞R=Q4πε01R",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#21": "22Esempio1.15Calcolare l’energia elettrostatica di una sfera di raggioRin cui ` e distribuita uniformemente una carica condensit` a⇢costante. (R:4⇡⇢2R515\"0)1.16In una certa regione di spazio sono presenti i due campi vettoriali~E1=K1xˆı+K2y2ˆ|+K1zˆke~E2=K2xyˆı+K2x2ˆ|. Determinarea) il gradiente della grandezza~E1·~E2(R: (2K1K2+2K21)xyˆı+(K1K2x2+1K22X2y)ˆ|);b) quale dei due campi pu essere considerato elettrostatico (R:~E1);1.17Si consideri il campo~F(x, y, z)=\u00002xˆı\u0000z2ˆ|\u0000ayzˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=2);b) il potenziale'generato dal campo~F(R:'=x2+yz2);c) la densit` a di carica⇢che genera il campo~F(R:⇢=\u00002✏0(y+ 1))1.18Si consideri il campo~F(x, y, z)=2xˆı\u0000zˆ|\u0000ayˆk. Determinare:a) per quali valori diail campo risulta conservativo (R:a=1);b) il potenziale'generato dal campo~F(R:'=yz\u0000x2);c) la densit` a di carica⇢che genera il campo~F(R:⇢=\u00002✏0)1.19Sia dato il campo~E(x, y, z)=↵(4xˆı+zˆ|+yˆk).a) Veriﬁcare che~E` e conservativo; (R: veriﬁcare che~r⇥~E= 0)b) calcolare il ﬂusso di~Eattraverso un cubo di spigoloLcon un vertice nell’origine del sistema diriferimento e tre spigoli posizionati sui tre semiassi positivi; (R:\u0000=4↵L3)c) calcolare la carica totale contenuta nel cubo, utilizzando il teorema di Gauss sia in forma integrale chedi↵erenziale (R:Q=4↵\"0L3)2 Elettrostatica dei conduttori2.1Una sfera conduttrice di raggior1=5 cm porta una caricaQ1=+10\u00006C. Un guscio sferico di materialeconduttore, concentrico alla prima sfera, di raggio internor2=10cm e raggio esternor3=12cm ` e caricato conuna caricaQ2=10Q1. Nell’ipotesi che il sistema sia nel vuoto, calcolare:a) la densit` a di carica superﬁciale\u00002sulla superﬁcie interna del guscio sferico (R:\u00002\u0000Q14⇡r22=\u00008·10\u00006C/m);b) la di↵erenza di potenziale tra i due conduttori. (R:\u0000V=Q14⇡\"0r2\u0000r1r1r2= 15kV)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#22": "23Esempio2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica\u0000Q. Determinare:a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanzardal centro delsistema, disegnando un graﬁco qualitativo dell’andamento del campo; (R:~E(r<a),~E(a<r<b)v e d ies 1.12,~E(r>b) = 0)b) l’espressione del potenziale sulla superﬁcie del volume sferico (inr=a, considerando nullo il potenzialeall’inﬁnito). (R:V(a)=Q4⇡\"0(1a\u00001b))2.3Due sfere conduttrici di raggiR1=2 m eR2=3 m , caricate inizialmente ciascuna con caricaQ=1 mC, vengonocollegate da un ﬁlo conduttore sottile. Nel caso in cui le sfere siano poste a distanza tale da poter trascuraree↵etti di induzione elettrostatica, come si ridistribuisce la carica?(R:Q1=2QR1R1+R2=0.8 mC,Q2=2QR2R1+R2=1.2mC)2.4Calcolare la capacit` a di un condensatore sferico.2.5Calcolare la capacit` a di un condensatore cilindrico.2.6Dato il circuito rappresentato in ﬁgura 1 (\u0000VAB= 300V,C1=3µF,C2=2µF,C3=4µF), deter-minare la carica e la di↵erenza di potenziale di ciascun condensatore. (R:Q1=0.6mC, Q2=0.2mC, Q3=0.4mC,\u0000V1= 200V,\u0000V2=\u0000V3= 100V)ABC1C3C2ABC1C2C3\nC1C2SFigure 1:2.7Dato il circuito rappresentato in ﬁgura 2 (\u0000VAB= 12V,C1=C2=2µF,C3=5µF), determinare:a) la carica e la di↵erenza di potenziale ai capi di ogni condensatore del circuito (R:Q1=Q2=12µC, Q3= 60µC,\u0000V1=\u0000V2=6V,\u0000V3= 12V);b) l’energia accumulata su ciascun condensatore (R:U1=U2= 36µJ, U3= 360µJ).",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#23": "24Ridistribuzione delle caricheQ0\nR1Siano date due sfere conduttrici di raggi R1 e R2 con R1 > R2 Inizialmente sulla prima sfera c’è una carica Q0, la seconda sfera è scarica Le sfere sono poste a distanza tale da poter trascurare effetti di induzione elettrostatica\nSuccessivamente le sfere vengono connesse con un sottile cavo conduttore. Come si ridistribuisce la carica? \nR2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#24": "25Ridistribuzione delle cariche\nR1\nR2Dobbiamo calcolare le cariche finali sulle due sfere: Q1 e Q2Per la conservazione della carica (il sistema è isolato): Q1 + Q2 =Q0Le due sfere unite formano un unico conduttore  ⇒ equipotenziale V1 = V2 Q1Q2V1=14πε0Q1R1V2=14πε0Q2R214πε0Q1R1=14πε0Q2R2Q1R2=Q2R1Q1R1=Q2R2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#25": "26Ridistribuzione delle cariche\nR1\nR2Q1Q2Risolvendo il sistema: {Q1+Q2=Q0Q1R2=Q2R1{Q2=Q0−Q1Q1R2=(Q0−Q1)R1{Q2=Q0−Q1Q1(R1+R2)=Q0R1Q1=R1R1+R2Q0Q2=R2R1+R2Q0La carica si redistribuisce proporzionalmente al raggioCaso particolare R1 = R2 Q1=Q2=Q02",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#26": "27Potere delle punte\nR1\nR2Q1Q2Cosa succede alle densità di carica (e ai campi elettrici delle sfere?)σ1=Q14πR21σ2=Q24πR22Q1=σ14πR21Q2=σ24πR22V1 = V2  ⇒Q1R1=Q2R2σ14πε0R21R1=σ14πε0R22R2σ1R1=σ2R2La densità superficiale di carica è maggiore sulla sfera più piccolaσ1=(R2R1)σ2⟶R1>R2σ2>σ1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#27": "28Potere delle punteConsideriamo un conduttore di una forma generica, con raggio di curvatura che varia da punto a punto della superficie.⃗E=σε0̂nIn vicinanza delle punte il campo elettrico                 può essere molto intenso La densità di cariche è inversamente proporzionale al raggio di curvatura \nmaggiore addensamento di carica sulle punte\n+ + + + + + + + + + + + + + ++++++++++++++++",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#28": "29Potere delle punte\nIn vicinanza delle punte dei conduttori le densità di carica elettrostatica ed i campi elettrostatici possono essere molto intensi Campi molto intensi possono causare l’espulsione di cariche dal conduttoreLe cariche espulse subiscono forti accelerazioni, guadagnando energia cineticaInteragendo con l’aria, provocano un riscaldamento del mezzo per cui si osservano “scintille”",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#29": "30Collegamento a terra\nR1\nR2Q0Poniamoci nella condizione limite: R1 ≫ R2 Inizialmente carica Q0 sul conduttore piccolo.Q1=R1R1+R2Q0⟶R1≫R2Q0Q2=R2R1+R2Q0⟶R1≫R20La carica fluisce interamente sul conduttore più grandeLa Terra può essere considerata come un enorme conduttore, da cui si capisce il significato di collegamento a terra (o messa a terra, ground)VT=Q4πε0RT⟶RT≈6400km0Collegando i due conduttori:In elettrotecnica si utilizza il potenziale di terra come valore di riferimento del potenzialeSimbolo  messa a terra",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#3": "4Conduttori in presenza di carica esterna\n+++++++\n+++++++\nConduttorebacchetta caricaoscilloscopio a foglieL’oscilloscopio misura la presenza di caricaL’oscilloscopio misura una maggiore presenza di caricaInduzione elettrostatica (spostamento di cariche sul conduttore)+++++++-------",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#30": "31Massa e messa a terra\nTerraIn elettrotecnica la massa (chassis) è la scatola metallica di un’apparecchiatura elettrica Si comporta come una gabbia di Faraday La massa è utilizzata per assegnare il potenziale di riferimento comune delle componenti elettriche\nmassaguasto delle componenti elettriche ⇒ eccesso di cariche sulla massa (pericolo!)Collegando la massa a terra, si scaricano pericolosi eccessi di caricacomponenti  elettrici/elettronici",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#31": "32Capacità di un conduttoreIl potenziale di un conduttore isolato è proporzionale alla carica presente sul conduttoreC=QVDefiniamo la capacità di un conduttoreNel S.I. la capacità si misura in Farad (F):  1F=1C/1VLa capacità quantifica l’attitudine di un conduttore ad accumulare carica ad un dato potenziale  La capacità dipende solo dalla forma e dalle dimensioni del conduttore e dal mezzo che lo circonda (nel nostro caso il vuoto, per ora)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#32": "33Capacità di un conduttore sferico\nRQConsideriamo una sfera conduttrice di raggio R con carica QC=QV=QQ4πε0R=4πε0RLa capacità dipende solamente da fattori geometriciEsempiCapacità di una sfera di raggio R=1m nel vuoto: \nCapacità di un Conduttore •!Dato un conduttore isolato nello spazio, il suo potenziale elettrostatico risulta proporzionale alla carica presente sul conduttore stesso.  •!L’inverso della costante di proporzionalità viene chiamata capacità del conduttore nel vuoto ed è una costante caratteristica della sua forma geometrica e delle sue dimensioni. •!Nel Sistema Internazionale la capacità si misura in Farad (F), ovvero in C/V (Coulomb/Volt) e le sue dimensioni sono: Q=CVC!\"#$=Q!\"#$V!\"#$=IT!\"#$ML2T%3I%1!\"#$=M%1L%2T4I2!\"#$\n21!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!\nCapacità di un Conduttore (II) •!Si osservi per inciso che, definito il Farad, la costante dielettrica del vuoto si scrive: •!Calcoliamo ora la capacità di un conduttore sferico. Come abbiamo visto, se Q è la carica del conduttore, il suo potenziale è: •!Segue che: !0=8.85\"10#12N#1m#2C2=8.85\"10#12Fm  V=14!\"0QR  C=QV=Q14!\"0QR=4!\"0R  C=4!\"0R(conduttore sferico) 22!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!++++++++QR!rSO,r()\nCapacità di un Conduttore (III) •!Se consideriamo una sfera conduttrice di raggio R = 1 m, la sua capacità sarà: •!Il Globo Terrestre (raggio R = 6.4%106 m) ha una capacità pari a: e dunque minore di un mF (milliFarad).   C=4!\"0R=4!#8.85#10$12#1F=1.11#10$10F=111pF   C=4!\"0R=4!#8.85#10$12#6.4#106F=712µF\n23!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!\nCapacità di un Conduttore all’Interno di una Cavità •!Se a un conduttore si avvicina un altro conduttore neutro e isolato, aumenta la capacità del primo conduttore. •!Calcoliamo la capacità di una sfera racchiusa nella cavità sferica di un conduttore (con le due superfici sferiche concentriche): V=!14\"#0Qr2$(%,R)&'(ˆnidP!\"!==!14\"#0Qr2$(%,R1)&'(ˆnidP!\"!!14\"#0Qr2$(R1,R)&'(ˆnidP!\"!==!0!14\"#0Qr2$(R1,R)&'(ˆnidP!\"!=!14\"#0Qr2$(R1,R)&'(ˆnidP!\"!\n24!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!+Q!R1!Q!\n!!!!!!!R+++++++Capacità della Terra R=6400 km: \nCapacità di un Conduttore •!Dato un conduttore isolato nello spazio, il suo potenziale elettrostatico risulta proporzionale alla carica presente sul conduttore stesso.  •!L’inverso della costante di proporzionalità viene chiamata capacità del conduttore nel vuoto ed è una costante caratteristica della sua forma geometrica e delle sue dimensioni. •!Nel Sistema Internazionale la capacità si misura in Farad (F), ovvero in C/V (Coulomb/Volt) e le sue dimensioni sono: Q=CVC!\"#$=Q!\"#$V!\"#$=IT!\"#$ML2T%3I%1!\"#$=M%1L%2T4I2!\"#$\n21!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!\nCapacità di un Conduttore (II) •!Si osservi per inciso che, definito il Farad, la costante dielettrica del vuoto si scrive: •!Calcoliamo ora la capacità di un conduttore sferico. Come abbiamo visto, se Q è la carica del conduttore, il suo potenziale è: •!Segue che: !0=8.85\"10#12N#1m#2C2=8.85\"10#12Fm  V=14!\"0QR  C=QV=Q14!\"0QR=4!\"0R  C=4!\"0R(conduttore sferico) 22!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!++++++++QR!rSO,r()\nCapacità di un Conduttore (III) •!Se consideriamo una sfera conduttrice di raggio R = 1 m, la sua capacità sarà: •!Il Globo Terrestre (raggio R = 6.4%106 m) ha una capacità pari a: e dunque minore di un mF (milliFarad).   C=4!\"0R=4!#8.85#10$12#1F=1.11#10$10F=111pF   C=4!\"0R=4!#8.85#10$12#6.4#106F=712µF\n23!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!\nCapacità di un Conduttore all’Interno di una Cavità •!Se a un conduttore si avvicina un altro conduttore neutro e isolato, aumenta la capacità del primo conduttore. •!Calcoliamo la capacità di una sfera racchiusa nella cavità sferica di un conduttore (con le due superfici sferiche concentriche): V=!14\"#0Qr2$(%,R)&'(ˆnidP!\"!==!14\"#0Qr2$(%,R1)&'(ˆnidP!\"!!14\"#0Qr2$(R1,R)&'(ˆnidP!\"!==!0!14\"#0Qr2$(R1,R)&'(ˆnidP!\"!=!14\"#0Qr2$(R1,R)&'(ˆnidP!\"!\n24!Domenico Galli – Fisica Generale B – 2. Elettrostatica dei conduttori metallici!E!+Q!R1!Q!\n!!!!!!!R+++++++",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#33": "34CondensatoriIl condensatore è un sistema formato da due conduttori carichi per i quali si verifica induzione completa (tutte le linee di forza uscenti da un conduttore incontrano l’altro conduttore) I due conduttori sono le armature del condensatore Lo spazio interposto tra le armature è l’intercapedineLa capacità del condensatore è definita come rapporto tra la carica (presente con segno opposto sui due conduttori) e la differenza di potenziale tra i due conduttoriC=QΔV\n+Q-Q++++++++++++____________La capacità di un condensatore dipende solo dalla geometria, dalla forma e dal materiale interposto tra i conduttoriSimbolo  condensatore",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#34": "35Capacità di un condensatore pianoIl condensatore piano (condensatore a facce piane e parallele) è costituito da due armature piane di superficie S poste parallelamente a piccola distanza d (d≪S, trascuriamo effetti di bordo)\nSdSd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QIl sistema è equivalente al doppio strato⃗E={σε0̂n=QS1ε0interno0esternoCapacità:C=QΔV=QQdε0S=ε0Sd• proporzionale alla superficie delle armature • inversamente proporzionale alla distanza tra le armatureΔV=∫d0Edz=Ed=QdSε0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#35": "36Capacità di un condensatore sferico\nR1+Q-QR2Un condensatore sferico è costituito da una sfera conduttrice di raggio R1 racchiusa all’interno di una cavità sferica di raggio R2 di un conduttore sfericoΔV=V1−V2=∫R2R1⃗E⋅d⃗r=Q4πε0∫R2R1drr2=Q4πε0[−1r]R2R1=Q4πε0(1R1−1R2)Differenza di potenziale tra le armatureCapacità del condensatore sfericoC=QΔV=QQ4πε0(1R1−1R2)=4πε0(R1R2R2−R1)Nel limite R1→ R2, definendo d=R2-R1 C=4πε0(R1R2R2−R1)⟶R1→R24πε0R2d=ε0Sdcapacità del condensatore piano",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#36": "37Capacità di un condensatore cilindricoUn condensatore cilindrico è costituito da un cilindro conduttore di raggio R1 racchiuso all’interno di una cavità cilindrica di raggio R2 di un conduttore cilindrico (nell’approssimazione R1,R2≪h , trascurando eff. bordo)⃗E=Q2πε0hr̂rCampo elettrico internoR2R1hΔV=∫R2R1Edr=∫R2R1Qdr2πε0hr=Q2πε0hlnR2R1Differenza di potenziale tra le armatureC=QQ2πε0hlnR2R1=2πε0hlnR2R1CapacitàNel limite R1→ R2, definendo d=R2-R1 lnR2R1=lnR1+R2−R1R1=ln(1+R2−R1R1)=ln(1+dR1)≅dRC=2πε0hdR=ε02πRhd=ε0Sdcapacità del condensatore piano",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#37": "38Sistemi di condensatori in paralleloI condensatori sono dispositivi dipolari  (hanno due capi di connessione)Connessione in parallelo (gli elementi circuitali sono alla stessa differenza di potenziale 𝛥V1=𝛥V2=VA-VB=𝛥VAB): Q1=C1𝛥V1=C1𝛥VAB Q2=C2𝛥V2=C2𝛥VABQTOT=Q1+Q2=(C1+C2)𝛥VAB=CTOT𝛥VABCTOT=C1+C2   \nla capacità del sistema formato da due (o più) condensatori collegati in parallelo è uguale alla somma delle singole capacitàCTOT=∑CiC1C2+Q2-Q1VAVB-Q2+Q1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#38": "39Sistemi di condensatori in serieConnessione in serie (gli elementi circuitali sono collegati con un solo polo in comune)Conduttore isolato e neutro -Q1+Q2=0 ⇒  Q1=Q2 I condensatori in serie hanno la stessa caricaC1C2+Q2+Q1VAVB-Q1-Q2VM=QC1+QC2=Q(1C1+1C2)=QCTOTVA−VB=(VA−VM)+(VM−VB)=1CTOT=1C1+1C2CTOT=C1C2C1+C21CTOT=∑1Ci\nL’inverso della capacità del sistema formato da due o più condensatori collegati in serie è uguale alla somma degli inversi delle singole capacità ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#39": "40Esempio\nserie o parallelo?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#4": "5Conduttori in presenza di carica esterna\n+++++++In presenza di un campo elettrostatico esterno le cariche del conduttore si spostano fino a raggiungere una nuova condizione di equilibrio (𝛥t∼10-9 s)Equilibrio ⇒ cariche ferme ⇒ forza nulla ⇒ campo elettrico complessivamente nulloLe cariche del  conduttore si dispongono in maniera tale da generare un campo interno      (indotto) che annulla il campo esterno⃗E⃗E⃗E′\u0000Il campo elettrico interno ai conduttori è sempre nullo\n+++++++-------⃗E′\u0000⃗E⃗Econd=⃗E+⃗E′\u0000=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#40": "41Esercizio2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica\u0000Q. Determinare:a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanzardal centro delsistema, disegnando un graﬁco qualitativo dell’andamento del campo; (R:~E(r<a),~E(a<r<b)v e d ies 1.12,~E(r>b) = 0)b) l’espressione del potenziale sulla superﬁcie del volume sferico (inr=a, considerando nullo il potenzialeall’inﬁnito). (R:V(a)=Q4⇡\"0a3(1a\u00001b))2.3Due sfere conduttrici di raggiR1=2 m eR2=3 m , caricate inizialmente ciascuna con caricaQ=1 mC, vengonocollegate da un ﬁlo conduttore sottile. Nel caso in cui le sfere siano poste a distanza tale da poter trascuraree↵etti di induzione elettrostatica, come si ridistribuisce la carica?(R:Q1=2QR1R1+R2=0.8 mC,Q2=2QR2R1+R2=1.2mC)2.4Calcolare la capacit` a di un condensatore sferico.2.5Calcolare la capacit` a di un condensatore cilindrico.2.6Dato il circuito rappresentato in ﬁgura 1 (\u0000VAB= 300V,C1=3µF,C2=2µF,C3=4µF), deter-minare la carica e la di↵erenza di potenziale di ciascun condensatore. (R:Q1=0.6mC, Q2=0.2mC, Q3=0.4mC,\u0000V1= 200V,\u0000V2=\u0000V3= 100V)ABC1C3C2ABC1C2C3\nC1C2SFigure 1:2.7Dato il circuito rappresentato in ﬁgura 2 (\u0000VAB= 12V,C1=C2=2µF,C3=5µF), determinare:a) la carica e la di↵erenza di potenziale ai capi di ogni condensatore del circuito (R:Q1= 12µC, Q2=Q3= 60µC,\u0000V1=\u0000V2=6V,\u0000V3= 12V);b) l’energia accumulata su ciascun condensatore (R:U1=U2= 36µJ, U3= 360µJ).2.2Si consideri un sistema formato da un volume sferico di raggioain cui ` e contenuta una carica +Qdistribuitauniformemente nel volume, e da un sottile guscio di materiale conduttore di raggiob(b>a), concentrico alvolume sferico, sul quale ` e depositata una carica\u0000Q. Determinare:a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanzardal centro delsistema, disegnando un graﬁco qualitativo dell’andamento del campo; (R:~E(r<a),~E(a<r<b)v e d ies 1.12,~E(r>b) = 0)b) l’espressione del potenziale sulla superﬁcie del volume sferico (inr=a, considerando nullo il potenzialeall’inﬁnito). (R:V(a)=Q4⇡\"0a3(1a\u00001b))2.3Due sfere conduttrici di raggiR1=2 m eR2=3 m , caricate inizialmente ciascuna con caricaQ=1 mC, vengonocollegate da un ﬁlo conduttore sottile. Nel caso in cui le sfere siano poste a distanza tale da poter trascuraree↵etti di induzione elettrostatica, come si ridistribuisce la carica?(R:Q1=2QR1R1+R2=0.8 mC,Q2=2QR2R1+R2=1.2mC)2.4Calcolare la capacit` a di un condensatore sferico.2.5Calcolare la capacit` a di un condensatore cilindrico.2.6Dato il circuito rappresentato in ﬁgura 1 (\u0000VAB= 300V,C1=3µF,C2=2µF,C3=4µF), deter-minare la carica e la di↵erenza di potenziale di ciascun condensatore. (R:Q1=0.6mC, Q2=0.2mC, Q3=0.4mC,\u0000V1= 200V,\u0000V2=\u0000V3= 100V)ABC1C3C2ABC1C2C3\nC1C2SFigure 1:2.7Dato il circuito rappresentato in ﬁgura 2 (\u0000VAB= 12V,C1=C2=2µF,C3=5µF), determinare:a) la carica e la di↵erenza di potenziale ai capi di ogni condensatore del circuito (R:Q1= 12µC, Q2=Q3= 60µC,\u0000V1=\u0000V2=6V,\u0000V3= 12V);b) l’energia accumulata su ciascun condensatore (R:U1=U2= 36µJ, U3= 360µJ).",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#41": "42Energia elettrostatica di un sistema di caricheEnergia potenziale elettrostatica di una carica situata in un punto dello spazio in cui è presente un potenziale V:  U=qV  Rappresenta il lavoro che bisogna fare sulla carica q per portarla dall’infinito al punto in cui il potenziale vale Vq1Per portare la prima carica nella posizione finale, non occorre fare lavoroPer portare la seconda carica, occorre fare un lavoro ℒ=∫⃗F⋅d⃗l=∫q2⃗E1⋅d⃗l⃗r12q2=q2∫⃗E1⋅d⃗l=q2V1(r12)=q2q14πε0r12U12=q1q24πε0r12=U21Energia del sistema di due cariche:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#42": "43Energia elettrostatica di un sistema di caricheq1Per portare una terza carica, occorre fare un lavoro ℒ=∫⃗F⋅d⃗l=∫q3⃗Etot⋅d⃗l=q3∫(⃗E1+⃗E2)⋅d⃗l⃗r12q2=q3[∫⃗E1⋅d⃗l+∫⃗E2⋅d⃗l]=q3[V1(r13)+V2(r23)]=⃗r13⃗r23q3=q3V1(r13)+q3V2(r23)=q3q14πε0r13+q3q24πε0r23U13=U31=q1q34πε0r13U23=U32=q2q34πε0r23UE=U12+U13+U23Energia elettrostatica del sistema di 3 cariche:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#43": "44Energia elettrostatica di un sistema di caricheUij=qiqj4πε0rijUE=12(U12+U21+U13+U31+U23+U32)Energia elettrostatica del sistema di 3 cariche:Utilizzando una notazione compatta:Vi=3∑j=1j≠iqj4πε0rijUE=123∑i=1qiVi=123∑i=1qi3∑j=1j≠iqj4πε0rij",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#44": "45Energia elettrostatica di un sistema di caricheL’energia elettrostatica totale di un sistema di N cariche puntiformi èqiqj⃗rijL’energia elettrostatica di un sistema è equivalente al lavoro necessario per portare le N cariche nella configurazione finale UE=12N∑i=1qiVi=12N∑i=1N∑j=1j≠iqiqj4πε0rij=N∑i=1N∑j>iqiqj4πε0rij",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#45": "46EsercizioEsercitazioni di Fisica Generale T2 - provvisorioLorenzo Rinaldi10/10/20171 Elettrostatica nel vuoto1.1Due piccole palline di sughero identiche di massamhanno ugual caricaq. Esse sono appese a due ﬁli dilunghezzal, a loro volta vincolati in un medesimo punto. In condizioni di equilibrio, determinare l’angolo✓che i due ﬁli formano con la verticale (risolvere nell’approssimazione✓⇡0 (R:✓=3qq216⇡✏0mgl2).1.2Tre cariche positive puntiformi identicheq1=q2=q3=4 mC sono disposte su un piano cartesiano ortogonalerispettivamente nei punti di coordinate (0;3m), (0;-1m) e (-1m;1m). Una quarta carica positivaq4=2 mC ` eposta nel punto di coordinate (1m;1m). Determinare:a) la forza a cui ` e sottoposta la caricaq4;( R :~F=q1q44⇡✏08p5+25100ˆı=3.09ˆıJ)b) l’energia necessaria a spostare la caricaq4dalla posizione iniziale (1m;1m) all’origine del sistema diriferimento. (R:L=q1q44⇡✏055+15p2+12p330=4.65J )1.3Tre cariche puntiformi sono poste ai vertici di un triangolo equilatero di latoa=10cm. Sapendo cheq1=\u00004·10\u00007C,q2=+ 2·10\u00007Ceq3=+ 1·10\u00007C, determinare l’energia elettrostatica del sistema. (R:U=\u000010q24⇡✏0a=\u00009·10\u00003J)1.4Quattro particelle con la stessa caricaQ=-1nC si trovano ai vertici di un quadrato di latol=12cm. Si calcoli:a) il modulo dell’intensit` a del campo elettrico nel centroOdel quadrato e nel punto medioMdi ciascunlato (R:EO= 0,EM=4p525q⇡✏0l2=8.93⇥102V/m);b) la di↵erenza di potenziale tra i puntiOeM;(R:\u0000V=q⇡✏0l(1 +p5/5\u0000p2)=1.12 V)c) il lavoro che si deve compiere per avvicinare le cariche e disporle ai vertici di un quadrato di latol/2.(R:L=q24⇡✏0⌃i,j>i1rij=4.06⇥10\u00007J)1.5Si consideri una carica elettrica distribuita uniformemente con densit` a di carica lineare\u0000=10\u00005C/m su diun ﬁlo di lunghezzaL=10 cm. Si calcoli il campo elettrico in un puntoAposto a distanzah=3 cm daun’estremit` a del ﬁlo, perpendicolarmente ad esso. (Ex=\u00004⇡✏0hLph2+L2,Ey=\u00004⇡✏0h(hph2+L2\u00001))1.6Sia data una sbarretta di lunghezza L e dimensioni trasversali trascurabili, disposta lungo il semiasse dellexpositive in un sistema di riferimento avente l’origine coincidente con uno degli estremi. Sulla barretta ` edepositata una carica Q con densit` a lineare\u0000=kx. Determinare in funzione diQed iL, l’espressione delpotenziale generato dalla barretta nel puntoP=( 2L,0,0). (V=Q2⇡✏0L(ln 4\u00001))1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#46": "47Energia elettrostaticaNel caso in cui le cariche siano distribuite con una densità 𝜌 su un volume 𝜏UE=12∫τρVdτUtilizzando la legge di Gauss in forma locale: ρ=ε0⃗∇⋅⃗E⃗∇⋅(V⃗E)=V⃗∇⋅⃗E+⃗E⋅⃗∇VV⃗∇⋅⃗E=⃗∇⋅(V⃗E)−⃗E⋅⃗∇VUE=12∫τρVdτ=12∫τε0⃗∇⋅⃗EVdτUso le proprietà del prodotto scalareUE=ε02∫τ(⃗∇⋅(V⃗E)−⃗E⋅⃗∇V)dτUE=ε02∫τ⃗∇⋅(V⃗E)−∫τ⃗E⋅⃗∇Vdτ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#47": "48Densità di energia del campo elettrico⃗∇V=−⃗EUE=ε02∫τ⃗∇⋅(V⃗E)−∫τ⃗E⋅⃗∇Vdτ∫div⃗Fdτ=∮⃗F⋅̂ndSUE=ε02∮SV⃗E⋅̂ndS+∫τ⃗E⋅⃗EdτGli integrali vanno calcolati su tutto lo spazio in  cui è presente il campo elettrico Il campo elettrico si estende e si annulla all’infinito se la carica 𝜌 è localizzataIl flusso all’infinito è nullo (E si annulla all’infinito) ⃗E⋅⃗E=E2uE=12ε0E2densità di energia del campo elettrostaticoUE=∫spazio12ε0E2dτUE=∫spaziouEdτ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#48": "49Densità di energia del campo elettrico\nuE=12ε0E2densità di energia del campo elettrostatico (quantità di energia per unità di volume) L’energia elettrostatica è localizzata nel campo elettrico (e non nella carica)UE=∫spazio12ε0E2dτUE=∫spaziouEdτUE=12∫τρVdτuE=dUEdτEspressioni dell’energia elettrostaticavolume in cui è contenuta la caricavolume in cui è presente il campo elettrico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#49": "50Energia di un condensatoreSd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+q-qCondensatore (piano) carico con carica q+dqdℒ=dqΔVq=dqqCIl lavoro complessivo per caricare completamente il condensatore dalla carica 0 alla carica Q:ℒ=∫Q0dℒ=∫Q0dqqC=1C∫Q0qdq=12Q2CL’energia elettrostatica accumulata in un condensatore è Ue=12Q2C=12CΔV2=12QΔVIl lavoro (di una forza esterna) per portare una carica +dq dall’armatura di destra a quella di sinistra è:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#5": "6Elettrizzazione per contatto\n++++++++++++++++In caso di contatto parte della carica sulla bacchetta si trasferisce al conduttoreLa carica resta sul conduttore dopo aver rimosso il contatto (misurabile con oscilloscopio)\n+++++++++++++ConduttoreConduttore⃗Econd=0Nuova situazione di equilibrio ⇒",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#50": "51Energia di un condensatoreIn un condensatore piano la capacità vale: Sd+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QC=ε0SdRiscriviamo l’energia: La differenza di potenziale tra le armature: ΔV=EdL’energia è pari alla densità di energia integrata su tutto lo spazio dove si estende il campo (il campo è nullo esternamente al condensatore)densità di energia elettrostaticavolume interno del condensatoreUE=12CΔV2=12ε0Sd(Ed)2=12ε0dSE2=(12ε0E2)(dS)=uEτ=∫τuEdτ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#51": "52Energia del condensatore\nSi può pensare di utilizzare un condensatore al posto di una batteria (chimica) ricaricabile? Svantaggi: •Ingombro. La densità di energia (energia per unità di volume) di un condensatore è enormemente minore di quella di una batteria. •Potenziale non costante. Mano mano che si scarica, la differenza di potenziale ai capi di un condensatore diminuisce (proporzionalmente alla carica).Vantaggi: •Velocità. Un condensatore si può caricare molto velocemente e può produrre intensità di corrente molto elevate scaricandosi (flash macchine fotografiche) •Durata. Una batteria si esaurisce dopo alcune migliaia di cicli di carica-scarica, mentre un condensatore ha una durata teoricamente illimitata.  •Basse temperature. Funzionano anche a -40° C, temperatura alla quale le normali batterie non sono in grado di operare. ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#52": "53Forza tra le armature di un condensatoreLe armature di un condensatore hanno cariche opposte: si attraggonoSx+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+Q-QUE=12Q2C=12Q2xε0Steniamo fissa un’armatura e applichiamo una forza esterna opposta a quella attrattiva, in modo tale che il lavoro della forza esterna bilanci la variazione di energia del condensatore⃗F⃗FestdUE=δℒest=FestdxdUE=12Q2dxε0S=δℒest=Festdxpossiamo definire la pressione elettrostatica:Per calcolare la forza tra le armature di un condensatore piano partiamo dall’energiaForza tra le armature ⃗F=−⃗Fest=−Q22ε0Ŝnp=FS=Q22ε0S2=σ22ε0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#53": "54EsempioABC1C3C2ABC1C2C3\nC1C2SFigure 2:2.8Siano dati due condensatori rispettivamente di capacit` aC1=3m FeC2=4 mF disposti come in ﬁgura 3.Inizialmente le armature del condensatore 1 sono poste ad una d.d.p.\u0000V1= 100 V, il condensatore 2 ` escarico e l’interruttoreSaperto. Una volta collegati tramite la chiusura diS, i due condensatori arrivanodopo un transitorio ad una fase di equilibrio. Calcolare:a) l’energia immagazzinata nel sistema prima della chiusura dell’interruttoreS(R:U=U1= 15J);b) l’energia immagazzinata nel sistema dopo la chiusura dell’interruttoreS(R:U=c21\u0000V212(c1+c2)=6.43J);c) dimostrare che la situazione di equilibrio corrisponde ad un minimo di energia elettrostatica del sistema(S: scrivereUin funzione del potenziale sul condensatoreV1, e poidU(V1)dV1= 0).ABC1C3C2ABC1C2C3\nC1C2SFigure 3:2.9Un condensatore a facce piane parallele poste ad una distanzaD` e inizialmente caricato in modo da possedereuna energia elettrostatica pari aUin= 10\u00004J. Supponendo di mantenere isolato il condensatore si allontaninola due armature di una quantit` a\u0000x=D/2. Calcolare il lavoro fatto dalla forza esterna.(R:L=\u000012Uin)2.10Una lastra a forma di parallelepipedo di spessorebe areaSviene inserita parallelamente all’interno di uncondensatore piano ideale avente le armature di areaSdistanti tra di loroa>b. Determinare la variazionedi energia elettrostatica nei due casi in cui il processo avviene rispettivamente a carica e a di↵erenza dipotenziale costante. (R: le energie ﬁnali dipenderanno dalla capacit` a ﬁnalecF=\"0Sa\u0000b, a seconda se siacostante la carica ovvero la d.d.p.)2.11Un condensatore piano ideale formato da due armature quadrate di latoLdisposte parallelamente a distanzad. Il condensatore ` e isolato e su di esso ` e depositata una caricaQ. Inizialmente tra le armature c’` e ilvuoto. Successivamente si introduce nel condensatore, parallelamente alle facce del condensatore, una lastra",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#54": "55EsempioABC1C3C2ABC1C2C3\nC1C2SFigure 2:2.8Siano dati due condensatori rispettivamente di capacit` aC1=3m FeC2=4 mF disposti come in ﬁgura 3.Inizialmente le armature del condensatore 1 sono poste ad una d.d.p.\u0000V1= 100 V, il condensatore 2 ` escarico e l’interruttoreSaperto. Una volta collegati tramite la chiusura diS, i due condensatori arrivanodopo un transitorio ad una fase di equilibrio. Calcolare:a) l’energia immagazzinata nel sistema prima della chiusura dell’interruttoreS(R:U=U1= 15J);b) l’energia immagazzinata nel sistema dopo la chiusura dell’interruttoreS(R:U=c21\u0000V212(c1+c2)=6.43J);c) dimostrare che la situazione di equilibrio corrisponde ad un minimo di energia elettrostatica del sistema(S: scrivereUin funzione del potenziale sul condensatoreV1, e poidU(V1)dV1= 0).ABC1C3C2ABC1C2C3\nC1C2SFigure 3:2.9Un condensatore a facce piane parallele poste ad una distanzaD` e inizialmente caricato in modo da possedereuna energia elettrostatica pari aUin= 10\u00004J. Supponendo di mantenere isolato il condensatore si allontaninola due armature di una quantit` a\u0000x=D/2. Calcolare il lavoro fatto dalle forze del campo elettrico.(R:L=\u000012Uin)2.10Una lastra a forma di parallelepipedo di spessorebe areaSviene inserita parallelamente all’interno di uncondensatore piano ideale avente le armature di areaSdistanti tra di loroa>b. Determinare la variazionedi energia elettrostatica nei due casi in cui il processo avviene rispettivamente a carica e a di↵erenza dipotenziale costante. (R: le energie ﬁnali dipenderanno dalla capacit` a ﬁnalecF=\"0Sa\u0000b, a seconda se siacostante la carica ovvero la d.d.p.)2.11Un condensatore piano ideale formato da due armature quadrate di latoLdisposte parallelamente a distanzad. Il condensatore ` e isolato e su di esso ` e depositata una caricaQ. Inizialmente tra le armature c’` e il",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#55": "56Condensatori con dielettriciCosa succede se riempiamo con un materiale isolante l’intercapedine di un condensatore?+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  +−  ++𝜎-𝜎-𝜎P𝜎PNel dielettrico le cariche non si muovono.Però a livello microscopico le molecole (dipolari) possono orientarsiSulle superfici del dielettrico a contatto con le armature del condensatore si osserva un eccesso di carica 𝜎P (carica di polarizzazione)Le cariche di polarizzazione creano un campo elettrico opposto al campo del condensatoreIl campo elettrico totale (e di conseguenza la differenza di potenziale) diminuisce La capacità del condensatore aumenta⃗E0⃗E′\u0000",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#56": "57Il dipolo elettrico\nTeorema della Divergenza (II) •!Per comprendere il significato del Teorema della Divergenza: immaginiamo di suddividere il volume V in tanti cubetti infinitesimi, di volume: •!Per ogni cubetto si ha, per quanto abbiamo visto: per cui si ha, per ogni cubetto (che ha 6 facce): !viˆndSS\"!!=!\"i!vdVV!!!\n57!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V1,!V2,!V3,…!!i!v()P()=limV\"P{}!vSV()\"##iˆndSdVV###=$tot!v()%V!!i!v()Pi()\"Vi=#toti()!v()=#ki()!v()k=16$!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V\nTeorema della Divergenza (III) •!Distinguiamo ora, tra le facce dei cubetti, le facce interne e le facce esterne: –!Le facce interne separano un cubetto da un cubetto adiacente; –!Le facce esterne fanno parte della frontiera del volume totale V. •!Sommando le divergenze dei cubetti, i contributi dei flussi delle facce interne si cancellano tra loro: –!Il flusso uscente dal cubetto i verso il cubetto j adiacente è opposto al flusso dal cubetto j al cubetto i. •!Si ha pertanto: \n58!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!!i!v()Pi()\"Vii=1N#=$ki()!v()k=16#i=1N#=$ki()!v()facceesterne#=!viˆn\"Sfacceesterne#!!i!vdVV%%%=!viˆndSS\"%%!V1!V2!V3!V4!V5!V6!V8!V7!V10!V9V\nLinee di Flusso del Campo Elettrico •!Come tutti i campi vettoriali, anche il campo elettrico si può rappresentare graficamente con le linee di flusso (o linee di campo), ovvero con linee: –!Tangenti in ogni punto al vettore campo elettrico         ; –!Orientate col verso del campo elettrico         ; –!In numero, per unità di superficie trasversale, proporzionale al modulo del campo elettrico            .   !E!r()  !E!r()\n59!  !E!r()\nDomenico Galli – Fisica Generale B – 1. Elettrostatica!\nAngolo Solido •!Come è noto, l’angolo piano (in radianti) è definito come il rapporto tra un arco di circonferenza l centrata nel vertice e il raggio r: •!L’angolo solido \" si definisce in maniera analoga come il rapporto tra la parte di superficie sferica S (centrata nel vertice), intercettata dal cono centrato nel vertice e il quadrato del raggio della sfera: •!L’angolo solido si misura in steradianti (sr). lr  !=lr\"0,2#$%$%!=Sr2\"0,4#$%&'S!r\n60!Domenico Galli – Fisica Generale B – 1. Elettrostatica!-+   Il dipolo elettrico è un sistema formato da 2 cariche elettriche in quiete, di uguale valore assoluto ma segno opposto (Q e –Q), poste a una distanza fissata d.  \nx\nz\ny+Q-QdMolti materiali isolanti sono formati da molecole che hanno una struttura “dipolare”. \nDefiniamo il momento di dipolo ⃗p=(Qd)̂k\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#57": "58Azioni meccaniche su un dipolo elettricoCalcoliamo il momento della forza esercitato da un campo esterno su un dipolo\n⃗M=⃗p∧⃗E\nDipolo Elettrico (IV) •!Si ha: \n•!Dunque il potenziale di un dipolo elettrico decresce con la distanza come 1/r2.      !pi!r=QdversP+!P!()i!r=Qdrcos!   V!r()\"d#rQ4!\"0dr2cos#=14!\"01r2!pi!rr   V!r()\"d#r14!\"0!pi!rr3\n9!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!qr++ – + QQ!r!rxyzd!\nDipolo Elettrico (V) •!Per calcolare il campo elettrico del dipolo scriviamo il potenziale in coordinate cartesiane e calcoliamo il gradiente:    Vx,y,z()!d\"r14!\"0xpx+ypy+zpzx2+y2+z2()32\n   Exx,y,z()=!\"V\"x\"d#r!14#$0\"\"xxpx+ypy+zpzx2+y2+z2()32==!14#$0pxx2+y2+z2()32!xpx+ypy+zpz()32x2+y2+z2()122xx2+y2+z2()3==14#$03xxpx+ypy+zpz()x2+y2+z2()52!pxx2+y2+z2()32%&'''()***=14#$03!pi!r()xr5!pxr3%&''()**10!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!\nDipolo Elettrico (VI) •!Ripetendo il calcolo per le componenti y e z si ottiene: •!Il campo elettrico di un dipolo elettrico decresce con la distanza come 1/r3:    !Ex,y,z()\"d#r14!\"03!pi!r()!rr5#!pr3$%&&'())\n11!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!qr++ – + QQ!r!rxyzd!!Ex,y,z()\"d#r14!\"03!pi!r()!rr5#!pr3$%&&'())=14!\"01r33!piˆr()ˆr#!p$%'(\nDipolo Elettrico (VII) •!Calcoliamo ora il momento della forza esercitato da un campo elettrico esterno su di un dipolo elettrico. •!Trattandosi di due forze di uguale modulo QE, medesima direzione e verso opposto, le cui rette di azione distano d sin !, si ha: \nQ!Qd– !pF!!F!!!Esind!+    !M=!p!!E   M=Fb=QE()dsin!()=Qd()Esin!()=pEsin!\n12!Domenico Galli – Fisica Generale B – 3. Problema Generale dell'Elettrostatica!M=FEdsinθ=(QE)dsinθ=(Qd)Esinθ=pEsinθLe due forze hanno stesso modulo QE, stessa direzione e verso opposto il momento delle forze (prendendo come polo una delle due cariche) è⃗M=⃗rd∧⃗FE",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#58": "59Elettrostatica dei dielettrici+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |⃗E0−  +⃗pOgni singolo atomo/molecola del dielettrico ha un momento di dipolo elettrico ⃗p(⃗p=q⃗d)Ogni dipolo sentirà un momento delle forze e tenderà ad allinearsi con il campo:⃗M=⃗p∧⃗E0Definiamo il momento di dipolo medio          (media di tutti i dipoli) ⟨⃗p⟩sia                 il numero di atomi/molecole per unità di volumen=NΔτSi definisce il vettore polarizzazione ⃗P=n⟨⃗p⟩[C/m2] come densità di carica • indica il grado di allineamento degli atomi/molecole in un dielettrico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#59": "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+𝜎L-𝜎L+𝜎P-𝜎P\n+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n60Elettrostatica dei dielettrici|⃗P|=σpIl modulo del vettore polarizzazione è la densità di carica di polarizzazione⃗P=σp̂n⃗P=σp̂nIn un dielettrico isotropo e omogeneo le cariche di polarizzazione sono distribuite solo superficialmente (±𝜎P)Chiamiamo la carica libera (±𝜎L) quella sulle armature del condensatoreSi definisce il vettore spostamento elettrico⃗D=σL̂n⃗D=σL̂n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#6": "7Carica interna al conduttore\nSConsideriamo una generica superficie chiusa S interna al conduttore  ΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0Per la legge di GaussInternamente al conduttore il campo elettrico è nullo, quindi la carica interna ad S sarà sempre nullaQS=∭τ(S)ρdτ=0All’interno del conduttore non ci sono cariche in eccesso (cariche positive e negative hanno uguale densità)⃗E=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#60": "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +\n|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |+𝜎L-𝜎L𝜎P-𝜎P\n+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n61Elettrostatica dei dielettriciIl campo all’interno del dielettrico⃗E=⃗E0+⃗EP⃗EP=−σPε0̂n⃗E0=σLε0̂n⃗D=ε0⃗E+⃗P=⃗Dε0−⃗Pε0=σL̂nε0−σP̂nε0In un dielettrico isotropo e omogeneo i vettori campo elettrico, polarizzazione e spostamento sono paralleliIn un dielettrico isotropo e omogeneo si definisco le due quantità adimensionali suscettività dielettrica 𝜒 (𝜒≥0) e la costante dielettrica relativa 𝜀R (𝜀R≥1), legati dalla relazione 𝜒=𝜀R-1Il campo elettrico ed il vettore polarizzazione sono legati dalla relazione⃗P=ε0χ⃗E=ε0(εR−1)⃗E",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#61": "62Elettrostatica dei dielettrici⃗P=ε0χ⃗E=ε0(εR−1)⃗E⃗D=ε0⃗E+⃗P⃗D=ε0⃗E+ε0(εR−1)⃗E=ε0εR⃗EUtilizzando il vettore spostamento elettrico, formuliamo la legge di Gauss (in forma locale e integrale) in funzione delle sole cariche libere 𝜌L e QL :⃗∇⋅⃗D=ρL∬⃗D⋅̂ndS=QLIn un dielettrico isotropo e omogeneo il vettore spostamento elettrico è proporzionale al campo elettrico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#62": "Capacità di un condensatore piano con dielettrico63Condensatori con dielettriciΔV=ΔV0εrC=QΔV=εrQΔV0=εrC0C=ε0εrSdSe riempiamo un condensatore con un dielettrico isotropo e omogeneo, il campo elettrico totale vale:\nCapacità di un condensatore con dielettricoDi conseguenza, la differenza di potenziale tra le armature⃗E=⃗Dε0εR=σL̂nε01εR=⃗E0εRcampo elettrico con condensatore vuoto",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#63": "64Costanti dielettriche relativematerialecostante dielettrica relativa 𝜀R Aria1.00059Acqua distillataca. 80Etanolo25Petrolio2.1Vetro comune5 ÷ 10Plexiglas3.40Mica8Ebanite2Paraffina2.1Glicerolo42.6Ossido di titanio90 ÷ 170Titanati di Ba-Sr1000 ÷ 10000",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#64": "Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/\n65",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#7": "8Carica superficiale di un conduttore La carica in eccesso (dovuto ad elettrizzazione per induzione o per contatto) si  dispone sulla superficie del conduttore Microscopicamente la carica occupa uno spessore di 10-10 m (dimensioni atomiche)Nei conduttori le cariche in eccesso si dispongono in superficie, in una configurazione tale che il campo elettrico interno al conduttore sia nullo\n+++++++++++++++++++++++Conduttore elettrizzato\n--++++++++++-----------Conduttore polarizzato per induzione elettrostatica100 pm",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#8": "9Campo elettrico in prossimità della superficie dei conduttoriIn equilibrio elettrostatico le cariche si dispongono in superficieIl campo generato da tali cariche non può avere componenti tangenti alla superficie, altrimenti si osserverebbero movimenti di cariche⃗EEnEt⃗F⃗E=Ên\nIl campo elettrico è sempre normale alla superficie dei conduttori",
    "data_test\\rootfolder\\università\\FisicaGenerale\\10-conduttori.pdf#9": "10Campo elettrico in prossimità della superficie dei conduttoriIl campo elettrico è sempre normale alla superficie dei conduttoriSi dimostra in maniera formale calcolando la circuitazione del campo lungo una linea chiusa 𝛤 che interseca la superficieIl campo è nullo all’interno del conduttoreConservatività del campo elettrostatico⇒∫BA⃗E⋅d⃗l=∫BA⃗E⋅̂utdl=0⟺⃗E=ÊnSABCD0=∮L⃗E⋅d⃗l=∫BA⃗E⋅d⃗lAB+∫CB⃗E⋅d⃗lBC+∫DC⃗E⋅d⃗lCD+∫AD⃗E⋅d⃗lDA∫DC⃗E⋅d⃗lCD=0∫CB⃗E⋅d⃗lBC,∫AD⃗E⋅d⃗lDA⟶BC,AD→00d⃗lAB=̂utdlABSia 𝛤 un rettangolo di vertici ABCD • lati AB e CD sufficientemente piccoli e paralleli a S • lati BC e AD infinitesimi di ordine superiore rispetto a AB e CD\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#0": "1 Correnti elettriche CdS Ingegneria Informatica A.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#1": "2Corrente elettricaIn condizione statiche, il campo elettrico all’interno dei conduttori è sempre nullo altrimenti gli elettroni sarebbero accelerati e addio condizione staticaCosa succede se tramite un artificio esterno (generatore) si pone una differenza di potenziale (d.d.p.) tra due punti del conduttore?Gli elettroni di conduzione si mettono in moto ed il conduttore risulta percorso da una corrente elettrica ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#10": "11EsempioDeterminare numero di elettroni di conduzione e velocità di deriva in un filo di rame di raggio r=0.8mm percorso uniformemente da una corrente i=15A Il rame ha densità di massa 𝛿=8.96 g/cm3 e peso atomico A=6335 g/mol mediamente si avrà nC=1 elettrone di conduzione per atomon=nCδNAA=1×8.96 g cm−3×6.022×1023mol−16355 g mol−1=8.45×1022cm−3j=iS=iπr2=15Aπ×0.82×10−6 m=7.46×106 Am−2elettroni di conduzione per unità di volumedensità di correntevelocità di derivavd=jnqe=7.46×106Am−28.45×1022 cm−3×1.6×10−19As=0.55mmsquantità di carica in moto per unità di volumenqe=8.45×1022cm−3×1.6×10−19C=13.6×103 C/m3≈14 C/mm3",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#11": "12Conservazione della carica elettrica\nConsideriamo una superficie S chiusa e orientata, interna ad un conduttoreil flusso di una corrente di densità j attraverso S è dato da⃗𝚥⃗𝚥̂ncarica che passa attraverso S nell’unità di tempo (corrente uscente) flusso positivo ⇒ carica diminuisce\nPrincipio di conservazione della carica elettrica La carica che attraversa la superficie chiusa S è pari alla variazione di carica complessiva contenuta in SΔq=qout−qinΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=i=qin−qoutΔt=−ΔqΔt→Δt→0−dqdt=iuscente",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#12": "13Equazione di continuitàLa carica interna alla superficie S può essere scritta in funzione della densità di carica: q=∭τSρdτ𝜏S è il volume delimitato dalla superficie S=−∂∂t∭τSρdτ=∭τS(−∂ρ∂t)dτ∬S⃗𝚥⋅̂ndS=∭τS⃗∇⋅⃗𝚥dτΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=−dqdtteorema della divergenzastesso dominio di integrazione 𝜏S⃗∇⋅⃗𝚥=−∂ρ∂tequazione di continuità ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#13": "14Equazione di continuità⃗∇⋅⃗𝚥+∂ρ∂t=0La divergenza del vettore densità di corrente bilancia la variazione di caricaL’equazione descrive una situazione locale (o differenziale) in ogni punto del volume in cui scorre corrente.  Una variazione di cariche corrisponde ad un moto di cariche non solenoidale  (le cariche non si muovono su linee chiuse)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#14": "15Condizioni stazionarie\nSi hanno condizioni stazionarie se la carica entrante è pari alla carica uscente⃗𝚥⃗𝚥̂nΔq=qout−qin=0La carica q internamente a S si mantiene costanteΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=0⃗∇⋅⃗𝚥=0Il flusso della densità di corrente è nulloIl campo densità di corrente è solenoidale (linee di campo sempre chiuse)−dqdt=iuscente=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#15": "16Prima legge di OhmConsideriamo un conduttore filiforme ai cui estremi c’è una differenza di potenziale Internamente al filo scorre una corrente proporzionale alla differenza di potenzialeLa costante di proporzionalità tra l’intensità di corrente e la differenza di potenziale è la resistenza elettricaΔV=RiTale relazione (prima legge di Ohm) è una legge empirica, valida a temperature ordinarie costanti La resistenza si misura in Ohm (Ω)    1Ω=1V/1Asimbolo circuitale della resistenza",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#16": "17Seconda legge di OhmLa resistenza di un conduttore omogeneo, filiforme di lunghezza l e sezione S vale R=ρRlSR=ρRlSresistività elettrica dipende dalla natura del materiale si misura in ΩmMaterialeResistività (Ωm)Argento1,62 × 10−8Rame1,68 x 10−8Oro2,35 × 10−8Alluminio2,75 × 10−8Tungsteno5,25 × 10−8Ferro9,68 × 10−8Platino10,6 × 10−8Acqua di mare2.00 × 10−1Acqua potabiletra 2.00×101 e 2.00×103Silicio puro (non drogato)2,5 × 103Vetrotra 1010   e 1014Ariatra 1.30×1016 e 3.30×1016Quarzo fusocirca 1016",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#17": "18Leggi di Ohm in forma locale\ndSdl⃗𝚥Nell’interno di un conduttore, consideriamo un sottile cilindro di base dS e lunghezza dl percorso da una corrente di densità ⃗𝚥VAVBsia dV=VA-VB la differenza di potenziale ai capi del cilindro (VA>VB)dV=Rdi=ρRdldSdiper le due leggi di Ohmdi=jdSdV=Edl⃗𝚥=σC⃗E⃗E=ρR⃗𝚥E=ρRjσC=1ρRConduttività  (o conducibilità) elettricail vettore densità di corrente ha stessa direzione e verso del campo elettrico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#18": "19Resistenze in serieVA\nVBVMDue (o più) resistenze in serie sono attraversate dalla stessa corrente i (per equazione di continuità)R1R2i{VA−VM=R1iVM−VB=R2i(VA−VM)+(VM−VB)=VA−VB=(R1+R2)isomma membro a membroRTOT=∑iRiRTOT=R1+R2\nla resistenza del sistema formato da due (o più) resistenze collegate in serie è uguale alla somma delle singole resistenzeApplicando la legge di Ohm (caduta ohmica) ai capi di ciascuna resistenza",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#19": "20Resistenze in parallelo\nVBVAR1R2i1i2Due (o più) resistenze in parallelo hanno la stessa differenza di potenziale VA-VBi1=VA−VBR1i2=VA−VBR2i=(VA−VB)(1R1+1R2)=VA−VBRTOTi=i1+i2=VA−VBR1+VA−VBR2=\nL’inverso della resistenza del sistema formato da due o più resistenze collegate in parallelo è uguale alla somma degli inversi delle singole resistenze Applicando la legge di Ohm ai capi di ciascuna resistenza1RTOT=1R1+1R21RTOT=∑i1Ri",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#2": "3Modello di Drude-LorentzSe la d.d.p. è costante nel tempo, lo sarà anche il campo elettrico e la forza sugli elettroniCi si aspetta che il moto sia uniformemente accelerato (forza e accelerazioni costanti)Sperimentalmente, però, si trova che la velocità media degli elettroni è proporzionale al campo⟨⃗ve⟩∝⃗E⟨⃗ae⟩∝⃗EModello di Drude-Lorentz  gli elettroni si comportano come cariche libere di un gas nel reticolo cristallino, soggette al campo elettrico ed interagenti con le cariche del reticolo \n_\n_\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+⃗E=−⃗∇V",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#20": "Esempio\n21\nEsempio\n22metallica quadrata di spessored/2 e latoL/2. Determinare il lavoro fatto per introdurre interamente lalastra all’interno del condensatore. (R:L=\u0000DQ210\"0L2)2.12Tre condensatori di capacit` aC1=0.5µF,C2=0.8µF,C3=0.1µF, sono collegati in serie (vedi ﬁgura 4). IpuntiAeBsono collegati inizialmente ad un generatore di tensioneV0=100 V.a) calcolare la carica elettrica su ciascun condensatore. Successivamente i condensatori vengono staccatidal generatore e il puntoBviene collegato ad un punto tra i condensatoriC1eC2.b) determinare la variazione di energia nelle↵ettuare il nuovo collegamento.   FISICA GENERALE II  -  TEST di VERIFICA     (27-10-2015)  Costanti: c = 3x108  m/s  ε0 = 8.85x10-12    F/m  G = 6.67x10-11  Nm2/kg2 e= 1.60x10-19  C me = 9.11x10-31 kg  mp = 1.67x10-27 kg   ESERCIZIO 1  Si consideri il campo F(x,y,z)=2xi-zj-ayk. Determinare: a) per quali valori di a il campo risulta conservativo; b) il potenziale generato dal campo F.  ESERCIZIO 2  Tre cariche positive puntiformi identiche q1= q2=q3=4mC sono disposte su un piano cartesiano ortogonale rispettivamente nei punti di coordinate (0,3m), (0,-1m) e (-1m,1m). Una quarta carica positiva q4=2mC  è posta nel punto di coordinate (1m,1m). Determinare: a) la forza a cui è sottoposta la carica q4; b) l’energia necessaria a spostare la carica q4 dalla posizione iniziale (1m,1m) all’origine del sistema di riferimento.  ESERCIZIO 3 Si consideri un sistema formato da un volume sferico di raggio a in cui è contenuta una carica +Q distribuita uniformemente nel volume, e da un sottile guscio di materiale conduttore di raggio b (b>a), concentrico al volume sferico, sul quale è depositata una carica –Q. Determinare: a) l’espressione del campo elettrostatico in tutto lo spazio in funzione della distanza r dal centro del sistema, disegnando un grafico qualitativo dell’andamento del campo; b) l’espressione del potenziale sulla superficie del volume sferico (in r=a, considerando nullo il potenziale all’infinito).   ESERCIZIO 4  Tre condensatori di capacità C1=0.5 µF, C2=0.8 µF,  C3=0.1 µF, sono collegati in serie (vedi figura). I punti A e B sono collegati inizialmente ad un generatore di tensione V0=100 V. a) calcolare la carica elettrica su ciascun condensatore. Successivamente i condensatori vengono staccati dal generatore e il punto B viene collegato ad un punto tra i condensatori C1 e C2. b) determinare la variazione di energia nell’effettuare il nuovo collegamento.              \nFigure 4:3 Correnti elettriche3.1Un conduttore cilindrico cavo di lunghezzad=2cm ha raggia=2mm eb=5mm; esso ` e costituito da unasostanza con resistivit` a⇢=2⌦m. Una f.e.m.E=20 V pu` o essere applicata al conduttore in modo chela corrente ﬂuisca parallelamente all’asse del cilindro oppure radialmente dalla superﬁcie interna a quellaesterna. Calcolare nei due casi l’intensit` a di correnteiche percorre il conduttore, la potenza dissipata e ladensit` a di corrente sulle superﬁci terminali.3.2Un resistore di forma cilindrica di sezioneA` e composto da una parte di lunghezzal1fatta di materiale diresistivit` a⇢1=⇢e da un’altra parte di lunghezzal2fatta di materiale di resistivit` a⇢2=3⇢. Il resistore ` eattraversato da una correnteIuniformemente sulla sezioneA. Determinare:a) l’intensit` a dei campi elettriciE1eE2nelle due parti del resistore;b) la di↵erenza di potenziale ai capi del resistore;c) il valore della carica elettrica presente sulla superﬁcie di separazione tra i due materiali che formano ilresistore.3.3Nel circuito in ﬁgura 5, calcolare l’intensit` a di correntei, il potenziale nei quattro vertici e il bilancioenergetico (R= 50⌦,E1=50 V,r1= 20⌦,E2=100 V,r2= 30⌦)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#21": "22Effetto JouleQuando una corrente i scorre attraverso un conduttore filiforme, la carica che attraversa una sezione S in un tempo dt è: dq=i dt Il lavoro compiuto dal campo elettrico nello spostamento della carica nell’intervallo dt èδℒ=dU=ΔVdq=ΔVidt=(Ri)idt=Ri2dtLa potenza (energia per unità di tempo) spesa dal campo elettrico per sostare la carica èP=dUdt=Ri2La potenza viene persa negli urti degli elettroni di conduzione con gli atomi del conduttore, i  quali aumentano la propria energia vibrazionale (la potenza viene dissipata in calore)\nEffetto Joule aumento della temperatura del conduttore attraversato da correnteP=iΔV=ΔV2R",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#22": "23Effetto Joule: interpretazione microscopicaLavoro compiuto dal campo sugli N elettroni contenuti in un volume d𝜏 in un tempo dt=ndτqe⃗E⋅d⃗l=⃗E⋅⃗𝚥dτdtdPdτ=δℒdτdt=⃗E⋅⃗𝚥\nEffetto Joule in forma locale Relazione locale che esprime la potenza per unità di volume come prodotto scalare del campo elettrico per la densità di correnten=Ndτδℒ=NqeΔV=ndτqe⃗E⋅⃗vddt=⃗E⋅(nqe⃗vd)dτdt",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#23": "24Superconduttori\nLa resistività è funzione lineare della temperaturaρR=ρ0(1+αT)Alcuni metalli (Hg, Al, Pb, Ti, Zn, …) o altre leghe al di sotto di una temperatura critica Tc prossima allo zero assoluto (0°K=-273.15 °C) mostrano una resistività nullaIn tali condizioni di superconduttività, le correnti circolano senza dissipazione di energia e i superconduttori non si riscaldano, anche con correnti molto intense𝜌0,𝛼 costanti T temperatura in °K ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#24": "25Generatori di forza elettromotriceSi è  detto che per avere una corrente in un conduttore è necessario stabilire una differenza di potenziale in due punti del conduttore  Per loro natura i conduttori sono equipotenziali. Per forzare una d.d.p occorre connettere il conduttore ad un generatore di forza elettromotrice (o generatore elettrico)Consideriamo un semplice circuito formato da un generatore (pila o batteria) e da una resistenzaIn tale circuito la circuitazione del campo elettrico è diversa da zero (altrimenti non avremmo corrente)\nGeneratori Elettrici (II) • Segue che nel generatore ci debbono essere forze di natura non elettrica le quali non sono conservative e determinano il moto delle cariche: – Nelle pile e batterie avvengono reazioni chimiche di ossidoriduzione nelle quali è energeticamente favorito il movimento delle cariche contro il campo elettrico. – Nelle dinamo e negli alternatori è presente un campo magnetico che muove le cariche elettriche in direzione opposta al campo elettrico. – Nel generatore di Van der Graaf un’azione meccanica esterna trasporta le cariche elettriche in direzione opposta al campo elettrico. \n29Domenico Galli – Fisica Generale B – 3. Corrente Elettricaiiii!E!E1V1V2V2VG∮⃗E⋅d⃗l=∮ρR⃗𝚥⋅d⃗l≠0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#25": "26Generatori di forza elettromotriceNel circuito il campo avrà due componenti\nGeneratori Elettrici (II) • Segue che nel generatore ci debbono essere forze di natura non elettrica le quali non sono conservative e determinano il moto delle cariche: – Nelle pile e batterie avvengono reazioni chimiche di ossidoriduzione nelle quali è energeticamente favorito il movimento delle cariche contro il campo elettrico. – Nelle dinamo e negli alternatori è presente un campo magnetico che muove le cariche elettriche in direzione opposta al campo elettrico. – Nel generatore di Van der Graaf un’azione meccanica esterna trasporta le cariche elettriche in direzione opposta al campo elettrico. \n29Domenico Galli – Fisica Generale B – 3. Corrente Elettricaiiii!E!E1V1V2V2VG⃗E=⃗Es+⃗Em⃗Es⃗E=⃗Es+⃗EmAll’interno del generatore si deve aggiungere il campo elettromotore        (NON conservativo)⃗EmLe forze interna ai generatori sono non conservative (di natura chimica o altro). Il loro effetto è quello di trasportare e mantenere le cariche interne ad una differenza di potenziale 𝛥V=V2-V1Nei conduttori si avrà solo campo elettrostatico⃗Es",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#26": "27Generatori di forza elettromotrice∮⃗E⋅d⃗l=∮(⃗Es+⃗Em)⋅d⃗l=∮⃗Es⋅d⃗l+∮⃗Em⋅d⃗lV2V1⃗Es⃗Em⃗EsIl campo elettromotore è definito solo internamente al generatore, non è conservativo e la sua circuitazione è definita forza elettromotrice =ℰ\nℰ=∫21⃗Em⋅d⃗l=−∫21⃗ES⋅d⃗l=V2−V1=ΔVIn condizioni stazionarie (generatore non connesso al circuito) le cariche sono ferme, pertanto ∮(⃗Es+⃗Em)⋅d⃗l=0La forza elettromotrice è uguale alla differenza di potenziale (Tensione del generatore)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#27": "28Generatori di forza elettromotriceGeneratori ideali  • la tensione ai capi del generatore si mantiene costanteGeneratori reali  • la tensione ai capi del generatore presenta una caduta ohmica • occorre considerare la resistenza interna del generatore (in serie al circuito)+_\n+_simbolo circuitale generatore idealesimbolo circuitale generatore reale",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#28": "Prima legge di Kirchhoff (dei nodi)\n29+i1\nS1\n+i2-i3-i4-i5S\nS2S5S4S3In condizioni stazionarie (fissato un intervallo 𝛥t, la carica entrante deve bilanciare la carica uscente) ΦS(⃗𝚥)=∬S⃗𝚥⋅̂ndS=0=∑entrantiik−∑uscentiik∬Sk⃗𝚥k⋅̂nkdSk={+ikentrantenelnodo−ikuscentedalnodo∬S⃗𝚥⋅̂ndS=∑k∬Sk⃗𝚥k⋅̂nkdSkConsideriamo N fili che si congiungono in un nodo Siano Si le superfici di intersezione tra S e le sezioni dei fili \nPrima legge di Kirchhoff (dei nodi) In qualunque nodo di un circuito la corrente totale entrante è uguale alla corrente uguale uscente∑nodoik==∑entrantiik−∑uscentiik=0i1+i2−i3−i4−i5=0i1+i2=i3+i4+i5",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#29": "Legge di Ohm generalizzata\n30Prendiamo in considerazione un circuito aperto (ramo)iA+_+_BCDRR1R2𝓔1𝓔2Fissiamo arbitrariamente un verso di percorrenza della corrente ( es. da A verso D)In condizioni stazionare la corrente entrante in A è pari a quella uscente da DCiascun elemento del circuito è percorso dalla stessa corrente i (tutti gli elementi sono in serie)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#3": "4\n_\n_\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+\n+Gli elettroni subiscono urti, cedendo energia cineticaModello di Drude-Lorentz\n⃗ae=qeme⃗EII principio dinamicaNell’intervallo di tempo tra due urti consecutivi l’elettrone si muove di moto uniformemente accelerato:Nell’urto sulle cariche positive, l’elettrone cede energia • l’elettrone rallenta • gli atomi del reticolo aumentano la loro energia vibrazionale (gli atomi del reticolo vibrano sempre a T>0° K)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#30": "Legge di Ohm generalizzata\n31A+_+_BCDRR1R2𝓔1𝓔2Applichiamo la prima legge di Ohm ai capi dei vari elementiVA-VB=Ri              Caduta di potenziale ai capi di RVB-VC=R1i-𝓔1       Caduta di potenziale ai capi di R1, il generatore 𝓔1 fa salire il potenzialeVC-VD=R2i+𝓔2     Caduta di potenziale ai capi di R2, il generatore 𝓔2 fa scendere il potenzialeVA-VD=Ri+R1i+R2i+𝓔2-𝓔1 =(R+R1+R2)i+𝓔2-𝓔1  Differenza di potenziale ai capi dell’intero ramo   ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#31": "Legge di Ohm generalizzata\n32A+_+_BCDRR1R2𝓔1𝓔2+_VA-VD+(𝓔1-𝓔2)=RTOT i “Fissato”  il verso della corrente, stabiliamo anche il verso in cui diminuisce il potenziale (le cariche positive della corrente fluisco dal potenziale maggiore a quello minore)Convenzione dei generatori in un circuito (segno della tensione) + se la corrente “entra” nel polo negativo ed “esce” dal polo positivo -  se la corrente “entra” nel polo positivo ed “esce” dal polo negativo +_+_",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#32": "Legge di Ohm generalizzata\n33\u0000V+XkEk=RTOTiLegge di Ohm su un ramo di un circuito apertoLa differenza di potenziale ai capi di un ramo aperto di un circuito sommata alle tensioni erogate dai generatori è uguale alla caduta di tensione sulla resistenza totale del ramoN.B. Se dai calcoli numerici:  • la corrente ha segno positivo, allora essa circola nello stesso verso che si era supposto inizialmente • la corrente ha segno negativo, allora essa circola nel verso opposto a quello che si era supposto inizialmente",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#33": "Seconda legge di Kirchhoff (delle maglie)\n34A+_+_BCDRR1R2𝓔1𝓔2RConsideriamo un ramo chiuso (maglia)Connettendo i due capi, la differenza di potenziale si annulla: 𝛥V=0La legge di Ohm viene riformulata:XkEk=RTOTi\nSeconda legge di Kirchhoff (o delle maglie) Su qualunque maglia di un circuito la caduta di potenziale è uguale  alla somma delle tensioni erogate dai generatori",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#34": "Circuiti ideali e reali\n35+_Circuiti elettrici costituiti da fili conduttori, resistenze, generatori e altri elementi collegati tra loroIn un circuito ideale, gli elementi hanno resistenza interna nulla (escluso resistenza)filo conduttoreresistenzacondensatoregeneratore+_In un circuito reale, gli elementi sono schematizzati introducendo elementi resistivi",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#35": "Circuiti RC in regime transitorio\n36+_T𝓔CRConsideriamo il circuito (ideale) formato da una resistenza, un condensatore a da un generatore di forza elettromotriceInizialmente l’interruttore T è aperto, il condensatore è scaricoAd un dato istante iniziale t=0 l’interruttore viene chiuso. Cosa succede nel circuito? Circola corrente? Potenziale ai capi di resistenza e condensatore? Carica sul condensatore?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#36": "Circuiti RC in regime transitorio\n37𝛥VC𝛥VR+_T𝓔CRLe differenze di potenziale ai capi di R e C varieranno al passare del tempo:ΔVR(t)=Ri(t)ΔVC(t)=Q(t)Ci(t) corrente che circola nel circuitoQ(t) carica sul condensatore all’istante t=0 il condensatore è scarico Q(0)=0Applicando la legge delle maglie: ℰ=ΔVR(t)+ΔVC(t)ℰ=Ri(t)+Q(t)C",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#37": "Circuiti RC in regime transitorio\n38𝛥VC𝛥VR+_T𝓔CRℰ=Ri(t)+Q(t)CLa carica Q(t) che dal generatore fluisce verso il condensatore è legata alla corrente che circola nel circuito dalla relazionei(t)=dQ(t)dtQ(t)=∫t0i(t′\u0000)dt′\u0000L’equazione delle maglie è a tutti gli effetti un’equazione integro-differenziale0=Rdidt+1CdQdt=Rdidt+iCderivando tutto rispetto a t",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#38": "390=Rdidt+1CdQdt=Rdidt+iCCircuiti RC in regime transitorio𝛥VC𝛥VR+_T𝓔CRdidt=−iRCRisolviamo per separazione delle variabiliEquazione omogenea in i(t)dii=−dtRC∫i(t)i(0)di′\u0000i′\u0000=−1RC∫t0dt′\u0000lni(t)i(0)=−tRCi(t)i(0)=e−tRCi(t)=i(0)e−tRCAll’instante iniziale si haℰ=Ri(0)+Q(0)Ci(0)=ℰRi(t)=ℰRe−tRCQ(0)=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#39": "Carica di un condensatore\n40i(t)=ℰRe−tRC𝛥VC𝛥VR+_T𝓔CRCorrente che circola nel circuito in funzione del tempo=ℰR[−RCexp(−t′\u0000RC)]t0=−ℰC(e−tRC−1)=ℰC(1−e−tRC)Q(t)=∫t0i(t′\u0000)dt′\u0000=∫t0ℰRexp(−t′\u0000RC)dt′\u0000Q(t)=ℰC(1−e−tRC)ΔVR(t)=ℰe−tRCDifferenza di potenziale ai capi della resistenzaCarica sul condensatore in funzione del tempoΔVC(t)=ℰ(1−e−tRC)Differenza di potenziale ai capi del condensatoreτ=RCCostante di tempo del circuito RC",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#4": "5Modello di Drude-LorentzSupponiamo che l’elettrone abbia un urto all’istante t. Sia  p(t)dt la probabilità di avere un urto in un intervallo [t, t+dt]. ⟨t⟩=∫∞0tp(t)dtIl tempo medio che intercorre tra due urti:nel tempo tra due urti consecutivi, la velocità aumenterà linearmente con l’accelerazione⃗ve=qeme⃗Etla velocità media di un elettrone sara:⟨⃗ve⟩=∫∞0⃗ve(t)p(t)dt=∫∞0qeme⃗Etp(t)dt=qeme⃗E⟨t⟩",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#40": "41Carica di un condensatore\nTransitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ\n13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci\"t()d\"t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt\"d#i#ii0i$%&=!1RCd#t0t'\"ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC\"i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f\"i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=\"fe\"t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=\"1CfRe\"#t/RCd#t0t$+f==\"fRC\"RCe\"#t/RC%&'(0t+f=\"f1\"e\"t/RC()+f=fe\"t/RCQt()=C!VCt()=Cfe\"t/RC!VRt()=\"fe\"t/RC!VCt()=fe\"t/RCQt()=Cfe\"t/RC!VRt()t\"#$\"$$0!VCt()t\"#$\"$$0Qt()t\"#$\"$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ℰRi(t)=ℰRe−tRC\nTransitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ\n13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci\"t()d\"t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt\"d#i#ii0i$%&=!1RCd#t0t'\"ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC\"i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f\"i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=\"fe\"t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=\"1CfRe\"#t/RCd#t0t$+f==\"fRC\"RCe\"#t/RC%&'(0t+f=\"f1\"e\"t/RC()+f=fe\"t/RCQt()=C!VCt()=Cfe\"t/RC!VRt()=\"fe\"t/RC!VCt()=fe\"t/RCQt()=Cfe\"t/RC!VRt()t\"#$\"$$0!VCt()t\"#$\"$$0Qt()t\"#$\"$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ΔVR(t)=ℰe−tRCΔVR(t)=ℰe−tRC\nTransitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ\n13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci\"t()d\"t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt\"d#i#ii0i$%&=!1RCd#t0t'\"ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC\"i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f\"i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=\"fe\"t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=\"1CfRe\"#t/RCd#t0t$+f==\"fRC\"RCe\"#t/RC%&'(0t+f=\"f1\"e\"t/RC()+f=fe\"t/RCQt()=C!VCt()=Cfe\"t/RC!VRt()=\"fe\"t/RC!VCt()=fe\"t/RCQt()=Cfe\"t/RC!VRt()t\"#$\"$$0!VCt()t\"#$\"$$0Qt()t\"#$\"$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0ℰΔVC(t)=ℰ(1−e−tRC)\nTransitori in un Circuito RC. Chiusura del Circuito (VI) 0fiR=itf!VRttf!VCtCfQ\n13!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito •!Supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con il condensatore C completamente carico (Q = Cf ). Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione integrale: •!Derivando si ottiene l’equazione differenziale:   0=!VRt()+!VCt()==Rit()+1Ci\"t()d\"t0t#+Q0()C  0=Rdidtt()+1Cit()14!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (II) •!Risolvendo: •!All’istante iniziale si ha:   dii=!1RCdt\"d#i#ii0i$%&=!1RCd#t0t'\"ln#i()*+i0i=!1RC#t()*+0tlnii0=!tRC\"i=i0e!tRC  0=!VR0()+!VC0()=Ri0+f\"i0=#fR it()=!fRe!tRC15!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (III) •!Si ottiene inoltre: !VRt()=Rit()=\"fe\"t/RC!VCt()=1Ci#t()d#t0t$+!VC0()=\"1CfRe\"#t/RCd#t0t$+f==\"fRC\"RCe\"#t/RC%&'(0t+f=\"f1\"e\"t/RC()+f=fe\"t/RCQt()=C!VCt()=Cfe\"t/RC!VRt()=\"fe\"t/RC!VCt()=fe\"t/RCQt()=Cfe\"t/RC!VRt()t\"#$\"$$0!VCt()t\"#$\"$$0Qt()t\"#$\"$$016!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0Q(t)=ℰC(1−e−tRC)ℰC",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#41": "42Scarica di un condensatoreTCRSia dato un circuito formato da un condensatore e una resistenza Q(0)=Q0Inizialmente l’interruttore T è aperto, il condensatore è carico con Q(0)=Q0Calcoliamo quanto vale l’energia dissipata sulla resistenza i(t)=dQ(t)dtL’equazione della maglia alla chiusura dell’interruttore èΔVR(t)+ΔVC(t)=0Ri(t)+Q(t)C=0RdQdt+QC=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#42": "43Scarica di un condensatoreTCRQ(0)=Q0RdQdt+QC=0dQdt=−QRCdQQ=−dtRCPer separazione delle variabiliEq differenziale omogeneaQ(t)=Q0e−tRCCarica sul condensatorei(t)=−Q0RCe−tRC=−VcRe−tRCCorrente che circola nel circuitolnQ(t)Q(0)=−tRC",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#43": "44Scarica di un condensatore\nTransitori in un Circuito RC. Apertura del Circuito (IV) •!Si noti che la carica del condensatore diminuisce nel tempo tendendo al valore limite 0.  •!Commutando il deviatore su 0 si ottiene perciò la scarica del condensatore. \n17!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (V) 0fiR=!itf!RV!ttfCV!tCfQ\n18!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nhttp://campus.cib.unibo.it/2475/ Domenico Galli Dipartimento di Fisica domenico.galli@unibo.it http://www.unibo.it/docenti/domenico.galli https://lhcbweb.bo.infn.it/GalliDidattica \ni(t)=−VcRe−tRC\nTransitori in un Circuito RC. Apertura del Circuito (IV) •!Si noti che la carica del condensatore diminuisce nel tempo tendendo al valore limite 0.  •!Commutando il deviatore su 0 si ottiene perciò la scarica del condensatore. \n17!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nTransitori in un Circuito RC. Apertura del Circuito (V) 0fiR=!itf!RV!ttfCV!tCfQ\n18!Domenico Galli – Fisica Generale B – 5. Circuiti in Corrente Continua!RCf!+01RV!CV!iAMBt=0\nhttp://campus.cib.unibo.it/2475/ Domenico Galli Dipartimento di Fisica domenico.galli@unibo.it http://www.unibo.it/docenti/domenico.galli https://lhcbweb.bo.infn.it/GalliDidattica \nQ0Q(t)=Q0e−tRC\n−Q0RC=−VcR",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#44": "45Scarica di un condensatoreTCRQ(0)=Q0UR=∫∞0PRdt=∫∞0Ri2dt=∫∞0R[−VCRe−tRC]2dtL’energia dissipata è pari all’integrale della potenza nel tempo=12CV2C[−e−∞RC+e−0RC]=V2CR∫∞0e−2tRCdt=V2CR[−RC2e−2tRC]∞0UR=12CV2C=UCL’energia che era inizialmente accumulata nel condensatore viene interamente dissipata sulla resistenza",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#45": "DRAM \n46\nIl condensatore può essere utilizzato come cella di memoria in alternativa al flip-flop Cella di memoria formata da condensatore + transistor Lo stato di carica del condensatore determina lo stato logico Il transistor è usato per pilotare la lettura/scrittura (funziona come un interruttore) Ad ogni lettura/scrittura, tutti i C di un array vengono ri-caricati/scaricatiLinea indirizziLinea dati",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#46": "DRAM \n47\nPRO economicità, alta densità, velocità di accesso ~10 ns (un po’ più lente delle SRAM)\nCONS carica sui C diminuisce nel tempo (effetti dissipativi) necessario un circuito di “refresh” che faccia delle letture/scritture “fittizie” (con frequenza del kHz)  Problemi in ambienti ad elevata radiazione (centrali nucleari, detector, spazio): particelle cariche da raggi cosmici o da decadimenti radioattivi possono alterare gli stati  logici",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#47": "Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/\n48",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#5": "6Modello di Drude-LorentzVelocità media o velocità di deriva proporzionale al campo: stessa direzione e verso opposto gli elettroni possiedono anche una velocità dovuta all’agitazione termica, ma si può dimostrare che essa ha valore medio nullo (perché casuale in ogni direzione) Valori tipici: velocità di termica a temperatura ambiente ~100 km/s velocità di deriva: qualche mm/s⃗vd=⟨⃗ve⟩=qeme⃗E⟨t⟩",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#6": "7Intensità di correnteConsideriamo un conduttore all’interno del quale è mantenuta una differenza di potenziale VA-VB\nNel S.I. l’unità di misura della corrente è l’Ampere (A) (grandezza fisica fondamentale) \nSdqVAVBi=limΔt→0ΔqΔt=dqdtData una sezione S, interna al conduttore, definiamo la corrente elettrica come la quantità di carica che attraversa il conduttore per unità di tempo",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#7": "8Intensità di correntei=dqdtLa carica che attraversa la superficie S è al netto delle cariche positive e negative Dal punto di vista sperimentale, in elettromagnetismo, il moto di una carica positiva è equivalente al moto di una carica negativa che procede in verso opposto\nSdq=dq++dq-VAVBConvenzione: verso positivo delle correnti quello in cui si muovono i portatori di carica positivi  la corrente ha verso opposto alla velocità di deriva degli elettroni",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#8": "9Intensità di corrente\n̂nα\ndSdS´VAVB⟨⃗v+⟩Consideriamo un tubo (di flusso) cilindrico di sezione infinitesimafissiamo il verso della corrente concorde alla velocità di derivain un intervallo dt, avremo una quantità di carica dq (positiva) che attraversa il volume d𝜏 delimitato dalle superfici orientate S e S´  n=Ndτnumero di portatori di carica N per unità di volumecarica elementare (positiva)d𝜏dq=Ne+=nq+edτdτ=[(⃗vd⋅̂n)dt]dS(⃗vd⋅̂n)dtaltezza del cilindretto obliquo",
    "data_test\\rootfolder\\università\\FisicaGenerale\\11-correnti.pdf#9": "10Densità di correnteDefiniamo il vettore densità di corrente elettricai=dqdt=∬S⃗𝚥⋅̂ndSRiscriviamo la carica che attraversa il volume d𝜏\n̂nα\ndSdS´VAVB⃗𝚥d𝜏\nCorrente (infinitesima) che attraversa una superficie dSL’intensità di corrente è pari al flusso della densità di corrente attraverso la sezione del conduttore\nFlusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: \n37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=\"v!t!\"!v()=#V#t=\"v#t#t=\"v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v\nFlusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: \n38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos\"!viˆn=!vˆn1\"cos\"=vcos\"#S!v()=!v=Svcos\"=!viˆnS!ˆn!Sr!v\nFlusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: \n39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS\"\"d!=dScos\"d!!SdSd!!vd#dS!v()=vd!=vdScos\"=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) \nFlusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. \n40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) \ndSdS!viˆnd!!S!v()=!viˆndSS\"\"\nFlusso di un Campo Vettoriale (III) •!La quantità di fluido che ha attraversato nel tempo !t la sezione && del tubo è pari al volume di un cilindro avente la stessa base del tubo e un’altezza pari a v &t, cioè: •!Il flusso del fluido sarà pertanto: \n37!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!V=\"v!t!\"!v()=#V#t=\"v#t#t=\"v!!!v!vt=t0t=t0+!tv!tv!t!v!v!v!v\nFlusso di un Campo Vettoriale (IV) •!Possiamo anche esprimere il flusso ''  (v) utilizzando una sezione obliqua S invece che una sezione trasversale &. •!Si ha: \n38!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!=Scos\"!viˆn=!vˆn1\"cos\"=vcos\"#S!v()=!v=Svcos\"=!viˆnS!ˆn!Sr!v\nFlusso di un Campo Vettoriale (V) •!Consideriamo ora il caso in cui la velocità del fluido non è uniforme sulla sezione del tubo. –!È il caso, per esempio, di un flusso laminare di un fluido viscoso, per il quale la velocità al centro del tubo è maggiore della velocità in prossimità delle pareti. •!In tal caso scomponiamo il tubo in tanti tubicini di sezione trasversale infinitesima              . Il flusso attraverso una qualunque sezione di un tubicino infinitesimo vale: •!Il flusso totale si ottiene sommando il flusso attraverso un insieme di tubicini che coprono completamente la sezione del tubo: \n39!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v()=!viˆndSS\"\"d!=dScos\"d!!SdSd!!vd#dS!v()=vd!=vdScos\"=!viˆndS(volume di fluido che attraversa nell’unità di tempo la superficie S) \nFlusso di un Campo Vettoriale (VI) •!La superficie S potrebbe anche non essere piana, ma l’espressione: è ugualmente valida, in quanto le superfici infinitesime dS possono essere considerate piane e il prodotto scalare        tiene conto della loro inclinazione rispetto alla velocità. \n40!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!S!v(volume di fluido che attraversa nell’unità di tempo la superficie S) \ndSdS!viˆnd!!S!v()=!viˆndSS\"\"\n⃗𝚥di=(dqdt)dS=⃗𝚥⋅̂ndSdq=nqe[(⃗vd⋅̂n)dt]dS=[(nqe⃗vd)⋅̂n]dSdt⃗𝚥=nqe⃗vd",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#0": "1 Cmpi magnetici stazionari CdS Ingegneria Informatica A.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#1": "2Fenomeni magneticiI fenomeni magnetici sono noti dall’antichità  (Talete, Archimede, Cinesi…) Il minerale magnetite (FeO+Fe2O3+FeO4) ha la capacità di attrarre oggetti contenenti ferro o materiali ferrosi\nEsistenza forze magnetiche\nLimatura di ferro vicino ad una calamita è attratta maggiormente dagli estremi (poli magnetici) in cui sembra si concentri la forza",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#10": "Rotore e circuitazione del campo magnetico\n11\nLe linee del campo magnetico sono sempre chiuse  𝛤La circuitazione lungo una generica linea chiusa 𝛤 sarà in generale non nullaAnche il rotore del campo magnetico (thm Stokes) sarà in generale non nullo⃗∇∧⃗B≠0\nIl campo magnetico NON è conservativo∮Γ⃗B⋅d⃗l≠0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#11": "Magneti, cariche elettriche, correnti\n12Le forze a cui sono sottoposti gli aghi magnetici corrispondono a quelle dei dipoli elettrici, piuttosto che a quelle delle cariche singoleNon ci sono interazioni tra magneti e cariche elettriche fermeCosa succede se avviciniamo un magnete a delle cariche in movimento ? (filo percorso da corrente)\nConsideriamo un esperimento in cui colleghiamo un filo conduttore ad un generatore  di f.e.m. Poniamo un ago magnetico vicino al tratto di filo rettilineo",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#12": "Esperimento di Oersted (1820)\n13\nA circuito aperto, l’ago non sente nessuna forza e resta fermoChiudendo il circuito, nel filo passa corrente e l’ago si orienta perpendicolarmente al filoInvertendo la polarità del generatore, l’ago ruota in senso opposto",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#13": "Esperimento di Faraday (1821)\n14\nPoniamo un filo conduttore in un campo magneticoSe nel conduttore passa corrente, esso sente una forzapossiamo bilanciare (→ misurare) la forza con dei pesi",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#14": "Esperimento di Ampère (1820)\n15\nEsperimento con due fili rettilinei e paralleli percorsi da corrente\nI fili si attraggono se le correnti hanno lo stesso versoI fili si respingono se le correnti hanno verso opposto",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#15": "Cariche in movimento e campi magnetici\n16Si osservano interazioni di tipo magnetico tra: •magneti •magneti e fili percorsi da corrente  •fili percorsi da correntePossiamo concludere che le correnti generano dei campi magneticiMa le correnti sono cariche in movimento\nI campi magnetici sono generati da cariche in movimento sia macroscopicamente (correnti) che microscopicamente (magneti)Domanda: cariche in movimento sono l’unico modo per generare campi magnetici?I movimenti possono essere anche microscopici (elettroni che orbitano attorno ai nuclei, all’interno delle calamite)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#16": "Magnetostatica nel vuoto\n17Consideriamo un circuito in corrente stazionaria i e consideriamo un piccolo tratto      che sia  •libero di muoversi su connessioni flessibili e mediante un dinamometro. •elettricamente neutro •orientato con il verso della corrente •immerso in un campo magnetico d⃗ld⃗FIl tratto di filo     subisce una forza     con le seguenti caratteristiche:d⃗l|d⃗F|∝i|d⃗l|d⃗F⊥d⃗ld⃗F=0Quando la corrente (    )  e il campo magnetico sono parallelid⃗l\niRdinamometro a molle𝓔(entrante nel piano)⃗Bd⃗l",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#17": "Seconda legge di Laplace\n18d⃗F=id⃗l∧⃗BUn tratto di filo percorso da corrente ed immerso in un campo di induzione magnetica subisce una forza descritta da:\nDefinizione operativa del campo induzione magnetica⃗Bla direzione ed il verso di       sono determinati dalla corrente che circola nel filod⃗l\nRegola della mano destra",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#18": "19Seconda legge di Laplaced⃗F=id⃗l∧⃗BCosa succede a livello microscopico nel filo?Una sezione dS del filo sarà attraversata da una densità di corrente di modulo j=i/dSid⃗l=idSdSd⃗l=⃗𝚥(dSdl)=⃗𝚥dτdi=⃗𝚥⋅̂ndS⃗𝚥 orientato come d⃗lForza magnetica sull’intero volume del filodτ volume infinitesimo⃗F=∫filo⃗𝚥∧⃗BdτForza magnetica su un volume infinitesimod⃗Fτ=⃗𝚥∧⃗Bdτ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#19": "Forza magnetica su cariche puntiformi\n20La densità di corrente era stata definita come:⃗𝚥=nq⃗vdn=Ndτ⃗vdNumero di portatori di carica per unità di volumevelocità di derivaLa forza magnetica per unità di volume diventad⃗Fτ=⃗𝚥∧⃗Bdτ=nq⃗vd∧⃗Bdτ=Nq⃗vd∧⃗B⃗F=q⃗v∧⃗BIn base a questa relazione, possiamo generalizzare al caso di una singola carica puntiforme q che in moto con velocità    , in presenza di un campo di induzione magnetica    , subisce una forza  (forza di Lorentz)  ⃗B⃗v",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#2": "Fenomeni magnetici\n3Le calamite esercitano forze tra di loro, che possono essere attrattive o repulsive In analogia con l’elettrostatica, possiamo introdurre la definizione di poli magnetici NORD e SUD La definizione deriva dal fatto che la Terra si comporta come una calamita in una calamita il polo sud si orienta verso il sud geografico e il polo nord con il nord terrestre\nS\nN",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#20": "Forza di Lorentz\n21⃗F=q⃗v∧⃗BMetodo alternativo per definire il campo induzione magnetica (usando una singola carica)Tale relazione è puntuale (vale in ciascun punto dello spazio) ed è più precisa della seconda legge di Laplace (definita su un tratto     )d⃗lDall’espressione della Forza di Lorentz ricaviamo che il campo magnetico ha le dimensioni di una forza su carica e velocità. Nel S.I. il campo magnetico si misura in Tesla (T)  1T=1V 1s/1m2 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#21": "Forza di Lorentz\n22⃗F=q⃗v∧⃗BIn presenza di un campo di induzione magnetica: •Cariche ferme non soggette a forza di Lorentz  •Cariche in movimento soggette a forza di Lorentz \nLa forza di Lorentz è sempre perpendicolare al campo induzione magnetica \nLa forza di Lorentz è sempre perpendicolare alla velocità  (centripeta)  \nLa forza di Lorentz non compie lavoro sulla carica in moto (è conservativa???)\ndirezione della forza data dalla regola della mano destraF=qvBsinαModulo della forza di Lorentz𝛼",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#22": "Forza di Lorentz generalizzata\n23⃗F=q⃗E+q⃗v∧⃗BSe sono presenti sia un campo elettrico che un campo magnetico la forza di Lorentz si scrive⃗F=q(⃗E+⃗v∧⃗B)Le cariche elettriche interagiscono con il campo elettrico ed il campo magnetico •Cariche ferme sentono solo gli effetti del campo elettrico •Cariche in moto sentono sia l’effetto del campo elettrico che del campo magneticoCosa succede che se cambiamo Sistema di Riferimento? (esempio, se scegliamo un SdR solidale con la carica in moto?)Le leggi della Fisica devono essere invarianti: non devono dipendere dal SdR.  Importante indizio del fatto che campo elettrico e campo magnetico sono strettamente legati: sono due aspetti della stessa entità fisica: il campo elettromagnetico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#23": "Moto di cariche in campi magnetici\n24Studiamo il moto di una carica q che si muove con velocità costante, perpendicolare ad un campo magnetico uniformeLa forza di Lorentz è ortogonale a velocità e campo magnetico. Forza e velocità sono complanari. ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗B⃗F⃗FPer calcolare il raggio di curvatura R dell’orbita ricordiamo che nella cinematica di un moto curvilineo l’accelerazione è⃗a=dvdt̂ut+v2R̂n⃗vcostanteForza centripeta: moto circolare uniforme⃗v⃗vR",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#24": "Moto di cariche in campi magnetici\n25⃗F=m⃗a=mv2R̂n⃗F=q⃗v∧⃗B=qvB̂n̂n=⃗v∧⃗Bvbsinα=1mv2R=qvBForza centripetaForza di Lorentzdirezione e verso della forza di LorentzLa forza di Lorentz è centripetaR=mvqBRaggio di curvatura⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BR⃗F⃗F⃗v⃗v",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#25": "Moto di cariche in campi magnetici\n26Calcoliamo il periodo di rotazione⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ La velocità angolare (o frequenza angolare)ω=vR=vqBmv=qBm(T=2πω)Il periodo e la frequenza non dipendono né dal raggio né dalla velocità T=2πRv=2πvmvqB=2πmqB⃗F⃗F⃗v⃗v⃗BR",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#26": "Circuito in campo magnetico\n27Utilizziamo la seconda legge di Laplace per determinare le azioni meccaniche cui è soggetto un circuito percorso da corrente  immerso in un campo magnetico  d⃗F=id⃗l∧⃗BSupponiamo che il circuito sia: •rigido (non cambia forma) •la corrente i sia mantenuta costante da un generatore di f.e.m. (anche se vedremo che B tende a modificare la corrente nel circuito…)La forza totale sul circuitoIl momento (delle forze) totale sul circuito⃗rDistanza tre dl e il polo⃗F=i∮d⃗l∧⃗B⃗M=∮⃗r∧d⃗F=i∮⃗r∧(d⃗l∧⃗B)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#27": "Spira in un campo magnetico\n28Consideriamo il caso semplice di una spira rettangolare di lati a e b immersa in un campo induzione magnetica uniforme (diretto lungo l’asse z).⃗B̂n1ba234𝜃Calcoliamo la forza agente su ogni lato⃗F1=∫1id⃗l∧⃗B=∫1iBdl̂𝚥=ilB̂𝚥i⃗F1l=axy⃗F2=∫2id⃗l∧⃗B=∫2iBdl(−̂ı)=−ilB̂ıl=b⃗F3=∫3id⃗l∧⃗B=∫3iBdl(−̂𝚥)=−ilB̂𝚥=−⃗F1⃗F4l=al=b⃗Ftot=∑⃗Fi=0La forza totale sulla spira è nulla⃗F2⃗F3⃗F4=∫4id⃗l∧⃗B=∫4iBdl̂ı=ilB̂ı=−⃗F2z",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#28": "Spira in un campo magnetico\n29zSe il sistema è visto dall’alto:⃗B̂n1ba234𝜃ixyzTuttavia il momento delle forze sarà non nulloCalcoliamo il momento rispetto al centro della spira⃗r1⃗M1=⃗r1∧⃗F1=0⃗F1⃗r1//⃗F1⃗F4⃗r2⃗B\n̂n𝜃ixb/2b/2𝜃𝜃⃗M3=⃗r3∧⃗F3=0⃗r3//⃗F3⃗F2⃗M2=⃗r2∧⃗F2=(b2)(iaB)sinθ(̂𝚥)⃗M4=⃗r4∧⃗F4=(b2)(iaB)sinθ(̂𝚥)⃗r4⃗Mtot=⃗M1+⃗M2=i(ab)Bsinθ(̂𝚥)=iŜn∧⃗BIl momento delle forze è diretto verso l’alto (lungo asse di rotazione)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#29": "Momento magnetico di una spira\n30⃗M=i(ab)Bsinθ(̂𝚥)=iŜn∧⃗BIl momento delle forze è proporzionale alla corrente e al prodotto vettoriale tra superficie della spira orientata e campo induzione magneticaDefiniamo il momento magnetico della spira di area S percorsa da corrente i ⃗m=iŜnS=ab superficie della spiraè il versore normale alla spira orientato in verso tale che esso vede circolare la corrente in verso antiorario (regola della mano destra)̂n\n̂n⃗M=⃗m∧⃗BIl momento delle forze è uguale al prodotto vettoriale del momento magnetico della spira per il campo induzione magnetica(si dimostra che la relazione vale per spire di qualsiasi forma                     )d⃗m=îndS",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#3": "Interazioni tra calamite\n4\nPoli opposti (N-S) si attraggonoPoli stesso segno (N-N o S-S) si respingono",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#30": "Teorema di equivalenza di Ampère\n31\nUna spira percorsa da corrente immersa in un campo magnetico si comporta come un dipolo magnetico elementare (ago magnetico) di momento                , perpendicolare al piano della spira e orientato con la regola della mano destra⃗m=iŜnSulla spira agisce un momento di forze solo se il campo magnetico ed il momento della spira formano un angolo 𝜃≠0 La coppia di forze è nulla quando campo magnetico e momento magnetico sono allineati (𝜃=0)La relazione tra momento delle forze su una spira e campo induzione è analoga al dipolo elettrico immerso in un campo elettrico⃗M=⃗p∧⃗E",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#31": "Esempio\n32v\tv\tv\tv\tv\tv\tv\tv\tR1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.\nrεv\tv\tv\tv\tRxy\nFigure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai.",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#32": "Galvanometro\n33Il galvanometro è uno strumento utilizzato per misurare piccole intensità di corrente\nIl momento delle forze magnetiche sulla spira è bilanciato dal momento delle forze elasticheMolla a spiraleMmolla=−kαk costante elastica 𝛼 angolo di aperturaAll’equilibrio⃗Mmolla=⃗MMi=kαSBSistema fatto in modo che 𝜃≈90° 𝜃≈90° MM=−iSBsinθ≃−iSBMisura della corrente",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#33": "Motore elettrico\n34Il motore elettrico trasforma energia elettrica in energia meccanica\nLa spira percorsa da corrente è messa in rotazione dall’interazione con il campo magneticoPer mantenere la rotazione sempre nello stesso senso si usano delle spazzole in contatto sul commutatore per invertire il verso della corrente nella spira",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#34": "Altoparlante\n35\nimpulso elettrico modulato dalla frequenza sonoraIl filo è collegato rigidamente al cono di cartoneQuando nel filo passa corrente (variabile nel tempo, modulata sulla frequenza sonora), esso sente la forza magnetica e mette in vibrazione l’altoparlante La vibrazione del cono produce onde sonore (conversione di energia elettrica in energia meccanica delle onde sonore)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#35": "Prima legge di Laplace\n36\nEvidenze sperimentali mostrano che i fili percorsi da corrente generano campi magneticid⃗B=μ0i4πd⃗l∧̂urr2d⃗B=μ0i4πd⃗l∧⃗rr3Consideriamo un tratto di filo infinitesimo      percorso da corrente i. Sperimentalmente si osserva che il campo magnetico generato a distanza    vale: ⃗rd⃗ld⃗lentrante se     e nel piano del foglio⃗rd⃗lxyz⃗r⃗B⨂iLa costante 𝜇0 è la permeabilità magnetica del vuotoμ0=4π×10−7VsmA=4π×10−7NA2=4π×10−7HmHenry (H)  1H=1𝛺 1s",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#36": "Prima legge di Laplace\n37d⃗lxyz⃗Bi⨂⃗r−⃗r′\u0000⃗r⃗r′\u0000d⃗B=μ0i4πd⃗l∧(⃗r−⃗r′\u0000)(⃗r−⃗r′\u0000)3Notazione in forma più generale⃗B=μ04π∫lid⃗l∧(⃗r−⃗r′\u0000)(⃗r−⃗r′\u0000)3Il campo generato da un intero circuito l si ottiene integrandoVerifichiamo che il campo B è solenoidale⃗∇⋅⃗B=⃗∇⋅(μ0i4πd⃗l∧⃗rr3)=μ0i4π[(⃗∇∧d⃗l)⋅⃗rr3−d⃗l⋅(⃗∇∧⃗rr3)]=0⃗∇⋅(⃗A∧⃗B)=(⃗∇∧⃗A)⋅⃗B−⃗A⋅(⃗∇∧⃗B)=0  un vettore costante è irrotazionale=0  un vettore radiale è irrotazionale",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#37": "Prima legge di Laplace\n38|d⃗B|=μ0i4πdlsinθr2Modulo del campo magnetico:d⃗lxyz⃗r⃗B⨂iθL’angolo 𝜃 è tra la direzione della corrente e la posizione del punto in cui calcoliamo il campo magnetico se sin𝜃=0;180°  ⇒ dB=0: lungo la direzione della corrente non viene generato campo magnetico dB∝1r2come la legge di Coulomb per le cariche puntiformidB∝idipende dall’intensità della corrente, e quindi dal numero di portatori di caricadB⊥d⃗ldB⊥d⃗rperpendicolare al piano definito da corrente e posizione",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#38": "Legge di Biot-Savart\n39Determinare il campo induzione magnetica generato da un filo rettilineo di lunghezza indefinita, percorso da corrente i \n⃗B=μ0i2πr̂utLegge di Biot-Savart• il campo magnetico ha intensità inversamente proporzionale alla distanza dal filo • le linee di campo sono circonferenze nel piano trasverso al filo, centrate sul filo stesso • L’orientazione delle linee di campo segue la regola della mano destra ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#39": "Forza tra due fili percorsi da corrente\n40\nL’esperimento di Ampère evidenzia la forza tra due fili percorsi da correnteConsideriamo due fili rettilinei di lunghezza indefinita, paralleli, posti a distanza d, percorsi da correnti i1 e i2 (iniziamo con il caso di correnti equiverse)di1i2Il filo 1 genera a distanza d un campo magnetico ⃗B1⨂B1=μ0i12πdun tratto di filo dl2 sente una forza magneticad⃗F12=i2d⃗l2∧⃗B1d⃗l2(II Legge Laplace)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#4": "Campo magnetico\n5In analogia con l’elettrostatica, viene naturale introdurre un campo vettoriale      detto  campo magnetico⃗Bconvenzione: le linee di forza del campo magnetico entrano nel polo sud e escono dal polo nord Le linee di campo sono tangenti alla direzione lungo la quale si allineano gli aghi magneticiL’intensità è proporzionale al momento delle forze sull’ago\nS\nN\nS\nN\nS\nN\nS\nN\nS\nN\nS\nNIl campo      può essere anche definito come campo induzione magnetica⃗B",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#40": "41d⨂d⃗F12=i2d⃗l2∧⃗B1Forza tra due fili percorsi da correntedF12=i2dl2B1sinθ=i2dl2μ0i12πd𝜃=90°Forza sul filo 2:Modulo della forzadF12=μ02πi1i2ddl2i1i2Direzione di dF12: perpendicolare ai fili, diretta da 2 verso 1 Analogamente, sul filo 1dF21=μ02πi1i2ddl1d⃗F21=iid⃗l1∧⃗B2=−d⃗F21La forza dF21 esercitata dal filo 2 sul filo 1 è uguale e opposta (attrattiva)d⃗F12d⃗l2⃗B1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#41": "Forza tra due fili percorsi da corrente\n42d𝜃=90°i1i2⨂Se le correnti correnti i1 e i2 sono dirette in verso opposto le forze tra i fili saranno anch’esse opposte e repulsivePer il terzo principio della dinamica, le forze tra i due fili interagenti devono sempre essere uguali e opposteSu un tratto di filo L finito, basta integrare su dl|⃗F|=μ02πi1i2dLForza per unità di lunghezzadFdl=μ02πi1i2dd⃗F12d⃗l2⃗B1",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#42": "Definizione operativa della corrente\n43Un ampere è l'intensità di corrente elettrica che, se mantenuta in due conduttori lineari paralleli, di lunghezza infinita e sezione trasversale trascurabile, posti a un metro di distanza l'uno dall'altro nel vuoto, produce tra questi una forza pari a 2 × 10-7 N per ogni metro di lunghezza.Tale definizione fissa anche il valore di 𝜇0 . La definizione operativa della corrente (e quindi della carica elettrica) sono fatte attraverso la misura di una forza  ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#43": "Campi magnetici da cariche puntiformi in moto\n44d⃗B=μ0i4πd⃗l∧̂urr2Se esprimiamo la corrente in funzione della densità di corrente:id⃗l=idSdSd⃗l=⃗𝚥(dSdl)=⃗𝚥dτ⃗𝚥=nq⃗vdn=Ndτ⃗vdNumero di portatori di carica per unità di volumevelocità di deriva=μ04π⃗𝚥∧⃗rr3dτ=Nμ04πq⃗vd∧⃗rr3La prima legge di Laplace può essere riformulataCampo magnetico generato da N portatori di caricaUna singola carica in movimento genera un campo magnetico che a distanza r dalla carica vale⃗B=μ04πq⃗v∧⃗rr3",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#44": "Campi magnetici da cariche puntiformi in moto\n45⃗B=μ04πq⃗v∧⃗rr3Tale formula vale in un Sistema di Riferimento in cui q si muove con velocità vIn un SdR in cui la carica è ferma si ha che B=0 !!!Ricordiamo che a distanza r, la carica genera un campo elettrico⃗E=q4πε0⃗rr3Ammettendo che questa relazione sia valida anche per cariche in motoq⃗rr3=4πε0⃗E⃗B=μ04π⃗v∧q⃗rr3=⃗B=μ0ε0⃗v∧⃗E=1c2⃗v∧⃗Ec=1μ0ε0Chiara relazione tra campi elettrico e magnetico generati da una carica in motovelocità della luce nel vuoto…=3×108m/sμ04π⃗v∧⃗E4πε0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#45": "Campo da spira circolare\n46Determinare il campo induzione magnetica sull’asse di una spira circolare di raggio R percorsa da corrente i \nBz==μ0i2R2(R2+z2)3/2=μ02πm(R2+z2)3/2⃗m=iŜk=iπR2̂k",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#46": "Esempio\n474.3In uno spettrometro di massa (vedi ﬁgura 12), un fascio di ioni viene prima fatto passare attraverso unselettore di velocit` a, costituito da un condensatore piano che genera un campo elettrico~Euniforme nelladirezione ˆx, immerso in un campo magnetico uniforme~Bortogonale a ˆx.a) Se una caricaqviene lanciata in direzione ˆyin corrispondenza di un foro su una lamina che blocca lecariche, quale deve essere la sua velocit` ava\u0000nch´ e riesca a passare?b) Determinare a quale distanzaldal foro impattano gli ioni che passano attraverso i foro, attraversandola regione in cui ` e presente un campo magnetico~B0ortogonale alla direzione di moto .\nEvi✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ B B’ xyFigure 12:4.4Una striscia conduttrice di rame di sezione rettangolareab, cona= 1mm eb=3mm ` e disposta prependi-colarmente ad un campo di induzione magnetica di moduloB=2T. La striscia` e percorsa da una correntei= 50A. Sapendo che nel rame la densit` a degli elettroni liberi ` en=8.5⇥1023elettroni/m3, si calcoli ladi↵erenza di potenziale sui lati opposti della striscia.5 Magnetostatica nel vuoto5.1Calcolare il campo magnetico al centro di una spira quadrata di latoLpercorsa da una correntei.5.2Due ﬁli rettillinei percorsi entrambi da correnti di stessa intensit` ai1=i2=i, sono disposti paralleli all’asseydi un sistema di riferimento cartesiano e intersecano l’assexa distanze±adall’origine. Studiare il campomagnetico lungo gli assi cartesiani nei due casi in cui le correnti siano concordi e discordi.5.3Un nastro di lunghezza inﬁnita, spessore trascurabile e larghezzaa` e percorso da una corrente superﬁcialeuniformei. Determinare il valore del campo magnetico~Bin un punto a distanzaldal bordo, giacente sullostesso piano del nastro.5.4Calcolare il campo magnetico sull’asse di una spira circolare di raggioRpercorsa da correntei.5.5Si consideri il sistema rappresentato in ﬁgura 13. Determinare il valore del campo magnetico nel centro dellaspira circolare in funzione delle resistenzeR1,R2e della correnteiche circola sui rami esterni.",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#47": "Esempio\n484.3In uno spettrometro di massa (vedi ﬁgura 12), un fascio di ioni viene prima fatto passare attraverso unselettore di velocit` a, costituito da un condensatore piano che genera un campo elettrico~Euniforme nelladirezione ˆx, immerso in un campo magnetico uniforme~Bortogonale a ˆx.a) Se una caricaqviene lanciata in direzione ˆyin corrispondenza di un foro su una lamina che blocca lecariche, quale deve essere la sua velocit` ava\u0000nch´ e riesca a passare?b) Determinare a quale distanzaldal foro impattano gli ioni che passano attraverso i foro, attraversandola regione in cui ` e presente un campo magnetico~B0ortogonale alla direzione di moto .\nEvi✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ ✕ B B’ xyFigure 12:4.4Una striscia conduttrice di rame di sezione rettangolareab, cona= 1mm eb=3mm ` e disposta prependi-colarmente ad un campo di induzione magnetica di moduloB=2T. La striscia` e percorsa da una correntei= 50A. Sapendo che nel rame la densit` a degli elettroni liberi ` en=8.5⇥1023elettroni/m3, si calcoli ladi↵erenza di potenziale sui lati opposti della striscia.5 Magnetostatica nel vuoto5.1Calcolare il campo magnetico al centro di una spira quadrata di latoLpercorsa da una correntei.5.2Due ﬁli rettillinei percorsi entrambi da correnti di stessa intensit` ai1=i2=i, sono disposti paralleli all’asseydi un sistema di riferimento cartesiano e intersecano l’assexa distanze±adall’origine. Studiare il campomagnetico lungo gli assi cartesiani nei due casi in cui le correnti siano concordi e discordi.5.3Un nastro di lunghezza inﬁnita, spessore trascurabile e larghezzaa` e percorso da una corrente superﬁcialeuniformei. Determinare il valore del campo magnetico~Bin un punto a distanzaldal bordo, giacente sullostesso piano del nastro.5.4Calcolare il campo magnetico sull’asse di una spira circolare di raggioRpercorsa da correntei.5.5Si consideri il sistema rappresentato in ﬁgura 13. Determinare il valore del campo magnetico nel centro dellaspira circolare in funzione delle resistenzeR1,R2e della correnteiche circola sui rami esterni.v\tv\tv\tv\tv\tv\tv\tv\tR1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.\nrεv\tv\tv\tv\tRxy\nFigure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai.",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#48": "Esempio\n49v\tv\tv\tv\tv\tv\tv\tv\tR1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.\nrεv\tv\tv\tv\tRxy\nFigure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai.",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#49": "Flusso del campo magnetico\n50Abbiamo già dimostrato che il campo magnetico è solenoidale⃗∇⋅⃗B=0Per il teorema della divergenza, il flusso del campo magnetico attraverso una qualsiasi superficie chiusa sarà nullo: NON esistono cariche magnetiche isolateIl flusso attraverso una superficie aperta avrà un suo valore, non necessariamente nullo, ci torneremo in seguito…∬Saperta⃗B⋅̂ndS∬Schiusa⃗B⋅̂ndS=∭τ(S)⃗∇⋅⃗B=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#5": "6Campo magnetico\nLa limatura di ferro si orienta con il campo magnetico delle calamite\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#50": "Circuitazione del campo magnetico\n51Dal momento che le linee di forza del campo magnetico sono sempre chiuse, ci aspettiamo che la circuitazione può essere non-nullaSemplificando, calcoliamo la circuitazione del campo magnetico generato da un filo rettilineo indefinito percorso da corrente iCalcoliamo la circuitazione lungo una linea chiusa e orientata 𝛤 che concatena il filo. Su un tratto infinitesimo:îtrd𝜙=μ0i2πrrdϕ̂ut⋅d⃗l=rdϕProiezione su circonferenza (arco di circonferenza) ∮Γ⃗B⋅d⃗l=∫2π0μ0i2πdϕ=±μ0iSegno dipende da corrente (regola mano destra)𝛤d⃗l⃗B⋅d⃗l=μ0i2πr̂ut⋅d⃗l⃗B",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#51": "Circuitazione del campo magnetico\n52Se invece la linea chiusa 𝛤  non “concatena” il filo:i𝛤⃗B⋅d⃗l1=μ0i2πr1̂ut⋅d⃗l1=μ0i2πr1r1dϕd⃗l1⃗B⋅d⃗l2=μ0i2πr2̂ut⋅d⃗l2=μ0i2πr2r2(−dϕ)per ogni angolo d𝜙 ci saranno sempre due tratti precorsi in verso oppostole due proiezioni sottendono lo stesso angolo, quindi il contributo alla circuitazione è nullo∮Γ⃗B⋅d⃗l=0d𝜙d⃗l2⃗B⃗B",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#52": "Legge di Ampère\n53Il segno delle correnti si valuta usando la regola della mano destra, rispetto al verso di percorrenza della curva orientata 𝛤\nLa circuitazione del campo magnetico è proporzionale alla somma delle correnti concatenate ∮Γ⃗B⋅d⃗l=μ0conc∑kikLegge di Ampère fornisce un metodo per il calcolo del campo magnetico in particolari condizioni di simmetria",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#53": "54Circuitazione del campo magneticoPossiamo prendere un numero qualsiasi di correnti concatenate, su circuiti di forma arbitraria\n∮Γ1⃗B⋅d⃗l=0∮Γ2⃗B⋅d⃗l=μ0(i1−i2)∮Γ3⃗B⋅d⃗l=μ0(−i1+i2−i3)∮Γ1⃗B⋅d⃗l=μ0i1∮Γ2⃗B⋅d⃗l=μ0(−i2−i3)∮Γ3⃗B⋅d⃗l=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#54": "Densità di corrente concatenata\n55Consideriamo N fili, ciascuno di sezione Sk, percorsi da correnti ikCiascuna corrente può essere scritta in funzione della densità di corrente:ik=∬⃗𝚥k⋅̂nkdSk\ni1-i2i3𝛤SS1S2S3La somma delle correnti concatenate alla curva 𝛤 conc∑kik=conc∑k∬Sk⃗𝚥k⋅̂nkdSk=∬Sconc∑k⃗𝚥k⋅̂nkdSk=∬S⃗𝚥c⋅̂ndSDove S è una generica superficie orientata che ha per bordo 𝛤 e  jc è la densità di corrente concatenata ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#55": "56Il teorema di StokesConsideriamo una superficie S aperta orientata avente come bordo una linea chiusa orientata 𝛤 \n𝛤S(𝛤)̂n̂n\nSuperfici Aperte di R3 •!Nelle superfici aperte non si può distinguere la normale esterna dalla normale interna in un punto della superficie. •!Per convenzione, per calcolare i flussi attraverso una superficie chiusa, si utilizza l’orientamento     indicato dalla regola della mano destra sulla base dell’orientamento della linea di bordo: \n45!Domenico Galli – Fisica Generale B – 1. Elettrostatica!ˆn\nFlusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile •!Consideriamo ora il flusso della velocità di un fluido attraverso una superficie chiusa. •!Per semplicità consideriamo la superficie totale di un cubo. •!Consideriamo positivo il flusso uscente dal cubo e negativo il flusso entrante nel cubo. •!Se il fluido è incompressibile e non si sono al suo interno sorgenti (in cui si produce fluido) o pozzi (scarichi, in cui il fluido scompare), allora tanto fluido entra nel cubo quanto ne esce: –!Il flusso attraverso la superficie totale è nullo. –!Il cerchietto attorno al simbolo di integrale       indica che la superficie di integrazione è chiusa. 46!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot\"\"\"==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()=0532146!!!\nFlusso di un Campo Vettoriale attraverso una Superficie Chiusa e Orientabile (II) •!Se il flusso attraverso la superficie totale è positivo: allora dentro il cubo è presente una sorgente che produce fluido. •!Se il flusso attraverso la superficie totale è negativo: allora dentro il cubo è presente un pozzo (cioè uno scarico) in cui il fluido scompare. 47!Domenico Galli – Fisica Generale B – 1. Elettrostatica!!tot!v()=!viˆndSStot\"\"\"==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()>0532146\n!tot!v()=!viˆndSStot\"\"\"==!1!v()+!2!v()+!3!v()+!4!v()+!5!v()+!6!v()<0532146\nL’Operatore Divergenza \n48!Domenico Galli – Fisica Generale B – 1. Elettrostatica!•!Consideriamo una funzione vettoriale della posizione P: •!Si definisce l’operatore “divergenza” come: •!L’operatore divergenza si applica a una funzione vettoriale; il risultato è uno scalare: !!=ˆı\"\"x+ˆ!\"\"y+ˆk\"\"z!v=!vP()=!vx,y,z()=vxx,y,z()ˆı+vyx,y,z()ˆ!+vzx,y,z()ˆk\nEsempio:\"vx,y,z()=x2+y2()ˆı+x2+z2()ˆ!+zˆk!V\"\"i\"v()x,y,z()=2x+1!!!!i!v=div!v=\"vx\"x+\"vy\"y+\"vz\"z!!i!v=ˆı\"\"x+ˆ!\"\"y+ˆk\"\"z#$%&'(ivxˆı+vyˆ!+vzˆk()P!!3()\"v\"#\"\"vP()!VP!!3()\"$i\"v\"#\"\"\"$i\"v()P()!!%&'('𝛤∮Γ⃗F⋅d⃗lDefiniamo la circuitazione del campo lungo la linea chiusa orientata 𝛤 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#56": "57Il teorema di StokesIl flusso del rotore di un campo vettoriale attraverso una superficie S aperta e orientata è uguale alla circuitazione del campo vettoriale lungo il bordo 𝛤 di tale superficie∬S(Γ)(⃗∇∧⃗F)⋅̂ndS=∮Γ⃗F⋅d⃗lIl teorema di Stokes mette in relazione un integrale di superficie con un integrale di linea ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#57": "Il rotore del campo magnetico\n58Riscriviamo la legge di Ampère in funzione della densità di corrente concatenataconc∑kik=conc∑k∬Sk⃗𝚥k⋅̂nkdSk=∬Sconc∑k⃗𝚥k⋅̂nkdSk=∬S⃗𝚥c⋅̂ndSS è una generica superficie con bordo 𝛤 Applichiamo il teorema di Stokes:∮Γ⃗B⋅d⃗l=μ0conc∑kik=μ0∬S⃗𝚥C⋅̂ndS∮Γ⃗B⋅d⃗l=∬S⃗∇∧⃗B⋅̂ndS=μ0∬S⃗𝚥C⋅̂ndSL’uguaglianza è vera per qualsiasi superficie S con bordo 𝛤 \nLegge di Ampère in forma locale ⃗∇∧⃗B=μ0⃗𝚥In ogni punto dello spazio, il rotore del campo magnetico è proporzionale alla densità di corrente in quel punto",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#58": "Esempio\n59Calcolare il campo di un filo di lunghezza indefinita percorso da corrente i utilizzando la legge di Ampère",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#59": "Esempio\n60Determinare in tutto lo spazio il campo magnetico generato da un cilindro conduttore di raggio R e lunghezza indefinita percorso uniformemente da una corrente di intensità i ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#6": "Campo magnetico terrestre\n7\nUn ago magnetico libero di ruotare si orienta  con la linea di campo che esce dal polo nord (del magnete) e entra dal polo sud (del magnete)Ciò significa che la Terra si comporta come un magnete le cui linee di campo escono dal polo sud geografico ed entrano nel polo nord geografico.Convenzionalmente il polo nord magnetico coincide con il polo sud geografico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#60": "Esempio\n61v\tv\tv\tv\tv\tv\tv\tv\tR1R2iFigure 13:5.6Un disco isolante di raggioRe spessore trascurabile, uniformemente carico con caricaQ, ruota con velocit` aangolare costante!attorno all’asse passante per il centro. Determinare:a) il campo magnetico~Bnel centro del disco;b) il momento magnetico~mdel disco.5.7Una spira quadrata di latoL= 10 cm, percorsa da una correntei=1.3 A in senso antiorario, ` e posta in unaregione di spazio dove ` e presente un campo magnetico uniforme avente intensit` aB=2.1 T. Sapendo che duelati della spira sono paralleli al campo magnetico, calcolare:a) la forza agente sulla spira;b) il momento delle forze~Magente sulla spira.5.8Si consideri il circuito rappresentato in ﬁgura 14. Il tratto semicircolare del circuito ` e immerso in un uncampo magnetico uniforme~B=B0ˆ|. Determinare la forza che agisce sul circuito.\nrεv\tv\tv\tv\tRxy\nFigure 14:6 Legge di Amp` ere6.1Determinare il campo magnetico generato da un solenoide cilindrico di raggioRcomposto danspire perunit` a di lunghezza, percorse da una corrente stazionariai.\n⃗B=μonîk=μ0NLîk̂kCampo interno al solenoide (ideale)Esternamente il campo è nullo",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#61": "Esempio\n626.2Determinare il campo magnetico di un solenoide toroidale di raggio maggioreRe raggio internoa, dotatodiNspire percorse da una correntei.(B=µ0Ni2⇡r)6.3Un cavo coassiale di lunghezza indeﬁnita formato da due conduttori, il primo cilindrico di raggioae il secondocilindrico cavo di raggio internobe raggio esternoc. I due conduttori sono percorsi da correnti uniformi, diugual modulo e verso opposto. Tra i due conduttori vi ` e il vuoto. Determinare il campo induzione magneticain tutto lo spazio. (B(r<a)=µ0i2⇡a2r,B(a<r<b)=µ0i2⇡r,B(b<r<c)=µ0i2⇡r(c2\u0000r2)(c2\u0000b2),B(r>c) = 0)6.4Determinare il campo magnetico in tutto lo spazio generato da un cilindro indeﬁnito di raggioRpercorsoda una densit` a di corrente dipendente dalla distanza radiale dall’asse~|(r)=krˆnconkcostante, direttaparallelamente all’asse del cilindro. (B(r<R)=µ0k3r3,B(r>R)=µ0kR33r)6.5Sia dato un circuito composto da un generatore di f.e.m.Vcollegato in serie ad una resistenzaRed a uncondensatore di capacit` aC. Inizialmente il circuito ` e aperto ed il condensatore e scarico. Alla chiusuradel circuito, determinare la corrente di spostamento all’interno del condensatore, in funzione del tempo.(IS=VRe\u0000tRC)6.6Su un condensatore piano, con armature circolari di raggioR=40cm e distanti tra loroh=1cm, viene applicatauna d.d.p. variabile secondo la leggeV(t)=V0sin(2⇡⌫t), conV0=50v e⌫=6MHz,tespresso in secondi.Trascurando gli e↵etti di bordo, calcolare:a) il valore massimo del campo elettrico nel condensatore; (Emax=V0/h)b) il valore massimo della corrente di spostamento; (Is,max=\"0⇡2R2⌫V0/h)c) il valore massimo del campo magnetico indotto all’interno del condensatore alla distanzar=10 cmdall’asse centrale del condensatore. (Bmax=µ0\"0r⇡⌫V0/h)7 Induzione magnetica e legge di Faraday-Neumann-Lenz7.1Un circuito rigido ` e costituito da un ﬁlo conduttore, di resistenzaR=5⌦, rivestito di materiale isolantepiegato a forma di “8” su un piano (vedi ﬁg. 15). L’areaSdella superﬁcie piana delimitata dal ﬁlo ` e ugualealla somma dell’area della prima ansaS1=20cm2e di quella della secondaS2=12 cm2.I lc i r c u i t o ` ei m m e r s oin un campo magnetico uniforme, diretto perpendicolarmente al piano della spira, con verso entrante nelpiano e variabile nel tempo secondo la leggeB=kt, conk=0.04 T/s. Calcolare la corrente indotta nelcircuito, indicando il verso di percorrenza. (i=kR(S2\u0000S1), verso orario inS1)7.2Un solenoide cilindrico di raggior0= 3cm e lunghezzad=100cm ` e costituito daN= 50000 spire percorseda una corrente variabile nel tempo secondo la leggei(t)=i0e\u0000t/⌧, coni0= 50A e⌧= 5s. Si consideri unaspira circolare di raggiorer e s i s t e n z aR=0.5⌦, con piano perpendicolare all’asse del solenoide e centro sutale asse. Nell’approssimazione di solenoide indeﬁnito e trascurando gli e↵eti di autoinduzione della spira,determinare la correntei0indotta nella spira al tempot= 1s per due valori del raggio della spirar=1cm er=5cm. (i0(r<r0)=µ0N⇡ri0e\u0000t/⌧dR⌧),i0(r>r0)=µ0N⇡r0i0e\u0000t/⌧dR⌧))\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#62": "Magnetismo nella materia\n63Cosa succede se riempiamo la parte interna di un solenoide rettilineo ideale?Si osserverà una variazione del campo magnetico: alluminio, platino, sodio: leggero aumento   → materiali PARAMAGNETICIferro, nichel, cobalto: considerevole aumento → materiali FERROMAGNETICI\nmateriali organici, rame, argento: leggera diminuzione  → materiali DIAMAGNETICII materiali ferromagnetici restano magnetizzati ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#63": "64Momento magnetico orbitalePer spiegare il magnetismo nella materia occorre partire dalla struttura microscopicaIn un modello molto semplificato possiamo pensare gli elettroni più esterni in rotazione intorno al nucleoPartiamo dal caso più semplice: l’atomo di idrogenoEssendo la forza coulombiana centripetaricaviamo la velocità di rotazione:14πε0qeqpr2H=mev2rHRH=5.3×10−11m\nRH=5.3×10−11mme=9.1×10−31kg|qe|=|qp|=1.6×10−19Cv=14πε0qeqpmerH=2.2×106m/s",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#64": "65Momento magnetico orbitalepossiamo pensare che un elettrone che ruota intorno al nucleo genera una correnteil momento magnetico dell’elettronei=−qeTdove il periodoT=2πRHvdefinendo il momento angolare orbitale:⃗po=⃗RH∧me⃗vmo=iS=iπR2H=−qev2πRHπR2H=−qev2RHmememo=iS=iπR2H=−qev2πRHπR2H==−qev2RHmeme⃗mo=−qe2me⃗po",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#65": "Momento magnetico di spin\n66Oltre al momento magnetico orbitale, si può osservare che gli elettroni hanno un ulteriore momento magnetico di spin (come se gli elettroni ruotassero intorno al proprio asse)⃗ms=−qeme⃗psIl momento magnetico totale (o intrinseco) è dato da una combinazione di momento orbitale e momento di spin. L’accoppiamento è descritto dalle leggi della meccanica quantisticaIn un generico atomo, il momento magnetico dipende dagli elettroni più esterniIn assenza di campi magnetici esterni, il momento magnetico totale macroscopico è nullo, perché i momenti magnetici degli atomi sono orientati casualmente e la loro somma vettoriale è nulla\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#66": "Materiali diamagnetici\n67In presenza di campo magnetico esterno occorre fare delle distinzioniLa maggior parte dei materiali ha atomi con momento magnetico nullo. In questi materiali, l’effetto di un campo esterno è quello di deviare la traiettoria degli elettroni in moto (forza di Lorenz), inducendo una variazione di velocità (l’elettrone si allontana dal nucleo) e quindi una diminuzione della frequenza di rotazione (precessione di Larmor)L’effetto complessivo è una diminuzione del momento magnetico, che va ad opporsi leggermente al campo magnetico esternoTali materiali sono chiamati diamagnetici (in genere hanno un numero pari di elettroni e struttura simmetrica)\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#67": "Materiali paramagnetici\n68I materiali paramagnetici hanno atomi con momento angolare intrinseco diverso da zero\nI materiali paramagnetici sono caratterizzati da un numero dispari di elettroni  o da strutture atomiche asimmetricheGli atomi si comportano come dipoli magnetici che per effetto di un campo magnetico esterno tendono ad allinearsi  con il campo magnetico esterno, contribuendo ad aumentarne leggermente il valore\nB",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#68": "Vettore magnetizzazione\n69Definiamo il vettore magnetizzazione come il prodotto del momento angolare intrinseco medio del materiale per il numero di atomi per unità di volume⟨⃗m⟩⃗M=n⟨⃗m⟩=Ndτ⟨⃗m⟩dipende dai momenti magnetici orbitali e di spinIl campo magnetico totale nella materia dipenderà dal vettore magnetizzazione:⃗B=⃗B0+μ0⃗MPossiamo definire la densità di corrente di magnetizzazione⃗jM=⃗∇∧⃗MDa cui ricaviamo le relazione⃗∇∧⃗B=⃗∇∧(⃗B0+μ0⃗M)==⃗∇∧⃗B0+μ0⃗∇∧⃗M=Legge di Ampère in forma locale=μ0⃗J+μ0⃗JM",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#69": "Il vettore H\n70⃗∇∧⃗B=μ0(⃗J+⃗JM)Il campo magnetico totale B è generato dalle correnti di conduzione e dalle correnti di magnetizzazione\nPartendo dalla relazione⃗∇∧⃗B=μ0⃗J+μ0⃗∇∧⃗M⃗∇∧(⃗B−μ0⃗Mμ0)=⃗JDefiniamo il vettore H che descrive il campo magnetico nella materia,  in funzione solo delle correnti di conduzione lungo i fili⃗H=⃗B−μ0⃗Mμ0=⃗Bμ0−⃗M⃗∇∧⃗H=⃗J⃗B=μ0⃗H+μ0⃗M",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#7": "Poprietà del campo magnetico\n8La forza magnetica tra due calamite potrebbe essere descritta con una formula simile alla legge di Coulomb (fine 1700)⃗FM=kMm1m2r2̂urm1 e m2 sono le “cariche magnetiche” kM è una costante magneticaLa forza magnetica è proporzionale al prodotto delle cariche magnetiche ed inversamente proporzionale al quadrato della distanza Attrattiva per cariche magnetiche opposte, repulsiva per cariche magnetiche ugualiUnica analogia con forza elettrostatica di Coulomb!!",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#70": "Magnetismo nella materia\n71Nei materiali diamagnetici e paramagnetici, omogenei e isotropi i campi B H e M sono paralleli, e vengono espressi dalle relazioni⃗B=μrμ0⃗HDove:μrPermeabilità magnetica relativa⃗M=(μr−1)⃗H=χm⃗Hχm=(μr−1)Suscettività magnetica   {negativa per diamagneticipositiva per paramagnetici(molto piccola 10-4 —10-6)⃗M=(1μ0−1μ0μr)⃗B",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#71": "Materiali ferromagnetici\n72I materiali ferromagnetici microscopicamente hanno una configurazione elettronica per cui si creano forti interazioni tra momenti orbitali e momenti di spinTali interazioni comportano che momenti magnetici di atomi adiacenti si “accoppiano”, aumentando considerevolmente il loro effetto magnetico rispetto al singolo atomoAll’interno del materiale si creano regioni formate da numerosi dipoli allineati (domini di Weiss) I domini di Weiss hanno tipicamente volumi di 10-12 —10-12 m3 e contengono 1017 —1011 atomi \nSe il materiale non ha subito magnetizzazione, le direzioni dei momenti sono casuali",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#72": "73Materiali ferromagneticiQuando un materiale ferromagnetico viene posto in un campo magnetico esterno i momenti si allineano con il campo magnetico, generando un allargamento (una fusione) dei domini di Weiss\nPonendo campi magnetici sempre più intensi, si arriva ad una condizione di saturazioneIl materiale mantiene una magnetizzazione residua anche fuori dal campo magneticoI domini di Weiss vengono distrutti se il materiale viene riscaldato fino ad una temperatura critica (di Curie),che per il Fe vale ~1000°K",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#73": "Ciclo di isteresi\n74Per i materiali ferromagnetici la permeabilità magnetica non è costante, può essere molto elevata e dipende dalle correnti che generano il campo esterno e dalla storia di magnetizzazione. Inseriamo un cilindro di materiale ferromagnetico in un solenoide:\nLa curva a è detta di prima magnetizzazionediminuendo il campo H fino ad azzerarlo (curva b) nel materiale si ha una magnetizzazione residuaInvertendo il campo H, si raggiunge un valore critico HC per cui la magnetizzazione è nulla H generato da corrente nel solenoideCampo B del ferromagneteCampo M del ferromagnete",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#74": "Memorie di massa magnetiche\n75I supporti magnetici sono largamente utilizzati per l’archiviazione dei datiPer esempio gli hard disk sono formati da dischi di alluminio o vetro rivestiti da una pellicola di materiale ferromagneticoLa memorizzazione dell’informazione avviene associando un bit di magnetizzazione (verso di magnetizzazione) su un certo numero di domini di WeissLa densità di informazione è data dal numero di domini di Weiss che costituiscono un singolo bit, moltiplicato per la loro estensione superficiale media, rapportato alla superficie di archiviazione disponibileL’accesso ai dati avviene utilizzando testine magnetoresistive che variano la resistenza al variare del campo magnetico (in lettura) e viceversa (in scrittura)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#75": "Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/\n76",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#8": "Poli magnetici\n9\nSperimentalmente, se si spezza una calamita si otterranno due nuove calamiteI poli magnetici esistono sempre a coppie di eguale valore e segno opposto: dipoli magneticiFino ad ora non è stato mai osservato un polo magnetico isolato (monopolo magnetico)Conseguenza: il campo magnetico ha proprietà molto diverse dal campo elettrostatico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\12-magnetostatica.pdf#9": "Legge di Gauss per il campo magnetico\n10\nLe linee del campo magnetico sono sempre chiuse  (non possiamo isolare singoli poli magnetici)Il campo magnetico è solenoidale⃗∇⋅⃗B=0Di conseguenza (thm divergenza) scegliendo una qualunque superficie chiusa∬S⃗B⋅̂ndS=0La densità volumetrica di cariche magnetiche è sempre nulla (solo dipoli)S",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#0": "1 Campi elettrici e magnetici variabili nel tempo CdS Ingegneria Informatica A.A. 2019/20 ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#1": "Campi elettrici in condizioni stazionarie\n2⃗∇⋅⃗E=ρε0Legge di Gauss per il campo elettrico Forma integrale: il flusso del campo elettrico attraverso una superficie chiusa è proporzionale alla carica elettrica contenuta nella superficie Forma differenziale: Le cariche elettriche generano il campo elettricoΦS(⃗E)=∬S⃗E⋅̂ndS=QSε0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#10": "Legge di Ampère e equazione di continuità\n11⃗∇⋅⃗𝚥+∂ρ∂t=0La divergenza della densità di corrente compare nell’equazione di continuità (si veda cap. su correnti)In condizioni stazionarie (indipendenti dal tempo), la densità di carica è costante e la sua derivata è nulla.  In tale situazione , quindi ritroviamo che la legge di Ampère continua ad essere valida in condizioni stazionarie. Cosa succede nel caso più generale, in condizioni non necessariamente stazionarie?⃗∇⋅⃗𝚥=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#11": "Legge di Ampère in condizioni non stazionarie\n12⃗∇⋅⃗𝚥+∂ρ∂t=0Sostituiamo nell’equazione di continuità e invertiamo gli ordini di derivazioneDalla legge di Gauss in forma locale                             ricaviamo  ⃗∇⋅⃗E=ρε0ρ=ε0⃗∇⋅⃗E⃗∇⋅⃗𝚥+∂∂t(ε0⃗∇⋅⃗E)=0⃗∇⋅⃗𝚥+ε0⃗∇⋅∂⃗E∂t=0⃗∇⋅(⃗𝚥+ε0∂⃗E∂t)=0il vettore  ha sempre divergenza nulla!(⃗𝚥+ε0∂⃗E∂t)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#12": "tale vettore è la somma di due termini: • densità di corrente di conduzione    (dovuta a cariche in moto) • densità di corrente di spostamento              (dovuta a variazione di campo elettrico)Legge di Ampère-Maxwell\n13(⃗𝚥+ε0∂⃗E∂t)⃗𝚥ε0∂⃗E∂t⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tAggiungendo il termine di densità di corrente di spostamento nell’equazione di Ampere, otteniamo la legge di Ampère-Maxwell",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#13": "Legge di Ampère-Maxwell\n14⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tIl rotore del campo magnetico è proporzionale alla somma della densità di corrente di conduzione  e alla variazione del campo elettrico⃗∇⋅(μ0⃗𝚥+μ0ε0∂⃗E∂t)=0In altre parole, il campo magnetico può essere generato da cariche in moto e da campi elettrici variabili nel tempoLa legge di Ampère-Maxwell è valida sempre, sia in regime stazionario che non stazionario. Infatti la divergenza della somma dei termini di densità di corrente di spostamento e conduzione è sempre nulla",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#14": "Corrente di spostamento\n15A partire dalla densità di corrente di spostamento ⃗𝚥S=ε0∂⃗E∂tDefiniamo la corrente di spostamento come il flusso della densità di corrente attraverso una superficie aperta S: La corrente di spostamento è proporzionale alla variazione del flusso del campo elettrico e non dipende da cariche in movimento.Si osserva una corrente di spostamento nelle regioni di spazio in cui c’è un campo elettrico variabile. Esempio: all’interno di un condensatore in regime transotorio (carica/scarica)is=∬S⃗𝚥s⋅̂ndS=∬Sε0∂⃗E∂t⋅̂ndS=ε0ddt∬S⃗E⋅̂ndS=ε0dΦS(⃗E)dt",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#15": "Legge di Ampère-Maxwell in forma integrale\n16In forma integrale, la circuitazione del campo magnetico lungo una linea chiusa rimane proporzionale alla somma delle correnti concatenate, considerando sia le correnti di conduzione che le correnti di spostamento∮Γ⃗B⋅d⃗l=μ0conc∑k(ic+is)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#16": "Corrente di spostamento in condensatore\n17Consideriamo un circuito RC in fase di scarica. Inizialmente sul condensatore si ha una carica Q0.  Alla chiusura dell’interruttore la carica sul condensatore varia con la legge:TCRQ(0)=Q0Q(t)=Q0e−tRCNel circuito si avrà una corrente di conduzione (dovuta alle cariche che fuoriescono dal condensatore):ic(t)=dQ(t)dt=−Q0RCe−tRC",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#17": "Corrente di spostamento in condensatore\n18Q(t)Supponiamo che il condensatore sia a facce piane e parallele. Nel condensatore carico con carica Q(t) c’è un campo elettrico (normale alla superficie S delle armature):Il campo elettrico dipende dal tempo, quindi nel condensatore si ha una densità di corrente di spostamento:  ⃗E=σε0̂n=Q(t)ε0Ŝn=Q0e−tRCε0Ŝn⃗𝚥s=ε0∂⃗E∂t=ε0∂∂t(Q0e−tRCε0S)̂n=−Q0SRCe−tRĈned una corrente di spostamento:is(t)=∬S⃗𝚥s⋅̂ndS=∬S−Q0SRCe−tRĈn⋅̂ndS=−Q0SRCe−tRC∬SdS=−Q0RCe−tRC⃗E",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#18": "Corrente di spostamento in condensatore\n19ic(t)=is(t)=−Q0RCe−tRCNell’esempio del condensatore si trova che la corrente di conduzione e la corrente di spostamento hanno lo stesso valoreTale risultato è conseguenza dell’equazione di continuità, che lega le correnti alle variazioni di carica.𝛴⃗Eic(t)is(t)\nS1S2𝛤Se infine poniamo 𝛴=S1+S2, ritroviamo la validità generale della legge di Ampère (Maxwell) Considerando una qualsiasi superficie chiusa 𝛴 che “avvolge” metà condensatore∮Γ⃗B⋅d⃗l=μ0∬S1⃗𝚥c⋅̂ndS=μ0∬S2⃗𝚥s⋅̂ndS∬Σ(⃗𝚥c+⃗𝚥s)⋅̂ndS=∬Σ(⃗𝚥c⋅̂n+⃗𝚥s⋅̂n)dS=∬Σ(jc−js)dS=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#19": "Esempio\n206.2Determinare il campo magnetico di un solenoide toroidale di raggio maggioreRe raggio internoa, dotatodiNspire percorse da una correntei.(B=µ0Ni2⇡r)6.3Un cavo coassiale di lunghezza indeﬁnita formato da due conduttori, il primo cilindrico di raggioae il secondocilindrico cavo di raggio internobe raggio esternoc. I due conduttori sono percorsi da correnti uniformi, diugual modulo e verso opposto. Tra i due conduttori vi ` e il vuoto. Determinare il campo induzione magneticain tutto lo spazio. (B(r<a)=µ0i2⇡a2r,B(a<r<b)=µ0i2⇡r,B(b<r<c)=µ0i2⇡r(c2\u0000r2)(c2\u0000b2),B(r>c) = 0)6.4Determinare il campo magnetico in tutto lo spazio generato da un cilindro indeﬁnito di raggioRpercorsoda una densit` a di corrente dipendente dalla distanza radiale dall’asse~|(r)=krˆnconkcostante, direttaparallelamente all’asse del cilindro. (B(r<R)=µ0k3r3,B(r>R)=µ0kR33r)6.5Sia dato un circuito composto da un generatore di f.e.m.Vcollegato in serie ad una resistenzaRed a uncondensatore di capacit` aC. Inizialmente il circuito ` e aperto ed il condensatore e scarico. Alla chiusuradel circuito, determinare la corrente di spostamento all’interno del condensatore, in funzione del tempo.(IS=VRe\u0000tRC)6.6Su un condensatore piano, con armature circolari di raggioR=40cm e distanti tra loroh=1cm, viene applicatauna d.d.p. variabile secondo la leggeV(t)=V0sin(2⇡⌫t), conV0=50v e⌫=6MHz,tespresso in secondi.Trascurando gli e↵etti di bordo, calcolare:a) il valore massimo del campo elettrico nel condensatore; (Emax=V0/h)b) il valore massimo della corrente di spostamento; (Is,max=\"0⇡2R2⌫V0/h)c) il valore massimo del campo magnetico indotto all’interno del condensatore alla distanzar=10 cmdall’asse centrale del condensatore. (Bmax=µ0\"0r⇡⌫V0/h)7 Induzione magnetica e legge di Faraday-Neumann-Lenz7.1Un circuito rigido ` e costituito da un ﬁlo conduttore, di resistenzaR=5⌦, rivestito di materiale isolantepiegato a forma di “8” su un piano (vedi ﬁg. 15). L’areaSdella superﬁcie piana delimitata dal ﬁlo ` e ugualealla somma dell’area della prima ansaS1=20cm2e di quella della secondaS2=12 cm2.I lc i r c u i t o ` ei m m e r s oin un campo magnetico uniforme, diretto perpendicolarmente al piano della spira, con verso entrante nelpiano e variabile nel tempo secondo la leggeB=kt, conk=0.04 T/s. Calcolare la corrente indotta nelcircuito, indicando il verso di percorrenza. (i=kR(S2\u0000S1), verso orario inS1)7.2Un solenoide cilindrico di raggior0= 3cm e lunghezzad=100cm ` e costituito daN= 50000 spire percorseda una corrente variabile nel tempo secondo la leggei(t)=i0e\u0000t/⌧, coni0= 50A e⌧= 5s. Si consideri unaspira circolare di raggiorer e s i s t e n z aR=0.5⌦, con piano perpendicolare all’asse del solenoide e centro sutale asse. Nell’approssimazione di solenoide indeﬁnito e trascurando gli e↵eti di autoinduzione della spira,determinare la correntei0indotta nella spira al tempot= 1s per due valori del raggio della spirar=1cm er=5cm. (i0(r<r0)=µ0N⇡ri0e\u0000t/⌧dR⌧),i0(r>r0)=µ0N⇡r0i0e\u0000t/⌧dR⌧))",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#2": "Campi elettrici in condizioni stazionarie\n3Conservatività del campo elettrostatico⃗∇∧⃗E=0La circuitazione del campo elettrostatico lungo qualsiasi linea chiusa è nullaIrrotazionalità del campo elettrostatico: implica che il campo è conservativo e che possiamo definire il potenziale elettrostatico V tale che ⃗E=−⃗∇V∮Γ⃗E⋅d⃗l=0Il campo elettromotore in una pila non è conservativo. Tale relazione è verificata solamente nel caso stazionario. ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#20": "Interazioni tra magneti e circuiti\n21Abbiamo visto che le correnti generano campi magnetici (prima legge di Laplace, Biot-Savart) E’ vero anche il contrario?Se teniamo un magnete fermo vicino ad un circuito, in esso non si osserva corrente\nSe muoviamo il magnete verso il circuito, allora si osserva una corrente (nell’intervallo in cui il magnete è in movimento)\nIl movimento in verso opposto, “induce” nel circuito una corrente di segno opposto",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#21": "Interazioni tra circuiti percorsi da corrente\n22\nUn effetto analogo si osserva tra due circuiti posti in vicinanzaNel circuito di sinistra si osserva una corrente per un breve intervallo di tempo dopo la chiusura/apertura dell’interruttore (effetto transitorio con corrente variabile nel tempo)\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#22": "Correnti indotte\n23\nEstraendo una spira fatta di materiale conduttore da una regione in cui è presente un campo magnetico, si misura una corrente sulla spira  • si ha corrente anche se il campo magnetico è uniforme• la corrente è massima se il piano della spira è ortogonale al campo magnetico• la corrente è nulla se il piano della spira è parallelo al campo magneticoDal momento che sul conduttore ci sono cariche libere, proviamo a spiegare il fenomeno in termini di forza di Lorentz",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#23": "Correnti indotte\n24⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BConsideriamo un sistema formato da due binari conduttori, paralleli e connessi elettricamente⃗vPoniamo una barretta conduttrice ortogonale ai binari e mettiamola in movimento con velocità costanteSe il sistema è posto in un campo magnetico (costante, uniforme, ortogonale al piano del circuito) nel circuito circola corrente, come se ci fosse un generatore di forza elettromotrice",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#24": "Correnti indotte\n25⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗B⃗FLe cariche libere sulla barretta sentono una forza di Lorentz:⃗v⃗F=qe⃗v∧⃗BLe cariche in un tratto dl è come se fossero sottoposte agli effetti di un campo elettromotoreN.B. gli elettroni si muovono verso l’alto, quindi la corrente convenzionalmente circola in verso orariod⃗ldℰ=⃗E⋅d⃗l=⃗Fqe⋅d⃗l=⃗v∧⃗B⋅d⃗l",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#25": "Correnti indotte\n26⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗BLa velocità può essere scritta come d⃗ld⃗x⃗v=d⃗xdtIn un intervallo dt, la barretta si sarà spostata di un tratto dxdℰ=(⃗v∧⃗B)⋅d⃗l=(d⃗xdt∧⃗B)⋅d⃗lUtilizzando le proprietà del prodotto misto:dℰ=(d⃗xdt∧⃗B)⋅d⃗l=(d⃗l∧d⃗xdt)⋅⃗B=solo dx dipende dal tempo, B e  dl sono costanti=ddt[(d⃗l∧d⃗x)⋅⃗B]⃗v",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#26": "Induzione elettromagnetica\n27⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⃗Bd⃗ld⃗x\nd⃗l∧d⃗x=−̂n(dldx)=−̂ndSNegativo, perché “entrante” (verso opposto a B)dℰ=ddt[⃗B⋅(d⃗l∧d⃗x)]dℰ=−ddt[⃗B⋅̂ndS]⃗B⋅̂ndS=dΦS(⃗B)⃗vdSFlusso infinitesimo del campo magnetico attraverso dS",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#27": "Induzione elettromagnetica\n28⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ \nℰ=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dtNel circuito si genera una forza elettromotrice indotta opposta (segno meno) alla variazione del flusso del campo magnetico concatenato con la spiraIntegrando su tutta l’area S spazzata dalla barretta \nSi può dimostrare che tale relazione è valida ogni volta in cui si verifica una variazione temporale del flusso concatenato del campo magnetico⃗Bd⃗ld⃗x⃗vS",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#28": "Legge di Faraday-Neumann-Lenz\n29La variazione temporale del flusso di un campo magnetico “induce” una forza elettromotriceℰind=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dtLa forza elettromotrice indotta si oppone alla variazione del flusso che l’ha generata Tale legge rappresenta un ulteriore metodo per generare una corrente in un conduttore  (in aggiunta a forze elettrochimiche di pile e batterie)Il segno meno nell’equazione (storicamente attribuito di Lenz) è conseguenza del 3° principio della dinamica (azione-reazione) e quindi della conservazione dell’energia",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#29": "Induzione elettromagnetica\n30ℰind=−ddt∬S⃗B⋅̂ndS=−dΦS(⃗B)dt1)area della spira variabile nel tempo 2)campo magnetico variabile nel tempo 3)moto relativo di una spira rispetto ad  campo magnetico  Con aggiunta di tutte le possibili combinazioni delle situazioni elencateConsiderando un generico circuito chiuso (una spira), il flusso del campo magnetico concatenato con la spira può variare al verificarsi di tre tre principali situazioni:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#3": "Campi magnetici in condizioni stazionarie\n4⃗∇⋅⃗B=0Legge di Gauss per il campo magnetico Il flusso del campo magnetico attraverso una superficie chiusa è sempre nullo non possiamo isolare cariche magnetiche (monopoli)Il campo magnetico ha sempre divergenza nulla (è solenoidale). Le linee di campo sono sempre chiuse su loro stesse∬⃗B⋅̂ndS=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#30": "Esempio\n31Si consideri un circuito rettangolare con un lato di lunghezza L in movimento con velocità v0 costante. La resistenza totale del circuito vale R. Il circuito è completamente immerso in un campo magnetico costante ed uniforme, ortogonale al piano del circuito. Calcolare: a)l’espressione della corrente indotta nel circuito b)la forza necessaria per mantenere la velocità costanteCampo magnetico costante (e uniforme) e area della spira variabile⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ ⊙      ⊙      ⊙      ⊙       ⊙      ⊙ V0 L L6. Un circuito (vedi figura) è costituito di due binari conduttori paralleli di resistività trascurabile, posti ad una distanza L l’uno dall’altro, collegati da un conduttore fisso di resistenza 2R, e da un’asta metallica, anch’essa di resistività trascurabile, che può scorrere senza attrito sui due binari. Il circuito è immerso in un campo di induzione magnetica variabile 0||BKt=G diretto perpendicolarmente al piano in figura in verso uscente (K0 è una costante positiva nota). Inizialmente l’asta si trova ad una distanza L dal conduttore fisso e si muove con velocità V0 costante verso destra. Determinare: a. il verso di rotazione della corrente nel circuito; b. l’espressione dell’intensità della corrente che circola nel circuito; c. l’espressione del modulo F della forza che viene applicata all’asta per mantenerne costante la velocità.   7. Un circuito (vedi figura) è costituito di due binari conduttori paralleli di resistività trascurabile, posti ad una distanza L l’uno dall’altro, collegati da un conduttore fisso di resistenza R, e da un’asta metallica, anch’essa di resistività trascurabile, che può scorrere senza attrito sui due binari. Il circuito è immerso in un campo di induzione magnetica variabile 0||BKt=G diretto perpendicolarmente al piano in figura in verso uscente (K0 è una costante positiva nota). Inizialmente l’asta si trova ad una distanza 2L dal conduttore fisso e  s i  m u o v e  c o n  v e l o c i t à  2 V0 c o s t a n t e  v e r s o  d e s t r a .  Determinare: a. il verso di rotazione della corrente nel circuito; b. l’espressione dell’intensità della corrente che circola nel circuito; c. l’espressione del modulo F della forza che viene applicata all’asta per mantenerne costante la velocità.   8. Un circuito elettrico è costituito da due binari conduttori paralleli di resistenza trascurabile posti ad una distanza 2D, da una conduttore fisso di resistenza 2R e da un’asta metallica AB di resistenza trascurabile che può scorrere senza attrito sui due binari (vedi figura). La posizione dell’asta AB varia nel tempo secondo la r e l a z i o n e  x ( t )  =  2 x0(1 - cosωt), con x0 ed ω costanti positive note. Il circuito è immerso in un campo induzione magnetica B, diretto perpendicolarmente al piano del circuito, la cui intensità varia nel tempo secondo la relazione B(t)=2B0(1 + cosωt), con B0 costante positiva nota. Determinare: a. la forza elettromotrice indotta nel circuito; b. il valore massimo iM dell’intensità di corrente che circola nel circuito; c. la forza che agisce sull’asta AB.       2V0 2L L\nV(t) 2R xB2D A⃗B",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#31": "Campo magnetico variabile nel tempo e spira ferma\n32S2S1Figure 15:7.3Una spira quadrata conduttrice di latol=20 cm e resistenzaR=0.1⌦si trova ad una distanza ﬁssaa=80cm da un ﬁlo rettilineo indeﬁnito percorso da una correntei. Due dei lati della spira sono paralleli al ﬁlo.Calcolare:a) il ﬂusso del campo magnetico generato dal ﬁlo , supponendo che la corrente sia costantei0=3A (\u0000=µ0li02⇡lna+la=2.68·10\u00008Wb);b) la f.e.m. massima indotta sulla spira supponendo che la corrente sul ﬁlo vari con secondo la leggei(t)=i0cos(!t), con!= 2 rad/s; (Emax=µ0li0!2⇡lna+la=5.36·10\u00008V)c) la massima potenza dissipata dalla spira, nel caso di corrente variabile nel tempo. (Pmax=E2maxR=2.9·10\u000014W)7.4Una bacchetta conduttrice di lunghezzaL=9.83cmer e s i s t e n z aR= 415 m⌦viene fatta muovere con velocit` acostantev=4.86 m/s su dei binari conduttori (di resistenza trascurabile) paralleli. La bacchetta si muovein un campo magnetico generato da una correntei= 110Ache scorre in un ﬁlo parallelo ai binari, a distanzaa= 10.2mm. Calcolare:a) la corrente indotta che scorre nella spira; (iind=\u0000µ0iv2⇡Rln\u0000a+La\u0000)b) la forza che bisogna applicare esternamente alla bacchetta per tenerla in moto uniforme; (Fest=µ0iiind2⇡ln\u0000a+La\u0000)c) confrontare la potenza dissipata sulla bacchetta con la potenza fornita dalla forza esterna. (P=Ri2ind=Fv)7.5Una spira quadrata di latoL=30 cm, resistenzaR=2⌦e massam= 10g, si muove senza attrito suun piano orizzontale con velocit` av0=1 m/s, perpendicolare ad un lato. Ad un certo istantet0la spiraentra in una regione in cui presente un campo magnetico uniforme e costante di moduloB=0.5 T, direttoperpendicolaremente al piano della spira (il bordo della regione con il campo magnetico ` e parallelo al latodella spira che sta entrando, come mostrato in ﬁgura 16). Calcolare:a) la velocit` a della spira nell’istantet0in cui essa ` e entrata completamente nella regione con campomagnetico; (v(t0)=v0\u0000B2L3mR)b) la corrente che percorre la spira nell’istantet0;(i(t0)=\u0000BLv(t0)R)c) la potenza dissipata all’istantet0.(P=B2L2v(t0)2R)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#32": "33Campo magnetico costante (non uniforme) e spira in movimento F1) Un circuito rigido quadrato, di lato L=100cm, è costituito di un filo di alluminio (resistività ρ=2.56 10-8 Ωm) di sezione S=10 mm2. Esso si trova nel piano xy con i lati paralleli ai due assi, ed è immerso (nel vuoto) in un campo di induzione magnetica uniforme di modulo Bz= 0,5T diretto lungo l’asse z nel verso positivo, limitato all’area grigia di figura. Il circuito, inizialmente tutto immerso nel campo magnetico, trasla con parallelamente all’asse x con velocità che viene mantenuta costante di modulo V0= 20 cm/s. Calcolare, giustificando:  1) il verso della corrente indotta (orario o antiorario), con riferimento alla figura; 2) l’intensità  di tale corrente nel circuito durante il moto; 3) l’energia totale dissipata nel circuito per effetto Joule; 4) il lavoro effettuato per portare il circuito completamente fuori del campo.              F2) Una spira rigida a forma di triangolo equilatero di lato L=2m, massa M=100g, e resistenza R=10 Ω ,  s i  m u o v e  c o n  v e l o c i t à  c o s t a n t e  V0 =  1 0  m / s  l u n g o  l ’ a s s e  x .  N e l semipiano delle x positive è presente un campo induzione magnetica uniforme di modulo B=0.5 T diretto lungo z nel verso positivo, mentre nel semipiano delle x negative B è identicamente nullo. Calcolare: 1)  il verso della corrente indotta (orario o antiorario), con riferimento alla figura; 2) il flusso di B c o n c a t e n a t o  c o n  i l  c i r c u i t o ,  n e l l ’ i s t a n t e  i n  c u i  m e t à  d e l l ’ a r e a  d e l  3) la corrente massima che circola nel circuito durante il moto; 4) l’espressione vettoriale della forza che agisce sul lato BC del circuito, all’istante       ijBv0L\nijBLABCUna spira quadrata conduttrice di lato L e resistenza R si muove con velocità costante v0 in una regione dove è presente un campo magnetico uniforme, limitato ad una regione rettangolare. a)determinare la corrente indotta sulla spira  b)il lavoro per estrarre la spira fuori dalla regione in cui è presente il campo magnetico c)l’energia dissipata per effetto Joule",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#33": "Generatore elettrico\n34\nConsideriamo un sistema di N spire rotanti con velocità angolare costante in un campo magnetico uniformesia S=area delle spire, 𝜑=𝜔t angolo tra vettore normale al piano della spira e campo magneticoin ogni istante il flusso valeΦ(⃗B)=N⃗B⋅̂nS=NBScosφ=NBScosωtnelle spire ci sarà una fem indotta:ℰ=−dΦ(⃗B)dt=−NBS(−ωsinωt)=NBSωsinωt\nfem alternata\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#34": "Correnti di Foucault\n35Le correnti di Foucault (o correnti parassite) si osservano nei conduttori in presenza di campi magnetici il cui flusso varia nel tempo. Esse sono una conseguenza del fenomeno dell’induzione magnetica. Tali correnti sono dovute al moto degli elettroni causato dalle fem indotte nel conduttore\nL’effetto di tali correnti è quello di creare campi magnetici che si oppongono alla variazione che le hanno generate: effetto “frenante”Per minimizzare gli effetti delle correnti parassite, occorre “tagliare” il conduttore\n",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#35": "Correnti di Foucault\n36Le correnti di Foucault possono anche generare calore per effetto JouleTale meccanismo è alla base dei fornelli ad induzione\nPerché non tutte le pentole funzionano sulle cucine ad induzione?",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#36": "Forma locale della legge di FNL\n37ℰ=∮Γ⃗E⋅d⃗l=∬SΓ⃗∇∧⃗E⋅̂ndSℰ=∮Γ⃗E⋅d⃗l=−ddt∬SΓ⃗B⋅̂ndS=∬SΓ−∂⃗B∂t⋅̂ndS⃗∇∧⃗E=−∂⃗B∂tApplichiamo il teorema di StokesCombinando con la legge di Faraday-Neumann-LenzIl campo E è detto campo elettrico indotto  Un campo magnetico variabile nel tempo è una sorgente di campo elettrico ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#37": "Forma locale della legge di FNL\n38⃗∇∧⃗E=−∂⃗B∂t• Il campo elettrico indotto dalla variazione di un campo magnetico ha rotore non-nullo: non è conservativoIn ogni punto dello spazio in cui è presente un campo magnetico variabile nel tempo, in quel punto si genera un campo elettrico• Il campo elettrico generato da cariche elettriche ha sempre rotore nullo ed è conservativo (campo elettrostatico)Il campo elettrico può essere generato da campi magnetici variabili nel tempo oppure da cariche elettriche",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#38": "Induzione mutua\n39Per la prima legge di Laplace, il campo magnetico dipende linearmente dalla corrente che l’ha generato:d⃗B=μ0i4πd⃗l∧̂rr2Il flusso del campo magnetico sarà dunque proporzionale alla corrente:Φ(⃗B)=MiDove M è un coefficiente che dipende solamente dalla geometria (forma) del circuito percorso da correntei⃗B\nSe le correnti sono variabili nel tempo:ℰind=−dΦ(⃗B)dt=−Mdidt",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#39": "Induzione mutua\n40Consideriamo due circuiti percorsi da correnti i1 e i2, che generano rispettivamente i campi magnetici B1 e B2 Il flusso di B1 attraverso il circuito 2 èΦ1(⃗B2)=M21i2Φ2(⃗B1)=M12i1Il flusso di B2 attraverso il circuito 1 èi1i2Si può dimostrare che M12=M21=MM è detto coefficiente di mutua induzioneNel sistema internazionale si misura in Henry (H)  1H=Tm2/A",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#4": "Campi magnetici in condizioni stazionarie\n5∮Γ⃗B⋅d⃗l=μ0conc∑kik⃗∇∧⃗B=μ0⃗𝚥Legge di Ampère la circuitazione del campo magnetico è proporzionale alla somma delle correnti concatenate con la linea di circuitazioneIn forma locale, il rotore del campo magnetico è proporzionale alla densità di corrente. Il campo magnetico NON è conservativo Il campo magnetico è generato da correnti (cariche in movimento)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#40": "Esempio\n41habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF=\u0000tcon\u0000= 100A/s. Calcolare:a) il ﬂusso\u0000T(BF) del campo magnetico generato dal ﬁlo attraverso le spire del toroide; (\u0000T(BF)=µ0N\u0000tr2R)b) la f.e.m indotta nel toroide; (E=\u0000µ0N\u0000r2R)c) l’induttanzaLTdel toroide. (LT=µ0Nr22R)7.10Siano dati due solenoidi cilindrici aventi gli assi coincidenti. Il primo solenoide di lunghezzal` e formato daNspire di areaA. Esso ` e posto all’interno del secondo solenoide pi` u grande, di lunghezzalS>> lea v e n t eNSspire di areaS> >A. Calcolare il coe\u0000ciente di mutua induzione. (M=µ0ANNslS)7.11Si considerino due spire circolari concentriche sullo stesso piano di raggireR> >r. La spira piccola ` epercorsa da una correnteir(t)=i0sin(!t). Determinare la f.e.m. indotta sulla spira grande. (f.e.m.=\u0000µ0⇡r22Ri0!cos!t)7.12Una spira rettangolare di latiaebpercorsa da correnteis=i0sin(!t) ` e posta con il latoaa distanzabda un ﬁlo rettilineo di lunghezzaL> >a. Determinare la di↵erenza di potenzialeEindai capi del ﬁlo.(Eind=\u0000µ0a!i02⇡ln 2 cos!t)7.13Si consideri il circuito mostrato in ﬁgura 19 composto da due induttanzeL1=L2=L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza internar=R/2 che fornisce una forza elettromotriceEe da un interruttoreTinizialmente aperto. Determinare:a) la corrente elettrica che circola nelle tre resistenze in funzione del tempo; (i(t)=ER(1\u0000e\u0000RLt))Determinare inoltre in regime stazionario:b) il valore del potenziale nel puntoA;(VA= 0)c) l’energia totale immagazzinata nel sistema; (U=12LE2R2)d) la potenza dissipata nel sistema. (P=E2R)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#41": "Autoinduzione\n42i⃗BUn circuito percorso da corrente genera un campo magnetico Tale campo avrà un flusso concatenato con il circuito stessoSe la corrente varia nel temp, nel circuito si genererà una fem autoindottaΦ(⃗B)=LiL è detto coefficiente di autoinduzione (o induttanza) e si misura in Henryℰind=−dΦ(⃗B)dt=−LdidtLa fem autoindotta si oppone alla variazione di corrente che l’ha generata ",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#42": "Esempio\n43Calcolare l’induttanza di un solenoide cilindrico ideale di lunghezza l formato da N spire circolari di raggio r \n9. Circuiti in Corrente Alternata Fisica Generale B \nhttp://campus.cib.unibo.it/2482/ March 29, 2011 \nAutoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d\"solenoide!Bt()()dt=!µ0N2Sldidt\n4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2SlSupponiamo che il solenoide sia percorso da una corrente i(t) variabile nel tempo. Internamente al solenoide vi è un campo magnetico (dipendente dal tempo): Il flusso del campo attraverso una singola spira vale ⃗BS=πr2area di una spiraB(t)=μ0Nli(t)Φspira(⃗B(t))=B(t)S=μ0Nli(t)πr2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#43": "Esempio\n44Il flusso attraverso l’intero solenoide sarà pari ad N volte il flusso attraverso una singola spira  \n9. Circuiti in Corrente Alternata Fisica Generale B \nhttp://campus.cib.unibo.it/2482/ March 29, 2011 \nAutoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d\"solenoide!Bt()()dt=!µ0N2Sldidt\n4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BΦsolenoide(⃗B(t))=NΦspira(⃗B(t))=Nμ0Nli(t)πr2=μ0N2li(t)πr2L’induttanza L si calcola come il rapporto tra il flusso “autoindotto”  (autoflusso) e la corrente:L=Φsolenoide(⃗B)i(t)=μ0N2lπr2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#44": "Esempio\n45habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF=\u0000tcon\u0000= 100A/s. Calcolare:a) il ﬂusso\u0000T(BF) del campo magnetico generato dal ﬁlo attraverso le spire del toroide; (\u0000T(BF)=µ0N\u0000tr2R)b) la f.e.m indotta nel toroide; (E=\u0000µ0N\u0000r2R)c) l’induttanzaLTdel toroide. (LT=µ0Nr22R)7.10Siano dati due solenoidi cilindrici aventi gli assi coincidenti. Il primo solenoide di lunghezzal` e formato daNspire di areaA. Esso ` e posto all’interno del secondo solenoide pi` u grande, di lunghezzalS>> lea v e n t eNSspire di areaS> >A. Calcolare il coe\u0000ciente di mutua induzione. (M=µ0ANNslS)7.11Si considerino due spire circolari concentriche sullo stesso piano di raggireR> >r. La spira piccola ` epercorsa da una correnteir(t)=i0sin(!t). Determinare la f.e.m. indotta sulla spira grande. (f.e.m.=\u0000µ0⇡r22Ri0!cos!t)7.12Una spira rettangolare di latiaebpercorsa da correnteis=i0sin(!t) ` e posta con il latoaa distanzabda un ﬁlo rettilineo di lunghezzaL> >a. Determinare la di↵erenza di potenzialeEindai capi del ﬁlo.(Eind=\u0000µ0a!i02⇡ln 2 cos!t)7.13Si consideri il circuito mostrato in ﬁgura 19 composto da due induttanzeL1=L2=L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza internar=R/2 che fornisce una forza elettromotriceEe da un interruttoreTinizialmente aperto. Determinare:a) la corrente elettrica che circola nelle tre resistenze in funzione del tempo; (i(t)=ER(1\u0000e\u0000RLt))Determinare inoltre in regime stazionario:b) il valore del potenziale nel puntoA;(VA= 0)c) l’energia totale immagazzinata nel sistema; (U=12LE2R2)d) la potenza dissipata nel sistema. (P=E2R)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#45": "Circuiti con induttanze\n46\nUn solenoide inserito all’interno di un circuito percorso da corrente variabile nel tempo si comporta come un generatore di forza elettromotrice (fem autoindotta) con polarità opposta alla variazione di corrente\n9. Circuiti in Corrente Alternata Fisica Generale B \nhttp://campus.cib.unibo.it/2482/ March 29, 2011 \nAutoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d\"solenoide!Bt()()dt=!µ0N2Sldidt\n4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BSimbolo circuitale dell’induttanza +_𝓔(t)ℰautoindotta=−dΦsolenoide(⃗B(t))dt=−Ldi(t)dtREquazione del circuitoℰ(t)−Ldi(t)dt=Ri(t)ℰ(t)+ℰautoindotta=Ri(t)La fem autoindotta si “oppone” alla variazione di corrente che l’ha generata",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#46": "Induttanze in serie\n47+_𝓔(t)RL1L2In serie, le due induttanze sono percorse dalla stessa correnteΔV=ΔV1+ΔV2=−L1di(t)dt−L2di(t)dt=−(L1+L2)di(t)dt=−Ltotdi(t)dtDifferenza di potenziale ai capi delle due induttanze\nL’induttanza del sistema formato da due (o più) induttanze collegate in serie è uguale alla somma delle singole induttanzeLtot=∑iLitrascuriamo gli effetti di mutua induzione",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#47": "Induttanze in parallelo\n48\n+_𝓔(t)RL1L2In parallelo, le due induttanze sono alla stessa differenza di potenzialetrascuriamo gli effetti di mutua induzionedi1dt=−ΔVL1di2dt=−ΔVL2=−ΔVL1−ΔVL2=i=i1+i2Per la legge dei nodididt=di1dt+di2dt\nL’inverso dell’induttanza del sistema formato da due o più induttanze collegate in parallelo è uguale alla somma degli inversi delle singole induttanza 1Ltot=1L1+1L2=−ΔV(1L1+1L2)=−ΔVLtot1Ltot=∑i1Li",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#48": "Energia magnetica\n49\n9. Circuiti in Corrente Alternata Fisica Generale B \nhttp://campus.cib.unibo.it/2482/ March 29, 2011 \nAutoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d\"solenoide!Bt()()dt=!µ0N2Sldidt\n4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗B+_𝓔(t)RL’induttanza percorsa da corrente variabile nel tempo si comporta come un generatore con polarità opposta alla variazione correnteInnalzare la corrente di un valore di equivale a far passare nell’induttanza una carica q in un tempo dt (dq=idt)Per spostare la carica occorre contrastare la fem autoindottaℰautoindotta=−Ldidtδℒ=−ℰautoindottadq=−(−Ldidt)(idt)Occorre fare un lavoro “contro” la forza elettromotrice autoindotta",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#49": "Energia magnetica\n50Se inizialmente nell’induttanza non circola corrente i(0)=0, per portare il circuito a corrente i occorre compiere un lavoroℒ=∫i0Lidi=12Li2δℒ=−ℰautoindottadq=−(−Ldidt)(idt)Lavoro per aumentare la corrente di un valore di\nIl lavoro accumula energia nell’induttanza.Energia magnetica accumulata in un’induttanzaUB=12Li2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#5": "Equazioni di Maxwell (caso stazionario)\n6⃗∇⋅⃗E=ρε0⃗∇∧⃗E=0⃗∇⋅⃗B=0⃗∇∧⃗B=μ0⃗𝚥Forma locale(differenziale)",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#50": "Densità di energia magnetica\n51\n9. Circuiti in Corrente Alternata Fisica Generale B \nhttp://campus.cib.unibo.it/2482/ March 29, 2011 \nAutoinduzione •!Consideriamo un solenoide percorso da una corrente variabile nel tempo.  •!Esso genera un campo magnetico, entro il volume cilindrico delimitato dal solenoide, anch’esso variabile nel tempo. •!Tale campo magnetico, a sua volta, essendo variabile nel tempo, genera una forza elettromotrice indotta nel solenoide che si sovrappone alla forza elettromotrice esterna. •!Questo fenomeno prende il nome di autoinduzione. i2!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (II) •!Se nel solenoide scorre una corrente di intensità i(t) e n è il numero di spire per unità di lunghezza, il campo magnetico all’interno del solenoide, come abbiamo visto, è diretto lungo l’asse del solenoide e ha intensità: •!Se S è l’area della sezione del solenoide, il flusso di tale campo magnetico concatenato con una spira vale: ovvero, se N è il numero totale di spire e l è la lunghezza del solenoide: Bt()=µ0it()n!spira!Bt()()=Bt()S=µ0it()nS!spira!Bt()()=µ0it()nS=µ0it()NSli!B!B3!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!\nAutoinduzione (III) •!Il flusso del campo magnetico concatenato con le N spire del solenoide vale: •!La forza elettromotrice autoindotta vale perciò: •!La costante di proporzionalità: è chiamata coefficiente di autoinduzione o induttanza. !solenoide!Bt()()=N!spira!Bt()()=µ0it()N2Slft()=!d\"solenoide!Bt()()dt=!µ0N2Sldidt\n4!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!if!B!B  L=µ0N2Sl⃗BS=πr2Ricordando l’espressione dell’induttanza di un solenoideL=μ0N2lSIl campo magnetico vale:B=μ0Nlii=Blμ0NL’energia magnetica sarà pari aUB=12Li2=12(μ0N2lS)(Blμ0N)2=12(μ0N2lS)(B2l2μ20N2)=B22μ0(lS)volume del solenoideL’energia magnetica è il prodotto di una densità di energia per il volume del solenoide",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#51": "Densità di energia magnetica\n52uB=B22μ0Definiamo la densità di energia del campo magnetico:L’energia magnetica è localizzata in ogni punto dello spazio in cui è presente il campo magneticoUB=∭spaziouBdτL’energia del campo magnetico si calcola come l’integrale sul volume in tutto lo spazio in cui è presente il campo magnetico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#52": "Circuiti RL in regime transitorio\n53Come abbiamo fatto per i condensatori, analizziamo un circuito composto da un generatore di forze elettromotrice costante, una resistenza e un’induttanza \n+_T𝓔LR\nInizialmente l’interruttore è aperto (non circola corrente i(0)=0, l’induttanza è scarica)Ad un dato istante iniziale t=0 l’interruttore viene chiuso. Scriviamo l’equazione della maglia:ℰ+ℰind=Riℰ−Ldidt=Ri",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#53": "Circuiti RL in regime transitorio\n54ℰ−Ldidt=Rididt=−RL(i−ℰR)Separiamo le variabilidi(i−ℰR)=−RLdtIntegriamo tra i(0) e i(t) e tra t=0 e t∫i(t)i(0)di(i−ℰR)=∫t0−RLdtln(i−ℰR)i(t)i(0)=−RLtlni(t)−ℰRi(0)−ℰR=−RLti(t)−ℰRi(0)−ℰR=e−RLtImponendo la condizione iniziale i(0)=0i(t)−ℰR=−ℰRe−RLt",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#54": "Circuiti RL in regime transitorio\n55i(t)=ℰR(1−e−RLt)\nTransitori in un Circuito RL. Chiusura del Circuito (IV) •!Per trovare la costante i0, imponiamo la condizione iniziale: \n•!La quantità # = L/R, che ha le dimensioni di un tempo, viene detta costante di tempo del circuito. i0()=0\"fR+i0e!RL0=fR+i0=0\"i0=!fRit()=fR!fRe!RLt  it()=fR1!e!RLt\"#$%&'\n45!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0\n Transitori in un Circuito RL. Chiusura del Circuito (V) •!Si ottiene inoltre: VR=Rit()=f1!e!RLt\"#$%&'VL=Ldidtt()=LfR!e!RLt\"#$%&'!RL\"#$%&'=fe!RLtit()=fR1!e!RLt\"#$%&'VRt()=f1!e!RLt\"#$%&'VLt()=fe!RLt()****+****it()t!\"#!##fRVRt()t!\"#!##fVLt()t!\"#!##046!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0\nTransitori in un Circuito RL. Chiusura del Circuito (VI) tfRi\ntfRVfLVt47!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0\nTransitori in un Circuito RL. Apertura del Circuito •!Consideriamo il circuito in figura e supponiamo ora che, inizialmente, il deviatore si trovi nella posizione 1, con l’induttanza L percorsa da una corrente di intensità costante (i = f /R). •!Supponiamo poi che a un certo istante, t = 0, il deviatore venga commutato nella posizione 0. •!Avremo l’equazione differenziale: •!L’integrale generale è: Ldidtt()+Rit()=0i0()=fR!\"##$##  it()=i0e!RLt48!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0ℰRAndamento nella corrente in un circuito RL alla chiusura dell’interruttore L/R ha le dimensioni du un tempo (costante di tempo)inizialmente la corrente è nulla e si porta ad un valore asintoticoℰind=−Ldidt=−LℰRRLe−RLt⟶t→∞0in regime stazionario (t→∞ ) la fem autoindotta si annullal’induttanza si comporta come un filo a resistenza nullanell’induttanza vi è immagazzinata un’energia magneticaUB=12Li2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#55": "56Circuiti RL in regime transitorioSia dato un circuito formato da un condensatore e un’induttanza Inizialmente l’interruttore T è aperto, l’induttanza è carica con UB=UoCalcoliamo quanto vale l’energia dissipata sulla resistenza L’equazione della maglia alla chiusura dell’interruttore èTLR\nℰind=Ri−Ldidt=Rididt=−RLiRisolvendo l’eq. differenziale per separazione delle variabili:dii=−RLdti(t)=i(0)e−RLtlni(t)i(0)=−RLt",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#56": "57Circuiti RL in regime transitorioi(t)=i(0)e−RLtUB=12Li(0)2La corrente iniziale si ricava dalla condizione iniziale di energia immagazzinata nell’induttanza\nTransitori in un Circuito RL. Apertura del Circuito (II) •!Per trovare la costante i0, imponiamo la condizione iniziale: \n•!Si ottiene inoltre: i0()=fR\"i0e!RL0=i0=fR\"i0=fR it()=fRe!RLtVR=Rit()=fe!RLtVL=Ldidtt()=LfRe!RLt!RL\"#$%&'=!fe!RLt\n49!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0\nTransitori in un Circuito RL. Apertura del Circuito (III) •!Riassumendo: \n•!La corrente che scorre nel circuito dopo che è stato escluso il generatore di tensione prende il nome di extracorrente di apertura. it()=fRe!RLtVRt()=fe!RLtVLt()=!fe!RLt\"#$$$%$$$it()t!\"#!##0VRt()t!\"#!##0VLt()t!\"#!##0\n50!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0\nTransitori in un Circuito RL. Apertura del Circuito (IV) fRti\ntfRVf!LVt51!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0\nTransitori in un Circuito RL. Apertura del Circuito (V) •!Se dopo avere escluso il generatore il circuito rimane aperto, si osserva una scarica elettrica tra i contatti dell’interruttore. •!Il motivo è nel fatto che il flusso del campo magnetico nell’induttanza passa in un tempo estremamente breve dal valore iniziale f/R al valore finale 0. •!Segue che la derivata          è estremamente elevata, e con essa è estremamente elevata la f.e.m. autoindotta: ft()=!L\"i\"t=!L0!fR\"t\"t#0$#$$%  didt\n52!Domenico Galli – Fisica Generale B – 9. Circuiti in Corrente Alternata!RLf!+01VRVLiAMBt=0i(0)=2UBLi(0)L’energia dissipata sulla resistenza per effetto Joule durante l’intero processo di scarica:UR=∫∞0Ri2dt=R∫∞0(i(0)e−RLt)2dt=R∫∞0i2(0)e−2RLtdt=R2UBL∫∞0e−2RLtdt=R2UBL[−L2Re−2RLt]∞0=UBTutta l’energia accumulata nell’induttanza viene dissipata per effetto Joule sulla resistenza",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#57": "Esempio\n58habFigure 18:7.9Un solenoide torioidale costituito daN= 1000 spire ciascuna di raggior=1cm. Il raggio maggiore delsolenoide ` eR=10cm. Un ﬁlo di lunghezza indeﬁnita ` e posto lungo l’asse del toroide ed ` e percorso verso l’altoda una corrrente variabile nel tempoiF=\u0000tcon\u0000= 100A/s. Calcolare:a) il ﬂusso\u0000T(BF) del campo magnetico generato dal ﬁlo attraverso le spire del toroide; (\u0000T(BF)=µ0N\u0000tr2R)b) la f.e.m indotta nel toroide; (E=\u0000µ0N\u0000r2R)c) l’induttanzaLTdel toroide. (LT=µ0Nr22R)7.10Siano dati due solenoidi cilindrici aventi gli assi coincidenti. Il primo solenoide di lunghezzal` e formato daNspire di areaA. Esso ` e posto all’interno del secondo solenoide pi` u grande, di lunghezzalS>> lea v e n t eNSspire di areaS> >A. Calcolare il coe\u0000ciente di mutua induzione. (M=µ0ANNslS)7.11Si considerino due spire circolari concentriche sullo stesso piano di raggireR> >r. La spira piccola ` epercorsa da una correnteir(t)=i0sin(!t). Determinare la f.e.m. indotta sulla spira grande. (f.e.m.=\u0000µ0⇡r22Ri0!cos!t)7.12Una spira rettangolare di latiaebpercorsa da correnteis=i0sin(!t) ` e posta con il latoaa distanzabda un ﬁlo rettilineo di lunghezzaL> >a. Determinare la di↵erenza di potenzialeEindai capi del ﬁlo.(Eind=\u0000µ0a!i02⇡ln 2 cos!t)7.13Si consideri il circuito mostrato in ﬁgura 19 composto da due induttanzeL1=L2=L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza internar=R/2 che fornisce una forza elettromotriceEe da un interruttoreTinizialmente aperto. Determinare:a) la corrente elettrica che circola nelle tre resistenze in funzione del tempo; (i(t)=ER(1\u0000e\u0000RLt))Determinare inoltre in regime stazionario:b) il valore del potenziale nel puntoA;(VA= 0)c) l’energia totale immagazzinata nel sistema; (U=12LE2R2)d) la potenza dissipata nel sistema. (P=E2R)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B \nR3 L2 T \nA L1 ε R2 R1R3L2 L3 C1 C2 \nA L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B \nR1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B \nR3 L2 T \nA L1 ε R2 R1R3L2 L3 C1 C2 \nA L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B \nR1R3L2T \nFigure 20:",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#58": "Esempio\n59  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B \nR3 L2 T \nA L1 ε R2 R1R3L2 L3 C1 C2 \nA L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B \nR1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B \nR3 L2 T \nA L1 ε R2 R1R3L2 L3 C1 C2 \nA L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B \nR1R3L2T \nFigure 20:  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B \nR3 L2 T \nA L1 ε R2 R1R3L2 L3 C1 C2 \nA L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B \nR1R3L2T Figure 19:7.14Si consideri il circuito mostrato in ﬁgura 20 composto da tre induttanzeL1=L2=L3=2L,d at r er e s i s t e n z eR1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotriceEe da due condensatori di capacita` aC1=C2=C. Determinare in regime stazionario:a) la corrente elettrica che circola nelle tre resistenze; (i=ER1+R3)b) lenergia totale immagazzinata nel sistema; (U=12LE2R2+12CE2)c) la potenza dissipata nel sistema. (P=E2R1+R3)  37. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=2L, da tre resistenze R1= R2= R3= 2R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e  d a  u n  i n t e r r u t t o r e  T  i n i z i a l m e n t e  aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;       Determinare inoltre in regime stazionario (t Æ ∞): b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   38. Si consideri il circuito mostrato in figura composto da due induttanze L1= L2=L, da tre resistenze R1= R2= R3= R, da un generatore di resistenza interna r=R/2 che fornisce una forza elettromotrice ε e da un interruttore T inizialmente aperto. Determinare:  a. la corrente elettrica che circola nelle tre resistenze in funzione del tempo;            Determinare inoltre in regime stazionario (t Æ ∞):  b. il valore del potenziale nel punto B; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.   39. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=2L, da tre resistenze R1=R2=R3=R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e da due condensatori di capacità C1= C2=C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  40. Si consideri il circuito mostrato in figura composto da tre induttanze L1=L2=L3=L, da tre resistenze R1=R2=R3=2R, da un generatore di resistenza interna trascurabile che fornisce una forza elettromotrice ε e  da due condensatori di capacità C1= C2=2C. Determinare in regime stazionario: a. la corrente elettrica che circola nelle tre resistenze; b. il valore del potenziale nel punto A; c. l’energia totale immagazzinata nel sistema. d. la potenza dissipata nel sistema.  L1 r ε R2 R1A B \nR3 L2 T \nA L1 ε R2 R1R3L2 L3 C1 C2 \nA L1 εR2 R1 R3L2 L3 C1 C2 L1 r ε R2 A B \nR1R3L2T \nFigure 20:4",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#59": "Le equazioni di Maxwell\n60⃗∇⋅⃗E=ρε0∬S⃗E⋅̂ndS=QSε0⃗∇⋅⃗B=0⃗∇∧⃗E=−∂⃗B∂t∮Γ⃗E⋅d⃗l=−ddt∬S⃗B⋅̂ndS∮Γ⃗B⋅d⃗l=μ0conc∑k(ic+is)⃗∇∧⃗B=μ0⃗𝚥+μ0ε0∂⃗E∂tForma differenzialeForma integrale∬S⃗B⋅̂ndS=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#6": "Equazioni di Maxwell (caso stazionario)\n7∮Γ⃗E⋅d⃗l=0∮Γ⃗B⋅d⃗l=μ0conc∑kikForma integrale∬S⃗E⋅̂ndS=QSε0∬S⃗B⋅̂ndS=0",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#60": "Le equazioni di Maxwell\n61Le quattro equazioni di Maxwell descrivono completamente l’elettromagnetismo A partire da esse è possibile ricavare tutte le leggi dell’elettromagnetismo, dall’elettrostatica, alle correnti, alle forze elettriche e magnetiche Dalle equazioni di Maxwell si evince che i campi elettrico e magnetico sono strettamente legati tra di loro e che essi sono due modi di manifestarsi della stessa entità chiamata campo elettromagnetico Partendo dalle equazioni di Maxwell, si dimostra che il campo elettromagnetico si propaga attraverso onde elettromagnetiche, le quali hanno sempre una componente di campo elettrico e una di campo magnetico",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#61": "Argomenti Facoltativi\n62• Equazione delle onde elettromagnetiche • Onde elettromagnetiche piane • Teorema di Poynting ed energia trasportata dalle onde elettromagnetiche",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#62": "Onde elettromagnetiche\n63Prendiamo in considerazione le quattro equazioni di Maxwell in  assenza di cariche e di correnti di conduzione⃗∇⋅⃗E=0⃗∇⋅⃗B=0⃗∇∧⃗E=−∂⃗B∂t⃗∇∧⃗B=μ0ε0∂⃗E∂t∇2⃗E=ε0μ0∂2⃗E∂t2Combinando le quattro relazioni e utilizzando le proprietà delle operazioni tra operatori si ricavano le due equazioni di D’Alambert per campo elettrico e magnetico∇2⃗B=ε0μ0∂2⃗B∂t2ε0μ0=1c2c=3×108 m/s velocità della luce nel vuoto",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#63": "Lorenzo Rinaldi Dipartimento di Fisica e Astronomia lorenzo.rinaldi@unibo.it https://www.unibo.it/sitoweb/lorenzo.rinaldi/\n64",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#7": "Legge di Ampère su condensatore\n8Scriviamo la legge di Ampère in funzione della densità di corrente ∮Γ⃗B⋅d⃗l=μ0∬S⃗𝚥C⋅̂ndSTale legge deve essere vera per qualsiasi superficie aperta S avente per bordo la linea chiusa 𝛤Applichiamo tale legge in un circuito con condensatore:\nS1S2𝛤S1 interseca il filo  S2 passa nell’intercapedine del condensatore (senza intersecare il filo) Entrambe hanno come bordo la linea chiusa 𝛤",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#8": "Legge di Ampère su condensatore\n9\nS1S2𝛤In condizioni stazionarie, nei rami di circuiti con condensatori non circola corrente quindi la circuitazione è nulla: legge di Ampère è soddisfatta per entrambe le superfici Cosa succede in regime transitorio, quando si ha una corrente:                   \nLa legge di Ampère                                         è valida solo in condizioni stazionarie ∮Γ⃗B⋅d⃗l=μ0∬S⃗𝚥C⋅̂ndSi(t)=ℰRe−tRCIn tal caso il flusso attraverso S1 è diverso da zero, mentre risulta nullo attraverso S2",
    "data_test\\rootfolder\\università\\FisicaGenerale\\13-elettromagnetismo.pdf#9": "Legge di Ampère\n10Oltre al caso del condensatore, la legge di Ampère presenta un altro problema formale⃗∇∧⃗B=μ0⃗𝚥⃗∇⋅(⃗∇∧⃗B)=μ0⃗∇⋅⃗𝚥⃗∇⋅(⃗∇∧⃗B)=0Si dimostra facilmente che la divergenza del rotore di un campo vettoriale è sempre nulla (qualunque sia il campo)⃗∇⋅⃗𝚥=?Non è vero invece che la divergenza della densità di corrente sia sempre nulla In quali condizioni è nulla? (il vettore densità di corrente è solenoidale?) Applicando l’operatore divergenza ad entrambi i membri dell’equazione di Ampère in forma differenziale:",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nIntroduzione al Machine Learning  \n\u0000\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#1": "Introduzione al  \nmachine Learning\nIntuitivamente, un sistema è in grado di apprendere se, \nattraverso la sua attività, è in grado di migliorare le \nproprie prestazioni.\nNell’IA, il miglioramento delle prestazioni coincide in \ngenerale con l’acquisizione di nuove conoscenze.\n\u00002",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#10": "\u000011\nApplicazioni Finanziarie  \nApplicazioni in Medicina (e.g., rilevamento di tumori nelle \nscansioni cerebrali)\nRecommender Systems (e.g., raccomandare un prodotto a cui \nun cliente potrebbe essere interessato, sulla base di acquisti \npassati)\nRilevamento di frodi con carte di credito  \nRilevamento di pattern di accesso anomali a un sito Web\nSegnalazione automatica di commenti offensivi nei forum  \nIdentiﬁcazione di fake news\nEsempi di applicazione",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#11": "\u000012\nApplicazioni in vari campi dell’ingegneria (Civile, \nAeronautica, Telecomunicazioni, ecc. ecc.)\nMarketing (e.g., segmentazione dei clienti in base ai loro \nacquisti in modo da poter progettare una strategia di \nmarketing diversa per ogni segmento)  \nPrevisione dei ricavi della tua azienda per il prossimo anno, \nsulla base di varie metriche di performance\nCostruire un bot intelligente per un gioco  \nFar reagire la tua app ai comandi vocali  \nCreare un chatbot o un assistente personale\nEsempi di applicazione",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#12": "metodi di apprendimento\nApprendimento supervisionato\nRichiede che si apprenda una funzione partendo da esempi di input \ne output\nApprendimento non supervisionato\nRichiede di imparare a riconoscere pattern o schemi nell’input \nsenza alcuna indicazione speciﬁca dei valori di uscita.\nApprendimento per rinforzo\nL’agente apprende in base al rinforzo (ricompensa) ottenuto.\n\u000013",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#13": "Tipici problemi di  \nMachine Learning\nRegression \nClassiﬁcation  \nClusteringUna tipica classiﬁcazione dei problemi affrontati in ML  \nè la seguente:\n\u000014",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#14": "Applicazioni di  \nMachine Learning\nDEMO\n\u000015",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#2": "Introduzione al  \nmachine Learning\nQualsiasi cambiamento in un sistema che gli permetta di \navere prestazioni migliori la seconda volta, nella \nripetizione dello stesso compito o di un altro compito \ntratto dalla stessa popolazione.\n(Simon, 1984)\n\u00003",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#3": "Introduzione al  \nmachine Learning\nA computer program is said to learn from experience E \nwith respect to some class of tasks T and performance \nmeasure P, if its performance at tasks in T, as measured \nby P, improves with experience E .\n(Mitchell, 1997)\n\u00004",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#4": "Definizioni\nTask T : obiettivo del sistema\nGiocare a dama\nGuidare un autoveicolo\nRiconoscere parole pronunciate\nExperience E : Insieme di addestramento dal quale apprendere\nPartite giocate\nPercorsi\n.........\nPerformance measure P : misura della capacità di eseguire il \ntask\nNumero di partite vinte\nNumero di parole classiﬁcate correttamente\n\u00005",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#5": "Introduzione al  \nmachine Learning\nUn elemento fondamentale dell’apprendimento è la \ncapacità di valutare le proprie prestazioni, o almeno di \naccettare una valutazione dall’esterno.\nSenza una valutazione, infatti, non sarebbe possibile \nparlare di miglioramento.\nA sua volta, la valutazione delle prestazioni richiede la \ncapacità di accettare un certo tipo di informazioni \ndall’ambiente esterno.\n\u00006",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#6": "Progetti Rilevanti nello \nSviluppo del Machine Learning\n1989 : Guida autoveicolo - ALVINN system (Pomerlau, 1989)\n1995 : Classiﬁcazione nuove strutture astronomiche - NASA: classiﬁcazione \noggetti celesti (Fayyad et al., 1995)\n1992-95 : Backgammon - TD-Gammon (Tesauro, 1992, 1995): \napprendimento su 1 milione di partite giocate contro se stesso.\n2004 : DARPA introduce la “DARPA Grand Challenge”, una sﬁda per la \nguida autonoma di veicoli.\n2006 : Geoffrey Hinton dell’Università di Toronto introduce un algoritmo di \napprendimento veloce  per reti neurali artiﬁciali, che dà il via alla \nrivoluzione del Deep Learning.\n\u00007",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#7": "\u00008\n2006 : Netﬂix lancia la “Netﬂix Prize competition”, con una borsa di \nun milione di dollari, sﬁdando i gruppi di ricerca ad usare il Machine \nLearning per migliorare la accuracy del proprio Recommender \nSystem  di almeno il 10%. Un gruppo ha vinto il premio nel 2009.\n2010 : ImageNet lancia un concorso annuale - la “ImageNet Large \nScale Visual Recognition Challenge (ILSVRC)” - in cui i team \nutilizzano il Machine Learning per rilevare e classiﬁcare \ncorrettamente gli oggetti in un set di dati di immagini ampio e ben \ncurato. L’errore di classiﬁcazione migliora dal 25% nel 2011 a pochi \npunti percentuali nel 2015, grazie ai progressi nelle deep \nconvolutional neural networks.\nProgetti Rilevanti nello \nSviluppo del Machine Learning",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#8": "\u00009\n2011 : IBM Watson, un sistema di question-answering, batte i \ncampioni del gioco Jeopardy!   Brad Rutter e Ken Jennings. IBM \nWatson è ora utilizzato in diversi settori, tra cui l’assistenza sanitaria \ne la vendita al dettaglio. \n2014 : Facebook pubblica un lavoro su DeepFace, un sistema basato \nsu reti neurali artiﬁciali in grado di identiﬁcare volti con \nun’accuratezza del 97%, una prestazione al livello “umano”, che \nmigliora di circa il 27% le prestazioni di sistemi precedenti.\n2014 : Il Il consumo di energia per il raffreddamento dei Data Center \nè stato ridotto del 40% con un modello di Machine Learning:\nProgetti Rilevanti nello \nSviluppo del Machine Learning\nGao,\tJ.\t(2014) .\tMachine\tLearning\tApplica:ons\tfor\tData\tCenter\tOp:miza:on.\t Google\tResearch.  \nhCps://sta:c.googleusercontent.com/media/research.google.com/it//pubs/archive/42542.pdf",
    "data_test\\rootfolder\\università\\MachineLearning\\1-Introduzione ML-sbloccato.pdf#9": "\u000010\n2015 : AlphaGo di DeepMind batte il giocatore Fan Hui nel gioco del \nGo. Nel 2016 , batte Lee Sedol e, nel 2017 , batte Ke Jie.\n2017 : Il software per analizzare le immagini delle galassie sotto lenti \ngravitazionali è stato velocizzato di un fattore di 10 milioni  con un \nmodello di Machine Learning:\nProgetti Rilevanti nello \nSviluppo del Machine Learning\nHezaveh,\t Y.D.,\t Levasseur,\t I.P .,\t Marshall,\t P .J.\t (2017).\t Fast\t Automated\t Analysis\t of\t Strong\t\nGravita:onal\tLenses\twith\tConvolu:onal\tNeural\tnetworks.\t Nature ,\t548,\tpp.\t555-557.  \nhCps://arxiv.org/abs/1708.08842\nRecentemente David Patterson (Turing Award winner) e Jeff Dean (Google AI \nhead) hanno dichiarato l'alba di una \"età dell'oro\" per l'architettura dei computer \ngrazie al Machine Learning . ",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nAlgoritmo K-NN\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#1": "Sommario\nRipasso su Information Retrieval \nAlgoritmo k-NN \nkd-trees per k-NN\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#10": "Modello Bag-of-Words\nUn problema che emerge in questa semplice rappresentazione è \nrelativa ai termini poco frequenti (“rare words”). \nIn effetti, in tale rappresentazione tutti i termini sono considerati \nugualmente importanti.  \nIn realtà certi termini hanno poca capacità discriminante ai ﬁni \ndella determinazione della rilevanza di un documento (e.g., \nquando ne calcoliamo la distanza rispetto ad un altro).  \nAd esempio, nel caso di una collezione di documenti relativi \nall’industria automobilistica, è piuttosto probabile avere il termine \n“automobile” in quasi ogni documento. \nTali termini dominerebbero dunque quelli più rari. \n \n11",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#11": "Modello TF-IDF\nUna rappresentazione alternativa che possiamo considerare è \nquella chiamata \n tf-idf\n. \nCome vedremo, questa rappresentazione enfatizza i termini \n“importanti”, individuati dalle seguenti caratteristiche: \n•\n appaiono frequentemente in un documento (“common locally”) \n•\n appaiono raramente nel corpus (“rare globally”) \n \n12",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#12": "Modello TF-IDF\nDeﬁniamo \n Document Frequency\n  (\ndf\n) per il termine \n t\n come il \nnumero di documenti nel corpus che contengono \n t\n. \nDeﬁniamo inoltre l’\n Inverse Document Frequency\n  come segue: \ndove N è la cardinalità del corpus. \n \n13idf t= logN\ndft",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#13": " \n14termine dft idft\ncar 18.165 1,65\nauto 6.723 2,08\ninsurance 19.241 1,62\nbest 25.235 1,5ESEMPIO: \nNella seguente tabella sono riportati alcuni esempi di valori df e idf \nrelativi alla collezione Reuters, costituita da 806.791 documenti:\nModello TF-IDF",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#14": "Modello TF-IDF\nIl tf-idf è deﬁnito come segue: \nIn sostanza il \n tf-idf\n per un termine \n t\n in un documento \n d\n assegna al \ntermine un peso nel documento che è: \n•\n molto elevato quando \n t\n è molto frequente in un piccolo numero \ndi documenti; \n•\n più basso quando il termine è poco frequente nel documento, \noppure quando è presente in molti documenti; \n•\n il più basso quando il termine compare in tutti i documenti. \n \n15tf-idf t,d=t f t,d ·idft",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#15": "Metriche\nVediamo ora come possiamo calcolare la distanza tra due \n item\n.\n \n16distanza( xi,xq)= |xi\u0000xq|\ndistanza( xi,xq)=q\n(xi[1]\u0000xq[1])2+···+(xi[d]\u0000xq[d])2\ndistanza( xi,xq)=q\n(xi\u0000xq)T·(xi\u0000xq)\nNel semplice caso di una dimensione possiamo deﬁnire la \nfunzione distanza come segue (Distanza Euclidea):\nNel caso di \n d \ndimensioni, la funzione \n distanza\n  può assumere la \nseguente forma (Distanza Euclidea):\nche possiamo riscrivere come segue, in forma matriciale:",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#16": "Metriche\n \n17distanza( xi,xq)=q\na1(xi[1]\u0000xq[1])2+···+ad(xi[d]\u0000xq[d])2\ndistanza( xi,xq)=q\n(xi\u0000xq)T·A ·(xi\u0000xq)\nNel caso in cui vogliamo pesare in modo diverso le varie \ndimensioni, possiamo usare una \n Scaled Euclidean distance\n :\nA=2\n664a10 ... 0\n0 a2 ... 0\n... ... ... ...\n00 ... a d3\n775\nche possiamo riscrivere come segue, in forma matriciale:\ndove:",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#17": "Cosine Similarity\nUna metrica largamente utilizzata per quantiﬁcare la similarità tra \ndue documenti \n x\ni \ne \nx\nq \nè la \n cosine similarity\n , che si avvale della \nrappresentazione vettoriale dei documenti: \n \n18sim(xi,xq)=xT\ni·xq\nkxik·kxqk\ndove il numeratore rappresenta il prodotto scalare tra i due vettori \ne il denominatore il prodotto tra i moduli dei due vettori. \nL’effetto del denominatore è dunque quello di normalizzare i \nvettori \n x\ni \ne \nx\nq \nottenendone i corrispondenti versori. Possiamo \ndunque riscrivere la precedente espressione come segue: \nsim(xi,xq)=ˆxT\ni·ˆxq",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#18": "Consideriamo ad esempio i documenti in ﬁgura a), rappresentati \nmediante i vari \n tf\n. La quantità: \n \n19Doc1 Doc2 Doc3\ncar 27 4 24\nauto 3 33 0\ninsurance 0 33 29\nbest 14 0 17Doc1 Doc2 Doc3\ncar 0,88 0,09 0,58\nauto 0,10 0,71 0\ninsurance 0 0,71 0,70\nbest 0,46 0 0,41\nCosine Similarity\nha i valori 30,56, 46,84 e 41,30 per Doc1, Doc2 e Doc3. \nApplicando la normalizzazione otteniamo la ﬁgura b): \na) \n b) kxk=vuutdX\nj=1x2\nj",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#19": "La similarità deﬁnita in precedenza corrisponde al coseno \ndell’angolo tra i due vettori: \n \n20θ\n01\n1sim(xi,xq)=xT\ni·xq\nkxik·kxqk= cos( ✓)\nˆxi\nˆxq\nCosine Similarity",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#2": "Document Retrieval\n \n3Diversamente dagli esseri umani,\nche presumibilmente …\nQuesto è un esempio di quello\nche gli informatici ….L’approccio ai sistemi simbolici\nnon è affatto ………\nPer rispondere a questa domanda\nl’approccio migliore …..\nProvate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando\nla sostituzione del capitale …..\nPotrebbe valere la pena correre dei\n rischi  ……\nIn precedenza, nel tentativo di\ndeﬁnire l’IA, …….Dopo la conferenza di Dartmouth,\nl’interesse …….\nPer affrontare la lettura occorre\n una certa dimestichezza …….\nNel testo si trovano inseriti  …….La relazione tra matrici ora\ndeﬁnita è riﬂessiva,  …….\nUna trasformazione può  …….\nPer questa ragione gran parte\ndegli psico-proseliti …….\nPer tutti costoro il massimo  …….Le ragioni per cui si è instaurata\nuna stretta connessione ….Il lettore può essere sorpreso  dalla\nquantità di spazio …..\nMolta della utilità di questo …….\nGalton si era convinto che i\ncaratteri mortali si ereditassero …..\nOltre a ciò Galton, memore dei  …….La situazione è tuttavia comple-\ntamente diversa …..\nUn’area in pieno sviluppo è  …..Storicamente, il modo più semplice\nper assistere i clienti …..\nAnche se quasi tutti i sistemi \nsperimentali  …..\nSupponiamo di avere disponibile un corpus di documenti: Come \npossiamo misurare la similarità tra di loro? Come possiamo \neffettuare ricerche? ",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#20": "K-NN: Complessità della ricerca \n \n21Diversamente dagli esseri umani,\nche presumibilmente …\nQuesto è un esempio di quello\nche gli informatici ….L’approccio ai sistemi simbolici\nnon è affatto ………\nPer rispondere a questa domanda\nl’approccio migliore …..\nProvate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando\nla sostituzione del capitale …..\nPotrebbe valere la pena correre dei\n rischi  ……\nIn precedenza, nel tentativo di\ndeﬁnire l’IA, …….Dopo la conferenza di Dartmouth,\nl’interesse …….\nPer affrontare la lettura occorre\n una certa dimestichezza …….\nNel testo si trovano inseriti  …….La relazione tra matrici ora\ndeﬁnita è riﬂessiva,  …….\nUna trasformazione può  …….\nPer questa ragione gran parte\ndegli psico-proseliti …….\nPer tutti costoro il massimo  …….Le ragioni per cui si è instaurata\nuna stretta connessione ….Il lettore può essere sorpreso  dalla\nquantità di spazio …..\nMolta della utilità di questo …….\nGalton si era convinto che i\ncaratteri mortali si ereditassero …..\nOltre a ciò Galton, memore dei  …….Storicamente, il modo più semplice\nper assistere i clienti …..\nAnche se quasi tutti i sistemi \nsperimentali  …..La situazione è tuttavia comple-\ntamente diversa …..\nUn’area in pieno sviluppo è  …..\nIl calcolo delle distanze tra documenti può essere molto pesante \ncomputazionalmente quando N è molto elevato: ",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#21": "K-NN: Complessità della ricerca \n \n22\nDato un \n query point\n , il costo della scansione su tutti i punti è: \n•\n O(N) per una query per 1-NN \n•\n O(N log k) per una query per k-NN \nPer rendere più efﬁciente la ricerca è possibile utilizzare una \nparticolare struttura dati, i \n KD-Trees\n . ",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#22": "KD-Trees\n \n23\nPermette un’organizzazione strutturata degli item: \n•\n partiziona ricorsivamente i data point in “axis aligned boxes”. \nComporta un più efﬁciente pruning dello spazio di ricerca. \nOttiene buoni risultati in dimensioni “low-medium”. \nRiferimenti: \nBentley, J.L. “Multidimensional Binary Search Trees Used for Associative Searching”, in: \nCommunications of the ACM , 18(9), 1975, pp. 509-517.\nFriedman, J.H., Bentley, J.L., Finkel, R.A. “An Algorithm for Finding Best Matches in \nLogarithmic Expected Time”, in: ACM Transactions on Mathematical Software , 3(3), 1977, pp. \n209-226.",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#23": "KD-Trees\n \n24\nCostruzione dell’albero: \nData Point x[1] x[2]\n1 0,00 0,00\n2 1,00 4,31\n3 0,13 2,85\n… … …\nfeature 1feature 2",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#24": "KD-Trees\n \n25\nSplit relativo alla prima feature: \nData Point x[1] x[2]\n2 1,00 4,31\n… … …Data Point x[1] x[2]\n1 0,00 0,00\n3 0,13 2,85\n… … …x[1] > 0,5\n0,5x[1] ≤ 0,5",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#25": "KD-Trees\n \n26\nConsideriamo ora la parte sinistra: \nData Point x[1] x[2]\n2 1,00 4,31\n… … …Data Point x[1] x[2]\n1 0,00 0,00\n3 0,13 2,85\n… … …x[1] > 0,5\n0,5x[1] ≤ 0,5\n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#26": "KD-Trees\n \n27\nSplit relativo alla seconda feature: \nData Point x[1] x[2]\n3 0,13 2,85\n… … …Data Point x[1] x[2]\n1 0,00 0,00\n… … …x[2] > 0,1 x[2] ≤ 0,1\n0,1\n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#27": "KD-Trees\n \n28\nSi procede in tal modo ﬁno a completare l’albero: \n•split feature \n•split value \n•bounding box\nx[1] > 0,5 x[1] ≤ 0,5\nx[2] ≤ 0,1 x[2] > 0,1",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#28": "KD-Trees\n \n29\nEsempi di bounding box: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#29": "KD-Trees\n \n30\nEuristiche per effettuare le decisioni sugli splitting: \n•\n Scelta della dimensione (la più ampia, dim. alternate) \n•\n Valore della feature a cui effettuare lo split (mediana, centro \ndel box) \n•\n Condizione di terminazione (numero di punti sotto una \ndeterminata soglia, larghezza del box sotto una determinata \nsoglia)",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#3": "Nearest Neighbor\n \n4Diversamente dagli esseri umani,\nche presumibilmente …\nQuesto è un esempio di quello\nche gli informatici ….L’approccio ai sistemi simbolici\nnon è affatto ………\nPer rispondere a questa domanda\nl’approccio migliore …..\nProvate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando\nla sostituzione del capitale …..\nPotrebbe valere la pena correre dei\n rischi  ……\nIn precedenza, nel tentativo di\ndeﬁnire l’IA, …….Dopo la conferenza di Dartmouth,\nl’interesse …….\nPer affrontare la lettura occorre\n una certa dimestichezza …….\nNel testo si trovano inseriti  …….La relazione tra matrici ora\ndeﬁnita è riﬂessiva,  …….\nUna trasformazione può  …….\nPer questa ragione gran parte\ndegli psico-proseliti …….\nPer tutti costoro il massimo  …….Le ragioni per cui si è instaurata\nuna stretta connessione ….Il lettore può essere sorpreso  dalla\nquantità di spazio …..\nMolta della utilità di questo …….\nGalton si era convinto che i\ncaratteri mortali si ereditassero …..\nOltre a ciò Galton, memore dei  …….\nStoricamente, il modo più semplice\nper assistere i clienti …..\nAnche se quasi tutti i sistemi \nsperimentali  …..La situazione è tuttavia comple-\ntamente diversa …..\nUn’area in pieno sviluppo è  …..\nObiettivo: dato un documento \n x\nq\n, trovare l’articolo più simile nel \ncorpus di documenti disponibili: \ndocumento xqnearest neighbor",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#30": "KD-Trees\n \n31\nDato un query point (in verde), attraversiamo l’albero alla ricerca \ndel nearest neighbor. \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#31": "KD-Trees\n \n32\nPrima metà dell’area: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#32": "KD-Trees\n \n33\n.. e così via … \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#33": "KD-Trees\n \n34\nAbbiamo raggiunto la foglia che contiene il query point: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#34": "KD-Trees\n \n35\nCalcolo della distanza del NN tra i punti contenuti nella foglia: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#35": "KD-Trees\n \n36\nBacktrack e proviamo altri rami per ogni nodo visitato: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#36": "KD-Trees\n \n37\nValutiamo la distanza dal bounding box: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#37": "KD-Trees\n \n38\nLa distanza è minore di quella corrente, perciò visitiamo i \nsottoalberi (in questo caso le foglie). La prima ha distanza \nminore: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#38": "KD-Trees\n \n39\nBacktrack e visitiamo l’altra foglia: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#39": "KD-Trees\n \n40\nLa distanza dal bounding box è superiore alla minima, perciò \npossiamo potare il ramo: ",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#4": "Algoritmo 1-NN\n \n5dist min = 1\nnearest doc = ;\nfor i=1,. . . ,N\n\u0000= distanza( xq,xi) ; distanza tra documento query ed o c u m e n t oi - e s i m o\nif\u0000<dist min\nnearest doc = xi; documento pi` u vicino corrente\ndist min = \u0000 ; distanza minima corrente\nreturn nearest doc\nInput: documento \n x\nq\n per la query e documenti \n x\n1\n , \nx\n2\n, … , \n x\nN \nOutput: documento \n x\ni\n più vicino (nearest_doc) a \n x\nq ",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#40": "KD-Trees\n \n41\nBacktrack e proviamo altri rami per ogni nodo visitato: ",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#41": "KD-Trees\n \n42\nLa distanza dal bounding box è superiore alla minima corrente, \nperciò possiamo potare il ramo: ",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#42": "KD-Trees\n \n43\nBacktrack e proviamo altri rami per ogni nodo visitato: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#43": "KD-Trees\n \n44\nLa distanza dal bounding box è superiore alla minima corrente, \nperciò possiamo potare il ramo: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#44": "KD-Trees\n \n45\nPruning complessivo: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#45": "Riferimenti\n \n46\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , Apogeo, 3a edizione, \n2015. \nMachine Learning: Clustering & retrieval\n , University of Washington - Coursera, \n2017. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. \nMurphy, K.P. \n Machine Learning - A Probabilistic Approach\n , The MIT Press, 2012.",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#5": " \n6Diversamente dagli esseri umani,\nche presumibilmente …\nQuesto è un esempio di quello\nche gli informatici ….L’approccio ai sistemi simbolici\nnon è affatto ………\nPer rispondere a questa domanda\nl’approccio migliore …..\nProvate a pensare a come sarebbero ..Sfortunatamente, l’IA sta accelerando\nla sostituzione del capitale …..\nPotrebbe valere la pena correre dei\n rischi  ……\nIn precedenza, nel tentativo di\ndeﬁnire l’IA, …….Dopo la conferenza di Dartmouth,\nl’interesse …….\nPer affrontare la lettura occorre\n una certa dimestichezza …….\nNel testo si trovano inseriti  …….La relazione tra matrici ora\ndeﬁnita è riﬂessiva,  …….\nUna trasformazione può  …….\nPer questa ragione gran parte\ndegli psico-proseliti …….\nPer tutti costoro il massimo  …….Le ragioni per cui si è instaurata\nuna stretta connessione ….Il lettore può essere sorpreso  dalla\nquantità di spazio …..\nMolta della utilità di questo …….\nGalton si era convinto che i\ncaratteri mortali si ereditassero …..\nOltre a ciò Galton, memore dei  …….\nStoricamente, il modo più semplice\nper assistere i clienti …..\nAnche se quasi tutti i sistemi \nsperimentali  …..La situazione è tuttavia comple-\ntamente diversa …..\nUn’area in pieno sviluppo è  …..\nObiettivo: dato un documento \n x\nq\n, trovare i k articoli più simili nel \ncorpus di documenti disponibili: \ndocumento xqk nearest neighbors\nk Nearest Neighbors",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#6": "Algoritmo k-NN\n \n7\nInput: documento \n x\nq\n per la query e documenti \n x\n1\n , \nx\n2\n, … , \n x\nN \nOutput: lista dei k documenti più vicini a \n x\nq \nlista kdist min = sort( \u00001,\u00002,..., \u0000k)\nlista knearest doc = sort( x1,x2,..., xk)\nfor i=k+1,. . . ,N\n\u0000= distanza( xq,xi) ; distanza tra documento query ed o c u m e n t oi - e s i m o\nif\u0000<lista kdist min[ k]\ninserisci \u0000in lista kdist min ; inserimento in lista ordinata\ninserisci xiin lista knearest doc ; inserimento in lista ordinata\nreturn lista knearest doc",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#7": "Criticità nella NN search\nPer effettuare una ricerca dei nearest neighbors occorre risolvere i \nseguenti problemi: \n•\nCome rappresentare gli item coinvolti (nel nostro esempio i \ndocumenti). \n•\nCome valutare la distanza tra gli item, ossia deﬁnire una metrica \nche consenta di calcolare la similarità tra i vari item. \n \n8",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#8": "Richiami su \nRappresentazione dei Documenti\nVediamo ora due possibili metodi per la rappresentazione dei \ndocumenti non strutturati: \n•\n bag of words \n•\n tf-idf \n (term frequency - inverse document frequency)  \n \n9",
    "data_test\\rootfolder\\università\\MachineLearning\\10-Algoritmo K-NN-sbloccato.pdf#9": "Modello Bag-of-Words\nIn questo modello è ignorato l’esatto ordine dei termini nel \ndocumento. \nViene preso in considerazione solo il numero di occorrenze (\n term \nfrequency\n : \ntf\n) di ogni termine nel documento. \nIn tal modo è possibile rappresentare ogni documento mediante \nun vettore di occorrenze: \n \n10Doc1 Doc2 Doc3\ncar 27 4 24\nauto 3 33 0\ninsurance 0 33 29\nbest 14 0 17",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nMachine Learning con Python: \nIntroduzione  \n\u0000\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#1": "Introduzione al \nMachine Learning con Python   \nTesto consigliato:\n\u00002Andreas C. Müller,  Sarah Guido\n“Introduction to Machine Learning with Python - A guide for Data Scientists”\nO’Reilly, 2017.\n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#10": "\u000011\nCaricamento del  \nDataset IRIS\nIl nostro obiettivo è quello di realizzare un modello di \nmachine learning che apprenda, dagli esempi disponibili, \ncome classiﬁcare la specie di un nuovo ﬁore iris partendo \ndalle 4 misure relative ai suoi petali e sepali.\nIl dataset Iris è incluso in scikit-learn  nel modulo \ndatasets . E’ possibile caricarlo chiamando la funzione \nload_iris :\n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#11": "\u000012\nL’oggetto iris restituito da load_iris  è un Bunch  object, ed \nè simile a un dizionario. Esso contiene chiavi e valori:\nDataset IRIS",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#12": "\u000013\nBunch objects\n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#13": "\u000014\nIl valore associato alla chiave DESCR  è una descrizione \nsintetica del dataset. Vediamo i primi caratteri di tale \ndescrizione:\nDataset IRIS",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#14": "\u000015\nVediamo i valori associati alle chiavi target_names  e \nfeature_names :\nDataset IRIS",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#15": "\u000016\nI dati sono contenuti nei campi data e target . Vediamo il \ntipo e lo shape di data:\nDataset IRIS\n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#16": "\u000017\nL’array target  contiene le specie di ciascuno dei ﬁori del \ndataset ( 0 per setosa , 1 per versicolor , 2 per virginica ): \nDataset IRIS\n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#17": "I dati che useremo per il training e il test possono essere \nvisti come segue:\n\u000018\nData Set IRIS\nsepal \nlengthsepal \nwidthpetal \nlengthpetal \nwidthTarget \n(Iris species)\n5.9 3.0 4.2 1.5 1\n5.8 2.6 4.0 1.2 1\n6.8 3.0 5.5 2.1 2\n4.7 3.2 1.3 0.2 0\n6.9 3.1 5.1 2.3 2",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#18": "Esempi di valori delle feature presenti in data:\n\u000019\nData Set IRIS\nsepal \nlengthsepal \nwidthpetal \nlengthpetal \nwidthTarget \n(Iris species)\n5.9 3.0 4.2 1.5 1\n5.8 2.6 4.0 1.2 1\n6.8 3.0 5.5 2.1 2\n4.7 3.2 1.3 0.2 0\n6.9 3.1 5.1 2.3 2\nX",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#19": "Esempi di valori delle specie presenti in target :\n\u000020\nData Set IRIS\nsepal \nlengthsepal \nwidthpetal \nlengthpetal \nwidthTarget \n(Iris species)\n5.9 3.0 4.2 1.5 1\n5.8 2.6 4.0 1.2 1\n6.8 3.0 5.5 2.1 2\n4.7 3.2 1.3 0.2 0\n6.9 3.1 5.1 2.3 2\ny",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#2": "\u00003https://github.com/amueller/introduction_to_ml_with_python\nGli esempi di codice presentati nel libro sono disponibili \nnel seguente sito :\nIntroduzione al \nMachine Learning con Python   ",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#20": "\u000021\nSuddivisione in \nTraining Set e Test Set \nscikit-learn  contiene una funzione che mescola il dataset \ndelle osservazioni disponibili e ne fa la suddivisione in  \ntraining set e test set . Si tratta della funzione:\ntrain_test_split\nQuesta funzione estrae il 75% degli esempi per formare il \ntraining set , costituito quindi dal 75% delle righe in data \ne le corrispondenti label in target .\nIl rimanente 25% degli esempi va a costituire il test set .",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#21": "\u000022\nIstruzioni per lo split:\nndarray da ripartire tra  \nX_train e X_testfunzione per lo split\nndarray da ripartire tra  \ny_train e y_test\nSuddivisione in \nTraining Set e Test Set ",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#22": "\u000023\nShape delle variabili relative al training set e al test set:\nSuddivisione in \nTraining Set e Test Set ",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#23": "\u000024\nIspezione dei Dati\nPrima di costruire un modello di machine learning è \nsempre opportuno ispezionare i dati disponibili, intanto \nper capire se il problema è risolvibile mediante tecniche \ndi machine learning.\nL’ispezione è utile anche per la individuazione di \neventuali anomalie, inconsistenze, ecc.\nUn ottimo metodo per effettuare tale ispezione è quello \ndi visualizzare i dati in questione (e.g., scatter plot).\nNella ﬁgura che segue viene rappresentato un “pair plot” \ndelle feature relativamente alle osservazioni del training \nset per il nostro esempio.",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#24": "\u000025\nIspezione dei Dati",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#25": "\u000026\nK-Nearest Neighbors \nCostruzione del Modello \nL’algoritmo k-NN  in scikit-learn  è implementato nella \nclasse KNeighborsClassiﬁer  nel modulo neighbors .\nPrima di usare il modello, dobbiamo istanziare la classe in \nun oggetto. In tal modo impostiamo i parametri del \nmodello.\nIl parametro più importante di KNeighborsClassiﬁer è il \nnumero del neighbors, che in questo caso impostiamo a 1:\n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#26": "\u000027\nK-Nearest Neighbors \nCostruzione del Modello \nL’oggetto knn incapsula l’algoritmo che sarà utilizzato per \ncostruire il modello a partire dai dati di training, così \ncome l’algoritmo per fare le previsioni su nuovi data \npoints.\nNel caso di KNeighborsClassiﬁer  verrà semplicemente \nmemorizzato il training set.",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#27": "\u000028\nAddestramento del Modello\nPer addestrare il modello sul training set, scikit-learn  \nmette a disposizione il metodo ﬁt da chiamare \nsull’oggetto knn:\nmetodo per l’addestramento",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#28": "\u000029\nUso del Modello  \nper effettuare Previsioni \nDato un nuovo data point da classiﬁcare:\nfeatures del nuovo ﬁore da classiﬁcare ",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#29": "\u000030\n… possiamo usare il metodo predict per la predizione \ndella sua specie:\nmetodo per la predizione\nUso del Modello  \nper effettuare Previsioni ",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#3": "Testo consigliato:\n\u00004A. Géron\n“Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow”\nO’Reilly, 2019.\nIntroduzione al \nMachine Learning con Python   ",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#30": "\u000031\nValutazione del Modello \nPer valutare il modello possiamo richiamare il metodo \npredict  su tutti gli esempi del test set:\n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#31": "\u000032\nCalcolo del punteggio:\nValutazione del Modello ",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#32": "\u000033\nSintesi della esercitazione\nDeﬁnizione di un task di machine learning (classiﬁcazione delle specie Iris \nmediante k-NN ).\nIndividuazione dei data points  (esempi, osservazioni) disponibili per \naddestrare il sistema (supervised learning task)\nSplit  del dataset, import  della classe, che poi è istanziata su un oggetto (setting \nparameters)\nFase di addestramento (metodo ﬁt) e valutazione  (metodo score ):\n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#4": "\u00005\nScikit-learn  è uno dei package più popolari per il \nMachine Learning in Python.\nMette a disposizione efﬁcienti implementazioni di \nnumerosi algoritmi di ML e un gran numero di utili \nstrumenti per attività di pre- e post- processing relative a \ntask di ML.\nE’ possibile trovare la documentazione necessaria nel \nseguente sito: \nhttp://scikit-learn.org\nScikit-Learn ",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#5": "\u00006\nJupiter Notebook : ambiente interattivo per eseguire \ncodice nel browser.\nNumPy : è uno dei package fondamentali per il calcolo \nscientiﬁco in Python.\nLibrerie e Strumenti \npandas : libreria per data wrangling e analisi.\nmatplotlib : libreria per il plotting.\nmglearn : libreria di utility functions che gli autori (Müller \n& Guido) hanno scritto per il loro libro, in modo da non \n“intasare” il codice presentato con dettagli di plotting e di \ndata loading.",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#6": "Versioni linguaggio e librerie:\n\u00007\nAmbiente di Sviluppo \n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#7": "Cominciamo con un semplice esempio di classiﬁcation, \nutilizzando il data set Iris.\nQuesto è un famoso data set che contiene 150 esempi di \nﬁori iris, descritti da 4 features (lunghezza e larghezza di \npetali e sepali) e appartenenti ad una di tre specie \ndifferenti:\nIris setosa\nIris versicolor  \nIris virginica  \n\u00008\nUna prima applicazione:  \nClassificazione delle specie IRIS",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#8": "Ecco un esempio di ﬁori iris relativo alle tre specie:\n\u00009\nUna prima applicazione:  \nClassificazione delle specie IRIS\n",
    "data_test\\rootfolder\\università\\MachineLearning\\11-ML con Python - Introduzione-sbloccato.pdf#9": "\u000010\nUna prima applicazione:  \nClassificazione delle specie IRIS\nPetal\nSepal\nLa classiﬁcazione può essere fatta in base ai valori delle 4 \nfeatures, ossia lunghezza e larghezza dei petali e sepali:",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#0": "Intelligenza Artiﬁciale \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Regressione (Ex02)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#1": "Sommario\nDataset Better Life Index \nRichiami: Model Selection, Simple Linear Regression, Funzione di Costo \nLibreria Scikit-learn \nLinear Regression in Python \nEsempio: Dataset Diabete \nLinear Regression e Predizione \nEsercitazione su dataset Better Life Index",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#10": "Il modulo \n linear_model\n  di \nsklearn\n  implementa l'addestramento basandosi \nsu un modello lineare. La funzione di costo di default è la \n RSS\n. \nLa funzione \n ﬁt()\n prende come parametri due arrays \n X\n e \ny\n, effettua \nl'addestramento (o \n ﬁtting\n ) e memorizza i coefﬁcienti nella variabile \n coef_\n . \nAd esempio: \n>>> \nfrom \nsklearn \nimport\n linear_model \n>>> \nreg \n=\n linear_model\n .\nLinearRegression() \n>>> \nreg\n.\nfit([[\n0\n, \n0\n], [\n1\n, \n1\n], [\n2\n, \n2\n]], [\n0\n, \n1\n, \n2\n]) \nLinearRegression()  \n>>> \nreg\n.\ncoef_ \narray([0.5, 0.5]) \nNell'esempio si impiegano 2 valori (cioè 2 features) per punto, e la retta ha \n2 coefﬁcienti \n w\n1\n. Il valore di \n w\n0\n si ottiene con la variabile \n intercept_\n  del \nmodello. \nNota\n : l'underscore nel nome delle variabili indica che i valori sono ottenuti \ndurante l'addestramento, e perciò non sono iperparametri del modello.\nLinear Regression in Python\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#11": "Il modulo \n metrics\n  di \nsklearn\n  implementa varie misure di performance. \nhttps://scikit-learn.org/stable/modules/model_evaluation.html  \nNota: troviamo MSE ma non RSS.\nScikit-learn e le misure di performance\n12\n",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#12": "Un dataset diabete è un dataset \n toy \n(cioè utile per scopi didattici e per \ntestare il codice)  \n disponibile all'interno della libreria scikit-learn. \nURL: \n https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html   \nhttps://scikit-learn.org/stable/datasets/toy_dataset.html   \n442 istanze \n10 features reali normalizzate ove richiesto -.2 < x < .2 \nage age in years\nsex\nbmi body mass index\nbp average blood pressure\ns1 tc, total serum cholesterol\ns2 ldl, low-density lipoproteins\ns3 hdl, high-density lipoproteins\ns4 tch, total cholesterol / HDL\ns5 ltg, possibly log of serum triglycerides level\ns6 glu, blood sugar level\nTarget: intero nell'intervallo 25 - 346 che indica quanto la malattia sia \naccresciuta dopo 1 anno\nEsempio: dataset diabete\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#13": "Codice per impiegare il dataset: \nimport \nmatplotlib.pyplot  \nas \nplt \nimport \nnumpy \nas \nnp \nfrom \nsklearn \nimport\n datasets, linear_model \nfrom \nsklearn.model_selection  \nimport\n train_test_split \nfrom \nsklearn.metrics  \nimport \nmean_squared_error\n , \nr2_score  \n# Carico il dataset  \ndiabetes_X, diabetes_y \n = \ndatasets\n .\nload_diabetes\n (return_X_y\n =\nTrue\n) \n# Mantengo solo la terza feature  \ndiabetes_X \n =\n diabetes_X[:, \n np\n.\nnewaxis\n, \n2\n] \n# Suddivido il dataset in training/test 80/20%  \ndiabetes_X_train,diabetes_X_test,diabetes_y_train, diabetes_y_test \n =    \n  train_test_split(diabetes_X, diabetes_y,test_size=0.2) \n... \nEsercizio\n : completa il codice impiegando un modello lineare, \nvisualizzando il valore dei coefﬁcienti e l'errore MSE.\nEsempio Python: diabete (1)\n14",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#14": "# Istanzia un modello di regressione lineare  \nregr \n= \nlinear_model\n .\nLinearRegression\n () \n# Addestramento con funzione di costo RMSE  \nregr\n.\nfit(diabetes_X_train, diabetes_y_train) \n# Ricava le predizioni sul test set  \ndiabetes_y_pred \n =\n regr\n.\npredict(diabetes_X_test) \n# Stampa i parametri del modello  \nprint\n(\n\"Coefficients: \n \\n\n\"\n, regr\n.\ncoef_) \n# Valuto il MSE  \nprint\n(\n\"Mean squared error: \n %.2f\n\" \n% \nmean_squared_error\n (diabetes_y_test, diabetes_y_pred)) \nplt\n.\nscatter\n(diabetes_X_test, diabetes_y_test, color\n =\n\"black\"\n) \nplt\n.\nplot\n(diabetes_X_test, diabetes_y_pred, color\n =\n\"blue\"\n, linewidth\n =\n3\n) \nplt\n.\nxticks\n(()) \nplt\n.\nyticks\n(()) \nplt\n.\nshow\n() \n# Coefficients:   [938.23786125]  \n# Mean squared error: 2548.07\nEsempio Python: diabete (2)\n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#15": "Il modulo \n linear_model\n  permette facilmente di fare predizione sui dati. \nLa funzione \n predict()\n  prende un array di istanze (una o più features) e \nricava il valore in base al modello addestrato. \nX_new = [[\n 22587\n]] \nprint\n(model.predict(X_new))\nLinear Regression e predizione\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#16": "Il problema consiste nel determinare i due parametri \n w\n. Chiaramente il \nmodello può solo approssimare la correlazione tra i valori.  \nSe facciamo più ipotesi, cioè creiamo più modelli, ci occorre una misura di \nperformance (o di costo) per confrontarli e scegliere il più adatto.\nEsempio: dataset Better Life Index (3)\n17PIL pro capiteLivello di soddisfazione\nPIL pro capitew0=8w1=-5×10-5\nw0=4w1=5×10-5 w0=0w1=2×10-5w0=?\nw1=?Livello di soddisfazione",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#17": "Accedi al seguente notebook dove i dati sono già caricati e formattati per gli step \nsuccessivi:  \nhttps://colab.research.google.com/drive/1apLqC0KAveOkkCT8JuO5kNQyj1GT5Hz9?usp=sharing   \nRisolvi i seguenti esercizi: \nEsercizio #1\n : crea e addestra un modello lineare con funzione di costo RSS \nEsercizio #2\n : visualizza i parametri del modello \nEsercizio #3\n : prendi tre campioni random dal dataset e ricava la predizione in base \nal modello addestrato \nEsercizio #4\n : calcola RSS MSE e RMSE valutando i tre campioni \nEsercizio #5\n : suddividi il dataset in input in train e test con un rapporto 80/20 \nEsercizio #6\n : addestra nuovamente il modello, e ricava RSS MSE e RMSE sui test set \nEsercizio #7\n : suddividi nuovamente il dataset ma con un rapporto 50/50. Valuta \nnuovamente le performance del modello e discuti eventuali differenze nei valori \nottenuti.\nEsercizio Python: Better Life Index\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#18": "Aurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017 \nAndreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016\nTesti di Riferimento\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#2": "Richiami\nLe tecniche di \n Regressione\n  ricadono nell'ambito dell'apprendimento \nModel-based\n , dove  \nSi costruisce un modello che rappresenta le caratteristiche dei dati in \ningresso (es. andamento).  \nTale modello verrà poi impiegato nella fase di \n predizione\n  su istanze in \ningresso distinte da quelle impiegate durante l'apprendimento.\n3\n",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#3": "Datasets\nDurante le esercitazioni faremo uso di vari datasets, alcuni reali, altri \nsintetici che ci permetteranno di mettere in evidenza vari aspetti e \nproblematiche rilevanti nell'ambito dell'apprendimento automatico.\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#4": "Esempio: dataset Better Life Index (1)\nDataset che lega il benessere (life satisfaction) con indicatori giudicati essenziali \nnella vita quotidiana (es. salario, livello istruzione), suddivisi per nazione. \nhttps://stats.oecd.org/index.aspx?DataSetCode=BLI  \n5\n",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#5": "Esempio: dataset Better Life Index (2)\nValore del PIL (GDP) annuale \nhttps://www.imf.org/external/datamapper/NGDP_RPCH@WEO/OEMDC/ADVEC/WEOWORLD\n6\n",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#6": "Se prendiamo i due dataset e creiamo un join, possiamo mettere in \ncorrelazione due variabili, es. PIL pro capite e livello di soddisfazione \npercepito. \nSi nota come i due valori siano correlati, sebbene non esattamente, con un \nlegame lineare. \nPossiamo supporre che esista un modello \n lineare\n  (o \nordinary least squares\n ) \nche leghi la soddisfazione con il valore del PIL (fase di \n model selection\n ).\nRichiami: Model selection\n7\nPIL pro capiteLivello di soddisfazione\n",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#7": "Richiami: Simple Linear Regression Model\nI parametri del modello lineare sono \n w\n0\n e \nw\n1\n. \nAttenzione: non esiste un formalismo standard per rappresentare i \nparametri, a volte si impiega \n θ\n o altri simboli. \nI parametri del modello lineare sono \n w\n0\n e \nw\n1\n.  \nAdattando tali valori possiamo deﬁnire qualsiasi modello lineare.\n8yi=w0+w1xi+✏i\nˆyi=f(xi)=w0+w1xiy\nx\nPIL pro capiteLivello di soddisfazione",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#8": "Tipicamente is impiega una misura di costo basata sulla distanza tra valore \nesatto e valore determinato dal modello, come la \n Residual Sum of Squares  \n(RSS), sempre positiva, chiamata anche \n Sum of Squared Residuals\n  (SSR) o \nSum of Squared estimate of Errors\n  (SSE): \nValori prossimi allo \n 0\n indicano un modello ideale. \nLa \nMean Square Error \n (MSE), chiamata anche \n Mean Squared Deviation  \n(MSD), corrisponde alla RSS normalizzata sul numero di campioni.  \nÈ utile per valutare il modello ﬁnale dopo l'addestramento.\nRichiami: funzione di costo\n9RSS( w0,w1)=NX\ni=1(yi\u0000ˆyi)2=NX\ni=1[yi\u0000(w0+w1xi)]2",
    "data_test\\rootfolder\\università\\MachineLearning\\12-Ex_02 Esercitazione su Regressione-sbloccato.pdf#9": "È la libreria con licenza aperta (BSD) più conosciuta di machine learning in \nPython. La prima release risale al 2010.  \nhttps://scikit-learn.org/stable/   \nInclude gli algoritmi più popolari di classiﬁcazione, regressione, clustering \n(es. support-vector machines, random forests, gradient boosting, k-means e \nDBSCAN). \nAlcune parti del codice sono state scritte in modo altamente efﬁciente con \nvarie tecnologie (vedi Cython) \nÈ facilmente interfacciabile con altre librerie per la gestione e il calcolo \nnumerico di dati, es. NumPy (algebra lineare), SciPy (ottimizzazione, \nalgebra lineare, analisi dei segnali, etc) e Pandas.\nRichiami: la libreria Scikit-learn\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Regressione e Classiﬁcazione (Ex03)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#1": "Sommario\nRichiami: Classiﬁcazione e Regressione, overﬁtting, underﬁtting \n4 datasets: Forge, Wave, Wisconsin breast cancer, Boston housing \nClassiﬁcazione k-Neighbors e Scikit-learn, decision boundaries \nMisura R\n2 \nk-Neighbors regression e Scikit-learn \nEsercizi su linear, Ridge e LASSO regressioni su vari dataset",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#10": "Regression: Boston housing dataset\nIl dataset di 506 istanze mira a predire il costo degli immobili residenziali in \nvari quartieri di Boston nel 1970, impiegando 13 features (es. il tasso di \ncrimine, vicinanza al ﬁume, accessibilità alle autostrade). \nfrom \nsklearn.datasets \n import \nload_boston\nboston \n= \nload_boston\n ()\nprint\n(\n\"Data shape: {}\"\n .\nformat\n(\nboston\n.\ndata\n.\nshape\n))\n> Data shape: (506, 13)\nÈ possibile combinare due o più features creandone ulteriori non presenti nel \ndataset originale, attività che rientrano nella fase di \n feature engineering, \n dove \nsi identiﬁcano o costruiscono le caratteristiche salienti. \nIn questo esempio combiniamo 2 features alla volta: \nX\n, \ny \n= \nmglearn\n.\ndatasets\n .\nload_extended_boston\n ()\nprint\n(\n\"X.shape: {}\"\n .\nformat\n(\nX\n.\nshape\n))\n> X.shape: (506, 104)\nOra abbiamo 104 features, ottenute dalle 13 originali con tutte le 91 possibili \ncombinazioni di coppie.\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#11": "Classiﬁcazione k-Neighbors (k-NN)\nNel caso più semplice l'algoritmo k-NN considera solo 1 vicino (k=1), che \nrisulta il più vicino all'istanza su cui vogliamo esprimere una predizione. \nmglearn\n.\nplots\n.\nplot_knn_classification\n (\nn_neighbors\n =\n1\n)\nPer k=3: \nmglearn\n.\nplots\n.\nplot_knn_classification\n (\nn_neighbors\n =\n3\n)\nPer il forge dataset otteniamo:\n12\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#12": "Esercizio: Scikit-learn, k-NN e valutazione\nLa libreria Scikit-learn rende disponibile la classe \n KNeighborsClassiﬁer\n  per \ncreare modelli basati sull'algoritmo k-NN. \nLa funzione \n score\n ()\n valuta l'accuracy media, cioè il numero di label \ncorrettamente stimate rispetto al totale delle istanze valutate. \nfrom \nsklearn.neighbors \n import \nKNeighborsClassifier\nmodel \n= \nKNeighborsClassifier\n (\nn_neighbors\n =\n3\n)\nmodel\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Test set accuracy: {:.2f}\"\n .\nformat\n(\nclf\n.\nscore\n(\nX_test\n, \ny_test\n)))\nEsercizio\n : (1) prendere il dataset forge, (2) creare una partizione training/\ntest, (3) addestrare un classiﬁcatore KNeighborsClassiﬁer  \ne (4) valutarne \nl'accuratezza. \n13",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#13": "k-NN e decision boundaries\nIn presenza di 2 features è possibile rappresentare su un piano \n 2d\n la classe \nche verrebbe assegnata dal modello per ogni punto del piano, così da \nriconoscere il conﬁne tra una label e l'altra. Sfruttiamo la libreria \n mglearn\n : \nfig\n, \naxes \n= \nplt\n.\nsubplots\n (\n1\n, \n3\n, \nfigsize\n=\n(\n10\n, \n3\n))\nfor \nn_neighbors\n , \nax \nin \nzip\n([\n1\n, \n3\n, \n9\n], \naxes\n):\n \n clf \n= \nKNeighborsClassifier\n (\nn_neighbors\n =\nn_neighbors\n )\n.\nfit\n(\nX\n, \ny\n)\n  \nmglearn\n.\nplots\n.\nplot_2d_separator\n (\nclf\n, \nX\n, \nfill\n=\nTrue\n, \neps\n=\n0.5\n, \nax\n=\nax\n, \nalpha\n=.\n4\n)\n  \nmglearn\n.\ndiscrete_scatter\n (\nX\n[:, \n0\n], \nX\n[:, \n1\n], \ny\n, \nax\n=\nax\n)\n  \nax\n.\nset_title\n (\n\"{} neighbor(s)\"\n .\nformat\n(\nn_neighbors\n ))\n  \nax\n.\nset_xlabel\n (\n\"feature 0\"\n )\n  \nax\n.\nset_ylabel\n (\n\"feature 1\"\n )\naxes\n[\n0\n]\n.\nlegend\n(\nloc\n=\n3\n)\nQuali considerazioni possiamo fare?\n14\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#14": "k-NN e decision boundaries\n1-NN segue in modo migliore i dati di addestramento.  \nPer k > 1 crea un conﬁne più \"dolce\" e un modello più semplice.  \nCosa succede se k corrisponde al numero di istanze del dataset?\n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#15": "k-NN e decision boundaries\n1-NN segue in modo migliore i dati di addestramento.  \nPer k > 1 crea un conﬁne più \"dolce\" e un modello più semplice.  \nCosa succede se k corrisponde al numero di istanze del dataset?  \nTutte le istanze avrebbero lo stesso neighbors e le predizioni sarebbero \nsempre le stesse.\n16\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#16": "Esercizio: studio dell'accuracy\nColleziona le accuracy del classiﬁcatore KNeighborsClassiﬁer sul training \nset sia sul test set, al variare di k in [1,10], e valuta gli andamenti. \nfrom \nsklearn.datasets \n import \nload_breast_cancer\ncancer \n= \nload_breast_cancer\n ()\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\ncancer\n.\ndata\n, \ncancer\n.\ntarget\n, \nstratify\n =\ncancer\n.\ntarget\n, \nrandom_state\n =\n66\n)\ntraining_accuracy \n = \n[]\ntest_accuracy \n = \n[]\n...\nplt\n.\nplot\n(\nneighbors_settings\n , \ntraining_accuracy\n , \nlabel\n=\n\"training accuracy\"\n )\nplt\n.\nplot\n(\nneighbors_settings\n , \ntest_accuracy\n , \nlabel\n=\n\"test accuracy\"\n )\nplt\n.\nylabel\n(\n\"Accuracy\"\n )\nplt\n.\nxlabel\n(\n\"n_neighbors\"\n )\nplt\n.\nlegend\n()\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#17": "Esercizio: studio dell'accuracy\nCon k=1 si ha una accuracy massima per il training set. Con \n k\n più grandi la \ncomplessità del modello si riduce e l'accuracy decrementa. \nAl contrario, con \n k=1 \nl'accuracy sul test set è più bassa (circa 0.90), \nsintomo che il modello è \n troppo complesso\n . Allo stesso modo con \n k\n elevati \nl'accuracy \n non è soddisfacente \n poiché il  \nmodello è \n troppo semplice\n . \nPer questo dataset un valore ottimale si ottiene intorno a k=6. \nAttenzione:  solitamente i graﬁci non sono sempre così \n smooth\n .\n18\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#18": "k-neighbors regression\nRichiami: per \n k=1\n, il valore predetto corrisponde al valore associato \nall'istanza più vicina. Nel caso k > 1, si mediano i valori. \nmglearn\n.\nplots\n.\nplot_knn_regression\n (\nn_neighbors\n =\n1\n)\n19\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#19": "k-neighbors regression (2)\nRichiami: per \n k=1\n, il valore predetto corrisponde al valore associato \nall'istanza più vicina. Nel caso k > 1, si mediano i valori. \nmglearn\n.\nplots\n.\nplot_knn_regression\n (\nn_neighbors\n =\n3\n)\n20\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#2": "Richiami: classiﬁcazione e regressione\nFinora abbiamo visto problemi di regressione, dove si richiede di predire \nun valore numerico a partire da una istanza in ingresso. \nL'obiettivo della classiﬁcazione è assegnare una \n label\n ad una istanza in \ningresso.  \nSe le label sono due si parla di \n binary classiﬁcation\n , altrimenti \n multiclass\n . \nIl dataset \n iris\n è un esempio di multiclass classiﬁcation. \nUn modello ben addestrato mostra la capacità di generalizzare sui dati del \ntest set, e in fase di produzione. \nChiaramente se training set e test set hanno molte caratteristiche in \ncomune, allora ci aspettiamo che il modello addestrato, se ben progettato, \nsia anche accurato.\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#20": "Performance: la misura \n R\n2\n21\nR\n2\n è il \ncoefﬁciente di determinazione\n , e indica la porzione di varianza della \nvariabile y correttamente predetta dal modello (cioè dalle features impiegate), \nperciò è una misura di accuratezza. \nAssume valori in [0,1]. Per valori prossimi a \n 1\n il modello predice \naccuratamente il valore della variabile dipendente \n y\n in base al valore delle \nfeatures.  \nAd esempio: per \n R\n2\n=0.83, il 17% della variazione nei dati non è rappresentato dal \nmodello, o perché è dovuto al caso, o perché dipende da un features che non sono stata \nconsiderate. \nPer valori vicini a 0, il modello si comporta come un predittore che assume \nsempre il valor medio come output, perciò non tiene conto della varianza \nLa funzione \n score()\n  del modello Python valuta il valore \n R\n2\n sui dati in input.R2=1−RSS\n∑N\ni=1(yi−¯y)2=1−∑N\ni=1(yi−̂yi)2\n∑N\ni=1(yi−¯y)2=∑N\ni=1(̂yi−¯y)2\n∑N\ni=1(yi−¯y)2",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#21": "scikit-learn: k-neighbors regression\nLa classe KNeighborsRegressor implementa l'algoritmo di regressione k-neighbors. \nIl parametro \n n_neighbors\n  corrisponde a \n k\n. \nreg \n= \nKNeighborsRegressor\n (\nn_neighbors\n =\nk\n)\nEsercizio\n : completa il codice con la classe suddetta e valuta i graﬁci che ottieni:  \nfig\n, \naxes \n= \nplt\n.\nsubplots\n (\n1\n, \n3\n, \nfigsize\n=\n(\n15\n, \n4\n))\n# create 1,000 data points, evenly spaced between -3 and 3\nline \n= \nnp\n.\nlinspace\n (\n-\n3\n, \n3\n, \n1000\n)\n.\nreshape\n(\n-\n1\n, \n1\n)\n# make predictions using 1, 3, or 9 neighbors\nfor \nn_neighbors\n , \nax \nin \nzip\n([\n1\n, \n3\n, \n9\n], \naxes\n):\n...\nax\n.\nplot\n(\nline\n, \nreg\n.\npredict\n(\nline\n))\nax\n.\nplot\n(\nX_train\n, \ny_train\n, \n'^'\n, \nc\n=\nmglearn\n.\ncm2\n(\n0\n), \nmarkersize\n =\n8\n)\nax\n.\nplot\n(\nX_test\n, \ny_test\n, \n'v'\n, \nc\n=\nmglearn\n.\ncm2\n(\n1\n), \nmarkersize\n =\n8\n)\nax\n.\nset_title\n (\n\"{} neighbor(s)\\n train score: {:.2f} test score: {:.2f}\"\n .\nformat\n(\nn_neighbors\n , \nreg\n.\nscore\n(\nX_train\n, \ny_train\n),\nreg\n.\nscore\n(\nX_test\n, \ny_test\n)))\nax\n.\nset_xlabel\n (\n\"Feature\"\n )\nax\n.\nset_ylabel\n (\n\"Target\"\n )\naxes\n[\n0\n]\n.\nlegend\n([\n\"Model predictions\"\n , \n\"Training data/target\"\n ,\n         \n \"Test data/target\"\n ], \nloc\n=\n\"best\"\n)\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#22": "scikit-learn: k-neighbors regression\nConsiderando più istanze durante la predizione si ottiene chiaramente una \ncurva più \n smooth\n .\n23\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#23": "k-NN nella pratica\nL'algoritmo ha due parametri principali: \n k\n e la \n misura di distanza\n . \nIn generale, si possono usare bassi valori per \n k\n (es. 5) sebbene occorra \nsperimentare il valore esatto in base al dataset.  \nLa \nmisura euclidea\n  si adatta bene in molti scenari. \nIl k-NN è spesso la scelta iniziale per la sua semplicità, ma in alcuni \ncontesti non è adatto: \nPer training set molto grandi (numero di istanze e/o features) che \ncausano tempi di predizione lenti, a meno di non precomputare \nl'output in una fase preliminare prima di impiegare l'algoritmo in \nproduzione. \nDataset sparsi, cioè con features spesso senza valore.\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#24": "Esercizio: linear regression e wave dataset\nEsercizio\n : applicare la \n linear regression\n  al wave dataset con 60 istanze. \nRicavare i parametri del modello. Valutare il valore \n R\n2\n.\n25",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#25": "Esercizio: linear regression e wave dataset\nEsercizio\n : applicare la \n linear regression\n  al wave dataset con 60 istanze. \nRicavare i parametri del modello. Valutare il valore \n R\n2\n. \nfrom \nsklearn.linear_model \n import \nLinearRegression\nX\n, \ny \n= \nmglearn\n.\ndatasets\n .\nmake_wave\n (\nn_samples\n =\n60\n)\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\nX\n, \ny\n, \nrandom_state\n =\n42\n)\nlr \n= \nLinearRegression\n ()\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"lr.coef_: {}\"\n .\nformat\n(\nlr\n.\ncoef_\n))\nprint\n(\n\"lr.intercept_: {}\"\n .\nformat\n(\nlr\n.\nintercept_\n ))\n> lr.coef_: [ 0.394]\n> lr.intercept_: -0.031804343026759746\nprint\n(\n\"Training set score: {:.2f}\"\n .\nformat\n(\nlr\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Test set score: {:.2f}\"\n .\nformat\n(\nlr\n.\nscore\n(\nX_test\n, \ny_test\n)))\n> Training set score: 0.67\n> Test set score: 0.66\nNota: coef_ è di tipo NumPy array, avendo dimensione pari al numero di \nfeatures per istanza. \nCosa possiamo dire con i valori di performance ottenuti?\n26",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#26": "Esercizio: linear regression e wave dataset\n> Training set score: 0.67\n> Test set score: 0.66\nSono valori piuttosto bassi.  \nI valori sul training e test set sono molto simili, sintomo di \n underﬁtting\n .  \nPer modelli lineari e dataset semplici (es. mono-dimensionali) esiste un \nrischio minore di fare overﬁtting data la semplicità del modello. \nEsercizio\n : prova lo stesso approccio con il Bostong housing dataset e \nconfronta le performance.\n27",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#27": "Esercizio: linear regression e wave dataset\nEsercizio\n : prova lo stesso approccio con il Bostong housing dataset e \nconfronta le performance.  \nX\n, \ny \n= \nmglearn\n.\ndatasets\n .\nload_extended_boston\n ()\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\nX\n, \ny\n, \nrandom_state\n =\n0\n)\nlr \n= \nLinearRegression\n ()\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Training set score: {:.2f}\"\n .\nformat\n(\nlr\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Test set score: {:.2f}\"\n .\nformat\n(\nlr\n.\nscore\n(\nX_test\n, \ny_test\n)))\n> Training set score: 0.95\n> Test set score: 0.61\nLa differenza tangibile tra training e test set è sintomo di overﬁtting. \nOccorre adattare il modello. \n28",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#28": "Richiami: Ridge regression\nNella \n ridge regression\n  si implementa un forma semplice di \nregolarizzazione\n , cioè tecniche per affrontare il problema del overﬁtting. \nI parametri \n w\n del modello lineare devono rispettare un vincolo \naggiuntivo: il valore assoluto dei singoli parametri deve essere piccolo.  \nIntuitivamente:\n  ogni feature può avere un effetto limitato sul valore \npredetto dal modello. \nPrende il nome di L2 regularization. \nLa funzione che rappresenta il costo nella ridge è la seguente:\n29\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#29": "Scikit-learn: Ridge regression\nLa classe \n Ridge\n  nel modulo sklearn.linear_model implementa la ridge \nregression: \nclf \n=\n Ridge(alpha\n =\n1.0\n) \nIl parametro \n λ\n che controlla il peso della regolarizzazione è deﬁnito \nmediante il parametro \n alpha,\n  che per default assume valore 1. \n30",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#3": "Richiami: overﬁtting e underﬁtting\nSupponiamo di avere il seguente dataset che rappresenta la possibilità che \nun cliente acquisti una barca in base a certe sue caratteristiche: \nSe guardi questi dati, che proﬁlo di cliente potenzialmente interessato a \ncomprare puoi identiﬁcare dalle features riportate?\n4\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#30": "Esercitazione: Ridge regression\nEsercizio\n : impiegare la ridge regression nel Boston housing dataset.  \nCosa ti aspetti dalle performance che ottieni rispetto alla linear regression \nsenza regolarizzazione? \nEsercizio\n : ricava gli score per \n λ\n pari a 0.1 e 10. Cosa ti aspetti? \nEsercizio\n : crea un graﬁco 2d dove visualizzi i parametri dei tre modelli \nridge\n , \nridge10\n  e \nridge01\n . Cosa ti aspetti nella distribuzione dei parametri? \nEsercizio\n : Come pensi che vari lo score \n R\n2\n, sul training e sul test set, al \nvariare del numero di istanze usate durante l'addestramento?\n31",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#31": "Richiami: LASSO\nNel modello \n LASSO\n  si impiega la \n L1-regularization\n , dove alcuni parametri \nassumono valore esattamente pari a 0, ignorando perciò alcune features. \nPuò essere interpretato come una sorta di \n feature selection\n , cioè un \nprocesso per selezionare le feature più rilevanti nel task in esame. \nIl vantaggio è avere un modello più semplice, più veloce da addestrare, che \nconsidera solo le features più rilevanti.\n32\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#32": "Scikit-learn: LASSO\nLa classe \n Lasso\n  nel modulo sklearn.linear_model implementa il modello \nLASSO:  \nclf \n=\n Lasso(alpha\n =\n1.0\n) \nIl parametro \n λ\n che controlla il peso della regolarizzazione è deﬁnito \nmediante il parametro alpha, che per default assume valore 1. \nEsercizio\n : impiegare LASSO nel Boston housing dataset. Cosa ti aspetti \ndalle performance che ottieni rispetto alla linear e Ridge regression?\n33",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#33": "Esercitazione: LASSO\nEsercizio\n : impiega LASSO nel Boston housing dataset \nEsercizio\n : prova a variare nuovamente \n λ\n per migliorare le performance. \n34",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#34": "Ridge e LASSO: considerazioni\nSolitamente si impiega la Ridge come primo approccio.  \nNel caso ci siano molte features, ma solo un sottoinsieme verosimilmente \nrilevanti, LASSO risulta la scelta migliore. \nLASSO inoltre produce modelli più semplici e più facilmente interpretabili \nrispetto a Ridge, utile per investigare il dataset nelle fasi iniziali. \nScikit-learn implementa la classe \n ElasticNet\n  che combina i due approcci e \nottiene ottime performance, ma con due iperparametri da impostare, uno \nper L1 e uno per L2 regularization.\n35",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#35": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n36",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#4": "Richiami: overﬁtting e underﬁtting (2)\nCliente di \n 45 anni o più\n , \nmeno di 3 ﬁgli\n  o \nnon divorziato\n . \nQuesta \"regola\" è al \n 100%\n  accurata. \nMa una regola sull'età del tipo età=66 OR 52 OR 53 OR 58 è altrettanto \naccurata. \nDobbiamo ricordarci che il modello dovrà funzionare altrettanto \naccuratamente su dati mai visti in precedenza. \nLe regole che abbiamo escogitato sembrano funzionare, ma sono troppo \nspeciﬁche per le istanze del nostro dataset. Se nel test set abbiamo istanze \nsimili, allora questo semplice modello può funzionare, ma non è detto che \nfunzioni anche in produzione.\n5",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#5": "Richiami: overﬁtting e underﬁtting (3)\nIl nostro obiettivo è sempre trovare il modello più semplice che abbia \nbuone performance anche sul test set. \nCostruire un modello troppo complesso rispetto ai dati disponibili crea \noverﬁtting\n .  \nIl modello è troppo speciﬁco per le istanze nel training set ma non è capace di \ngeneralizzare sui dati nel test set. \nUn modello troppo semplice rispetto ai dati disponibili può creare \nfenomeni di \n underﬁtting\n , cioè scarse performance perﬁno nel training set \npoiché non riesce a catturare tutte le caratteristiche e legami tra le features.\n6\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#6": "4 datasets\nIntroduciamo 4 datasets utili per osservare come si comportano diversi \nalgoritmi di machine learning implementati in scikit-learn. \nForge dataset\n  (classiﬁcazione) \nwave dataset\n  (regressione) \nWisconsin Breast Cancer dataset\n  (classiﬁcazione) \nBoston housing dataset\n  (regressione)\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#7": "Classiﬁcazione: Forge dataset\n26 istanze, 2 features per istanza, e 2 classi: \n# codice per ottenere il dataset\nX\n, \ny \n= \nmglearn\n.\ndatasets\n .\nmake_forge\n ()\n# grafico le istanze\nmglearn\n.\ndiscrete_scatter\n (\nX\n[:, \n0\n], \nX\n[:, \n1\n], \ny\n)\nplt\n.\nlegend\n([\n\"Class 0\"\n , \n\"Class 1\"\n ], \nloc\n=\n4\n)\nplt\n.\nxlabel\n(\n\"First feature\"\n )\nplt\n.\nylabel\n(\n\"Second feature\"\n )\nprint\n(\n\"X.shape: {}\"\n .\nformat\n(\nX\n.\nshape\n))\n8\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#8": "Regressione: wave dataset\nSingola feature per istanza, singolo valore reale in output. \nX\n, \ny \n= \nmglearn\n.\ndatasets\n .\nmake_wave\n (\nn_samples\n =\n40\n)\nplt\n.\nplot\n(\nX\n, \ny\n, \n'o'\n)\nplt\n.\nylim\n(\n-\n3\n, \n3\n)\nplt\n.\nxlabel\n(\n\"Feature\"\n )\nplt\n.\nylabel\n(\n\"Target\"\n )\nPer dataset così piccoli è sempre utile studiare le caratteristiche delle \nistanze su graﬁci.\n9\n",
    "data_test\\rootfolder\\università\\MachineLearning\\13-Ex_03 Esercitazione su Regressione-sbloccato.pdf#9": "Classiﬁcazione: Wisconsin Breast Cancer dataset\nMisure cliniche associate a patologie tumorali, con label '\n benigno\n ' '\nmaligno\n '  \nfrom \nsklearn.datasets \n import \nload_breast_cancer\ncancer \n= \nload_breast_cancer\n ()\nprint\n(\n\"cancer.keys(): \\n{}\"\n .\nformat\n(\ncancer\n.\nkeys\n()))\n> cancer.keys():\n> dict_keys(['feature_names', 'data', 'DESCR', 'target', 'target_names'])\nprint\n(\n\"Shape of cancer data: {}\"\n .\nformat\n(\ncancer\n.\ndata\n.\nshape\n))\n> Shape of cancer data: (569, 30)\nprint\n(\n\"Sample counts per class:\\n{}\"\n .\nformat\n(\n{\nn\n: \nv \nfor \nn\n, \nv \nin \nzip\n(\ncancer\n.\ntarget_names\n , \nnp\n.\nbincount\n (\ncancer\n.\ntarget\n))}))\n> Sample counts per class: {'benign': 357, 'malignant': 212}\nprint\n(\n\"Feature names:\\n{}\"\n .\nformat\n(\ncancer\n.\nfeature_names\n ))\n> Feature names:\n['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n'mean smoothness' 'mean compactness' 'mean concavity'\n'mean concave points' 'mean symmetry' 'mean fractal dimension'\n'radius error' 'texture error' 'perimeter error' 'area error'\n'smoothness error' 'compactness error' 'concavity error'\n'concave points error' 'symmetry error' 'fractal dimension error'\n'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n'worst smoothness' 'worst compactness' 'worst concavity'\n'worst concave points' 'worst symmetry' 'worst fractal dimension']\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nClassiﬁcazione:  \nAlberi di Decisione\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#1": "Sommario\nIntroduzione ai Decision Trees \nEsempio di applicazione \nFeature split learning \nDecision Stump \nAlgoritmo greedy decision tree learning \nClassiﬁcazione mediante Decision Trees\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#10": "Learning Goal \n \n11\nIl nostro obiettivo è dunque quello di costruire un albero di \ndecisione che minimizzi il Classiﬁcation Error sui dati di \ntraining, calcolato mediante la metrica di qualità che \nabbiamo deﬁnita. \nPurtroppo questo è un task estremamente difﬁcile: \n•abbiamo un numero esponenziale di possibili alberi da considerare  \n•problema NP-hard \n•possiamo però utilizzare delle euristiche che funzionano bene in \npratica",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#11": "Algoritmo greedy  \ndecision tree learning \n1. Cominciamo da un albero “vuoto” e consideriamo tutti gli esempi \ndisponibili. \n2. Selezioniamo la feature “migliore” con la quale possiamo \npartizionare (split) i dati in base ai diversi valori che essa può assumere. \n3. Per ogni split: \n•\nSe non ci sono altre operazioni da fare, costruire foglia con la \nprevisione. \n•\nAltrimenti, continua la costruzione dell’albero a partire dallo \nsplit che stiamo considerando. \n \n12Vediamo informalmente come poter procedere per costruire un albero di \ndecisione:",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#12": "Algoritmo greedy  \ndecision tree learning \n1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi \ndisponibili. \n2. Selezioniamo la feature “migliore” con la quale possiamo \npartizionare (split) i dati in base ai vari valori che essa può assumere. \n3. Per ogni split: \n•\nSe non ci sono altre operazioni da fare, costruire foglia con la \nprevisione. \n•\nAltrimenti, continua la costruzione dell’albero a partire dallo \nsplit che stiamo considerando. \n \n13Primo problema:\nfeature\n selection",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#13": "Algoritmo greedy  \ndecision tree learning \n1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi \ndisponibili. \n2. Selezioniamo la feature “migliore” con la quale possiamo \npartizionare (split) i dati in base ai vari valori che essa può assumere. \n3. Per ogni split: \n•\nSe non ci sono altre operazioni da fare, costruire foglia con la \nprevisione. \n•\nAltrimenti, continua la costruzione dell’albero a partire dallo \nsplit che stiamo considerando. \n \n14Secondo problema:\nstopping conditions",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#14": "Algoritmo greedy  \ndecision tree learning \n1. Cominciamo da un albero “vuoto”. Consideriamo tutti gli esempi \ndisponibili. \n2. Selezioniamo la feature “migliore” con la quale possiamo \npartizionare (split) i dati in base ai vari valori che essa può assumere. \n3. Per ogni split: \n•\nSe non ci sono altre operazioni da fare, costruire foglia con la \nprevisione. \n•\nAltrimenti, continua la costruzione dell’albero a partire dallo \nsplit che stiamo considerando. \n \n15Chiamata ricorsiva:\nchiamata ricorsiva",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#15": "Predizioni con Decision Stump \n[feature selection]\n \n1622  18\nSicuroRoot node: relativo a tutte le osservazioni. \n22: output “Sicuro” \n18: output “Rischioso” \nOra dobbiamo selezionare una feature  \n(feature selection problem)",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#16": "Predizioni con Decision Stump \n[feature: Reputazione]\n \n17Reputazione22  18\nSicuroScarsa EccellenteSufﬁciente\n9    0 9    4 4    14Se scegliamo “Reputazione”:",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#17": "Decision Stump \n[feature: Reputazione]\n \n18SicuroReputazione22  18\nRischioso SicuroScarsa EccellenteSufﬁciente\n9    0 9    4 4    14\nset  ŷ = “majority value” ",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#18": "Decision Stump \n[feature: Reputazione]\n \n19SicuroReputazione22  18\nRischioso SicuroScarsa EccellenteSufﬁciente\n9    0 9    4 4    14\n0 errori 4 errori 4 errori",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#19": "Decision Stump \n[feature: Durata]\n \n20SicuroDurata22  18\nRischioso5 anni 3 anni\n16    4 6    14Se scegliamo “Durata”:\n4 errori 6 errori",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#2": "Alberi di Decisione \nVediamo ora un altro metodo per la classiﬁcazione, molto \nutile nella pratica. \nUn albero di decisione prende come ingresso un oggetto o \nuna situazione descritta da un insieme di attributi (features) e \nrestituisce una “decisione”. \nEffettua dunque una “classiﬁcazione” della situazione \npresentata in input.  \n \n3",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#20": "Selezione della migliore feature \n[feature selection]\n \n21SicuroDurata22  18\nRischioso5 anni 3 anni\n16    4 6    14\nSicuroReputazione22  18\nRischioso SicuroScarsa EccellenteSufﬁciente\n9    0 9    4 4    14Dobbiamo deﬁnire un criterio per la scelta della migliore feature:\nvs.",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#21": "Selezione della migliore feature \n[feature selection]\n \n22SicuroDurata22  18\nRischioso5 anni 3 anni\n16    4 6    14\nSicuroReputazione22  18\nRischioso SicuroScarsa EccellenteSufﬁciente\n9    0 9    4 4    14\n0 errori 4 errori 4 errori 4 errori 6 erroriPer far questo consideriamo gli errori già visti in precedenza …….\nvs.",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#22": " \n23SicuroDurata22  18\nRischioso5 anni 3 anni\n16    4 6    14\nSicuroReputazione22  18\nRischioso SicuroScarsa EccellenteSufﬁciente\n9    0 9    4 4    14\n0 errori 4 errori 4 errori 4 errori 6 errori…… e usiamoli per calcolare il Classiﬁcation Error per ogni feature:\nvs.4+4\n22 + 18=0 .24+6\n22 + 18=0 .25\nScegliamo la feature con il Classiﬁcation Error più basso.\nSelezione della migliore feature \n[feature selection]",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#23": "Calcolo Classiﬁcation Error \nAbbiamo dunque diviso il calcolo del Classiﬁcation Error in \ndue fasi: \n1.\n Per ogni nodo relativo ad un sottoinsieme dei dati, ottenuto \nconsiderando uno dei possibili valori della feature \nd’interesse, assegniamo il valore della majority class del \nnodo (\n ŷ\n = “majority class”). \n2.\n Calcolo del Classiﬁcation Error considerando come  \npredizione per ogni nodo considerato quella assegnata nel \npasso precedente. \n \n24",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#24": "Algoritmo per  \nFeature Split Selection \nDato un sottoinsieme M di osservazioni disponibili (nodo \ndell’albero): \n• \n∀\n feature \n ɸ\nj\n(\nx\n): \n•\n Split dei dati M in  base ai valori della feature \n ɸ\nj\n(\nx\n). \n•\n Calcolo del Classiﬁcation Error per il Decision Stump \ndella feature \n ɸ\nj\n(\nx\n). \n•\n Scelta della feature \n ɸ\nj*\n(\nx\n) con il Classiﬁcation Error più \nbasso. \n \n25",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#25": "Tree Learning \n[recursive stump learning]\n \n26SicuroReputazione22  18\nScarsa EccellenteSufﬁciente\n9    0 9    4 4    14\ncostruire un decision \nstump con il sotto-\ninsieme dei dati in cui: \nReputazione = Sufﬁciente costruire un decision \nstump con il sotto-\ninsieme dei dati in cui: \nReputazione = Scarsa \nfoglia dell’alberoLa costruzione dell’albero si effettua come segue:",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#26": "Tree Learning \n[secondo livello]\n \n27SicuroReputazione22  18\nScarsa EccellenteSufﬁciente\n9     0 9     4 4    14\nDurata\nRischioso Sicuro3 anni 5 anni\n0     4 9     0",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#27": "Tree Learning \n[secondo livello]\n \n28SicuroReputazione22  18\nScarsa EccellenteSufﬁciente\n9     0 9     4 4    14\nDurata\nRischioso Sicuro3 anni 5 anni\n0     4 9     0Reddito\nRischiosoAlto Modesto\n0     9 4     5\naltro \ndecision \nstump",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#28": "Tree Learning \n[terzo livello]\n \n29Scarsa\n4    14\nReddito\nRischiosoAlto Modesto\n0     9 4     5\nSicuro RischiosoDurata\n3 anni 5 anni\n0     2 4     3",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#29": "Tree Learning \n[stopping conditions]\n \n30Scarsa\n4    14\nReddito\nRischiosoAlto Modesto\n0     9 4     5\nSicuro RischiosoDurata\n3 anni 5 anni\n0     2 4     3 stopping conditions?",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#3": "Esempio di applicazione \n[valutazione richiesta prestito]\n \n4Richiesta \nPrestitoModello di \nClassiﬁcazioneSicuro\nRischioso\nInput: xi(Output: y i = +1)\n(Output: y i = -1)\nVediamo un esempio di applicazione, relativo alla \nvalutazione di richieste di prestito da parte di un cliente alla \npropria banca:",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#30": "Stopping Conditions \nLa costruzione di un ramo dell’albero si ferma quando arriviamo \nad un nodo nel quale si veriﬁca una delle seguenti condizioni: \n1.\n Gli esempi relativi al nodo sono tutti di uno stesso tipo (e.g., \ntutti \nSicuro\n  o tutti \n Rischioso\n ): scegliamo come foglia il valore in \nquestione. \n2.\n Gli esempi relativi al nodo sono di tipo diverso, e non ci sono \npiù feature da considerare: scegliamo come foglia il majority \nvalue. \n3.\n Nel nodo non ci sono più esempi, ma c’è ancora qualche \nfeature non considerata nel percorso che porta a quel nodo: \nvalore di default (e.g., maggioranza nodo genitore). \n \n31",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#31": "Algoritmo greedy decision tree \nlearning \n1. Start da un nodo relativo a M esempi \n2. Feature Selection \n3. Per ogni split: \nif\n  Stopping Condition \nthen\n: costruire la foglia con la previsione \n ŷ \nelse\n:  decision_tree_learning(nodo relativo allo split) \n \n32decision_tree_learning (nodo) \nChiamata RicorsivaNon ci sono altre \noperazioni da fareSelezione Feature  \nper dividere i dati",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#32": "Algoritmo per fare previsioni \nmediante Decision Tree \nVediamo ora il semplice algoritmo che implementa la funzione \nT(\nx\n), ossia l’algoritmo che, a fronte di un ingresso \n x\ni\n, visita l’albero \ndi decisione costruito nella fase di training e fornisce in output una \nprevisione \n ŷ\ni\n: \n \n33 \nif\n tree_node corrente è una foglia \n         \n then\n: \nreturn\n  majority class dei punti relativi alla foglia \n        \n else\n: \n•\nnext_node = ﬁglio di tree_node il cui valore della feature \ncorrisponde all’input \n•\nreturn\n  predict(next_node, input) predict (tree_node, input) ",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#33": "Riferimenti\n \n34\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , 3a edizione, \nApogeo, 2015. \nMachine Learning: Classiﬁcation\n , University of Washington - Coursera, 2017. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. ",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#4": "Esempio di applicazione \nNel formulare questo problema come un problema di \napprendimento dobbiamo anzitutto decidere quali proprietà, \no attributi (features), sono disponibili per descrivere esempi \n(osservazioni) nel dominio. \nIn genere, alcune delle caratteristiche prese in considerazione \ni tali casi sono le seguenti: \n•\n  reputazione cliente (e.g., ha pagato regolarmente vecchi prestiti?) \n•\nreddito cliente \n•\ndurata prestito  \n•\n  altre informazioni personali (età, motivo per il prestito, ecc.)  \n \n5",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#5": "Decision Tree Classiﬁer \n \n6Sicuro Durata RedditoReputazioneStart\nSicuro RischiosoRischioso Rischioso Sicuro DurataScarsa Eccellente\nSufﬁciente\nAlto Modesto3 anni 5 anni\n3 anni 5 anniEsempio di decision tree per il problema in esame:",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#6": "Valutazione richiesta prestito \n \n7\nSicuro\nDurataRedditoReputazioneStart\nSicuro\nRischioso\nRischioso\nRischioso\nSicuroDurataScarsa\nEccellente\nSufﬁciente\nAlto\nModesto\n3 anni\n5 anni\n3 anni\n5 annixi = (Reputazione = Scarsa , Reddito = Alto, Durata = 5 anni)  ",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#7": " \n8Richiesta \nPrestitoModello di \nClassiﬁcazione\nInput: xiSicuro\nRischioso(Output: y i = +1)\n(Output: y i = -1)\nSicuro Durata RedditoReputazioneStart\nSicuro RischiosoRischioso Rischioso Sicuro DurataScarsa Eccellente\nSufﬁciente\nAlto Modesto3 anni 5 anni\n3 anni 5 anniRichiesta \nPrestitoSicuro\nRischioso(Output: y i = +1)\n(Output: y i = -1) Input: xi\nDecision Tree Model \nT(xi)",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#8": "Apprendimento albero dai dati\n \n9\nReputazione Durata Reddito yi\neccellente 3 anni alto Sicuro\nsufﬁciente 5 anni modesto Sicuro\nsufﬁciente 3 anni alto Rischioso\nscarso 5 anni alto Sicuro\nsufﬁciente 5 anni modesto Sicuro\nscarso 3 anni alto Rischioso\nscarso 5 anni modesto Rischioso\nsufﬁciente 3 anni alto Rischioso\neccellente 3 anni modesto SicuroT(xi)\nVediamo come sia possibile costruire (ossia apprendere) un decision \ntree a partire da un certo numero di osservazioni:  \nMinimizzazione  \nfunzione di costo",
    "data_test\\rootfolder\\università\\MachineLearning\\14-Classification - Decision Trees-sbloccato.pdf#9": "Metrica di Qualità \n[quality metric]\n \n10Errore =#previsioni errate\n#esempi\nLa metrica che si usa misura la frazione delle previsioni \nerrate fornite dall’albero:\nOvviamente: \n• miglior valore possibile: 0.0 \n• peggior valore possibile: ?",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nClassiﬁcazione:  \nAlgoritmo C4.5",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#1": "Algoritmi Induzione DT\nAlgoritmo Greedy Decision Tree Learning  \n•Scelta della migliore feature utilizzando come metrica il Classification Error  \nsui dati di training —> problema NP-Hard —> servono euristiche \nAlgoritmo C4.5\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#10": "Guadagno\nIntroduciamo ora il Guadagno (Gain)  di un attributo A \nCalcolo di Gain(S,A) per ciascun attributo A \n•Riduzione di Entropia attesa a seguito dell’ordinamento del \nset di istanze S basato su A \nScelta dell’attributo con il valore di Guadagno più elevato \ncome nodo dell’albero \nGain(S,A) = Entropy(S) – Expectation(A)  \n \n \n \ndove {S1 ... Si ... Sn} sono le partizioni di S secondo i valori \ndell’attributo A, n il numero di valori distinti di A, |Si| il \nnumero di istanze nella partizione Si e |S| il numero totale di \nistanze in S)( )( ),(\n1in\niiS EntropySSS Entropy AS Gain ∗ − = ∑\n=\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#11": "Scelta Nodo Radice\nSe Outlook è radice dell’albero ci \nsono 3 partizioni sulle istanze (S1 per \nSunny , S2 per Cloudy, S3 per Rainy ) \nS1 (Sunny) = {istanze 1,2,8,9,11} \n|S1| = 5 (di queste 5 istanze, i \nvalori per Play sono 3 No e 2 Yes) \nEntropy(S1) =  \n= -2/5 (log2 2/5) – 3/5 (log2 3/5) =        \n= -0.4 (-1.322) – 0.6 (-0.737) =  \n= 0.53 +0.44 = 0.97 \nAnalogamente si ottiene  \n Entropy(S2) = 0  \n Entropy(S3) = 0.97 \n 12",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#12": "Scelta Nodo Radice\nGain(S,Outlook) = Entropy(S) – Expectation(Outlook) = \n= Entropy(S) – [|S1|/|S| * Entropy(S1) + |S2|/|S| * Entropy(S2) +  \n+ |S3|/|S| * Entropy(S3)] = 0.94 – [5/14 * 0.97 + 4/14 * 0 + 5/14 * 0.97]  \nda cui si ottiene \nGain(S,Outlook) = 0.247 \nAnalogamente \nGain(S,Temperature) = 0.029 \nGain(S,Humidity) = 0.152 \nGain(S,Windy) = 0.048  \nIn conclusione Gain(S,Outlook)  è il guadagno più elevato e quindi \nOutlook dovrebbe essere scelto come radice dell’Albero di Decisione  \n13",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#13": "Scelta Nodi Successivi \nRipetiamo il procedimento per il ramo \n Sunny\n  …\ntemperatureoutlook\nrainy sunnycloudy\nhot mild cold?\n0    2 1    1 1    04    0\nwindyoutlook\nrainy sunnycloudy\nfalse?\ntrue\n1    2 1    14    0 humidityoutlook\nrainy sunnycloudy\nhigh?\nnormal\n0    3 2    04    0\n14\n",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#14": "Scelta Nodi Successivi \n… e per il ramo Rainy\nhumidityoutlook\nrainy sunnycloudy\nhigh normalMild High False Yes\nCool Normal False Yes\nCool Normal True No\nMild Normal False Yes\nMild High True NoNo Yes Yes \n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#15": "humidityoutlook\nrainy sunnycloudy\ntrue\nNo Yes\nYes normal\nDecision Tree \nwindy\nhigh\nNo Yes falseIn conclusione, si ottiene il seguente Albero di Decisione\n16\nNodi interni = test sugli attributi (feature) \nArchi uscenti = risultati dei test \nNodi foglia = etichette classe di appartenenza",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#16": "Scelta Nodo Radice \nLa selezione dell’attributo come nodo radice è eseguita \nvalutando il Guadagno di Informazione (Information Gain)  per \nciascun attributo e scegliendo quello che dà il valore maggioreQual è l’attributo migliore per essere nodo radice dell’albero?\noutlook\nrainy sunnycloudyhumidity\nlow hightemperature\ncold hotmildwindy\nfalse true\n2     \n34     \n04     \n23     \n13     \n23     \n46     \n12     \n26     \n23     \n3\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#17": "Algoritmo C4.5\nN.B. Pure: all instances in the subset fall in the same classSet di dati (tabella) attributo-valore\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#18": "Algoritmo C4.5\nSalvatore Ruggieri. 2000. Efficient C4.5.  Technical Report. University of \nPisa.  \nAbstract: We present an analytic evaluation  of the run-time behavior  of the \nC4.5 algorithm which highlights some efficiency improvements. We have \nimplemented a more efficient version of the algorithm, called EC4.5, that \nimproves on C4.5 by adopting the best among three strategies at each node \nconstruction. The first strategy uses a binary search of thresholds instead of \nthe linear search of C4.5. The second strategy adopts a counting sort method \ninstead of the quicksort of C4.5. The third strategy uses a main-memory \nversion of the RainForest algorithm for constructing decision trees. Our \nimplementation computes the same decision trees as C4.5 with a \nperformance gain of up to 5 times.\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#19": "Esercizio\nCreare l’Albero di Decisione (Indice) per la  \nPrevisione di Rischio per Richieste di Prestito\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#2": "Algoritmo C4.5\n J. Ross Quinlan. 1993. C4.5: Programs for Machine Learning.   \nMorgan Kaufmann Publishers Inc., San Francisco, CA, USA. \n X. Wu, V. Kumar, J. R. Quinlan , J. Ghosh, Q. Yang, H. Motoda, G. J. \nMcLachlan, A. Ng, B. Liu, P. S. Yu, Z.-H. Zhou, M. Steinbach, D. J. \nHand, and D. Steinberg. 2007. Top 10 Algorithms in Data Mining.  \nKnowledge and Information Systems , Volume 14, Issue 1, December \n2007, Pages 1-37, Springer-Verlag New York, Inc. New York, NY, USA.  \nDOI=http://dx.doi.org/10.1007/s10115-007-0114-2  \n3",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#20": "Esercizio\n21",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#21": "Esercizio\n( ) )( )( ,)( )(log )(\n12\n1\nAn Expectatio S Entropy AS GainS EntropySSAn Expectatiop p S Entropy\nin\niiin\nii\n− =∗ =∗− =\n∑∑\n==\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#22": "Algoritmi Induzione DT\nAlgoritmo Greedy Decision Tree Learning  \n•Scelta della migliore feature utilizzando come metrica il Classification Error \nsui dati di training —> problema NP-Hard —> servono euristiche \nAlgoritmo C4.5  \n•Scelta della migliore feature utilizzando come metrica l’ Information Gain   \nsui dati di training —> problema risolvibile tramite strategia divide&conquer  \n23",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#23": "Algoritmi Induzione DT\nAlgoritmo Greedy Decision Tree Learning  \n•Scelta della migliore feature utilizzando come metrica il Classification Error \nsui dati di training —> problema NP-Hard —> servono euristiche \nAlgoritmo C4.5  \n•Scelta della migliore feature utilizzando come metrica l’ Information Gain   \nsui dati di training —> problema risolvibile tramite strategia divide&conquer \nAlgoritmo CART  \n24",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#24": "Algoritmo CART\nBreiman, Leo; Friedman, J. H.; Olshen, R. A.; Stone, C. J. (1984). \nClassification and Regression Trees.  Monterey, CA: Wadsworth & \nBrooks/Cole Advanced Books & Software. \n25",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#25": "Algoritmo CART\nObiettivo: generare un Albero di Decisione da una Tabella di Dati  \nSi basa sul Gini Index (o Indice di Gini) \nIn corrispondenza di un certo nodo t dell’albero in costruzione, e rispetto alla \ncorrispondente partizione del dataset di training, si definisce l’Indice di Gini \ncome segue: \n \n      dove p(j/t) è la frequenza relativa (proporzione) della classe j  al nodo t  \nL’Indice di Gini misura l’ impurezza ( o disordine)  del dataset corrispondente a t \n•Massimo valore ( 1-1/n c, con nc=numero di classi equiprobabili) quando i \nrecord sono equamente distribuiti fra tutte le classi \n•Minimo valore (0) quando tutti i record appartengono a una sola classeGini(t)=1−∑\nj[p(j/t)]2\n26",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#26": "Indice di Gini\n           \nNel caso di una sola classe: \n                                                     \nNel caso di nc classi equiprobabili \n                                               \n \n       dove n è il numero di record del dataset al nodo tGini(t)=1−∑\nj[p(j/t)]2\nGini(t)=1−12=0\nGini(t)=1−∑\nj((n/nc)/n)2=1−∑\nj(1/nc)2=1−nc(1/nc)2=1−1/nc\n27",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#27": "Indice di Gini\n           \nC1=0, C2=6 —> P(C1)=0/6=0 , P(C2)=6/6=1  \n                             \nC1=1, C2=5 —> P(C1)=1/6 , P(C2)=5/6  \n                                    \nC1=2, C2=4 —> P(C1)=2/6 , P(C2)=4/6  \n                                    \nC1=3, C2=3 —> P(C1)=3/6=0.5 , P(C2)=3/6=0.5  \n                                   Gini(t)=1−∑\nj[p(j/t)]2\nGini(t)=1−P(C1)2−P(C2)2=1−0−1=0\nGini(t)=1−1/62−5/62=0.278\nGini(t)=1−2/62−4/62=0.444\nGini(t)=1−0.52−0.52=0.500\n28",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#28": "Algoritmo CART\n29\nCriterio di Splitting: Minimizzare l’Indice di Gini della suddivisione  \nQuando un nodo t è suddiviso in k partizioni (figli), la qualità della suddivisione è \ncalcolata come:  \n \n \n \n \ndove  \n   ni = numero di record della partizione (figlio) i \n   n = numero di record del dataset al nodo t \n   n i/n = peso dei vari Gini(i) \nDato il dataset associato al nodo t, si sceglie l’attributo che fornisce il più piccolo \nGini split(t) per partizionare il dataset \n•E’ necessario enumerare tutti i possibili punti di splitting per ciascun attributo, \novverosia tutte le possibili partizioni   \n Ginisplit=k\n∑\ni=1ni/n*Gini(i)",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#29": "Algoritmi Induzione DT\nAlgoritmo Greedy Decision Tree Learning  \n•Scelta della migliore feature utilizzando come metrica il Classification Error \nsui dati di training —> problema NP-Hard —> servono euristiche \nAlgoritmo C4.5  \n•Scelta della migliore feature utilizzando come metrica l’ Information Gain   \nsui dati di training —> problema risolvibile tramite strategia divide&conquer \nAlgoritmo CART  \n•Scelta della migliore feature utilizzando come metrica il Gini Index   \nsui dati di training —> problema risolvibile tramite strategia divide&conquer \n30",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#3": "Algoritmo C4.5\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#4": "Algoritmo C4.5\nObiettivo: generare un Albero di Decisione da una Tabella di Dati  \nSviluppato da J. R. Quinlan nel 1993 come estensione dell’ Algoritmo ID3   \nL’Albero ottenuto può essere usato per la classificazione, per cui \nl’Algoritmo C4.5  è spesso indicato come Statistical Classifier \nBasato sulla Teoria dell’Informazione (Claude E. Shannon, A Mathematical \nTheory of Communication , 1948) \nStrategia “divide and conquer” (suddivisione del problema in \nsottoproblemi più semplici e loro risoluzione ricorsiva):  \n•Scelta di uno degli attributi come nodo radice \n•Creazione ramo per ciascun valore di quell’attributo \n•Suddivisione delle istanze lungo i rami \n•Ripetizione del processo per ciascun ramo finché tutti le istanze nel ramo hanno \nla stessa classe di appartenenza (si dice che tutti i sottoalberi sono “puri”)  \nAssunzione di fondo: quanto più semplice  è l’albero che classifica le \nistanze, tanto meglio  è\n 5",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#5": "Entropia\nIntroduciamo il concetto di Entropia (Entropy) [(dal greco antico ἐν   \nen, \"dentro\", e τροπή  tropé, “trasformazione\")] \nEntropia in Meccanica Statistica: grandezza interpretata come \nmisura del disordine presente in un sistema fisico qualsiasi, \nincluso - come caso limite - l’universo \nEntropia in Teoria dell’Informazione: quantità di incertezza o \ninformazione presente in un segnale aleatorio \n•Primo Teorema di Shannon (Codifica di Sorgente): “Una \nsorgente casuale d’informazione non può essere rappresentata \ncon un numero di bit (da cui la base 2 del logaritmo) inferiore \nalla sua entropia, cioè alla sua autoinformazione media.”  \nTale teorema ha quindi un’implicazione in termini di \nrappresentazione dati, in quanto l’Entropia può essere \ninterpretata anche come la minima complessità descrittiva di \nuna variabile aleatoria, ovvero il limite inferiore della \ncompressione dei dati \n 6",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#6": "Tabella di Dati\n7\n",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#7": "Decision Tree\n8humidityoutlook\nrainy sunnycloudy\ntrue\nNo Yes\nYes normalwindy\nhigh\nNo Yes false\nNodi interni = test sugli attributi (feature) \nArchi uscenti = risultati dei test \nNodi foglia = etichette classe di appartenenza",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#8": "Entropia\nIntro duciamo il concetto di Entropia (Entropy) di un set di istanze  \nS è un set di istanze (i.e., record della tabella) \nA è una feature (Play nell’esempio) \n{S1 ... Si ... Sn} sono le partizioni  di S secondo gli n valori che può \nassumere A (“Yes” e “No”  nell’esempio) \n{p1 ... pi ... pn} sono le proporzioni  di {S1 ... Si ... Sn} in S \nSi definisce Entropia di S la seguente grandezza\n( ) ∑\n=∗− =n\nii i p p S Entropy\n12log )(\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\15-Alberi C4.5-sbloccato.pdf#9": "Entropia\nNel caso dell’esempio \nS è il set di 14 istanze \nL’obiettivo è classificare le istanze secondo i valori della \nfeature Play, ossia “Yes” e “No”  \nLa proporzione delle istanze con valore “Yes” è 9 su 14 \n(9/14=0.64) \nLa proporzione delle istanze con valore “No” è 5 su 14 \n(5/14=0.36) \nL’Entropia misura l’ impurezza di S e in questo caso vale  \nEntropy(S)= - 0.64 (log2 0.64) – 0.36 (log2 0.36)=  \n= - 0.64 (- 0.644) – 0.36 (- 1.474) = 0.41 + 0.53 = 0.94 \n10",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nClassiﬁcation:  \nBoosting",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#1": "Sommario\nIntroduzione \nEnsemble Learning \nBoosting \nAdaBoost\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#10": "Ensemble Classiﬁer \nL’idea è quella di considerare un certo numero di classiﬁcatori \nche, a fronte di un input, forniscono una loro previsione: \n \n11\nOgni classiﬁcatore esprime un voto in base al valore della \nfeature relativa. 1\nSicuroReputazione\nRischioso SicuroScarsa EccellenteSufﬁciente\nRischioso3 anni 5 anniDurata\nSicuro Rischiosocattive buoneCondizioni di \nmercato\nSicuroInput: xi = (Reputazione = Scarsa, Durata = 5 anni, Condizioni di Mercato = cattive)\nf1(xi) = -1 f2(xi) = +1 f3(xi) = -12 3\n",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#11": "Ensemble Model \nI vari voti espressi dai classiﬁcatori sono combinati insieme \ncome segue per formulare la previsione ﬁnale: \n \n12\nSe il segno è positivo la previsione vale +1, se è negativo vale -1. \nQuesto è un semplice esempio di Ensemble Classiﬁer. \nSi segnala l’importanza dei pesi w\n i\n, che devono essere \nindividuati mediante un processo di training. F(xi) = sign[w 1 * f 1(xi) + w 2 * f 2(xi) + w 3 * f 3(xi)]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#12": "Riepilogo sugli \nEnsemble Classiﬁer \nObiettivo: \n•\n predire un output \n ŷ\n (+1 o -1 nell’esempio) a partire da un \ninput \n x \n \n13\nApprendimento dell’Ensemble Model: \n• Classiﬁers: f 1(x), f2(x), …, f T(x) \n• Coefﬁcienti: ŵ1, ŵ2, …, ŵT \nPredizione: \nˆy= sign[TX\nt=1ˆwtft(x)]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#13": "Boosting \nxi\n(N esempi)Dati di Training\n(1° classiﬁcatore)Apprendimento\nPredizionef1(xi)\nŷi = sign[f 1(xi)]\nConsideriamo un problema di apprendimento automatico per  \nla classiﬁcazione: \n \n14",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#14": " \n15Credito Reddito yi\nA 130K $ Sicuro\nB 80K $ Rischioso\nC 110K $ Rischioso\nA 110K $ Sicuro\nA 90K $ Sicuro\nB 120K $ Sicuro\nC 30K $ Rischioso\nC 60K $ Rischioso\nB 95K $ Sicuro\nA 60K $ Sicuro\nA 98K $ SicuroApprendimento di un \nDecision Stump \n≤100K$ >100K$Reddito",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#15": " \n16Credito Reddito yi\nA 130K $ Sicuro\nB 80K $ Rischioso\nC 110K $ Rischioso\nA 110K $ Sicuro\nA 90K $ Sicuro\nB 120K $ Sicuro\nC 30K $ Rischioso\nC 60K $ Rischioso\nB 95K $ Sicuro\nA 60K $ Sicuro\nA 98K $ SicuroApprendimento di un \nDecision Stump \n≤100K$ >100K$Reddito\n3     1",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#16": " \n17Credito Reddito yi\nA 130K $ Sicuro\nB 80K $ Rischioso\nC 110K $ Rischioso\nA 110K $ Sicuro\nA 90K $ Sicuro\nB 120K $ Sicuro\nC 30K $ Rischioso\nC 60K $ Rischioso\nB 95K $ Sicuro\nA 60K $ Sicuro\nA 98K $ SicuroApprendimento di un \nDecision Stump \n≤100K$ >100K$Reddito\n3     1\nSicuro",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#17": " \n18Credito Reddito yi\nA 130K $ Sicuro\nB 80K $ Rischioso\nC 110K $ Rischioso\nA 110K $ Sicuro\nA 90K $ Sicuro\nB 120K $ Sicuro\nC 30K $ Rischioso\nC 60K $ Rischioso\nB 95K $ Sicuro\nA 60K $ Sicuro\nA 98K $ SicuroApprendimento di un \nDecision Stump \n≤100K$ >100K$Reddito\n4     3 3     1\nSicuro",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#18": " \n19Credito Reddito yi\nA 130K $ Sicuro\nB 80K $ Rischioso\nC 110K $ Rischioso\nA 110K $ Sicuro\nA 90K $ Sicuro\nB 120K $ Sicuro\nC 30K $ Rischioso\nC 60K $ Rischioso\nB 95K $ Sicuro\nA 60K $ Sicuro\nA 98K $ SicuroApprendimento di un \nDecision Stump \n≤100K$ >100K$Reddito\nSicuro4     3 3     1\nSicuro",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#19": "L’esempio precedente ci mostra che il decision stump non è \nriuscito a catturare adeguatamente le informazioni dal numero \nlimitato di dati disponibili. \n \n20\nQuello che fa il Boosting è considerare il decision stump, lo \nvaluta, vede come classiﬁca i vari punti, e addestra un \nsuccessivo decision stump (un successivo classiﬁcatore) con il \nquale si focalizza soprattutto sui punti dove il precedente \nclassiﬁcatore era debole. Boosting: focus sugli “hard points” ",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#2": "Boosting question \n \n3\nCan a set of weak learners be combined to create a stronger learner? \n(Kearns e Valiant, 1988, 1989)\nSì!!  —>  Boosting  \n(Schapire, 1990)\n",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#20": " \n21xi\n(N esempi)Dati di Training\n(1° classiﬁcatore)Apprendimento\nPredizione\nValutazione\nIndividuazione\npunti critici\n(2° classiﬁcatore)Apprendimentoyif1(xi)\n… e così viaŷiBoosting:  focus sugli “hard points” \nl’algoritmo di apprendimento \nfocalizza l’attenzione \nsui punti “critici”",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#21": "Apprendimento su Dati Pesati \n[weighted data]\nL’idea è quella di dare maggiore attenzione ai data points \nritenuti maggiormente importanti: \n•\n ogni data point (\n x\ni\n, y\ni\n) è pesato mediante un \n α\ni \n•\n più il punto è ritenuto importante, più è elevato il peso \n α\ni  \n•\n l’algoritmo di apprendimento rimane lo stesso \n \n22",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#22": " \n23Credito Reddito yi Peso α\nA 130K $ Sicuro 0.5\nB 80K $ Rischioso 1.5\nC 110K $ Rischioso 1.2\nA 110K $ Sicuro 0.8\nA 90K $ Sicuro 0.6\nB 120K $ Sicuro 0.7\nC 30K $ Rischioso 3\nC 60K $ Rischioso 2\nB 95K $ Sicuro 0.8\nA 60K $ Sicuro 0.7\nA 98K $ Sicuro 0.9≤100K$ >100K$Redditopeso α incrementato per i punti  \nerroneamente classiﬁcati\nApprendimento su Dati Pesati \n[weighted data]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#23": " \n24Credito Reddito yi Peso α\nA 130K $ Sicuro 0.5\nB 80K $ Rischioso 1.5\nC 110K $ Rischioso 1.2\nA 110K $ Sicuro 0.8\nA 90K $ Sicuro 0.6\nB 120K $ Sicuro 0.7\nC 30K $ Rischioso 3\nC 60K $ Rischioso 2\nB 95K $ Sicuro 0.8\nA 60K $ Sicuro 0.7\nA 98K $ Sicuro 0.9≤100K$ >100K$Reddito\n2     1.2\nSicuropeso α incrementato per i punti  \nerroneamente classiﬁcati\nApprendimento su Dati Pesati \n[weighted data]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#24": " \n25Credito Reddito yi Peso α\nA 130K $ Sicuro 0.5\nB 80K $ Rischioso 1.5\nC 110K $ Rischioso 1.2\nA 110K $ Sicuro 0.8\nA 90K $ Sicuro 0.6\nB 120K $ Sicuro 0.7\nC 30K $ Rischioso 3\nC 60K $ Rischioso 2\nB 95K $ Sicuro 0.8\nA 60K $ Sicuro 0.7\nA 98K $ Sicuro 0.9Rischioso≤100K$ >100K$Reddito\n3     6.5 2     1.2\nSicuropeso α incrementato per i punti  \nerroneamente classiﬁcati\nApprendimento su Dati Pesati \n[weighted data]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#25": "Apprendimento su Dati Pesati \n[weighted data]\nTale approccio comporta che: \n•\n Ogni punto i (\n x\ni\n, y\ni\n) conta come \n α\ni\n punti.  \n•\n L’algoritmo di apprendimento rimane lo stesso. \nL’apprendimento su dati pesati non è solo relativo ai decision \nstumps. \nEsso si può applicare a molti algoritmi di Machine Learning  \n•\n ad esempio, nel gradient ascent per la logistic regression: \n \n26w(t+1)\nj w(t)\nj+⌘·NX\ni=1\u0000j(xi){I[yi= +1]\u0000P(y=+ 1 |xi,w(t))}\n↵i w(t+1)\nj w(t)\nj+⌘·NX\ni=1\u0000j(xi){I[yi= +1]\u0000P(y=+ 1 |xi,w(t))}\n",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#26": "Boosting   \nAlgoritmo Greedy per l’apprendimento di “ensemble” dai \ndati. \nSi avvale di weak learners usati come black box.  \nWeak Learning Assumption\n : ciascun weak learner deve \navere prestazioni migliori di un classiﬁcatore “random”. \nNel Boosting i base classiﬁers sono addestrati in sequenza.  \nPer migliorare le prestazioni di un weak learner, l’algoritmo \ndeve poter manipolare i dati in ingresso, altrimenti si \nottengono sempre gli stessi risultati \n \n27",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#27": "Boosting framework \nStep principali: \n \n28xi(N esempi)Dati di Training\n(1° classiﬁcatore)Apprendimento\nPredizione\n(2° classiﬁcatore e ŵ)Apprendimentof1(xi)\n… e così viaŷi = sign[f1(xi)]\nŷi = sign[ŵ1*f1(xi) + ŵ 2*f2(xi)]Individuazione\npunti critici\ne ricalcolo pesi\nPredizioneŵ, f2(xi)weighted data\nIdea del Boosting: aggiungere via via \nnuovi classiﬁcatori ottimizzando i pesi \nper focalizzarsi sui punti critici per poi \napprendere i coefﬁcienti dei diversi \nclassiﬁcatori. ",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#28": "AdaBoost \n[Adaptive Boosting]\nProposto da Yoav Freund e Robert E. Schapire nel 1996. \nI due autori hanno vinto il Gödel Prize nel 2003. \nAlgoritmo estremamente utile e facile da implementare.  \n \n29Freund, Y ., Schapire, R. E. “A Short Introduction to Boosting”, in: J ournal of Japanese Society \nfor Artiﬁcial Intelligence , 14(5), 1999, pp. 771-780. Riferimenti:\nSchapire, R.E., Freund, Y . Boosting - Foundations and Algorithms . The MIT Press, 2012. Freund,  Y .,  Schapire,  R.  E.  “Experiments  with  a  new  Boosting  Algorithm”,  in:  Thirteenth  \nInternational Conference on Machine Learning , 1996, pp. 148-156. ",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#29": "AdaBoost \n[Adaptive Boosting]\nfor\n i = 1, 2, …, N: \nα\ni \n= 1\\N \nfor\n t = 1, 2, … T: \n•\n apprendi f\n t\n(\nx\n) con i pesi \n α\ni \n(\nminimizza funzione di costo\n ) \n•\n calcola il coefﬁciente \n ŵ\nt  \n•\n ricalcola i pesi \n α\ni \nCalcola la predizione ﬁnale: \n \n30ˆy= sign[TX\nt=1ˆwtft(x)]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#3": "Introduzione al Boosting \nIl Boosting è una potente tecnica per combinare molti \nclassiﬁcatori “di base” (detti anche “weak learners”) per produrre \nuna forma di comitato le cui prestazioni sono di gran lunga \nmigliori di ciascuno dei classiﬁcatori. \nOriginariamente progettato per risolvere problemi di \nclassiﬁcazione, può anche essere esteso alla regressione \n(Friedman, 2001).  \n \n4",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#30": "Evidenziamo qui il processo di training dei vari classiﬁcatori, basato su \nuna forma pesata dei punti del training set (linee rosse). \nOgni peso dipende dalle prestazioni del precedente classiﬁcatore (linee \nverdi)\n \n31f1(x) fT(x){↵(1)\ni} {↵(T)\ni}\nf2(x)······\n······{↵(2)\ni}\nˆy= sign[TX\nt=1ˆwtft(x)]\nBoosting framework ",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#31": "Dobbiamo risolvere i seguenti due problemi: \n1. come calcolare il coefﬁciente \n ŵ\nt  \n(qual è la mia \n“ﬁducia” in f\n t\n(\nx\n) ?) \n2. come ricalcolare i pesi \n α\ni \n(individuare i punti “critici”) \n \n32\nAdaBoost \n[Adaptive Boosting]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#32": "Il peso \n ŵ\nt\n rappresenta un “grado di ﬁducia” nella \n f\nt\n. Pertanto:\n \n33\n1° problema: \nCalcolo del coefﬁciente \n ŵ\nt \nft(x) buona?\nŵt elevato ŵt bassosi no\nUna funzione è considerata “buona” se ha un basso training error \nVediamo come misurare l’errore nel caso di dati “pesati” (“weighted \nclassiﬁcation error”) ",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#33": "Weighted Classiﬁcation Error \nLa misura di un errore pesato è simile a quella di un errore calcolato \nsu dati non pesati. \n \n34\nVediamo un semplice esempio: \nData point i yi αi ŷi risultato\n1 +1 1.2 +1\n 👍\n2 -1 0.5 +1\n 👎\n3 -1 0.7 -1\n 👍\n… … … …\npeso previsioni corrette 1.9\npeso previsioni errate 0.5",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#34": "Weighted Classiﬁcation Error \nPeso totale degli errori = \n \n35NX\ni=1↵iI[ˆyi 6=yi]\nNX\ni=1↵i\n Peso totale di tutti i data points = \nL’errore “pesato” misura la frazione del peso degli errori: \nweighted error =peso totale degli errori\npeso totale di tutti i data points=PN\ni=1↵iI[ˆyi 6=yi]\nPN\ni=1↵i\nMiglior valore: 0.0    Peggior valore: random classiﬁer ",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#35": "Calcolo del coefﬁciente \n ŵ\nt \n[per il classiﬁcatore f\n t\n(\nx\n)]\nLa formula usata in \nAdaBoost è la seguente:\n \n36   \nsui training dataŵt\n0.01 (1 - 0.01)/0.01 = 99 +2.3\n0.5 (1 - 0.5)/0.5 = 1 0\n0.99 (1 - 0.99)/0.99 = 0.01 -2.31\u0000weighted error (ft)\nweighted error (ft)weighted error (ft)ˆwt=1\n2ln⇣\n1\u0000weighted error( ft)\nweighted error( ft)⌘\nVediamo un esempio: \nft(x) buona?si\nno",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#36": "2° problema: Ricalcolo pesi alfa\nCome sappiamo, dobbiamo focalizzarci soprattutto sui data point \ndove la funzione commette errori: \n \n37↵i ⇢↵i·e\u0000ˆwtseft(xi)=yi\n↵i·eˆwt seft(xi)6=yift(xi) classiﬁca \n bene xi?\ndecrementa αisi no\nincrementa αi\n",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#37": "2° problema: Ricalcolo pesi alfa \nVediamo un esempio:\n \n38↵i ⇢↵i·e\u0000ˆwtseft(xi)=yi\n↵i·eˆwt seft(xi)6=yi\n  ft(xi) = y i ? ŵtmoltiplicare α i per: implicazioni\nSI (corretto) +2.3 0.1 diminuisci l’importanza del punto\nSI (corretto) 0 1 mantieni la stessa importanza\nNO (errore) +2.3 9.98 aumenta l’importanza del punto\nNO (errore) 0 1 mantieni la stessa importanza",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#38": "Normalizzazione pesi alfa \nLa normalizzazione dei pesi \n α\ni\n è suggerita dal fatto che:  \n•\n se la funzione sbaglia spesso la classiﬁcazione di \n x\ni\n, il peso \n α\ni \ntende ad assumere valori molto alti \n•\n se la funzione prevede spesso correttamente la classiﬁcazione \ndi \nx\ni\n, il peso \n α\ni \ntende ad assumere valori molto bassi \nTutto ciò può causare instabilità numerica dopo varie iterazioni. \nSi normalizza come segue in modo tale che, dopo ogni iterazione, \nla somma dei pesi \n α\ni\n risulti sempre uguale ad 1:\n \n39↵i ↵iPN\nj=1↵j",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#39": "AdaBoost\nfor\n i = 1, 2, …, N: \nα\ni \n= 1\\N \nfor\n t = 1, 2, … T: \n•\n apprendi f\n t\n(\nx\n) con i pesi \n α\ni \n•\n calcola il coefﬁciente \n ŵ\nt  \n•\n ricalcola i pesi \n α\ni \n•\n normalizza i pesi \n α\ni \nCalcola la predizione ﬁnale: \n \n40ˆy= sign[TX\nt=1ˆwtft(x)]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#4": "Introduzione al Boosting \nSuo impatto per il Machine Learning: \napproccio di default per molti task di computer vision (e.g., \nface detection) \nnumerose applicazioni nell’industria \nvince molte “ML competitions” (Kaggle, KDD Cup, ecc.): \n•   \nmalware classiﬁcation \n•\ncredit fraud detection \n•\nsales forecasting \n•\nHiggs boson detection, ecc., ecc.  \nSi basa sul concetto di Ensamble Learning  \n \n5",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#40": "AdaBoost\nfor\n i = 1, 2, …, N: \nα\ni \n= 1\\N \nfor\n t = 1, 2, … T: \n•\n apprendi f\n t\n(\nx\n) con i pesi \n α\ni \n•\n calcola il coefﬁciente \n ŵ\nt  \n•\n ricalcola i pesi \n α\ni \n•\n normalizza i pesi \n α\ni \nCalcola la predizione ﬁnale: \n \n41ˆy= sign[TX\nt=1ˆwtft(x)]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#41": "AdaBoost\nfor\n i = 1, 2, …, N: \nα\ni \n= 1\\N \nfor\n t = 1, 2, … T: \n•\n apprendi f\n t\n(\nx\n) con i pesi \n α\ni \n•\n calcola il coefﬁciente \n ŵ\nt  \n•\n ricalcola i pesi \n α\ni \n•\n normalizza i pesi \n α\ni \nCalcola la predizione ﬁnale: \n \n42ˆy= sign[TX\nt=1ˆwtft(x)]ˆwt=1\n2ln⇣\n1\u0000weighted error( ft)\nweighted error( ft)⌘",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#42": "AdaBoost\nfor\n i = 1, 2, …, N: \nα\ni \n= 1\\N \nfor\n t = 1, 2, … T: \n•\n apprendi f\n t\n(\nx\n) con i pesi \n α\ni \n•\n calcola il coefﬁciente \n ŵ\nt  \n•\n ricalcola i pesi \n α\ni \n•\n normalizza i pesi \n α\ni \nCalcola la predizione ﬁnale: \n \n43ˆy= sign[TX\nt=1ˆwtft(x)]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#43": "AdaBoost\nfor\n i = 1, 2, …, N: \nα\ni \n= 1\\N \nfor\n t = 1, 2, … T: \n•\n apprendi f\n t\n(\nx\n) con i pesi \n α\ni \n•\n calcola il coefﬁciente \n ŵ\nt  \n•\n ricalcola i pesi \n α\ni \n•\n normalizza i pesi \n α\ni \nCalcola la predizione ﬁnale: \n \n44ˆy= sign[TX\nt=1ˆwtft(x)]↵i ⇢↵i·e\u0000ˆwtseft(xi)=yi\n↵i·eˆwt seft(xi)6=yi",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#44": "AdaBoost\nfor\n i = 1, 2, …, N: \nα\ni \n= 1\\N \nfor\n t = 1, 2, … T: \n•\n apprendi f\n t\n(\nx\n) con i pesi \n α\ni \n•\n calcola il coefﬁciente \n ŵ\nt  \n•\n ricalcola i pesi \n α\ni \n•\n normalizza i pesi \n α\ni \nCalcola la predizione ﬁnale: \n \n45ˆy= sign[TX\nt=1ˆwtft(x)]",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#45": "AdaBoost\nfor\n i = 1, 2, …, N: \nα\ni \n= 1\\N \nfor\n t = 1, 2, … T: \n•\n apprendi f\n t\n(\nx\n) con i pesi \n α\ni \n•\n calcola il coefﬁciente \n ŵ\nt  \n•\n ricalcola i pesi \n α\ni \n•\n normalizza i pesi \n α\ni \nCalcola la predizione ﬁnale: \n \n46ˆy= sign[TX\nt=1ˆwtft(x)]↵i ↵iPN\nj=1↵j",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#46": "AdaBoost\nfor\n i = 1, 2, …, N: \nα\ni \n= 1\\N \nfor\n t = 1, 2, … T: \n•\n apprendi f\n t\n(\nx\n) con i pesi \n α\ni \n•\n calcola il coefﬁciente \n ŵ\nt  \n•\n ricalcola i pesi \n α\ni \n•\n normalizza i pesi \n α\ni \nCalcola la predizione ﬁnale: \n \n47ˆy= sign[TX\nt=1ˆwtft(x)]↵i ↵iPN\nj=1↵j↵i ⇢↵i·e\u0000ˆwtseft(xi)=yi\n↵i·eˆwt seft(xi)6=yiˆwt=1\n2ln⇣\n1\u0000weighted error( ft)\nweighted error( ft)⌘",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#47": "Riferimenti \n \n48Freund, Y ., Schapire, R. E. “A Short Introduction to Boosting”, in: J ournal of Japanese \nSociety for Artiﬁcial Intelligence , 14(5), 1999, pp. 771-780. \nSchapire, R.E., Freund, Y . Boosting - Foundations and Algorithms . The MIT Press, 2012. Freund,  Y .,  Schapire,  R.  E.  “Experiments  with  a  new  Boosting  Algorithm”,  in: \nThirteenth  International Conference on Machine Learning , 1996, pp. 148-156. \nFriedman, J.H. “Greedy Function Approximation: A Gradient Boosting Machine”, in: \nAnnals of Statistics , 29(5), 2001, pp. 1189-1232. Schapire, R.E.  “The Strength of Weak Learnability”, in: Machine Learning , 5(2), 1990, \npp. 197–227.\nMachine Learning: Classiﬁcation, University of Washington - Coursera, 2017.",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#5": "Weak Classiﬁers\nL’idea è quella di partire da Simple (o Base o Weak) \nClassiﬁers, come ad es.:  \n \n6SicuroReputazione\nRischioso SicuroScarsa EccellenteSufﬁciente+\n++++-\n--\n-+\n+\nLogistic Regression \ncon semplici featuresShallow \nDecision TreeDecision Stump\nEssi in genere sono caratterizzati da bassa varianza (scarso \noverﬁtting) ma alto bias. ",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#6": "Andamento Errori  \ne Bias-Variance Trade-off\n \n7\nL’andamento del training error e del true error per la classiﬁcation è in \ngenere il seguente:\nDobbiamo come al solito considerare il trade-off tra bias e variance.True Error\nTraining Error\nModel ComplexityClassiﬁcation\nError\n(Weak Learner)",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#7": " \n8\nUn approccio per migliorare un classiﬁcatore può essere quello di \naggiungere più features al classiﬁcatore, ad es.: \n•\n logistic regression: polinomio di grado più elevato, cercando di \nevitare l’overﬁtting \n•\n decision trees: aumentare la profondità dell’albero \nNel Boosting si fa qualcosa di diverso: si parte da un insieme di weak \nclassiﬁers i cui risultati sono opportunamente combinati per ottenere \nuno strong classiﬁer.\nIntroduzione al Boosting ",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#8": "Ensemble Classiﬁer \nAlla base del Boosting c’è l’idea dell’Ensemble Classiﬁer, che \nora vedremo. \nConsideriamo un weak classiﬁer, ad esempio un Decision \nStump:  \n \n9\nEsso, a fronte del valore della feature d’interesse, restituisce \nun risultato (+1 o -1). SicuroReputazione\nRischioso SicuroScarsa EccellenteSufﬁciente\nInput: xi\nOutput: ŷ = f( xi)",
    "data_test\\rootfolder\\università\\MachineLearning\\16-Classification - BoostingAdaBoost-sbloccato.pdf#9": "Ensemble Classiﬁer \nL’idea è quella di considerare un certo numero di classiﬁcatori \nche, a fronte di un input, forniscono una loro previsione: \n \n101\nSicuroReputazione\nRischioso SicuroScarsa EccellenteSufﬁciente\nRischioso3 anni 5 anniDurata\nSicuro Rischiosocattive buoneCondizioni di \nmercato\nSicuroInput: xi = (Reputazione = Scarsa, Durata = 5 anni, Condizioni di Mercato = cattive)\n2 3",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nClassiﬁcazione:  \nOverﬁtting e Regularization\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#1": "Sommario\nIntroduzione \nOverﬁtting nella Classiﬁcazione \nRegolarizzazione \nL2 Penalty \nL1 Penalty (sparse solutions)\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#10": "Funzione di Qualità \nnel caso L\n 2\n Penalty\n \n11\nQuesto è il caso in cui usiamo la somma dei quadrati ( L2 \nRegularization ). \nLa funzione che rappresenta la qualità totale nel caso della \nlogistic regression ( L2 regularized logistic regression ) è la \nseguente:    \ndove il parametro λ (tuning parameter ) serve per bilanciare i \ndue termini.    \n                                           Qualit` a totaleL2=l n L(w)\u0000\u0000·kwk2\n2\n<latexit sha1_base64=\"3dst1017rZDOv7BwzXBseJyVJLg=\">AAAC0nicbVFNbxMxEJ1dvkr4aIAjF4sICQ5Eu6ESXJAq4MCBQys1aaUkRF5n2pra65U9S1tWOSCu/EEOSPwUxts9pC2W7Jl5b55n7CkqowNl2e8kvXHz1u07G3d79+4/eLjZf/R4ElztFY6VM84fFDKg0SWOSZPBg8qjtIXB/eLkQ+T3v6EP2pV7dF7h3MqjUh9qJYkh13cwAwKEMz4b2IUaJBjQHP1lZsHW8Y4YworjBj7zOWJfwDve62oDZYtH1LKG4BhUq42qFbxgvOD7DCwZOWXkZZv9qlUYzrTML9nGWLEXa19wE67iu+jyHets7C/29qWzvUV/kA2zdonrTt45A+jWzqL/Z7Z0qrZYkjIyhGmeVTRvpCetDK56szpgJdWJPMIpu6W0GOZNO4eVeF4HSU5U6IU2ogVxXdFIG8K5LTjTSjoOV7kI/o+b1nT4dt7osqoJSxULkTbYFgrKax4wiqX2SCRj5yh0KZT0kgi9FlIpBmueePyP/OrrrzuT0TB/PRztbg2233c/swFP4RlPMIc3sA2fYAfGoJKPydckJJTupd/TH+nPi9Q06TRP4NJKf/0De4+6Ww==</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#11": " \n12Vediamo cosa accade a fronte di diversi valori del parametro λ: \nSe λ = 0: \nci riconduciamo alla vecchia soluzione, ossia massimizzazione \ndel likelihood( w) → ŵMLE \nSe λ → ∞: \nper soluzioni dove ŵ ≠ 0, il costo totale → - ∞ \nl’unica soluzione per massimizzare la qualità è: ŵ = 0 \nSe 0 < λ < ∞: \n0<kˆwk2\n2<kˆwMLEk2\n2\n<latexit sha1_base64=\"GbN8PXIxssjt4tSdrVsj583mbQM=\">AAACT3icdVBNSyNBFOyJ3/Erq0cvjUHwFGaioAcP4rLgQUHBRCEThzedpzbp+aD7ja408+P2J+zRg2ev7mlv4kycg0YtaCiq6vFeV5gqach1H5zaxOTU9MzsXH1+YXFpufFjpWuSTAvsiEQl+iIEg0rG2CFJCi9SjRCFCs/D4c/SP79FbWQSn9F9iv0IrmN5JQVQIQWNnsv3uK+6qIn7YaIG1r8Bsnd5/iYGtp1fFu+7VGB9wt9kj49+jY/Ug0bTbbkj8M/Eq0iTVTgJGo/+IBFZhDEJBcb0PDelvgVNUijM635mMAUxhGvsFTSGCE3fjkrI+UZmgBKeouZS8ZGI7ycsRMbcR2GRjIBuzLhXil95vYyudvtWxmlGGItyEUmFo0VGaFm0i3wgNRJBeTlyGXMBGohQSw5CFGJW1F324Y3//jPptlveVqt9ut3cP6iamWVrbJ1tMo/tsH12yE5Yhwn2hz2xZ/bP+ev8d15qVbTmVGSVfUBt7hUB/7VE</latexit>\nFunzione di Qualità \nnel caso L\n 2\n Penalty",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#12": " \n13Come già visto nel caso della Regressione, per la \ndeterminazione del parametro λ non usiamo mai il Test Set. Ci \navvaliamo invece: \ndel Validation Set , se abbiamo a disposizione un \nnumero sufﬁcientemente elevato di osservazioni; \ndella Cross-Validation , se abbiamo a disposizione un \nnumero limitato di osservazioni. \nScelta del Parametro di Tuning \n λ",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#13": "Bias-Variance Tradeoff\n \n14\nParametro λ elevato: \nhigh bias, low variance  (e.g., ŵ = 0 per λ = ∞) \nParametro λ piccolo: \nlow bias, high variance  (e.g., maximum likelihood (MLE) \nﬁt per polinomi di grado elevato per λ = 0) Il parametro λ controlla la complessità del modello: ",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#14": "L\n2\n Regularization \nEsempio\n \n15\nVediamo l’effetto della L 2 regularization nel caso visto in \nprecedenza (caso con 20 features):\nRegularization:\nRange coefﬁcienti: \nDecision boundary:",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#15": "Gradient Ascent \ncon la L\n 2\n Regularization \n \n16\nCome è noto, nell’algoritmo Gradient Ascent dobbiamo \naggiornare il vettore dei pesi w come segue:\nw(t+1) w(t)+↵·rQualit` a totaleL2(w(t))\n<latexit sha1_base64=\"TzTwdt9I3sAyHV9gN7z7vrC1WrU=\">AAAC0nicfVFNb9NAEB2bj5bw0QBHLisipFaVIjtUKscKOHDg0EpNWykJ0XgzaZeuvdbuGChWDogrf5BDpf4Uxk4O0AJjaefNvDc7452stCZwkvyM4lu379xdW7/Xuf/g4aON7uMnR8FVXtNQO+v8SYaBrCloyIYtnZSeMM8sHWfnbxr++BP5YFxxyBclTXI8LczcaGRJua6DMWTgwMIMavgMC/ggfhMYtiGFLYmVKCwQzCWH4OVzolP/rFvWbLcKFL6EM/FNpEXrRNHgQnKZsEuG5f4vctZwAFVbZSS6EmYq3rWdmxkWEtfwXs6B4M3/zrAFHehMu72kn7SmboJ0BXqwsv1p93I8c7rKqWBtMYRRmpQ8qdGz0ZYWnXEVqER9jqc0ElhgTmFSt3tYqBdVQHaqJK+MVW2Sfq+oMQ/hIs9EmSOfhetck/wbN6p4/mpSm6KsmArdNGJjqW0UtDeyYFIz44kZm8lJmUJp9MhM3ijUWpKVbLx5j/T6398ER4N++rI/ONjp7b1evcw6PIPn8rYp7MIevIN9GIKO3kYfoxBxfBh/jb/F35fSOFrVPIU/LP7xC+iqucA=</latexit>\nDobbiamo dunque calcolare il gradiente della funzione di \nqualità totale ( L2 regularized log-likelihood ):\nQualit` a totaleL2=l n L(w)\u0000\u0000·kwk2\n2\n<latexit sha1_base64=\"3dst1017rZDOv7BwzXBseJyVJLg=\">AAAC0nicbVFNbxMxEJ1dvkr4aIAjF4sICQ5Eu6ESXJAq4MCBQys1aaUkRF5n2pra65U9S1tWOSCu/EEOSPwUxts9pC2W7Jl5b55n7CkqowNl2e8kvXHz1u07G3d79+4/eLjZf/R4ElztFY6VM84fFDKg0SWOSZPBg8qjtIXB/eLkQ+T3v6EP2pV7dF7h3MqjUh9qJYkh13cwAwKEMz4b2IUaJBjQHP1lZsHW8Y4YworjBj7zOWJfwDve62oDZYtH1LKG4BhUq42qFbxgvOD7DCwZOWXkZZv9qlUYzrTML9nGWLEXa19wE67iu+jyHets7C/29qWzvUV/kA2zdonrTt45A+jWzqL/Z7Z0qrZYkjIyhGmeVTRvpCetDK56szpgJdWJPMIpu6W0GOZNO4eVeF4HSU5U6IU2ogVxXdFIG8K5LTjTSjoOV7kI/o+b1nT4dt7osqoJSxULkTbYFgrKax4wiqX2SCRj5yh0KZT0kgi9FlIpBmueePyP/OrrrzuT0TB/PRztbg2233c/swFP4RlPMIc3sA2fYAfGoJKPydckJJTupd/TH+nPi9Q06TRP4NJKf/0De4+6Ww==</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#16": "Gradient Ascent \ncon la L\n 2\n Regularization \n \n17\nNell’algoritmo l’aggiornamento dei pesi possiamo farlo per \nogni componente w j:\nw(t+1)\n0 w(t)\n0+↵·@Qualit` a totaleL2(w(t))\n@w0\nw(t+1)\n1 w(t)\n1+↵·@Qualit` a totaleL2(w(t))\n@w1\n······ ·····················\nw(t+1)\nj w(t)\nj+↵·@Qualit` a totaleL2(w(t))\n@wj\n······ ·····················\nw(t+1)\nD w(t)\nD+↵·@Qualit` a totaleL2(w(t))\n@wD\n<latexit sha1_base64=\"DNhBsTO/Fo42FgAscBocdQBJt+Y=\">AAAHvXic3VVLb9NAEJ4GiEt4pXDksiKiKlRK7XCAGxXkwIFDK5G2Up1G680k3dQvvGtCZOWHckDiwA9hdm1BmxQkokpFbGTvvL7sN/NJ3iANpdKu+2WtduPmrbqzfrtx5+69+w+aGw8PVJJnAnsiCZPsKOAKQxljT0sd4lGaIY+CEA+Ds7cmf/gJMyWT+IOepdiP+DiWIym4plCyUfsODfAhAIQxSIihIOsj7Rwy+nGYwXOYU80UBpRzyT6hfQs0bIMHz8hnsEmPDyEhRxQvkQkhyswyskRtWxQnXAqntBtPwJCQmmxmeY0sB0E4n6rMP2tiaTAmounEz/QuYB9yG5XkfaPMgPbEcjGs5pbBe3p3yN6y/SaUGVJ0usDLPKbfy0781cncdsAsZ7+ySs5ljbfynLy/ntOfpsSucU7ezzmZGTXOsVYXelC2/82l2KJ/FV7JpOQ3WVmjyZVqdH0KTf5xhborK9T9TxTqVgoZbZC+ysPffp8bg2bLbbt2sWXDq4wWVGtv0PzqDxORRxhrEXKljj031f2CZ1qKEOcNP1eYcnHGx3hMZswjVP3CXjlz9jRXXCcsxYzJkNkgnkcUPFJqFgVUGXF9qhZzJnhZ7jjXo1f9QsZprjEW5iAtQ7QHKZFJusuQDWWGWnPDHJmMmeAZ1xozybgQFMzpcjPz8Ba7XzYOOm3vRbuz32ntvqkmsw6P4Qlp5MFL2IV3sAc9EPWdeq9+Uh84rx10QicuS2trFeYRXFjO9AeM558S</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#17": "Gradient Ascent \ncon la L\n 2\n Regularization \n \n18\nLa derivata parziale della funzione di qualità totale rispetto al \ntermine generico w j è la seguente:\nComponente MLE Componente L 2 Penalty@Qualit` a totaleL2(w(t))\n@wj= derivata parziale[ j]\u00002\u0000w(t)\nj\n<latexit sha1_base64=\"qwKQWDz8o+RHfQa5roWAERrRYkA=\">AAAC/HicbVI7b9RAEB47PMLxOkJJs+KEFApO9gUJGqQIGgqKROKSSHfmtF7PhU3WD+2OE4J1VPwEWqjoorT8FwokfgqzjosjyUqz8+033zy83rQy2lEU/Q7ClWvXb9xcvdW7fefuvfv9B2s7rqytwrEqTWn3UunQ6ALHpMngXmVR5qnB3fTwjY/vHqF1uize00mFSS73Cz3XShJTZf8r9GAKc7AgQUHDuGJkgUCzNy1DgPCJ9wa2oW5Zzae/HJmxL9k8h7DgcwPveB8xXud4ylEDGbPHzHxgv87qp4y9LUBc2fG4rXPQKrzmFdvyFBkjy+oj1vvefo7zGp+7Gn6WCVdIOPMZ24g1hiM5T5SxF22Pg+WJZv1BNIzaJS6DuAMD6NbWrP9nmpWqzrEgZaRzkziqKGmkJa0MLnrT2mEl1aHcxwnDQubokqb9YwvxpHaSSlGhFdqIlsTljEbmzp3kKStzSR/dxZgnr4pNapq/TBpdVDVhoXwj0gbbRk5ZzU8BRaYtEkk/OQpdCCWtJEKrhVSKyZrfRo/vI7749ZfBzmgYbwxH288Hm6+7m1mFR/CYbzWGF7AJb2ELxqCCIvgWfA9+hF/Cn+FpeHYuDYMu5yH8t8Jf/wA0VMWQ</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#18": "Gradient Ascent \ncon la L\n 2\n Regularization \n \n19\nQuesta è la versione dell’algoritmo:\nw(1)= 0 (oppure lo inizializziamo in modo casuale)\nt=1\nwhilekrQualit` a totaleL2(w(t))k2>✏\nfor j=0,1,. . . ,D\nderivata parziale[ j]=NX\ni=1\u0000j(xi){I[yi= +1]\u0000P(y=+ 1 |xi,w(t))}\nw(t+1)\nj w(t)\nj+↵⇤(derivata parziale[ j]\u00002\u0000w(t)\nj)\nt t+1\n<latexit sha1_base64=\"2zh0FCvD+/2VMpyTakbuiEO167M=\">AAAGWXicnVTLbhMxFL0taSjl1dIlmxEVqC+iTBCCTVEFLEBCqJXoQ8qEyHGc1O28NPa0TUO+kC9ACIlfYAsbjh0zbdoGKsayfX1f5/rY41YaSqWr1S8Tk9dKU+Xr0zdmbt66fefu7Ny9bZXkGRdbPAmTbLfFlAhlLLa01KHYTTPBolYodloHr4x951BkSibxB91LRSNi3Vh2JGcaqmRuskYBtUhQlyTF1CdGIaQu5GUa0Aw9svYE2jasR9B9xLxIPi1B9mgNvYoe2K6R6Rij8UgoRcspg85DfILRYEg6QR/inDg5Kqyeldt2zWFRyGB8hcMLLJKpywPOEN93+ovV7iGniR0UFYa0jXVmYwPgMfiHGEer33SoEqvvsDQxJ+jMZWvC5x3Gms28OIYjbWteGkE1kbWinhd2FuBJ2UoTy8DpXvagT4HK4dMHzxV6Cjly8aeYHUjZmV16tF+czaplyIwV24z0+i8o/hmEU0batn5Jh/AzPBhOTExWnKbhpQ7chkM28eb0IrtnCZ3vmHmPOUC0OR1j28d6lMNjx7G0/JlMfXqL7L1Cu0YryGewHqNvIL7ndJ/GZlr95zkNrsDKUVHzn+iV4m8ILA8dy1CGlsD7soih94qNMNwZLpjlbNndp/9l3rBRc5WY/6qFeDa2hqUr3jU9dm/a7cNHFnOTY8vtuVekObtQrVTt510UfCcskPs2mrPfgnbC80jEmodMqbpfTXWjzzIteSgGM0GuRMr4AeuKOsSYRUI1+vY5HHgPc8V04qUi82ToWaU4G9FnkVK9qAXPiOk9dd5mlJfZ6rnuPG/0ZZzmWsTcAGkZCgukeCbxzgqvLTOhNTOVC0/GHmcZ01pk0mOcQ5nj4TV8+Od3f1HYrlX8J5XaZm1h/aVjZpru0wP7+j6jdXqDe79FvPS59KP0s/Rr6mt5ojxdnhm6Tk64mHka+crzvwEKslZZ</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#19": "Funzione di Qualità \nnel caso L\n 1\n Penalty\n \n20\nQuesto è il caso in cui usiamo la somma dei valori assoluti \nper la penalty ( L1 Regularization ). E’ in genere chiamata \n“sparse logistic regression ”. \nLa funzione che rappresenta la qualità totale nel caso della \nlogistic regression ( L1 regularized logistic regression ) è la \nseguente:    \ndove il parametro λ (tuning parameter ) serve per bilanciare i \ndue termini.                                              Qualit` a totaleL1=l n L(w)\u0000\u0000·kwk1\n<latexit sha1_base64=\"kVQvjmORbVIpZXR5YRGRGxnE/j0=\">AAACzHicbVFNb9QwEJ2Ej5bla4EjF4sVEhxYJS1SuYAquHBAqJXYbaXd1cpxpq1V24nsCVBFufIfOSDxUxinOWxbRrI98948z9hT1EYHyrLfSXrr9p27W9v3RvcfPHz0ePzk6TxUjVc4U5Wp/HEhAxrtcEaaDB7XHqUtDB4V558if/QdfdCV+0YXNa6sPHX6RCtJDFVjA0sgQPjJewuH0IAEA5qjv8ys+ax4RQyh47iFL7zn7At4z2tTbcD1eEQtawjOQPXaqOrgFeMF32egZOQHI6/77De9wnCmZb7kM8aKvVj7kptzFT9EV+/YZGN/sbcRjNbjSTbNehM3nXxwJjDYwXr8Z1lWqrHoSBkZwiLPalq10pNWBrvRsglYS3UuT3HBrpMWw6rtJ9CJl02QVIkavdBG9CBuKlppQ7iwBWdaSWfhOhfB/3GLhk7erVrt6obQqViItMG+UFBe82hRlNojkYydo9BOKOklEXotpFIMNjzr+B/59dffdOY703x3unP4drL/cfiZbXgOL3h2OezBPnyGA5iBSj4kZWITl35NKW3T7jI1TQbNM7hi6a9/TBq4og==</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#2": "Metriche di Qualità \n[quality metric]\n \n3Errore =#previsioni errate\n#esempi\nUna metrica che si usa misura la frazione delle previsioni errate \nfornite:\nmiglior valore possibile: 0.0\nAccuracy =#previsioni corrette\n#esempi\n<latexit sha1_base64=\"NDG+msvJ/lTBIqDvf5G5eA2dVhE=\">AAACPXicbVA9TxtBEN0jBIiTEBPKNCusSKmsO4JEGiRIGtIRCQOSz7LmhjEZsfeh3TmEdbrfxE/Ir0hBAanoEG1a9oyF+HrV03vzdnZeUhh2Eobnwcyr2ddz8wtvWm/fvV/80F76uOfy0iL1MDe5PUjAkeGMesJi6KCwBGliaD85/tH4+ydkHefZrowLGqRwlPGIEcRLw/bPWOhUqi3E0gKOa72h45FnVdy5c/xrJ9zEOR5ibi2JUF3f2+QoLbiuW61huxN2wwn0cxJNSUdNsTNsX8SHOZYpZYIGnOtHYSGDCqwwGqpbcemoADyGI+p7mkFKblBNTq7159KB5Logq9noiUgPExWkzo3TxE+mIL/dU68RX/L6pYy+DSrOilIow2aRsKHJIoeWfZekD7mpAZqfk+ZMI1jwtVjWgOjF0pfb9BE9vf452VvtRl+7q7/WOpvfp80sqE9qRX1RkVpXm2pb7aieQnWm/qpL9S/4E1wF18HN3ehMMM0sq0cI/t8C0Zew6Q==</latexit>\nUn’altra metrica possibile misura la frazione delle previsioni \ncorrette:\nmiglior valore possibile: 1.0",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#20": " \n21Anche in questo caso vediamo cosa accade a fronte di diversi valori \ndel parametro λ: \nSe λ = 0: \nci riconduciamo alla soluzione standard, ossia massimizzazione \ndel likelihood( w) → ŵMLE \nSe λ → ∞: \nper soluzioni dove ŵ ≠ 0, il costo totale → - ∞ \nl’unica soluzione per massimizzare la qualità è: ŵ = 0 \nSe 0 < λ < ∞:  \nsi va verso soluzioni “sparse”, in cui vari w j sono uguali a zero.\nFunzione di Qualità \nnel caso L\n 1\n Penalty",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#21": "Pesi nella regolarizzazione \n \n22\nNelle ﬁgure seguenti riportiamo un esempio di andamento \ndei pesi w j al variare di 𝜆 per i due tipi di penalty:\nL2 Penalty\n L1 Penaltyλ λ ",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#22": "Riferimenti\n \n23\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , 3a edizione, \nApogeo, 2015. \nMachine Learning: Classiﬁcation\n , University of Washington - Coursera, 2017. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. ",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#3": " \n4\nOverﬁtting \nApprendimento della Decision Boundary \nj 𝜱j wj\n0 1 0.23\n1 x{1} 1.12\n2 x{2} -1.07\nx[1] x[1]x[2] x[2]\nData Points dell’esempio Decision Boundary:\n0.23 + 1.12 x[1] - 1.07 x[2] = 0Score( x) < 0 Score( x) > 0",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#4": " \n5\nj 𝜱j wj\n0 1 1.68\n1 x{1} 1.39\n2 x{2} -0.59\n3 x{1}^2 -0.17\n4 x{2}^2 -0.96\nx[2]\nx[1] x[1]x[2]\nData Points dell’esempio\nOverﬁtting \nApprendimento della Decision Boundary \n1.68 + 1.39 x[1] - 0.59 x[2] - 0.17 x[1]^2  - 0.96 x[2]^2 = 0Score( x) < 0 Score( x) > 0\nDecision Boundary:",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#5": " \n6\nj 𝜱j wj\n0 1 21.6\n1 x{1} 5.3\n2 x{2} -42.7\n3 x{1}^2 -15.9\n4 x{2}^2 -48.6\n5 x{1}^3 -11.0\n6 x{2}^3 67.0\n… … …\n11 x[1]^6 0.8\n12 x[2]^6 -8.6\nx[2]\nx[1] x[1]x[2]\nData Points dell’esempio\nOverﬁtting \nApprendimento della Decision Boundary \nScore( x) < 0 Score( x) > 0\nI valori assoluti di vari coefﬁcienti \nwj sono aumentati(chiaro overﬁtting)Decision Boundary",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#6": " \n7\nx[2]\nx[1]x[2]\nx[1]\nData Points dell’esempio\nOverﬁtting \nApprendimento della Decision Boundary \nScore( x) < 0 Score( x) > 0\n(overﬁtting ancora più evidente)j 𝜱j wj\n0 1 8.7\n1 x{1} 5.1\n2 x{2} 78.7\n… … …\n11 x{1}^6 -7.5\n12 x{2}^6 3803\n13 x{1}^7 21.1\n14 x{2}^7 -2406\n… … …\n39 x[1]^20 -2*10^-8\n40 x[2]^20 0.03\nI valori assoluti di vari coefﬁcienti \nwj sono aumentati ancora di piùDecision Boundary",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#7": "Andamento Errori  \ne Bias-Variance Trade-off\n \n8\nL’andamento del training error e del true error per la \nclassiﬁcation è in genere il seguente:\nDobbiamo come al solito considerare il trade-off tra bias e varianza.True Error\nTraining Error\nModel ComplexityClassiﬁcation\nError\nDato un modello con parametri ŵ, si ha overﬁtting \nse esiste un modello con i parametri stimati w’ tale \nche: \n 1. training error( ŵ) < training error(w’) \n 2. true error( ŵ) > true error(w’) \nŵ w’\n",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#8": "Regularization \nnella Classiﬁcazione\n \n9\nL’idea è quella di limitare il valore assoluto dei coefﬁcienti w i \ndeﬁnendo come segue la funzione di qualità totale (da \nmassimizzare nella fase di training): \nQualità_totale  = misura del “ﬁt” - misura grandezza coefﬁcienti\nPer misura del “ﬁt” intendiamo una funzione come la MLE. \nLa misura dei coefﬁcienti possiamo deﬁnirla in vari modi. ",
    "data_test\\rootfolder\\università\\MachineLearning\\17-Classification - Overfitting e Regularization-sbloccato.pdf#9": "Misura dei Coefﬁcienti \n \n10\nSomma dei valori:                                                  \nSomma dei valori assoluti ( L1 norm ): \nSomma dei quadrati (quadrato della L2 norm ): w0+w1+w2+···+wD\n|w0|+|w1|+|w2|+···+|wD|=DX\nj=0|wj|,kwk1\n👍\n👎\n👍\nw2\n0+w2\n1+w2\n2+···+w2\nD=DX\nj=0w2\nj,kwk2\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Regressione e Classiﬁcazione (Ex04)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#1": "Sommario\nEsercizi su Linear models per la classiﬁcazione",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#10": "LinearLogistic: Breast cancer dataset\nEsercizio\n : visualizza i parametri del modello. Cosa ti aspetti? \nplt\n.\nplot\n(\nlogreg\n.\ncoef_\n.\nT\n, \n'o'\n, \nlabel\n=\n\"C=1\"\n)\nplt\n.\nplot\n(\nlogreg100\n .\ncoef_\n.\nT\n, \n'^'\n, \nlabel\n=\n\"C=100\"\n)\nplt\n.\nplot\n(\nlogreg001\n .\ncoef_\n.\nT\n, \n'v'\n, \nlabel\n=\n\"C=0.001\"\n )\nplt\n.\nxticks\n(\nrange\n(\ncancer\n.\ndata\n.\nshape\n[\n1\n]), \ncancer\n.\nfeature_names\n , \nrotation\n =\n90\n)\nplt\n.\nhlines\n(\n0\n, \n0\n, \ncancer\n.\ndata\n.\nshape\n[\n1\n])\nplt\n.\nylim\n(\n-\n5\n, \n5\n)\nplt\n.\nxlabel\n(\n\"Coefficient index\"\n )\nplt\n.\nylabel\n(\n\"Coefficient magnitude\"\n )\nplt\n.\nlegend\n()\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#11": "LinearLogistic: Breast cancer dataset\nRegolarizzazioni alte spingono i parametri a 0.  \nIn alcuni casi (\n mean perimeter\n ), per C=100 e C=1 il coefﬁciente è negativo, \npositivo per C=0.001.  \n12\nAttenzione: \n È sbagliato \npensare che i parametri \nsuggeriscano quali features \ndeterminino direttamente la \nclasse (tumore maligno o \nmeno). L'importanza della \nfeature dipende strettamente \ndal modello preso in \nconsiderazione.",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#12": "LinearLogistic: Breast cancer dataset\nEsercizio\n : cerca di interpretare meglio l'importanza delle feature \nimpiegando la L1 regularization. \n13",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#13": "LinearLogistic: Breast cancer dataset\nEsercizio\n : cerca di interpretare meglio l'importanza delle feature impiegando la L1 \nregularization. \nfor \nC\n, \nmarker \nin \nzip\n([\n0.001\n, \n1\n, \n100\n], [\n'o'\n, \n'^'\n, \n'v'\n]):\nlr_l1 \n= \nLogisticRegression\n (\nC\n=\nC\n, \npenalty\n=\n\"l1\"\n)\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Training accuracy of l1 logreg with C={:.3f}: {:.2f}\"\n .\nformat\n(\nC\n, \nlr_l1\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Test accuracy of l1 logreg with C={:.3f}: {:.2f}\"\n .\nformat\n(\nC\n, \nlr_l1\n.\nscore\n(\nX_test\n, \ny_test\n)))\nplt\n.\nplot\n(\nlr_l1\n.\ncoef_\n.\nT\n, \nmarker\n, \nlabel\n=\n\"C={:.3f}\"\n .\nformat\n(\nC\n))\nplt\n.\nxticks\n(\nrange\n(\ncancer\n.\ndata\n.\nshape\n[\n1\n]), \ncancer\n.\nfeature_names\n , \nrotation\n =\n90\n)\nplt\n.\nhlines\n(\n0\n, \n0\n, \ncancer\n.\ndata\n.\nshape\n[\n1\n])\nplt\n.\nxlabel\n(\n\"Coefficient index\"\n )\nplt\n.\nylabel\n(\n\"Coefficient magnitude\"\n )\nplt\n.\nylim\n(\n-\n5\n, \n5\n)\nplt\n.\nlegend\n(\nloc\n=\n3\n)\n> Training accuracy of l1 logreg with C=0.001: 0.91\n> Test accuracy of l1 logreg with C=0.001: 0.92\n> Training accuracy of l1 logreg with C=1.000: 0.96\n> Test accuracy of l1 logreg with C=1.000: 0.96\n> Training accuracy of l1 logreg with C=100.000: 0.99\n> Test accuracy of l1 logreg with C=100.000: 0.98\n14",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#14": "LinearLogistic: Breast cancer dataset\nL'effetto della L1 regularization dipende dal valore del parametro, in modo \nsimile al caso della regressione. \n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#15": "Linear models per la classiﬁcazione multiclass\nAlcuni modelli non si adattano facilmente al caso multiclass.  \nUn approccio piuttosto semplice è il\n  one-vs-rest:\n  si creano vari modelli, \ndove ogni modello si addestra a riconoscere una speciﬁca classe. Durante \nla predizione vengono valutati tutti i modelli e quello con score più alto \ndetermina la classe in output. \nChiaramente si avranno un insieme di parametri da addestrare per ogni \nclasse. \n16",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#16": "Linear models per la classiﬁcazione multiclass\nEsempio\n : creiamo un dataset con 2 features e 3 classi e impieghiamo il \nLinear SVM per la classiﬁcazione. Il dataset è creato seguendo una \ndistribuzione gaussiana. \nfrom \nsklearn.datasets \n import \nmake_blobs\nX\n, \ny \n= \nmake_blobs\n (\nrandom_state\n =\n42\n)\nmglearn\n.\ndiscrete_scatter\n (\nX\n[:, \n0\n], \nX\n[:, \n1\n], \ny\n)\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\nplt\n.\nlegend\n([\n\"Class 0\"\n , \n\"Class 1\"\n , \n\"Class 2\"\n ])\n17\n",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#17": "Linear models per la classiﬁcazione multiclass\nlinear_svm \n = \nLinearSVC\n ()\n.\nfit\n(\nX\n, \ny\n)\nprint\n(\n\"Coefficient shape: \"\n , \nlinear_svm\n .\ncoef_\n.\nshape\n)\nprint\n(\n\"Intercept shape: \"\n , \nlinear_svm\n .\nintercept_\n .\nshape\n)\n> Coefficient shape: (3, 2)\n>Intercept shape: (3,)\nOgni riga di \n _coef\n  rappresenta il vettore dei parametri per una delle 3 \nclassi, e le colonne sono le 2 features. \n intercept_\n  è un array 1d che \nmemorizza l'intercetta per ogni classe. \nmglearn\n.\ndiscrete_scatter\n (\nX\n[:, \n0\n], \nX\n[:, \n1\n], \ny\n)\nline \n= \nnp\n.\nlinspace\n (\n-\n15\n, \n15\n)\nfor \ncoef\n, \nintercept\n , \ncolor \nin \nzip\n(\nlinear_svm\n .\ncoef_\n, \nlinear_svm\n .\nintercept_\n ,\n[\n'b'\n, \n'r'\n, \n'g'\n]):\nplt\n.\nplot\n(\nline\n, \n-\n(\nline \n* \ncoef\n[\n0\n] \n+ \nintercept\n ) \n/ \ncoef\n[\n1\n], \nc\n=\ncolor\n)\nplt\n.\nylim\n(\n-\n10\n, \n15\n)\nplt\n.\nxlim\n(\n-\n10\n, \n8\n)\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\nplt\n.\nlegend\n([\n'Class 0'\n , \n'Class 1'\n , \n'Class 2'\n , \n'Line class 0'\n , \n'Line class 1'\n ,\n'Line class 2'\n ], \nloc\n=\n(\n1.01\n, \n0.3\n))\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#18": "Linear models per la classiﬁcazione multiclass\nOgni istanza etichettata con la classe 0 è al di sopra della \n boundary  \ndeﬁnita dal classiﬁcatore per la class 0. Le istanze delle altre classi al di \nsotto. Stessa cosa per la classe 1 e 2, e i relativi classiﬁcatori. \nCosa succede se una istanza si trova nel triangolo centrale? \n19\n",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#19": "Linear models per la classiﬁcazione multiclass\nCosa succede se una istanza si trova nel triangolo centrale? \nLa classe associata corrisponde alla linea più vicina. \n20\n",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#2": "Richiami: Linear models per la classiﬁcazione\nI modelli lineari possono essere impiegati per la classiﬁcazione con \ndecision boundary\n  che rappresento linee, piani o iperpiani.  \nNella logisitic regression si impiega un modello lineare tradizionale il cui \noutput è valutato da una funzione \n logistic\n  (s\nigmoid function\n ) che restituisce \nun valore in [0,1] ed indica la probabilità di appartenenza ad una certa \nclasse (> 0.5) o meno (< 0.5). \nIl \ngradient descent\n  è impiegato per minimizzare la funzione di costo. \nI due algoritmi di classiﬁcazione lineari più famosi sono la \n logistic \nregression\n , e i \nlinear support vector machine\n  (o Linear SVM) che vedremo \nin seguito. \nScikit-learn fornisce la classe \n linear_model.LogisticRegression\n  e \nsvm.LinearSVC\n  che implementa i due algoritmi.\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#20": "Linear models per la classiﬁcazione multiclass\nIl seguente codice mostra le regioni associate alle predizioni \nmglearn\n.\nplots\n.\nplot_2d_classification\n (\nlinear_svm\n , \nX\n, \nfill\n=\nTrue\n, \nalpha\n=.\n7\n)\nmglearn\n.\ndiscrete_scatter\n (\nX\n[:, \n0\n], \nX\n[:, \n1\n], \ny\n)\nline \n= \nnp\n.\nlinspace\n (\n-\n15\n, \n15\n)\nfor \ncoef\n, \nintercept\n , \ncolor \nin \nzip\n(\nlinear_svm\n .\ncoef_\n, \nlinear_svm\n .\nintercept_\n ,\n                            [\n 'b'\n, \n'r'\n, \n'g'\n]):\nplt\n.\nplot\n(\nline\n, \n-\n(\nline \n* \ncoef\n[\n0\n] \n+ \nintercept\n ) \n/ \ncoef\n[\n1\n], \nc\n=\ncolor\n)\nplt\n.\nlegend\n([\n'Class 0'\n , \n'Class 1'\n , \n'Class 2'\n , \n'Line class 0'\n , \n'Line class 1'\n ,\n      \n'Line class 2'\n ], \nloc\n=\n(\n1.01\n, \n0.3\n))\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\n21",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#21": "Linear models per la classiﬁcazione multiclass\n22\n",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#22": "Considerazioni sul tuning\nGli iperparametri C e \n λ\n sono solitamente campionati su scala logaritmica. \nSe si assume che il dataset contenga solo alcune feature rilevanti si può \ntestare la L1 regularization, altrimenti si tende a preferire la L2.  \nLa L1 regularization è utile anche per dare una interpretazione del modello.   \nI modelli lineari sono veloci da addestrare, anche su dati sparsi. \nPer dataset con >100.000 istanze si può impiegare il parametro \n solver='sag'  \nnella LogisticRegression e Ridge, che rende l'apprendimento più veloce. \nAltre opzioni sono SGDClassiﬁer e SGDRegressor che implementano \nversioni più scalabili dei relativi algoritmi. \nI parametri possono indicare quali feature siano più rilevanti, nei casi in cui \nle feature sono indipendenti tra loro. \nI modelli lineari hanno buone performance quando il numero di features è \ngrande rispetto al numero di istanze. Sono impiegati anche su grandi dataset \nperché spesso gli altri modelli non sono facilmente addestrabili.\n23",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#23": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#3": "Linear models per la classiﬁcazione: forge dataset\nEsercizio\n : impiega il forge dataset e la LogisticRegression per la \nclassiﬁcazione. Valuta le performance. \nfrom \nsklearn.linear_model \n import \nLogisticRegression\nX\n, \ny \n= \nmglearn\n.\ndatasets\n .\nmake_forge\n ()\n...\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#4": "Linear models per la classiﬁcazione: forge dataset\nEsercizio\n : impiega il forge dataset e la LogisticRegression per la \nclassiﬁcazione. Valuta le performance. \nfrom \nsklearn.linear_model \n import \nLogisticRegression\nfrom \nsklearn.svm \n import \nLinearSVC\nX\n, \ny \n= \nmglearn\n.\ndatasets\n .\nmake_forge\n ()\nfig\n, \naxes \n= \nplt\n.\nsubplots\n (\n1\n, \n2\n, \nfigsize\n=\n(\n10\n, \n3\n))\nfor \nmodel, \nax \nin \nzip\n([\nLinearSVC\n (), \nLogisticRegression\n ()], \naxes\n):\nclf \n= \nmodel\n.\nfit\n(\nX\n, \ny\n)\nmglearn\n.\nplots\n.\nplot_2d_separator\n (\nclf\n, \nX\n, \nfill\n=\nFalse\n, \neps\n=\n0.5\n,\nax\n=\nax\n, \nalpha\n=.\n7\n)\nmglearn\n.\ndiscrete_scatter\n (\nX\n[:, \n0\n], \nX\n[:, \n1\n], \ny\n, \nax\n=\nax\n)\nax\n.\nset_title\n (\n\"{}\"\n.\nformat\n(\nclf\n.\n__class__\n .\n__name__\n ))\nax\n.\nset_xlabel\n (\n\"Feature 0\"\n )\nax\n.\nset_ylabel\n (\n\"Feature 1\"\n )\naxes\n[\n0\n]\n.\nlegend\n()\nNota: \n Impieghiamo entrambe le implementazioni, anche se l'algoritmo SVM \nlo vedremo in dettaglio in seguito. \n5",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#5": "Linear models per la classiﬁcazione: forge dataset\nIn questo dataset la decision boundary è rappresentata da una retta. \n6\n",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#6": "Scikit-learn: Logistic regression\nIn Scikit-learn, la Logistic regression impiega la \n L2\n di default. \nIl parametro \n penalty\n  speciﬁca quale regolarizzazione impiegare {‘l1’, ‘l2’, \n‘elasticnet’, ‘none’}.  \nIl parametro \n C\n indica il peso della regolarizzazione (valori bassi \nrappresentano una regolarizzazione maggiore), il default è C=1.0  \n7",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#7": "Richiami: Linear models per la classiﬁcazione\nAl variare di \n C\n si può notare l'effetto sul dataset considerato. \nCon alta regolarizzazione (C basso) il modello sbaglia a classiﬁcare 2 \nistanze cercando di considerare la \"maggioranza\" durante la scelta della \ndecision boundary. \nPer valori più alti di C la retta si inclina dando più importanza ai 2 punti. \nUn punto rimane comunque non classiﬁcato, ed è impossibile considerarlo \ncon una semplice linea retta. \n8\n",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#8": "LinearLogistic: Breast cancer dataset\nEsercizio\n : valuta la \n linera logistic \n nel caso del Breast cancer dataset, \nconsiderando valori di C pari a 0.01, 1 e 100. Commenta i risultati ottenuti \nin termini di accuracy e potenziali fenomeni di over o underﬁtting.\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\18-Ex_04 Esercitazione Linear models per la classificazione-sbloccato.pdf#9": "LinearLogistic: Breast cancer dataset\nEsercizio\n : valuta la linera logistic nel caso del Breast cancer dataset, \nconsiderando valori di C pari a 1, 100 e 0.01. \nfrom \nsklearn.datasets \n import \nload_breast_cancer\ncancer \n= \nload_breast_cancer\n ()\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\ncancer\n.\ndata\n, \ncancer\n.\ntarget\n, \nstratify\n =\ncancer\n.\ntarget\n, \nrandom_state\n =\n42\n)\nlogreg \n= \nLogisticRegression\n (C=1)\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Training set score: {:.3f}\"\n .\nformat\n(\nlogreg\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Test set score: {:.3f}\"\n .\nformat\n(\nlogreg\n.\nscore\n(\nX_test\n, \ny_test\n)))\nTraining set score: 0.953\nTest set score: 0.958\nTraining set score: 0.972\nTest set score: 0.965\nTraining set score: 0.934\nTest set score: 0.930\nPer C=1 c'è un probabile underﬁtting. Per C=100 (modello più complesso) \nmigliorano le performance. Per C=0.01 si incrementa l'underﬁtting iniziale.\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Decision Trees (Ex05)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#1": "Sommario\nRichiami \nscikit-learn e decision trees \nVisualizzazione \nFeature importance \nDecision trees e regressione \nPruning",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#10": "scikit-learn e decision trees\ntree \n= \nDecisionTreeClassifier\n (\nmax_depth\n =\n4\n, \nrandom_state\n =\n0\n)\ntree\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Accuracy on training set: {:.3f}\"\n .\nformat\n(\ntree\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Accuracy on test set: {:.3f}\"\n .\nformat\n(\ntree\n.\nscore\n(\nX_test\n, \ny_test\n)))\n> Accuracy on training set: 0.988\n> Accuracy on test set: 0.951\nPiù bassa sul training, ma migliora (meno overﬁtting) sul test.\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#11": "scikit-learn: visualizzare i decision trees\nLa funzione \n export_graphviz\n  del modulo \n tree\n permette di visualizzare \nl'albero. Salva un ﬁle .dot che può essere importato per la visualizzazione. \nfrom \nsklearn.tree \n import \nexport_graphviz\nexport_graphviz\n (\ntree\n, \nout_file\n =\n\"tree.dot\"\n , \nclass_names\n =\n[\n\"malignant\"\n , \n\"benign\"\n ], \nfeature_names\n =\ncancer\n.\nfeature_names\n , \nimpurity\n =\nFalse\n, \nfilled\n=\nTrue\n)\nimport \ngraphviz\nwith \nopen\n(\n\"tree.dot\"\n ) \nas \nf\n:\ndot_graph \n = \nf\n.\nread\n()\ngraphviz\n .\nSource\n(\ndot_graph\n )\nVisualizzare il \"comportamento\" di un algoritmo di ML è molto utile per \nspiegarne l'output (\n explaination\n ), in questo caso anche ai non-esperti.\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#12": "scikit-learn: visualizzare i decision trees\nL'albero generato:\n13\nsamples  indica il numero di \nistanze, value  la rispettiva \nsuddivisione in base alle label, \nclass  la classe majoriy.",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#13": "scikit-learn: visualizzare i decision trees\nUn altro modo per esplorare i decision trees è assegnare una misura di \nimportanza\n  alle feature in base al funzionamento dell'algoritmo. \nLa variabile feature_importances_ del modello è un array con valori in [0,1] \ndove 1 indica \"predice perfettamente in valore target\". \nprint\n(\n\"Feature importances:\\n{}\"\n .\nformat\n(\ntree\n.\nfeature_importances_\n ))\nOut[62]:\n[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.01\n0.048 0. 0. 0.002 0. 0. 0. 0. 0. 0.727 0.046\n0. 0. 0.014 0. 0.018 0.122 0.012 0. ]\ndef \nplot_feature_importances_cancer\n (\nmodel\n):\nn_features \n = \ncancer\n.\ndata\n.\nshape\n[\n1\n]\nplt\n.\nbarh\n(\nrange\n(\nn_features\n ), \nmodel\n.\nfeature_importances_\n , \nalign\n=\n'center'\n )\nplt\n.\nyticks\n(\nnp\n.\narange\n(\nn_features\n ), \ncancer\n.\nfeature_names\n )\nplt\n.\nxlabel\n(\n\"Feature importance\"\n )\nplt\n.\nylabel\n(\n\"Feature\"\n )\nplot_feature_importances_cancer\n (\ntree\n)\n14",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#14": "Decision trees e feature importance\nUn altro modo per esplorare i decision trees è assegnare una misura di \nimportanza\n  alle feature in base al funzionamento dell'algoritmo. \nLa variabile \n feature_importances_\n  del modello è un array con valori in \n[0,1] dove 1 indica \"predice perfettamente in valore target\". È valutata \nmediante la metrica GINI. \nprint\n(\n\"Feature importances:\\n{}\"\n .\nformat\n(\ntree\n.\nfeature_importances_\n ))\nOut[62]:\n[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.01\n0.048 0. 0. 0.002 0. 0. 0. 0. 0. 0.727 0.046\n0. 0. 0.014 0. 0.018 0.122 0.012 0. ]\ndef \nplot_feature_importances_cancer\n (\nmodel\n):\nn_features \n = \ncancer\n.\ndata\n.\nshape\n[\n1\n]\nplt\n.\nbarh\n(\nrange\n(\nn_features\n ), \nmodel\n.\nfeature_importances_\n , \nalign\n=\n'center'\n )\nplt\n.\nyticks\n(\nnp\n.\narange\n(\nn_features\n ), \ncancer\n.\nfeature_names\n )\nplt\n.\nxlabel\n(\n\"Feature importance\"\n )\nplt\n.\nylabel\n(\n\"Feature\"\n )\nplot_feature_importances_cancer\n (\ntree\n)\n15",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#15": "Decision trees e feature importance\nSi può notare come worst radius è la feature più discriminante. Questo \nindica anche che l'albero è ben costruito avendo questa feature in cima. \nPuoi dire che una \n feature\n  con bassa importance è poco discriminante?\n16\n",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#16": "Esempio: feature importance\ntree \n= \nmglearn\n.\nplots\n.\nplot_tree_not_monotone\n ()\ndisplay\n(\ntree\n)\nEsercizio: \n In questo esempio come costruiresti l'albero di decisione?\n17\nX[0]X[1]",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#17": "Esempio: feature importance\ntree \n= \nmglearn\n.\nplots\n.\nplot_tree_not_monotone\n ()\ndisplay\n(\ntree\n)\nIn questo esempio, l'informazione rilevante è contenuta in X[1]. Infatti non \npossiamo dire che un valore alto per la feature X[0] identiﬁca la classe 0, e \nuno basso la classe 1. L'albero effettivamente impiega la feature corretta.\n18\nX[0]X[1]",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#18": "scikit-learn: decision tree per la regressione\nLa classe DecisionTreeRegressor impiega lo stesso algoritmo in ambito di \nregressione \nimport \npandas \nas \npd\nram_prices \n = \npd\n.\nread_csv\n (\n\"data/ram_price.csv\"\n )\nplt\n.\nsemilogy\n (\nram_prices\n .\ndate\n, \nram_prices\n .\nprice\n)\nplt\n.\nxlabel\n(\n\"Year\"\n)\nplt\n.\nylabel\n(\n\"Price in $/Mbyte\"\n )\n19\nhttps://github.com/amueller/introduction_to_ml_with_python/blob/master/data/ram_price.csvSu scala logaritmica per le y si può \nipotizzare una relazione lineare",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#19": "scikit-learn: decision tree per la regressione\nConfrontiamo i decision trees con un modelli lineare, con l'accortezza di \nconvertire i dati in valori logaritmo altrimenti il modello lineare non può \nfunzionare. \nfrom \nsklearn.tree \n import \nDecisionTreeRegressor\n# use historical data to forecast prices after the year 2000\ndata_train \n = \nram_prices\n [\nram_prices\n .\ndate \n< \n2000\n]\ndata_test \n = \nram_prices\n [\nram_prices\n .\ndate \n>= \n2000\n]\n# predict prices based on date\nX_train \n = \ndata_train\n .\ndate\n[:, \nnp\n.\nnewaxis\n]\n# we use a log-transform to get a simpler relationship of data to target\ny_train \n = \nnp\n.\nlog\n(\ndata_train\n .\nprice\n)\ntree \n= \nDecisionTreeRegressor\n ()\n.\nfit\n(\nX_train\n, \ny_train\n)\nlinear_reg \n = \nLinearRegression\n ()\n.\nfit\n(\nX_train\n, \ny_train\n)\n# predict on all data\nX_all \n= \nram_prices\n .\ndate\n[:, \nnp\n.\nnewaxis\n]\npred_tree \n = \ntree\n.\npredict\n(\nX_all\n)\npred_lr \n = \nlinear_reg\n .\npredict\n(\nX_all\n)\n# undo log-transform\nprice_tree \n = \nnp\n.\nexp\n(\npred_tree\n )\nprice_lr \n = \nnp\n.\nexp\n(\npred_lr\n)\nCosa ti aspetti?\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#2": "Richiami: Decision Trees\nImpiegati spesso per la classiﬁcazione e regressione.  \nIn sintesi creano una albero di nodi if/else che porta ad una certa \ndecisione.  \nSi può rappresentare come un albero dove le foglie contengono la risposta.\n3\n",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#20": "scikit-learn: decision tree per la regressione\nplt\n.\nsemilogy\n (\ndata_train\n .\ndate\n, \ndata_train\n .\nprice\n, \nlabel\n=\n\"Training data\"\n )\nplt\n.\nsemilogy\n (\ndata_test\n .\ndate\n, \ndata_test\n .\nprice\n, \nlabel\n=\n\"Test data\"\n )\nplt\n.\nsemilogy\n (\nram_prices\n .\ndate\n, \nprice_tree\n , \nlabel\n=\n\"Tree prediction\"\n )\nplt\n.\nsemilogy\n (\nram_prices\n .\ndate\n, \nprice_lr\n , \nlabel\n=\n\"Linear prediction\"\n )\nplt\n.\nlegend\n()\nIl modello lineare approssima con una retta. Il decision tree è molto più \naccurato nella predizione. \nMa che succede dopo l'ultima data presente nel dataset?\n21\n",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#21": "scikit-learn: decision tree per la regressione\nplt\n.\nsemilogy\n (\ndata_train\n .\ndate\n, \ndata_train\n .\nprice\n, \nlabel\n=\n\"Training data\"\n )\nplt\n.\nsemilogy\n (\ndata_test\n .\ndate\n, \ndata_test\n .\nprice\n, \nlabel\n=\n\"Test data\"\n )\nplt\n.\nsemilogy\n (\nram_prices\n .\ndate\n, \nprice_tree\n , \nlabel\n=\n\"Tree prediction\"\n )\nplt\n.\nsemilogy\n (\nram_prices\n .\ndate\n, \nprice_lr\n , \nlabel\n=\n\"Linear prediction\"\n )\nplt\n.\nlegend\n()\nIl modello lineare approssima con una retta. Il decision tree è molto più \naccurato nella predizione. \nAttenzione: \n L'algoritmo decision tree non è in grado di fare predizioni su \nnuovi dati con la data oltre a quella contenuta nel dataset. \n22\n",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#22": "scikit-learn: decision tree e pruning\nPer limitare l'overﬁtting e la complessità, solitamente è sufﬁciente \nimpiegare una tecnica di pre-pruning con uno dei seguenti parametri: \nmax_depth\n , \nmax_leaf_nodes\n ,  o.  \nmin_samples_leaf\nNota: \n min_samples_leaf indica il minimo numero di istanze per foglia. \nEsercizio\n : prova ad addestrare nuovamente il decision trees sul breast \ncancer dataset impostano a turno uno di questi valori e valutare le \nvariazioni di accuracy.\n23",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#23": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#3": "Richiami: Decision Trees\nIn ML, ogni \"domanda\" in un nodo è chiamata comunemente \n test\n, ed è \nspesso codiﬁcata con feature su domini continui, ad esempio: \nla feature \n i\n è maggiore del valore \n a\n? \nL'algoritmo si focalizza nello scegliere le sequenze if/else che portano ad \nuna riposta più velocemente, ovvero sono più \n informative\n  per la variabile \ntarget.\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#4": "Dataset two_moons\nToy dataset generato da scikit-learn \nsklearn.datasets.make_moons(\n n_samples=100\n , \n*\n, \nshuﬄe=True\n , \nnoise=None\n , \nrandom_state=None\n )\nOgni istanza ha 2 valori. \nAd esempio, per 75 istanze otteniamo: \nPer la profondità 0 dell'albero, quale test immagineresti?\n5\n",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#5": "Decision Trees su two_moons dataset\nDepth = 1 \nDepth = 2 \n...\n6\ndove [2,32] indica che 2 istanze appartengono \nalla classe 1 e 32 alla classe 2\nSe in una foglia ci sono istanze appartenenti \nad una sola classe allora la foglia si chiama \npure.",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#6": "Richiami: Decision Trees\nOgni test considera una singola feature, perciò la relativa decisione è \nrappresentata come una asse parallelo ad uno degli assi. \nNella predizione, una volta arrivati ad una foglia, si assegna la classe target \nche appare più spesso nella regione associata. In modo simile per la \nregressione si opera una media dei valori delle istanze nella regione. \nPer dataset grandi, creare foglie pure è molto dispendioso in termini di \nrisorse computazione e può creare fenomeni di overﬁtting. \nSi possono implementare tecniche di early stopping limitando la \nprofondità dell'albero (\n pre-pruning\n ), oppure rimuovere o fondere foglie \nche contengono poca informazione (\n post-pruning\n  o \npruning\n )\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#7": "scikit-learn e decision trees\nLa classe \n DecisionTreeClassiﬁer\n  del modulo \n DecisionTreeRegressor  \nimplementa l'algoritmo. \nEsercizio\n : prova ad impiegarlo nel dataset Breast Cancer e valuta l'accuracy \nsul training e test set \nfrom \nsklearn.tree \n import \nDecisionTreeClassifier\ncancer \n= \nload_breast_cancer\n ()\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\ncancer\n.\ndata\n, \ncancer\n.\ntarget\n, \nstratify\n =\ncancer\n.\ntarget\n, \nrandom_state\n =\n42\n)\n...\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#8": "scikit-learn e decision trees\nLa classe \n DecisionTreeClassiﬁer\n  del modulo \n DecisionTreeRegressor  \nimplementa l'algoritmo. \nEsercizio\n : prova ad impiegarlo nel dataset Breast Cancer e valuta l'accuracy \nsul training e test set \nfrom \nsklearn.tree \n import \nDecisionTreeClassifier\ncancer \n= \nload_breast_cancer\n ()\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\ncancer\n.\ndata\n, \ncancer\n.\ntarget\n, \nstratify\n =\ncancer\n.\ntarget\n, \nrandom_state\n =\n42\n)\ntree \n= \nDecisionTreeClassifier\n (\nrandom_state\n =\n0\n)\ntree\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Accuracy on training set: {:.3f}\"\n .\nformat\n(\ntree\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Accuracy on test set: {:.3f}\"\n .\nformat\n(\ntree\n.\nscore\n(\nX_test\n, \ny_test\n)))\n> Accuracy on training set: 1.000\n> Accuracy on test set: 0.937\nTi aspettavi una accuracy del 100%?\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\19-Ex_05 Esercitazione su Classificazione Decision Trees-sbloccato.pdf#9": "scikit-learn e decision trees\n> Accuracy on training set: 1.000\n> Accuracy on test set: 0.937\nTi aspettavi una accuracy del 100%? Sì, per come funziona l'algoritmo \nl'albero cresce ﬁno a creare foglie pure che rappresentazione perfettamente \nl'appartenenza delle istanze alle relative label.  \nL'accuracy sul test set è leggermente inferiore ai modelli lineari (95% ca). \nEsercizio\n : Prova a impostare una profondità col parametro \n max_depth  \ndurante la costruzione dell'oggetto DecisionTreeClassiﬁer. Cosa ti aspetti \nsulle due accuracy?\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#0": "Machine Learning \nAnno Accademico 2021 - 2022 \n  \nRichiami di Matematica",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#1": "Sommario\nRichiami sulle Funzioni Convesse \nFunzioni di più Variabili (Derivate Parziali) \nGradiente di una Funzione \nAlgoritmo di Gradient Descent \nCenni di Calcolo delle Probabilità\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#10": "Funzioni Convesse \n 11\nwg(w)\nv wg(w)\ng(v)\n..g(v)+rg(v)T(w\u0000v)g(v)+dg(v)\ndw(w\u0000v)\ncaso  \nmonodimensionale\nPer una funzione convessa g(\n w\n) differenziabile, il “piano” tangente giace sempre al \ndi sotto del graﬁco della funzione:\ng(w)\u0000g(v)+rg(v)T(w\u0000v)",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#11": "Funzioni di più Variabili\n \n12",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#12": "Derivate Parziali di \nFunzioni di più Variabili \n 13g(w0+\u0000w0,w1)\u0000g(w0,w1)\n\u0000w0\n<latexit sha1_base64=\"+SgtUNqNwOjhFnklqk6DFaFtyzI=\">AAACZXicbVHJTsMwEHXCXrayiAsHLCokEFAlgARHBBw4gkShUlNVEzMtFs6CPaGqonwn4sCZr0AiKT10YU7P772ZsZ/9WElDjvNp2VPTM7Nz8wulxaXlldXy2vqjiRItsCYiFem6DwaVDLFGkhTWY40Q+Aqf/NfrQn96R21kFD5QL8ZmAJ1QtqUAyqlW+c1raxBpZ9+LclsxJe1mrdTJ+CH3blAR8G5xPOKjBjc74Md8su0fX5YOD8pa5YpTdfrFJ4E7ABU2qLtW+ct7jkQSYEhCgTEN14mpmYImKRRmJS8xGIN4hQ42chhCgKaZ9qPJ+F5igCIeo+ZS8T6Jwx0pBMb0Aj93BkAvZlwryP+0RkLti2YqwzghDEWxiKTC/iIjtMwzQP4sNRJBcXPkMuQCNBChlhyEyMkk/4RSnoc7/vpJ8HhSdU+rJ/dnlcurQTLzbJvtsn3msnN2yW7ZHasxwT7YjzVrzVnf9rK9aW/9WW1r0LPBRsre+QVEDroO</latexit>0< |\u0000w0|<\u0000\n<latexit sha1_base64=\"u356CZIh7btrlBj4nRu25R6OhAY=\">AAACG3icbVC7TgJBFJ3FF+ILtbSZSIxWZBdNtLAwamGJiTwSIOTucMEJs4/M3NWYDZ/gJ/gVtlrZGVsLC//FATFR8FQn55ybe8/1YyUNue6Hk5mZnZtfyC7mlpZXVtfy6xtVEyVaYEVEKtJ1HwwqGWKFJCmsxxoh8BXW/P7Z0K/doDYyCq/oLsZWAL1QdqUAslI7v+vyY95UNkK8eY6KgN+2U3fwo1nTyF4A7XzBLboj8GnijUmBjVFu5z+bnUgkAYYkFBjT8NyYWilokkLhINdMDMYg+tDDhqUhBGha6ajQgO8kBijiMWouFR+J+HsihcCYu8C3yQDo2kx6Q/E/r5FQ96iVyjBOCEMxXERS4WiREVraysg7UiMRDC9HLkMuQAMRaslBCCsm9nU5+w9vsv00qZaK3n6xdHlQODkdfybLttg222MeO2Qn7IKVWYUJds8e2RN7dh6cF+fVefuOZpzxzCb7A+f9C3UZoAU=</latexit>\nConsideriamo una funzione                 di 2 variabili deﬁnita in un campo A.\ng(w0,w1)\n<latexit sha1_base64=\"0nuB/rhxp/IDPQ5Yo6JeFVwMZ9U=\">AAAB/XicbVDLSsNAFJ3UV62vqks3g0WoICWpgi6LblxWsA9IQ5hMb+vQyYOZG0sJxa9wqyt34tZvceG/mMQstHpWh3Pu5Z57vEgKjab5YZSWlldW18rrlY3Nre2d6u5eV4ex4tDhoQxV32MapAiggwIl9CMFzPck9LzJVeb37kFpEQa3OIvA8dk4ECPBGaaSPa5PXfOETl3r2K3WzIaZg/4lVkFqpEDbrX4OhiGPfQiQS6a1bZkROglTKLiEeWUQa4gYn7Ax2CkNmA/aSfLIc3oUa4YhjUBRIWkuws+NhPlaz3wvnfQZ3ulFLxP/8+wYRxdOIoIoRgh4dgiFhPyQ5kqkXQAdCgWILEsOVASUM8UQQQnKOE/FOC2nkvZhLX7/l3SbDeu00bw5q7Uui2bK5IAckjqxyDlpkWvSJh3CSUgeyRN5Nh6MF+PVePseLRnFzj75BeP9CxbnlII=</latexit>\nche si chiama rapporto incrementale parziale rispetto a       della     , perché in \nesso consideriamo incrementata soltanto la      , mantenendo inalterata la      .\nw0\n<latexit sha1_base64=\"sgHalUL2H+5/2ELVE3iy+BBsRNs=\">AAAB9XicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH6sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge64YFBJH5skSWEn1Aieq7DtTq5Tv/2I2sjAv6dZiH0Pxr4cSQGUSHfTgT0oV+yqnYEvEycnFZajMSh/9YaBiDz0SSgwpuvYIfVj0CSFwnmpFxkMQUxgjN2E+uCh6cdZ1Dk/iQxQwEPUXCqeifh7IwbPmJnnJpMe0INZ9FLxP68b0eiyH0s/jAh9kR4iqTA7ZISWSQfIh1IjEaTJkUufC9BAhFpyECIRo6SUUtKHs/j9MmnVqs5ZtXZ7Xqlf5c0U2RE7ZqfMYReszm5YgzWZYGP2xJ7ZizW1Xq036/1ntGDlO4fsD6yPb7Blkic=</latexit>\ng\n<latexit sha1_base64=\"M1D3T4qT4zLethYLQWkyJspQDuA=\">AAAB83icbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJSJRB5SYkXnyyaccj5bd3tIkZUvoIWKDtHyQRT8C7ZxAQlTjWZ2tbMTxFIYdN1Pp7S2vrG5Vd6u7Ozu7R9UD4+6JrKaQ4dHMtL9gBmQQkEHBUroxxpYGEjoBbPbzO89gjYiUvc4j8EP2VSJieAMU6k9HVVrbt3NQVeJV5AaKdAaVb+G44jbEBRyyYwZeG6MfsI0Ci5hURlaAzHjMzaFQUoVC8H4SR50Qc+sYRjRGDQVkuYi/N5IWGjMPAzSyZDhg1n2MvE/b2Bxcu0nQsUWQfHsEAoJ+SHDtUgbADoWGhBZlhyoUJQzzRBBC8o4T0WbVlJJ+/CWv18l3Ubdu6g32pe15k3RTJmckFNyTjxyRZrkjrRIh3AC5Ik8kxfHOq/Om/P+M1pyip1j8gfOxzdtWJF0</latexit>\nw0\n<latexit sha1_base64=\"sgHalUL2H+5/2ELVE3iy+BBsRNs=\">AAAB9XicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH6sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge64YFBJH5skSWEn1Aieq7DtTq5Tv/2I2sjAv6dZiH0Pxr4cSQGUSHfTgT0oV+yqnYEvEycnFZajMSh/9YaBiDz0SSgwpuvYIfVj0CSFwnmpFxkMQUxgjN2E+uCh6cdZ1Dk/iQxQwEPUXCqeifh7IwbPmJnnJpMe0INZ9FLxP68b0eiyH0s/jAh9kR4iqTA7ZISWSQfIh1IjEaTJkUufC9BAhFpyECIRo6SUUtKHs/j9MmnVqs5ZtXZ7Xqlf5c0U2RE7ZqfMYReszm5YgzWZYGP2xJ7ZizW1Xq036/1ntGDlO4fsD6yPb7Blkic=</latexit>\nw1\n<latexit sha1_base64=\"SMv9N8e7smYx2+Jzvx4lA9b269Q=\">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>\nsi ha                                 e si può considerare il seguente rapporto incrementale:\n(w0+\u0000w0,w1)2A\n<latexit sha1_base64=\"MtP2/MU/+3Vkqc9/VVk+7SdRHu8=\">AAACLXicbVDLSgNBEJz1bXxFPXoZDIKihN0oqLf4OHiMYFTIhtA7tjpk9sFMr0GW/RY/wa/wqicPgnr1N5yNOfiqU01VFz3VQaKkIdd9cYaGR0bHxicmS1PTM7Nz5fmFUxOnWmBTxCrW5wEYVDLCJklSeJ5ohDBQeBZ0Dwr/7Aa1kXF0QrcJtkO4iuSlFEBW6pR3V/3Y+kU86+WdzM35OvcPURHwXvHc4D8HvHyN+zLie51yxa26ffC/xBuQChug0Sm/+RexSEOMSCgwpuW5CbUz0CSFwrzkpwYTEF24wpalEYRo2lm/Ys5XUgMU8wQ1l4r3RfyeyCA05jYM7GQIdG1+e4X4n9dK6XKnnckoSQkjUSwiqbC/yAgtbXXkF1IjERQ/R267C9BAhFpyEMKKqT1myd7D+93+LzmtVb3Nau14q1LfH1xmgi2xZbbKPLbN6uyINViTCXbHHtgje3LunWfn1Xn/Gh1yBplF9gPOxyfAg6f7</latexit>\nSia                    .   Esiste allora un intorno circolare di centro       e \nopportuno raggio 𝜎, contenuto in A. Ne segue che, se:\nP\n<latexit sha1_base64=\"Vg7Q1rv1rOgh7aYWrlRKdHDIMjA=\">AAAB/3icbVC7TsNAEDzzDOEVoKQ5ESFRRXZAgjKChjJI5CElVnS+bMIp57O5WyNFVgq+ghYqOkTLp1DwL5yNC0iYajSzo92dIJbCoOt+OkvLK6tr66WN8ubW9s5uZW+/baJEc2jxSEa6GzADUihooUAJ3VgDCwMJnWBylfmdB9BGROoWpzH4IRsrMRKcoZX8fmTNLJs2Z3RQqbo1NwddJF5BqqRAc1D56g8jnoSgkEtmTM9zY/RTplFwCbNyPzEQMz5hY+hZqlgIxk/zo2f0ODEMIxqDpkLSXITfiZSFxkzDwE6GDO/MvJeJ/3m9BEcXfipUnCAoni1CISFfZLgW9mGgQ6EBkWWXAxWKcqYZImhBGedWTGw9ZduHN//9ImnXa95prX5zVm1cFs2UyCE5IifEI+ekQa5Jk7QIJ/fkiTyTF+fReXXenPef0SWnyByQP3A+vgGy5pat</latexit>\nP⌘(w0,w1)2A\n<latexit sha1_base64=\"JoT9dMpAcV9D5gyTs2M1a0HUaxE=\">AAACLnicbVDLSgNBEJz1bXxFPXoZDEIECbtRUDz5uHiMYBIhG8LspBMHZx/O9EbCkn/xE/wKr3oSPASvfoaz64IarVNNVTc9VV4khUbbfrOmpmdm5+YXFgtLyyura8X1jYYOY8WhzkMZqmuPaZAigDoKlHAdKWC+J6Hp3Z6nfnMASoswuMJhBG2f9QPRE5yhkTrFYzc0drqd1EbUhbtYDGj5W7wfdew9+uvt7FJXBPS0UyzZFTsD/UucnJRIjlqnOHa7IY99CJBLpnXLsSNsJ0yh4BJGBTfWEDF+y/rQMjRgPuh2kmUc0Z1YMwxpBIoKSTMRfm4kzNd66Htm0md4oye9VPzPa8XYO2onIohihICnh1BIyA5proQJDrQrFCCy9OdATXbOFEMEJSjj3IixabNg+nAm0/8ljWrF2a9ULw9KJ2d5Mwtki2yTMnHIITkhF6RG6oSTB/JEnsmL9Wi9WmPr/Wt0ysp3NskvWB+fwZ2pFA==</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#13": " 14\nSe esiste determinato e ﬁnito il seguente limite:\nlim\n\u0000w0!0g(w0+\u0000w0,w1)\u0000g(w0,w1)\n\u0000w0\n<latexit sha1_base64=\"JRgIcRMvmpBtpSOD2ft2HVySLE8=\">AAACh3icbVHLTsMwEHTCu7wKHDlgUSEVASUBBBx5HTiCRAGpqaKN2RYL5yF7Q4WifAVfx4EP4UYSeqCUPY1nZzzJOEiUNOQ4H5Y9MTk1PTM7V5tfWFxarq+s3ps41QLbIlaxfgzAoJIRtkmSwsdEI4SBwofg5bLcP7yiNjKO7ugtwW4I/Uj2pAAqKL/+7ikZ+pl3hYqAD/zMybmnZf+ZQOt4wMtjT4PI+k0vLi4qc7JBXul2+G/bLh8VuPk23+Pjtn90+Uh+7tcbTsupho8DdwgabDg3fv3Te4pFGmJEQoExHddJqJuBJikU5jUvNZiAeIE+dgoYQYimm1Xl5XwrNUAxT1BzqXhF4m9HBqExb2FQKEOgZ/N3V5L/7Top9U67mYySlDASZRBJhVWQEVoWHSB/khqJoPxy5DLiAjQQoZYchCjItHimWtGH+/fvx8H9Qcs9bB3cHjXOLobNzLJ1tsmazGUn7IxdsxvWZoJ9WRtW09q25+x9+9g+/ZHa1tCzxkbGPv8G8XPF8g==</latexit>Derivate Parziali di \nFunzioni di più Variabili \nla funzione   si dice parzialmente derivabile rispetto a       nel punto            .\ng\n<latexit sha1_base64=\"M1D3T4qT4zLethYLQWkyJspQDuA=\">AAAB83icbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJSJRB5SYkXnyyaccj5bd3tIkZUvoIWKDtHyQRT8C7ZxAQlTjWZ2tbMTxFIYdN1Pp7S2vrG5Vd6u7Ozu7R9UD4+6JrKaQ4dHMtL9gBmQQkEHBUroxxpYGEjoBbPbzO89gjYiUvc4j8EP2VSJieAMU6k9HVVrbt3NQVeJV5AaKdAaVb+G44jbEBRyyYwZeG6MfsI0Ci5hURlaAzHjMzaFQUoVC8H4SR50Qc+sYRjRGDQVkuYi/N5IWGjMPAzSyZDhg1n2MvE/b2Bxcu0nQsUWQfHsEAoJ+SHDtUgbADoWGhBZlhyoUJQzzRBBC8o4T0WbVlJJ+/CWv18l3Ubdu6g32pe15k3RTJmckFNyTjxyRZrkjrRIh3AC5Ik8kxfHOq/Om/P+M1pyip1j8gfOxzdtWJF0</latexit>\nw0\n<latexit sha1_base64=\"sgHalUL2H+5/2ELVE3iy+BBsRNs=\">AAAB9XicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH6sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge64YFBJH5skSWEn1Aieq7DtTq5Tv/2I2sjAv6dZiH0Pxr4cSQGUSHfTgT0oV+yqnYEvEycnFZajMSh/9YaBiDz0SSgwpuvYIfVj0CSFwnmpFxkMQUxgjN2E+uCh6cdZ1Dk/iQxQwEPUXCqeifh7IwbPmJnnJpMe0INZ9FLxP68b0eiyH0s/jAh9kR4iqTA7ZISWSQfIh1IjEaTJkUufC9BAhFpyECIRo6SUUtKHs/j9MmnVqs5ZtXZ7Xqlf5c0U2RE7ZqfMYReszm5YgzWZYGP2xJ7ZizW1Xq036/1ntGDlO4fsD6yPb7Blkic=</latexit>\n(w0,w1)\n<latexit sha1_base64=\"Hc3a+9D9w2RpqKTtwd9bdjillWY=\">AAACGHicbVC7TsNAEDyHVwgvAyXNiYAUJBTZAQnKCBrKIJGHlFjR+bIJJ84P3a1BkeUf4BP4Clqo6BAtHQX/gm1SkISpRjM72p11Qyk0WtaXUVhYXFpeKa6W1tY3NrfM7Z2WDiLFockDGaiOyzRI4UMTBUrohAqY50pou3eXmd++B6VF4N/gOATHYyNfDAVnmEp986DSC1I/i8cPST+2kmM6rdjJUd8sW1UrB50n9oSUyQSNvvndGwQ88sBHLpnWXdsK0YmZQsElJKVepCFk/I6NoJtSn3mgnThvk9DDSDMMaAiKCklzEf4mYuZpPfbcdNJjeKtnvUz8z+tGODx3YuGHEYLPs0UoJOSLNFciLQ10IBQgsuxyoMKnnCmGCEpQxnkqRunfSuk/7Nn286RVq9on1dr1abl+MflMkeyRfVIhNjkjdXJFGqRJOHkkz+SFvBpPxpvxbnz8jhaMSWaXTMH4/AEzF6Cm</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#14": " 15\nSupponiamo ora che la funzione g sia parzialmente derivabile rispetto a w\n 0 \nin ogni punto del campo A.  \nPer ogni punto di A resta ben determinato il corrispondente valore della \nderivata parziale rispetto a w\n 0\n. \nNasce così in A una nuova funzione di due variabili w\n 0\n, w\n 1\n che si chiama \nderivata parziale rispetto a \n w\n0\n della funzione g \n e si denota ad esempio come \nsegue:Derivate Parziali di \nFunzioni di più Variabili \n@g\n@w0\n<latexit sha1_base64=\"VQx8u7rzFuG6k3KXt2wTraBjelE=\">AAACI3icbZC5TsNAEIbX3IQrQEmzIkKiCjYgQRlBQxkkApFiyxpvJmHF+tDumEOWH4NH4ClooaJDNBR5F2wTiXOqX98/s7PzB4mShmz73ZqYnJqemZ2bry0sLi2v1FfXzk2caoEdEatYdwMwqGSEHZKksJtohDBQeBFcHZf+xTVqI+PojO4S9EIYRnIgBVCB/PqOO9AgMjcBTRJU5hLeUjbM87z2BW/8zC4I57zm1xt2066K/xXOWDTYuNp+feT2Y5GGGJFQYEzPsRPysvJloTCvuanBBMQVDLFXyAhCNF5WHZbzrdQAxTxBzaXiFcTvExmExtyFQdEZAl2a314J//N6KQ0OvUxGSUoYiXIRSYXVIiO0LBJD3pcaiaD8OXIZcQEaiFBLDkIUMC0iLPNwfl//V5zvNp295u7pfqN1NE5mjm2wTbbNHHbAWuyEtVmHCXbPHtkTe7YerBfr1Xr7bJ2wxjPr7EdZow9TRaVm</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#15": " 16Derivate Parziali di \nFunzioni di più Variabili \nsupposto determinato e ﬁnito.\nAnalogamente si deﬁnisce la derivata parziale rispetto a      , nel punto    ,  \ncome il limite\nw1\n<latexit sha1_base64=\"SMv9N8e7smYx2+Jzvx4lA9b269Q=\">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>\nP\n<latexit sha1_base64=\"RzOqhOyvtYvEmUKPvym5XynVJro=\">AAAB/nicbVC7TsNAEDyHVwivACXNiQiJKrIDEpQRNJRBIg8pjqLzZRNOOZ+tuzVSZEXiK2ihokO0/AoF/8LZuICEqUYzO9rdCWIpDLrup1NaWV1b3yhvVra2d3b3qvsHHRMlmkObRzLSvYAZkEJBGwVK6MUaWBhI6AbT68zvPoA2IlJ3OIthELKJEmPBGVrJ9yNrZtm0NR9Wa27dzUGXiVeQGinQGla//FHEkxAUcsmM6XtujIOUaRRcwrziJwZixqdsAn1LFQvBDNL85jk9SQzDiMagqZA0F+F3ImWhMbMwsJMhw3uz6GXif14/wfHlIBUqThAUzxahkJAvMlwL+y/QkdCAyLLLgQpFOdMMEbSgjHMrJradiu3DW/x+mXQade+s3rg9rzWvimbK5Igck1PikQvSJDekRdqEk5g8kWfy4jw6r86b8/4zWnKKzCH5A+fjG1b5loM=</latexit>\nlim\n\u0000w1!0g(w0,w1+\u0000w1)\u0000g(w0,w1)\n\u0000w1\n<latexit sha1_base64=\"AAg1+BW2nr0op9Oj8OQeUTZZmyE=\">AAACiHicjVFNTxsxEPVuaaHpB6E99jIiqkT6Ee0CEvSGoAeOIDWAlI1Ws2YSLLwfsmeJkLX/on+uh/6RnvCmORDgwJye38ybZz9nlVaWo+hPEL5Yeflqde11583bd+/XuxsfzmxZG0lDWerSXGRoSauChqxY00VlCPNM03l2fdT2z2/IWFUWv/i2onGO00JNlET2VNr9nWiVpy75SZoRZqmLG0iMml4xGlPOIPLHiUHppltJ6Re1Pm7WpC5qvsEy45Vf4f6iPnyH58j6zZJ/00m7vWgQzQseg3gBemJRJ2n3b3JZyjqngqVGa0dxVPHYoWElNTWdpLZUobzGKY08LDAnO3bz9Br4XFvkEioyoDTMSbqvcJhbe5tnfjJHvrIPey35VG9U82R/7FRR1UyFbI1YaZobWWmUD4HgUhlixvbmBKoAiQaZyShAKT1Z+39q84gfvv4xONsexDuD7dPd3sHhIpk18Ulsii0Riz1xII7FiRgKKf4FEPSDL2EnjMK98Mf/0TBYaD6KpQoP7wB2TsYJ</latexit>\nE se avviene che tale derivata esista in ogni punto                , resta ivi \ndeﬁnita una nuova funzione delle variabili            che si chiama la derivata \nparziale rispetto a       della                  e si indica ad esempio come segue:\n(w0,w1)2A\n<latexit sha1_base64=\"tqi9PhFGSNkmscV0Id0WgsEszQ0=\">AAACBHicbVC7TsNAEDyHVwgvAyXNiQgpSCiyAxKUARrKIJGHlFjW+bIJp5wfulsniqK0fAUtVHSIlv+g4F+wjQsITDWa2dXOjhdJodGyPozC0vLK6lpxvbSxubW9Y+7utXQYKw5NHspQdTymQYoAmihQQidSwHxPQtsbXad+ewxKizC4w2kEjs+GgRgIzjCRXNOsTFzrhE5c+5j2REAvXbNsVa0M9C+xc1ImORqu+dnrhzz2IUAumdZd24rQmTGFgkuYl3qxhojxERtCN6EB80E7syz5nB7FmmFII1BUSJqJ8HNjxnytp76XTPoM7/Wil4r/ed0YBxfOTARRjBDw9BAKCdkhzZVIKgHaFwoQWZocaPI7Z4ohghKUcZ6IcdJRKenDXvz+L2nVqvZptXZ7Vq5f5c0UyQE5JBVik3NSJzekQZqEkzF5JE/k2XgwXoxX4+17tGDkO/vkF4z3L2CgljI=</latexit>\nw0,w1\n<latexit sha1_base64=\"vH1j0jv1BCwogwzrtRh5C1k41l0=\">AAAB+nicbVC7TsNAEDzzDOEVoKQ5ESFRoMgOSFBG0FAGiTykxLLOl0045Xy27tZEkclP0EJFh2j5GQr+Bdu4gISpRjO72tnxIykM2vantbS8srq2Xtoob25t7+xW9vbbJow1hxYPZai7PjMghYIWCpTQjTSwwJfQ8cfXmd95AG1EqO5wGoEbsJESQ8EZplJ34tmndOI5XqVq1+wcdJE4BamSAk2v8tUfhDwOQCGXzJieY0foJkyj4BJm5X5sIGJ8zEbQS6liARg3yfPO6HFsGIY0Ak2FpLkIvzcSFhgzDfx0MmB4b+a9TPzP68U4vHQToaIYQfHsEAoJ+SHDtUiLADoQGhBZlhyoUJQzzRBBC8o4T8U4baac9uHMf79I2vWac1ar355XG1dFMyVySI7ICXHIBWmQG9IkLcKJJE/kmbxYj9ar9Wa9/4wuWcXOAfkD6+MbgT2TrA==</latexit>\nw1\n<latexit sha1_base64=\"SMv9N8e7smYx2+Jzvx4lA9b269Q=\">AAAB9XicbVC7TsNAEFyHVwivACXNiQiJKrIDEpQRNJRBkIeURNH5sgmnnB+6WxNFVj6BFio6RMv3UPAv2MYFJEw1mtnVzo4bKmnItj+twsrq2vpGcbO0tb2zu1feP2iZINICmyJQge643KCSPjZJksJOqJF7rsK2O7lO/fYjaiMD/55mIfY9PvblSApOiXQ3HTiDcsWu2hnYMnFyUoEcjUH5qzcMROShT0JxY7qOHVI/5pqkUDgv9SKDIRcTPsZuQn3uoenHWdQ5O4kMp4CFqJlULBPx90bMPWNmnptMepwezKKXiv953YhGl/1Y+mFE6Iv0EEmF2SEjtEw6QDaUGol4mhyZ9JngmhOhlowLkYhRUkop6cNZ/H6ZtGpV56xauz2v1K/yZopwBMdwCg5cQB1uoAFNEDCGJ3iGF2tqvVpv1vvPaMHKdw7hD6yPb7H0kig=</latexit>\ng(w0,w1)\n<latexit sha1_base64=\"0nuB/rhxp/IDPQ5Yo6JeFVwMZ9U=\">AAAB/XicbVDLSsNAFJ3UV62vqks3g0WoICWpgi6LblxWsA9IQ5hMb+vQyYOZG0sJxa9wqyt34tZvceG/mMQstHpWh3Pu5Z57vEgKjab5YZSWlldW18rrlY3Nre2d6u5eV4ex4tDhoQxV32MapAiggwIl9CMFzPck9LzJVeb37kFpEQa3OIvA8dk4ECPBGaaSPa5PXfOETl3r2K3WzIaZg/4lVkFqpEDbrX4OhiGPfQiQS6a1bZkROglTKLiEeWUQa4gYn7Ax2CkNmA/aSfLIc3oUa4YhjUBRIWkuws+NhPlaz3wvnfQZ3ulFLxP/8+wYRxdOIoIoRgh4dgiFhPyQ5kqkXQAdCgWILEsOVASUM8UQQQnKOE/FOC2nkvZhLX7/l3SbDeu00bw5q7Uui2bK5IAckjqxyDlpkWvSJh3CSUgeyRN5Nh6MF+PVePseLRnFzj75BeP9CxbnlII=</latexit>\n@g\n@w1\n<latexit sha1_base64=\"hykhrxvVEe3yRLuSCDFkAUXCvfY=\">AAACFXicbVC7TgJBFJ3FF+ILtbQZJSZWZBdNtCTaWGIijwQIuTtccMLsIzN3NWSztZ/gV9hqZWdsrS38F3eRRAVPdeac+5h73FBJQ7b9YeUWFpeWV/KrhbX1jc2t4vZOwwSRFlgXgQp0ywWDSvpYJ0kKW6FG8FyFTXd0kfnNW9RGBv41jUPsejD05UAKoFTqFfc7Aw0i7oSgSYKKh0ny87jrOUnSK5bssj0BnyfOlJTYFLVe8bPTD0TkoU9CgTFtxw6pG2czhcKk0IkMhiBGMMR2Sn3w0HTjySkJP4wMUMBD1FwqPhHxd0cMnjFjz00rPaAbM+tl4n9eO6LBWTeWfhgR+iJbRFLhZJERWqYZIe9LjUSQ/Ry59LkADUSoJQchUjFKQyukeTiz18+TRqXsHJcrVyel6vk0mTzbYwfsiDnslFXZJauxOhPsnj2yJ/ZsPVgv1qv19l2as6Y9u+wPrPcvW36gVg==</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#16": " 17\nOsserviamo che, mentre per le funzioni di una variabile la derivabilità in un \npunto implica la continuità in tale punto, non sussiste il fatto analogo per le \nfunzioni di due variabili.Derivate Parziali di \nFunzioni di più Variabili \nPossono cioè in un punto esistere le due derivate parziali senza che la \nfunzione g sia continua in esso.\nTutte le considerazioni fatte ﬁno ad ora sulle funzioni di due variabili si \nestendono immediatamente al caso delle funzioni di più di due variabili:\ng(w0,w1,...,w n)= g(w)\n<latexit sha1_base64=\"iUBK7+RA0FYb7PAax0+9XxEzqiQ=\">AAACIXicbVDLSsNAFJ34tr6iLt0MFqGClqQKuhGKblxWsK3QljKZXuvgZBJmbiwS8hV+gl/hVlfuxJ2I/+IkduHrbO6Zc19zTxBLYdDz3pyJyanpmdm5+dLC4tLyiru61jJRojk0eSQjfREwA1IoaKJACRexBhYGEtrB9Umeb9+ANiJS53gbQy9kQyUuBWdopb67O6yM+qmX7VAbfBu6gwhN8VLZNj2iw0o3iOQgHWXbpVLfLXtVrwD9S/wxKZMxGn33w87jSQgKuWTGdHwvxl7KNAouISt1EwMx49dsCB1LFQvB9NLirIxuJYZhRGPQVEhaiPC9I2WhMbdhYCtDhlfmdy4X/8t1Erw87KVCxQmC4vkiFBKKRYZrYf0COhAaEFn+c6BCUc40QwQtKOPciok1MPfD/339X9KqVf29au1sv1w/HjszRzbIJqkQnxyQOjklDdIknNyRB/JInpx759l5cV6/Sieccc86+QHn/RPB2qGW</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#17": "Gradiente\n \n18",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#18": "Gradiente di una Funzione \n 19\nIl gradiente di una funzione è una diretta generalizzazione della nozione di \nderivata per una funzione a più variabili.\nrg(w)=2\n6666666664@g(w)\n@w0\n@g(w)\n@w1\n···\n@g(w)\n@wn3\n7777777775\n<latexit sha1_base64=\"06VfDqyZDj5rj/n4a5yMYNZXbn4=\">AAADBnicpVI9j9QwEHXCxx3L1y6UNBYrpKNZJQcSNCedoKE8JPbupPVqNXFmc9Y5TmRPuFtZ6fkVtFDRIVr+BgX/BWeJBOxSwcjF6L158zxjZ7VWjpLkWxRfuXrt+s7ujcHNW7fv3B2O7h27qrESp7LSlT3NwKFWBqekSONpbRHKTONJdv6y40/eonWqMm9oVeO8hMKopZJAAVqMopEwkGkQhJfki3ZPZJXO/UX7mB9woXFJM85FhoUyHqyFVetlywc8hFhakF7UYEmB9tsd2vYXe7HwSdu2XIhw/kmebshlXpH7j34m9BsINHk/FxdWFWc0HyyG42SSrINvJ2mfjFkfR4vhd5FXsinRkNTg3CxNapr7zkpqDCaNwxrkORQ4C6mBEt3cr9+u5Y8aB1TxGi1Xmq9B/F3hoXRuVWahsgQ6c5tcB/6NmzW0fD73ytQNoZGdESmNayMnrQqfAnmuLBJBd3PkynAJFojQKg5SBrAJv6TbR7o5/XZyvD9Jn0z2Xz8dH77oN7PLHrCHbI+l7Bk7ZK/YEZsyGV1G76MP0cf4Xfwp/hx/+VkaR73mPvsj4q8/AIJp+C8=</latexit>\ng(w0,w1,...,w n)= g(w)\n<latexit sha1_base64=\"iUBK7+RA0FYb7PAax0+9XxEzqiQ=\">AAACIXicbVDLSsNAFJ34tr6iLt0MFqGClqQKuhGKblxWsK3QljKZXuvgZBJmbiwS8hV+gl/hVlfuxJ2I/+IkduHrbO6Zc19zTxBLYdDz3pyJyanpmdm5+dLC4tLyiru61jJRojk0eSQjfREwA1IoaKJACRexBhYGEtrB9Umeb9+ANiJS53gbQy9kQyUuBWdopb67O6yM+qmX7VAbfBu6gwhN8VLZNj2iw0o3iOQgHWXbpVLfLXtVrwD9S/wxKZMxGn33w87jSQgKuWTGdHwvxl7KNAouISt1EwMx49dsCB1LFQvB9NLirIxuJYZhRGPQVEhaiPC9I2WhMbdhYCtDhlfmdy4X/8t1Erw87KVCxQmC4vkiFBKKRYZrYf0COhAaEFn+c6BCUc40QwQtKOPciok1MPfD/339X9KqVf29au1sv1w/HjszRzbIJqkQnxyQOjklDdIknNyRB/JInpx759l5cV6/Sieccc86+QHn/RPB2qGW</latexit>\nData la seguente funzione:\ndeﬁniamo gradiente di g il vettore le cui componenti sono le derivate \nparziali della funzione:",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#19": " \n20\nw0w1ŵ\nŵ0ŵ1gradiente:\nijrg(w)=@g(w)\n@w0i+@g(w)\n@w1j\n<latexit sha1_base64=\"UbdTBP63qiqYyxQKEMwdHSMgLt8=\">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>\nW(t)gGradiente di una Funzione ",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#2": "Richiami sulle \nFunzioni Convesse\n \n3",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#20": " \n21\nw0w1ŵ\nŵ0ŵ1\nij\nrg(w)=@g(w)\n@w0i+@g(w)\n@w1j\n<latexit sha1_base64=\"UbdTBP63qiqYyxQKEMwdHSMgLt8=\">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>W(t)gGradiente di una Funzione ",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#21": " \n22w0w1gDerivata Direzionale \nnPw1\nw0\nQ\nw0 + 𝛼𝜌w1 + 𝛽𝜌\ngradiente:\nrg(w)=@g(w)\n@w0i+@g(w)\n@w1j\n<latexit sha1_base64=\"UbdTBP63qiqYyxQKEMwdHSMgLt8=\">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>n\nij",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#22": "Derivata Direzionale \n 23\nSi può dimostrare che la derivata direzionale secondo n è:\n@g\n@n=↵·@g\n@w0+\u0000·@g\n@w1\n<latexit sha1_base64=\"+Er6gFVcrheB4cs8jHX92VkksPI=\">AAACdXicjVHBbtNAEF2btqSBlgBSOSCkFSkIqVKw00gth0oVvXAMUpNWii1rvJmkq67Xq91xUWX5wGdy4MwncK2dBkFpqZjT2/fe7Oy+SY2SjoLgm+c/WFlde9habz96vLH5pPP02djlhRU4ErnK7WkKDpXUOCJJCk+NRchShSfp+VGjn1ygdTLXx3RpMM5gruVMCqCaSjpfo5kFUUYGLElQ5byqfh90VfEDHoEyZ8AjMc2J32f/kgR1ww6PUqT/84dV1U463aDXH3zo7+3z2yDsBYvqsmUNk873aJqLIkNNQoFzkzAwFJfNpUJh1Y4KhwbEOcxxUkMNGbq4XERV8TeFA8q5Qcul4gsS/+woIXPuMktrZwZ05v7WGvIubVLQbD8upTYFoRbNIJIKF4OcsLLeAfKptEgEzcuRS80FWCBCKzkIUZNFvZQmj1+f5v8G434v3O31Pw+6hx+XybTYS/aavWMh22OH7BMbshET7Ie34W15L7yf/it/2397bfW9Zc9zdqP891efxMJr</latexit>\nDetto \n n\n il versore della direzione \n n\n, la    è il prodotto scalare dei due \nvettori:@g\n@n\n<latexit sha1_base64=\"g3oVOo0czFVRrXmUUHD+5Uu0VMQ=\">AAACFHicdVC7TsNAEDzzDOEVoKQ5ESFRWXaIBHQRNJRBIoCURNH62IQT57N1t0aKLLd8Al9BCxUdoqWn4F+wQxDvqeZm9nE7QaykJc97cSYmp6ZnZktz5fmFxaXlysrqiY0SI7AlIhWZswAsKqmxRZIUnsUGIQwUngaXB4V/eoXGykgf0zDGbggDLftSAOVSr8I7fQMi7cRgSIJKB1n2+dBZVu5Vqp5bq+/Vdnb5b+K73ghVNkazV3ntnEciCVGTUGBt2/di6qbFSKEwK3cSizGISxhgO6caQrTddHRJxjcTCxTxGA2Xio9E/NqRQmjtMAzyyhDowv70CvEvr51Qf7ebSh0nhFoUi0gqHC2ywsg8IuTn0iARFD9HLjUXYIAIjeQgRC4meWZFHh9H8//JSc31t93aUb3a2B8nU2LrbINtMZ/tsAY7ZE3WYoJds1t2x+6dG+fBeXSe3ksnnHHPGvsG5/kN2TSgHQ==</latexit>\nrg·n\n<latexit sha1_base64=\"HmMzMEElHE9OTkg5/sPKXqpLV5A=\">AAACF3icdVC7TsNAEDzzDOEVoKQ5ESFRRU6IlNAhaCiDRCBSHEXryyacOJ+tuzUCWfkAPoGvoIWKDtFSUvAv2CZIPKe50cys9nb8SElLrvvqTE3PzM7NFxaKi0vLK6ultfVTG8ZGYFuEKjQdHywqqbFNkhR2IoMQ+ArP/IvDzD+7RGNlqE/oOsJeACMth1IApVK/VPY0+Ar4iHtiEBL3CK/IHyb5KynR43ExTbmVWn2v1mjy36RacXOU2QStfunNG4QiDlCTUGBtt+pG1EvAkBQKx0UvthiBuIARdlOqIUDbS/Jjxnw7tkAhj9BwqXgu4teJBAJrrwM/TQZA5/anl4l/ed2Yhs1eInUUE2qRLSKpMF9khZFpS8gH0iARZD9HLjUXYIAIjeQgRCrGaW1ZH59H8//Jaa1S3a3Ujuvl/YNJMwW2ybbYDquyBttnR6zF2kywG3bH7tmDc+s8Ok/O80d0ypnMbLBvcF7eAZzfoGg=</latexit>\ncioè è la componente del gradiente sulla retta orientata \n n\n. Questo signiﬁca \nche la derivata direzionale della funzione \n g \nè massima secondo la \ndirezione e verso del vettore gradiente.\nSi può avere una visione globale di tutte queste possibili derivate, \ncollegando al punto \n P \nil gradiente della funzione g in tale punto.",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#23": " \n24w0w1gDerivata Direzionale \nnPw1\nw0\nQ\nw0 + 𝛼𝜌w1 + 𝛽𝜌\ngradiente:\nrg(w)=@g(w)\n@w0i+@g(w)\n@w1j\n<latexit sha1_base64=\"UbdTBP63qiqYyxQKEMwdHSMgLt8=\">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>n\nij",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#24": " 25\nLa proprietà citata in precedenza del vettore gradiente, ossia il fatto che il \ngradiente fornisce direzione della pendenza più ripida, è alla base di \nalgoritmi di Ricerca Locale che operano in spazi continui.\nTali algoritmi si dividono in due classi principali: \n•\nAlgoritmi a Salita più Ripida (Hill-Climbing) \n•\nAlgoritmi a Discesa del Gradiente (Gradient Descent)\nAlgoritmo Gradient Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#25": " \n26\nw0w1g\nŵ\nŵ0ŵ1\nij\nW(t+1)W(t)\n- 𝛼 * gradiente\nAlgoritmo Gradient Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#26": "Algoritmo Gradient Descent\n \n27w(1)= 0 (oppure lo inizializziamo in modo casuale)\nt=1\nwhilekrg(w(t))k2>✏\nw(t+1) w(t)\u0000↵⇤rg(w(t))\nt t+1\n<latexit sha1_base64=\"C1wbNEwaiOAK1Ma17wL9dfyBIzQ=\">AAADRnichVJNbxMxEPWmfJTw1cKRy4iIKmlFtBuE4AKq4MKxlUhaKQ6R15kmVr32yp6ltKv9X/wE/gIHuMKJG+KKN42qpEViDtZ4Zt574/GkuVae4vhr1Fi7dv3GzfVbzdt37t67v7H5YOBt4ST2pdXWHabCo1YG+6RI42HuUGSpxoP0+G2dP/iIzitr3tNpjqNMTI06UlJQCI03o32e4lSZUmg1NdtVc4unVk/Kk+pD2U46FbyCGDhwwk9Utm2eFw5BW1BGnamAOQtnVl8hsxMLUvhCaAw4zqG5BRTwSfAvaGdKY1UT6gE6Am5EqsWCflq1l8SpU3XOq8Zlr4a8Bo65V9qac8KZz4XEMpFZyC7hduq2ucYjEs7ZE1jlhKfAhc5nAmAb/qe/IhR3n9dStMxNsANJk6OZXAywOd5oxd14bnDVSRZOiy1sb7zxjU+sLDI0JLXwfpjEOY1K4UjJMK0mLzyGDo7FFIfBNSJDPyrnf1/Bk8ILspCjA6VhHsRlRCky70+zNFRmgmb+cq4O/is3LOjo5ahUJi8IjayFKPzdXMhLp8JSIUyUQyJRd471DkjhBBE6BULKECzCltXzSC6//qoz6HWTZ93efq+1+2YxmXX2iD1mbZawF2yXvWN7rM9k9Dn6Hv2Ifja+NH41fjf+nJc2ogXmIVuxNfYXr1EImg==</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#27": "Algoritmo Gradient Descent\n \n28\nFunzione non convessa di due variabili:",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#28": "Richiami di Probabilità\n \n29",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#29": "Variabili Aleatorie\nLe quantità di interesse che sono determinate dal risultato di \nun esperimento casuale sono dette \n variabili aleatorie\n . \nPoiché il valore di una variabile aleatoria è determinato \ndall’esito di un esperimento, possiamo assegnare delle \nprobabilità ai suoi valori possibili. \nEsempi di v.a.: risultato del lancio di un dado, risultato del \nlancio di una moneta, ecc.\n \n30",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#3": "Insiemi Convessi \n 4Un insieme C in uno spazio vettoriale è convesso  se, comunque si scelgano \ndue punti v e w appartenenti a C, il segmento che unisce i due punti \nappartiene a C.\nPiù formalmente:\nUn insieme C in uno spazio vettoriale è convesso  se, ∀ v, w ∈ C, e ∀ λ ∈ [0, 1], si \nha:\n\u0000v+( 1\u0000\u0000)w2C",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#30": "Valore Atteso\nIl concetto di Valore Atteso è uno dei più importanti concetti \nin tutta la teoria della probabilità. \nSia X una variabile aleatoria discreta che può assumere i \nvalori x\n 1\n, x\n2\n, …, x\n N\n. Il Valore Atteso di X è il numero: \n \n31E[X],NX\ni=1[xi·P(X=xi)]",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#31": "Valore Atteso\n \n32\nSi tratta della media pesata dei valori possibili di X, usando \ncome pesi le probabilità che tali valori vengano assunti da X. \nPer questo E[X] è anche detto \n media\n  di X (termine che però è \nsconsigliabile), oppure \n aspettazione\n  (\nexpectation\n ). ",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#32": "Valore Atteso\nSia X il punteggio che si ottiene lanciando un dado non \ntruccato. Quanto vale E[X]?\n \n33E[X]=1 ·1\n6+2 ·1\n6+3 ·1\n6+4 ·1\n6+5 ·1\n6+6 ·1\n6=7\n2=3.5\nESEMPIO: lancio di un dado",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#33": "Valore Atteso\nSi noti che in questo esempio il valore atteso di X non è uno \ndei possibili valori che X può assumere.  \nPerciò, anche se E[X] è chiamato \n valore atteso\n  di X, ciò non \nvuole affatto dire che noi ci attendiamo di vedere questo \nvalore, ma piuttosto che ci aspettiamo che sia il limite a cui \ntende il punteggio medio del dado su un numero crescente di \nripetizioni.\n \n34\nESEMPIO: lancio di un dado",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#34": "Valore Atteso\nESEMPIO: Indicator Function\n \n35E[I]=1 ·P(I= 1) + 0 ·P(I= 0) = P(I= 1) = P(A)\nSe I[A] è la funzione indicatrice di un evento A, ossia se:\n     allora:\nQuindi il valore atteso della indicator function di un evento è \nla probabilità di quest’ultimo.I[A],8\n<\n:1 se A si veriﬁca\n0 se A non si veriﬁca",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#35": "Valore Atteso\nProprietà di E\n \n36\nSi riportano qui di seguito alcune proprietà della funzione E (a e \nb sono variabili aleatorie):\nE[a+b]= E[a]+E[b]\nE[k·a]= k·E[a] (k costante)\nE[a·b]= E[a]·E[b]( aebi n d i p e n d e n t i )",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#36": "Varianza\n \n37\nSia X una variabile aleatoria con media \n μ\n. La varianza di X è la \nquantità:\nVar(X),E[(X\u0000µ)2]",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#37": "Varianza\n \n38\nEsiste una formula alternativa per la varianza, che si ricava in \nquesto modo:\nossia:\nVar(X)=E[X2]\u0000E[X]2Var(X),E[(X\u0000µ)2]=\n=E[X2\u00002µX+µ2]=\n=E[X2]\u00002µ·E[X]+µ2=\n=E[X2]\u0000µ2",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#4": "Insiemi Convessi \n 5Vediamolo nel caso a due dimensioni:L’espressione: \ncorrisponde dunque ai punti appartenenti al  segmento che unisce i due punti \nv e w, al variare di λ ∈ [0, 1].\u0000v+( 1\u0000\u0000)w",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#5": " \n6wv\nλv + (1-λ)wλ(v - w)\nλv + (1- λ)w = w + λ(v-w)\nλ = 1\nλ = 0Insiemi Convessi \n[caso a due dimensioni]\nλ > 1\nλ < 0λ = 0.6\nC",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#6": " 7Vediamo ora alcuni esempi di insiemi convessi e non convessi nel caso di \nspazio a due dimensioni:\nsi ?\nsi\n noInsiemi Convessi \n[caso a due dimensioni]",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#7": " 8Vediamo ora alcuni esempi di insiemi convessi e non convessi nel caso di \nspazio a due dimensioni:\nsi no\nsi\n noInsiemi Convessi \n[caso a due dimensioni]\n",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#8": "Funzioni Convesse \n 9con\u00002[0,1]\nwg(w)\nv wg(w)\ng(v)\n.. .\n..\u0000g(v)+( 1\u0000\u0000)g(w)\ng(\u0000v+( 1\u0000\u0000)w)\n\u0000v+( 1\u0000\u0000)wg(\u0000v+( 1\u0000\u0000)w)\u0000g(v)+( 1\u0000\u0000)g(w)Sia C un insieme convesso. Una funzione                     si dice convessa se, per \nogni v e w appartenenti al suo dominio di deﬁnizione, vale la seguente proprietà:g:C!R\ng:R!R",
    "data_test\\rootfolder\\università\\MachineLearning\\2-Richiami di Matematica-sbloccato.pdf#9": "Deﬁnizione di Funzione  \nStrongly Convex\n \n10\nUna funzione \n g\n è detta \n λ\n-strongly convex\n  se, per ogni \n w\n, \nv\n e \nα \n∈\n (0, 1), si ha:\nOvviamente, ogni funzione convessa è 0\n -strongly convex.g(↵v+( 1\u0000↵)w)↵g(v)+( 1 \u0000↵)g(w)\u0000\u0000\n2↵(1\u0000↵)kv\u0000wk2\nwg(w)\nv wg(w)\ng(v)\n.. .\n..\u0000\u0000\n2↵(1\u0000↵)kv\u0000wk2\n↵v+( 1\u0000↵)wg(↵v+( 1\u0000↵)w)↵g(v)+( 1\u0000↵)g(w)",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Ensembles di Decision Trees (Ex 06)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#1": "Sommario\nEnsembles \nRandom Forests \nGradient boosted regression trees",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#10": "Scikit-learn: Random forests e breast cancer dataset\nEsercizio\n : crea un RF per il dataset breast cancer con 100 alberi, e valuta \nl'accuracy nel training e test set, confrontandola con quella ottenuta con \nun singolo DT.\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#11": "Scikit-learn: Random forests e breast cancer dataset\nEsercizio\n : crea un RF per il dataset breast cancer con 100 alberi, e valuta \nl'accuracy nel training e test set, confrontandola con quella ottenuta con \nun singolo DT. \nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\ncancer\n.\ndata\n, \ncancer\n.\ntarget\n, \nrandom_state\n =\n0\n)\nforest \n= \nRandomForestClassifier\n (\nn_estimators\n =\n100\n, \nrandom_state\n =\n0\n)\nforest\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Accuracy on training set: {:.3f}\"\n .\nformat\n(\nforest\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Accuracy on test set: {:.3f}\"\n .\nformat\n(\nforest\n.\nscore\n(\nX_test\n, \ny_test\n)))\nAccuracy on training set: 1.000\nAccuracy on test set: 0.972\nL'accuracy è più alta rispetto al modello lineare e al DT. \nÈ possibile fare un tuning con i parametri max_features e l'approccio \npruning, ma su alcuni dataset i valori di default possono essere già \nsufﬁcienti.\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#12": "Scikit-learn: Random forests e breast cancer dataset\nCosa ti aspetti dalla feature importance ottenuta mediando i valori dei \nsingoli trees?  \nplot_feature_importances_cancer\n (\nforest\n)\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#13": "Scikit-learn: Random forests e breast cancer dataset\nCosa ti aspetti dalla feature importance ottenuta mediando i valori dei \nsingoli trees?  \nplot_feature_importances_cancer\n (\nforest\n)\nIl valore aggregato ha più variabilità e tendenzialmente è più accurato. Il \nmodello considera più features dando meno importanza alle singole (es. \nworst radius\n )\n14\n",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#14": "Considerazioni sui Random forests (1)\nI RF sono modelli di ML molto utilizzati essendo versatili, non richiedono \nlunghe fasi di tuning degli iperparametri e il rescaling dei dati. \nD'altro canto se hai bisogno di una rappresentazione compatta, il singolo \nDT è la soluzione migliore. È impossibile interpretare il valore di centinaia \no più DT, soprattutto se hanno profondità elevate. \nLe implementazione dei RF possono essere facilmente parallelizzate su più \nCPU. Il parametro \n n_jobs\n  imposta il numero di core da impiegare (un \nvalore pari a -1 indica l'uso di tutti i core). \nL'approccio random nei RF rende i modelli generati sugli stessi dati anche \nmolto diversi tra loro. Se vuoi ottenere risultati riproducibili, imposta il \nparametro \n random_state\n . \nI RF non mostrano buone prestazioni su dati sparsi e/o con molte features, \nes. dati testuali. I modelli lineare sono da preferire.\n15",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#15": "Considerazioni sui Random forests (2)\nUn parametro elevato di n_estimators solitamente migliora le performance, \nma richiede più tempo e memoria per il training. \nUna indicazione per il parametro \n max_features\n  è impostarlo pari a \nsqrt(n_features)\n  per la classiﬁcazione, e \n log2(n_features)\n  per la \nregressione.\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#16": "Ensembles: Gradient boosted regression trees\nI \nGradient boosted regression trees\n  (\ngradient boosting machines\n ) \nGBRT  \nsono un approccio di \n ensembles\n , e possono essere impiegate sia per la \nclassiﬁcazione sia per la regressione.  \nA differenza dei RF, gli alberi sono costruiti in modo sequenziale, dove \nogni albero tenta di risolvere i problemi mostrati in precedenza. \nL'algoritmo è basato sull'approccio \n boosting\n  visto in precedenza.  \nAl posto dell'elemento casuale, è impiegato l'approccio pre-pruning. Gli \nalberi prodotti non sono profondi (tipicamenti depth da 1 a 5), e questo \nrende il modello più compatto e veloce nelle predizioni. \nI singoli alberi sono modelli \n semplici\n  (in ML sono spesso chiamati \n weak \nlearners\n ) che producono buone performance su alcune istanze dei dati. \nRispetto ai RF sono più sensibili alla scelta degli iperparametri, ma possono \nprodurre risultati migliori, per questo sono spesso impiegati in scenari reali.\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#17": "Ensembles: Gradient boosted regression trees\nOltre al pre-pruning e al numero di alberi (\n n_estimators\n ), un altro \niperparametro fondamentale è il \n learning_rate,\n  che controlla quanto un \nalbero deve correggere gli errori prodotti dal precedente. Un valore elevato \ngenera modelli più complessi. Allo stesso modo, un valore elevato di \nn_estimators\n  incrementa la complessità e può ridurre gli errori commessi. \nIn scikit-learn, la classe \n GradientBoostingClassiﬁer\n  implementa gli GBRT. \nNel caso del Breast cancer dataset, con 100 alberi, con profondità max pari \na 3 e un learning rate pari a 0.1: \nfrom \nsklearn.ensemble \n import \nGradientBoostingClassifier\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\ncancer\n.\ndata\n, \ncancer\n.\ntarget\n, \nrandom_state\n =\n0\n)\ngbrt \n= \nGradientBoostingClassifier\n (\nrandom_state\n =\n0\n)\ngbrt\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Accuracy on training set: {:.3f}\"\n .\nformat\n(\ngbrt\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Accuracy on test set: {:.3f}\"\n .\nformat\n(\ngbrt\n.\nscore\n(\nX_test\n, \ny_test\n)))\nAccuracy on training set: 1.000\nAccuracy on test set: 0.958\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#18": "Gradient boosted regression trees\nOtteniamo una accuracy pari al 100%, potrebbe indicare un possibile \noverﬁtting.  \nEsercizio\n : prova ad incrementare il pre-pruning o ridurre il learning rate.\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#19": "Gradient boosted regression trees\nEsercizio\n : prova ad incrementare il pre-pruning o ridurre il learning rate. \ngbrt \n= \nGradientBoostingClassifier\n (\nrandom_state\n =\n0\n, \nmax_depth\n =\n1\n)\ngbrt\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Accuracy on training set: {:.3f}\"\n .\nformat\n(\ngbrt\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Accuracy on test set: {:.3f}\"\n .\nformat\n(\ngbrt\n.\nscore\n(\nX_test\n, \ny_test\n)))\nAccuracy on training set: 0.991\nAccuracy on test set: 0.972\ngbrt \n= \nGradientBoostingClassifier\n (\nrandom_state\n =\n0\n, \nlearning_rate\n =\n0.01\n)\ngbrt\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Accuracy on training set: {:.3f}\"\n .\nformat\n(\ngbrt\n.\nscore\n(\nX_train\n, \ny_train\n)))\nprint\n(\n\"Accuracy on test set: {:.3f}\"\n .\nformat\n(\ngbrt\n.\nscore\n(\nX_test\n, \ny_test\n)))\nAccuracy on training set: 0.988\nAccuracy on test set: 0.965\nEntrambi gli approcci riducono la complessità e l'accuracy sul training set. \nIn questo scenario, ridurre la profondità migliora maggiormente le \nperformance.\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#2": "Ensembles\nIn ML, l'\n ensembles\n  un approccio che combina più modelli di ML per \ncreare un nuovo modello più soﬁsticato, che potenzialmente aggrega i \nbeneﬁci dei singoli modelli.  \nEsistono vari approcci di ensembles. Due approcci basati sui decision trees \n(\nDT\n) si sono dimostrati molto adatti in vari domini: \nRandom forests \nGradient boosted decision trees.\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#20": "Gradient boosted regression trees\nAvendo impiegato 100 alberi, è poco pratico visualizzare le decision \nboundaries di ognuno, ma possiamo analizzare le feature importance. \ngbrt \n= \nGradientBoostingClassifier\n (\nrandom_state\n =\n0\n, \nmax_depth\n =\n1\n)\ngbrt\n.\nfit\n(\nX_train\n, \ny_train\n)\nplot_feature_importances_cancer\n (\ngbrt\n)\nNoti differenze rispetto ai RF?\n21\n",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#21": "Gradient boosted regression trees\nI generale otteniamo \n importance\n  simili, ma in questo caso alcune features \nhanno peso pari a 0, cioè sono completamente ignorate dal modello.\n22\n",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#22": "Gradient boosted regression trees: considerazioni (1)\nEntrambi gli approcci ensembles mostrano buoni risultati su dati simili. Si \npuò applicare prima l'approccio RF, piuttosto robusto.  \nI GBRT richiedono un tuning degli iperparametri più lungo rispetto ai RF. \nSe il tempo impiegato per la predizione non è soddisfacente, o è \nfondamentale raggiungere una accuracy massima, si può considerare il \nGBRT. \nCome per i RF, i GBRT funzionano bene senza rescaling, e su combinazioni \ndi feature binary o continous. Ma non sono efﬁcienti per dataset con molte \nfeatures. \nI due iperparametri fondamentali sono \n n_estimators\n  e \nlearning_rate\n . Sono \ndipendenti l'uno dall'altro. Un basso learning rate richiede più alberi per \nraggiungere la stessa complessità. Un valore elevato di \n n_estimators  \nmigliora il modello, ma fa tendere il modello all'overﬁtting. \nTipicamente si imposta \n n_estimators\n  in base alle risorse a disposizione, \ndopodiché si ottimizza il valore \n learning_rates\n .\n23",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#23": "Gradient boosted regression trees: considerazioni (2)\nAltro iperparametro fondamentale è \n max_depth\n  (o alternativamente \nmax_leaf_nodes\n ) per ridurre la complessità per ogni albero. Tipicamente si \nimposta a un valore molto basso, es. < 5.  \nCon dataset di larghe dimensioni, si può considerare anche la libreria \nxgboost\n , che possiede una implementazione più ottimizzata.\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#24": "Esercizio su ensembles\nEsercizio\n : impiegare i due approcci ensembles sui restanti dataset introdotti \nnelle precedenti esercitazioni: \nForge dataset\n  (classiﬁcazione) \nwave dataset\n  (regressione) \nBoston housing dataset\n  (regressione) \nValutare la accuracy rispetto all'approccio basato sulla regressione lineare \ne al singolo decision tree.  \nOperare un tuning degli iperparametri per incrementare le performance. \n25",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#25": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n26",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#3": "Ensembles: Random forests\nI \nrandom forests\n  (\nRF\n) sono una collezione di DTs, ognuno costruito in \nmodo leggermo diverso dall'altro durante il training. \nI DTs tendono a mostrare overﬁtting. I RF tendono ad affrontare questa \nproblematica: ogni albero può mostrare overﬁtting su certi dati, ma se ne \ncostruiamo diversi in modo indipendente e mediamo i risultati complessivi, \nl'effetto dell'overﬁtting si riduce.  \nPer creare diversi DTs, introduciamo un elemento casuale durante il \nprocesso di training, ad esempio selezionando: \ndiversi set di training \ndiverse features in ogni split test\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#4": "Scikit-learn: Random forests\nIn scikit-learn esiste una implementazione dei RF per la classiﬁcazione e \nper la regressione: \n RandomForestClassiﬁer\n  e \nRandomForestRegressor\n . \nIl numero di DTs è un iperparametro del modello RF e si imposta col \nparametro \n n_estimators\n  del costruttore (es. 10). \nInizialmente si costruisce un \n bootstrap sample\n  dei dati.  \nDal training set estraiamo \n n_samples\n  istanze in modo casuale, con \nripetizione, e ripetiamo n_samples volte. \nIl dataset che si ottiene è grande come quello originale, ma alcune \nistanze si possono ripetere, altre sono mancanti (approssimativamente \n1/3)  \nEs.: se il dataset = ['a', 'b', 'c', 'd'], un possibile bootstrap è ['b', 'd', 'd', \n'c'], un altro ['d', 'a', 'd', 'a']. \nDopodiché si addestra un DT per ogni boostrap sample.\n5",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#5": "Scikit-learn: Random forests\nUn ulteriore elemento casuale è introdotto in ogni nodo dell'albero. \nDurante la costruzione, invece di scegliere il test migliore, si selezionando \nun modo casuale un sottoinsieme di features e si seleziona la migliore \nconsiderando tale sottoinsieme.  \nIl numero di features è impostato col parametro del costruttore \nmax_features\n  (ulteriore iperparametro del modello). \nUn valore alto di \n max_features\n  riduce la casualità nel modello RF, ma \nmigliora il ﬁt sui dati. Un valore basso produce degli alberi molto \ncomplessi per raggiungere lo stesso livello di ﬁt. \nPer generare l'output, ogni DT è valutato sull'istanza in input e i risultati \nsono sottoposti a \n soft voting, \n cioè le probabilità per ogni \n label\n ottenute dai \nsingoli DT sono mediate e la classe con probabilità più alta è l'output del \nRF.\n6",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#6": "Scikit-learn: Random forests e two_moons\nEsercizio\n : col dataset \n two_moons\n  crea un modello RF con 5 alberi. \nfrom \nsklearn.ensemble \n import \nRandomForestClassifier\nfrom \nsklearn.datasets \n import \nmake_moons\nX\n, \ny \n= \nmake_moons\n (\nn_samples\n =\n100\n, \nnoise\n=\n0.25\n, \nrandom_state\n =\n3\n)\n...\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#7": "Scikit-learn: Random forests e two_moons\nCol dataset two_moons creiamo un modello RF con 5 alberi: \nfrom \nsklearn.ensemble \n import \nRandomForestClassifier\nfrom \nsklearn.datasets \n import \nmake_moons\nX\n, \ny \n= \nmake_moons\n (\nn_samples\n =\n100\n, \nnoise\n=\n0.25\n, \nrandom_state\n =\n3\n)\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\nX\n, \ny\n, \nstratify\n =\ny\n,\nrandom_state\n =\n42\n)\nforest \n= \nRandomForestClassifier\n (\nn_estimators\n =\n5\n, \nrandom_state\n =\n2\n)\nforest\n.\nfit\n(\nX_train\n, \ny_train\n)\nI parametri sono salvati nella variabile \n estimator_\n  del modello. \nPossiamo rappresentare i decision boundary per ogni modello: \nfig\n, \naxes \n= \nplt\n.\nsubplots\n (\n2\n, \n3\n, \nfigsize\n=\n(\n20\n, \n10\n))\nfor \ni\n, (\nax\n, \ntree\n) in \nenumerate\n (\nzip\n(\naxes\n.\nravel\n(), \nforest\n.\nestimators_\n )):\nax\n.\nset_title\n (\n\"Tree {}\"\n .\nformat\n(\ni\n))\nmglearn\n.\nplots\n.\nplot_tree_partition\n (\nX_train\n, \ny_train\n, \ntree\n, \nax\n=\nax\n)\nmglearn\n.\nplots\n.\nplot_2d_separator\n (\nforest\n, \nX_train\n, \nfill\n=\nTrue\n, \nax\n=\naxes\n[\n-\n1\n, \n-\n1\n],\nalpha\n=.\n4\n)\naxes\n[\n-\n1\n, \n-\n1\n]\n.\nset_title\n (\n\"Random Forest\"\n )\nmglearn\n.\ndiscrete_scatter\n (\nX_train\n[:, \n0\n], \nX_train\n[:, \n1\n], \ny_train\n)\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#8": "Scikit-learn: Random forests e two_moons\nCosa puoi notare riguardo i modelli e i training set? \n9\n",
    "data_test\\rootfolder\\università\\MachineLearning\\20-Ex_06 Esercitazione su Ensembles di Decision Trees-sbloccato.pdf#9": "Scikit-learn: Random forests e two_moons\nOgni modello ha decision boundaries distinti, dove alcune istanze non sono \ncorrettamente classiﬁcati.  \nOgni modello ha un training set leggermente distinto: alcune istanze del \ntraining set complessivo non sono presenti. \nLe boundaries del modello ﬁnale sono più \"smooth\". \n10\n",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Voting e Stacking ensembles (Ex 07)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#1": "Sommario\nVoting \nStacking \nMutilayer Stacking \nDatasets MNIST e notMNIST \nAltri dataset di immagini \nEsercitazioni",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#10": "Multilayer Stacking ensemble\nÈ possibile considerare più blender, ognuno basato su un modello distinto \n(es. regressione lineare, random forest, etc), ottenendo un nuovo layer. \nIn questo caso si suddivide il training set in 3 parti. La prima usata nel \nprimo layer, come nel caso precedente. La seconda usata dai modelli che \ncombinano le predizioni del primo layer. E la restate parte che combina le \npredizioni del secondo layer. \nNota: scikit-learn non supporta lo stacking.  \nMa ci sono librerie open source, es.  \nhttps://github.com/viisar/brew   \nhttps://github.com/Menelau/DESlib  \n11\n",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#11": "MNIST\nE’ un dataset molto conosciuto (rielaborato da \n NIST\n ) di cifre per addestrare sistemi \ndi classiﬁcazione basati sulle immagini. \n\"If it doesn't work on MNIST, it won't work at all”; \"Well, if it does work on \nMNIST, it may still fail on others.\" \nContiene 60K immagini di addestramento e 10K di training. \n1998: un linear classiﬁer ha ottenuto 7.6% di errore rate. \n2012: per mezzo di una architettura DL (convolutional neural networks) si è \narrivati al 0.23%. \nOgni immagine è rappresentata in scala di grigi (256 livelli). Le cifre sono centrate \nin un box 28x28 pixel: abbiamo 784 valori in [0-255] per rappresentare una cifra. \nhttp://yann.lecun.com/exdb/mnist/  \nhttps://www.kaggle.com/c/digit-recognizer/data   \nImplementazione online JS (ott’17) \n http://myselph.de/neuralNet.html\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#12": "MNIST: train.csv e test.csv\nIl ﬁle train.csv contiene una matrice con 785 colonne. La prima \ncolonna è il \n label\n della cifra (es. 3) e le restanti colonne sono la \nrappresentazione sequenziale dell’immagine: \nIl ﬁle test.csv ha la stessa rappresentazione senza la prima colonna. \nEsempio di immagini:\n13\n",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#13": "MNIST: Considerazioni\nNon è impiegato per sistemi avanzati poiché è un task semplice. \nAlgoritmi classici di ML raggiungono i 97% di precisione, \napprocci Deep Learning il 99.7% \nTroppo utilizzato: si rischia di ideare nuovi approcci adatti solo per \nquesto dataset. \nMolto diverso dai task studiati oggi.\n14",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#14": "MNIST dataset\nscikit-learn include il dataset che può essere facilmente usato: \nfrom\n sklearn.datasets \n import\n fetch_openml\nimport\n numpy \nas\n np\nmnist = fetch_openml(\n 'mnist_784'\n , version=\n 1\n, as_frame=\n False\n)\nmnist.target = mnist.target.astype(np.uint8)\nfrom\n sklearn.model_selection \n import\n train_test_split\n# 50K instanze per il training, 10K validation e 10K test\nX_train_val, X_test, y_train_val, y_test = train_test_split(\n    mnist.data, mnist.target, test_size=\n 10000\n, random_state=\n 42\n)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_val, y_train_val, test_size=\n 10000\n, random_state=\n 42\n)\n15",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#15": "notMNIST\nSimile a MNIST, contiene 10 labels (lettere da A a J), ma ogni lettera \nnel dataset occorre con font diversi, es: \nhttp://yaroslavvb.blogspot.ﬁ/2011/09/notmnist-dataset.html   \nDownload \n http://yaroslavvb.com/upload/notMNIST/  \nnotMNIST_large.tar.gz -> training e validazione \nnotMNIST_small.tar.gz -> test \n16\n",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#16": "fashion-MNIST\nFornito da Zalando. 10 classi che fanno riferimento a generi di vestiario (es. \nsandali, t-shirt, borse, etc). \nContiene 60K immagini di addestramento e 10K di training.  \nOgni immagine è rappresentata in scala di grigi di 28x28 pixel  \nhttps://github.com/zalandoresearch/fashion-mnist   \nSide-by-side accuracy MNIST vs fashion MNIST: \nhttp://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#\n17\n",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#17": "Altri dataset popolari sulle immagini\nCIFAR-10 (e 100)\n : 60K 32x32 colour images in 10 classes. \nImageNet\n : 1,5 milioni di immagini organizzate etichettate su \nWordNet. In media 1K immagini per concetto. \nILSVRC2012 task 1\n : 10 milioni di immagini e +1K classi. \nOpen Image\n : 9 milioni di URLs di immagini annotate con bounding \nboxes e migliaia di classi. \nVisualQA\n : open-ended questions su 265K immagini. In media 5.4 \nquestions per immagini con 10 ground truth answers per question. \nThe Street View House Numbers\n : 600K immagini di numeri civici. \nRisultati sperimentali ottenuti per varie architetture avanzate: \nhttp://rodrigob.github.io/are_we_there_yet/build/#datasets  \n18",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#18": "Esercitazione: Voting Classiﬁer\nImpiega il dataset MNIST con uno split 50K/10K/10K. Scegli almeno tre \nclassiﬁcatori e addestrali singolarmente.  \nCrea un ensemble Voting, e valutalo sia con approccio soft che hard voting, \nsia sul validation sia sul test set.  \nConfronta i risultati con i classiﬁcatori singoli. \nProva a rimuovere il classiﬁcatore che si comporta meglio e valuta \nnuovamente le prestazioni.\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#19": "Esercitazione: Stacking Ensemble\nEsegui i singoli classiﬁcatori scelti in precedenza e colleziona gli output sul \nvalidation set. \nCrea un nuovo training set con tali predizioni. Ogni istanza del set è una \nvettore che contiene l'insieme di predizioni per una certa immagine, e il \ntarget e la classe associata all'immagine. Addestra un classiﬁcatore con tale \ntraining set. Valutalo sul test set. \nHai appena realizzato un Stacking ensemble.\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#2": "Ensembles: Voting\nL'approccio voting si ispira alla ﬁlosoﬁa \n wisdom of the crowd.\n  Supponiamo \ndi avere più classiﬁcatori (es. Logistic regression, SVM, Random forest, k-\nNN). Prendiamo la predizione di ognuno e scegliamo quella che riceve \n\"più voti\". Questa forma di aggregazione prende il nome di \n hard-voting\n . \nSe partiamo da weak classiﬁers con accuracy non soddisfacente, il \nclassiﬁcatore risultante può raggiungere accuracy elevate.\n3\n",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#20": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n21",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#3": "Scikit-learn: Voting\nLa classe \n VotingClassiﬁer\n  di scikit-learn implementa l'approccio.  \nEsercizio\n : completa il seguente frammento di codice basandoti sulla \ndocumentazione online di VotingClassiﬁer. \nfrom \nsklearn.ensemble \n import \nVotingClassifier\n(... importa gli altri classificatori ...)\nfrom\n sklearn.model_selection \n import\n train_test_split\nfrom\n sklearn.datasets \n import\n make_moons\nX, y = make_moons(n_samples=\n 500\n, noise=\n 0.30\n, random_state=\n 42\n)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=\n 42\n)\n...\nvoting_clf \n = \nVotingClassifier\n (\n    \n...\n, \n    \nvoting\n=\n'hard'\n)\nvoting_clf\n .\nfit\n(\nX_train\n, \ny_train\n)\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#4": "Scikit-learn: Voting\nImpieghiamo SVM, RandomForest e LogisticRegression: \nfrom \nsklearn.ensemble \n import \nRandomForestClassifier\nfrom \nsklearn.ensemble \n import \nVotingClassifier\nfrom \nsklearn.linear_model \n import \nLogisticRegression\nfrom \nsklearn.svm \n import \nSVC\nfrom\n sklearn.model_selection \n import\n train_test_split\nfrom\n sklearn.datasets \n import\n make_moons\nX, y = make_moons(n_samples=\n 500\n, noise=\n 0.30\n, random_state=\n 42\n)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=\n 42\n)\nlog_clf \n = \nLogisticRegression\n ()\nrnd_clf \n = \nRandomForestClassifier\n ()\nsvm_clf \n = \nSVC\n()\nvoting_clf \n = \nVotingClassifier\n (\n    \nestimators\n =\n[(\n'lr'\n, \nlog_clf\n), (\n'rf'\n, \nrnd_clf\n), (\n'svc'\n, \nsvm_clf\n)], \n    \nvoting\n=\n'hard'\n)\nvoting_clf\n .\nfit\n(\nX_train\n, \ny_train\n)\n5",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#5": "Scikit-learn: Voting\n(segue)\nfrom \nsklearn.metrics \n import \naccuracy_score\nfor \nclf \nin (\nlog_clf\n, \nrnd_clf\n, \nsvm_clf\n, \nvoting_clf\n ):\n    \nclf\n.\nfit\n(\nX_train\n, \ny_train\n)\n    \ny_pred \n= \nclf\n.\npredict\n(\nX_test\n)\n    \nprint\n(\nclf\n.\n__class__\n .\n__name__\n , \naccuracy_score\n (\ny_test\n, \ny_pred\n))\nLogisticRegression 0.864\nRandomForestClassifier 0.896\nSVC 0.888\nVotingClassifier 0.904\n6",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#6": "Scikit-learn: Voting\nSe i classiﬁcatori impiegati sono in grado di stimare probabilità di \nappartenenza alle singole label, cioè implementano la funzione \npredict_proba(), il voting può valutare le medie delle probabilità prodotte \nda ogni classiﬁcatore.  \nL'approccio si chiama \n soft voting,\n  e si seleziona col parametro voting del \ncostruttore: \n    \nvoting\n=\n'soft'\nEsercizio\n : controlla che i classiﬁcatori impiegati in precedenza \nimplementino predict_proba() e, in caso affermativo, lancia nuovamente il \ncodice precedente e valuta la differenza di performance.\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#7": "Scikit-learn: Voting\nog_clf = LogisticRegression(solver=\n \"lbfgs\"\n, random_state=\n 42\n)\nrnd_clf = RandomForestClassifier(n_estimators=\n 100\n, random_state=\n 42\n)\nsvm_clf = SVC(gamma=\n \"scale\"\n, probability=\n True\n, random_state=\n 42\n)\nvoting_clf = VotingClassifier(\n    estimators=[(\n 'lr'\n, log_clf), (\n 'rf'\n, rnd_clf), (\n 'svc'\n, svm_clf)],\n    voting=\n 'soft'\n)\nvoting_clf.fit(X_train, y_train)\nVotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n                             ('rf', RandomForestClassifier(random_state=42)),\n                             ('svc', SVC(probability=True, random_state=42))],\n                 \n voting='soft'\n )\nfrom\n·\nsklearn.metrics\n ·\nimport\n·\naccuracy_score\nfor\n·\nclf\n·\nin\n·\n(log_clf,\n ·\nrnd_clf,\n ·\nsvm_clf,\n ·\nvoting_clf):\n    \nclf.fit(X_train,\n ·\ny_train)\n    \ny_pred\n·\n=\n·\nclf.predict(X_test)\n    \nprint\n(clf.__class__.__name__,\n ·\naccuracy_score(y_test,\n ·\ny_pred))\nfrom sklearn.metrics import accuracy_score\nfor clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\nLogisticRegression 0.864\nRandomForestClassifier 0.896\nSVC 0.896\nVotingClassifier 0.92\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#8": "Ensembles: Stacking\nUn ulteriore approcio ensembles è lo \n stacking\n , che sta per \n stacked \ngeneralization\n . \nInvece di aggregare il risultato con una tecnica di voting, addestriamo un \nulteriore modello per questo scopo, chiamato \n blender\n  o \nmeta learner\n . \n9\n",
    "data_test\\rootfolder\\università\\MachineLearning\\21-Ex_07 Esercitazione Voting e Stacking ensembles-sbloccato.pdf#9": "Stacking\nUn approccio che spesso si impiega per addestrare il blender è il \n hold-out \nset\n. Inizialmente il training set è suddiviso in 2. Il primo è usato per \naddestrare i modelli nel primo layer, mentre il secondo (held-out) è usato \nper creare le predizioni. Per ogni istanza ci sono 3 predizioni. Tali \npredizioni costituiscono le features di una istanza in un \n nuovo training set\n , \nil cui valore target è quello originale. Il blender è addestrato sul nuovo set.\n10\n",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nIntroduzione al \nClustering\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#1": "Sommario\nSupervised e Unsupervised Learning \nIntroduzione al Clustering \nAlgoritmo k-means  \nAlgoritmo k-means++\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#10": "k-means Clustering \n \n11\nVediamo un esempio di esecuzione dell’algoritmo nel caso in cui i \ndata points siano quelli riportati in ﬁgura. \nSupponiamo di scegliere come numero di cluster: k=3 ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#11": "k-means Clustering \n \n12\nµ1,µ2,...,µ k\nScelta del numero di cluster k e inizializzazione dei k centroidi:\nEsempio per k = 3\nμ1\nμ2\nμ3",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#12": "Voronoi Tesselation \n \n13\n",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#13": "k-means Clustering \n \n14\nzi argmin\njkµj\u0000xik2\nAssegnazione delle osservazioni al più vicino centroide:\nμ1\nμ2\nμ3",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#14": "k-Means Clustering \n \n15\nSi ricalcolano i centroidi come media delle osservazioni assegnate \nad ogni cluster:\nµj=1\nnjX\ni:zi=jxi\nμ1\nμ2μ3",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#15": "k-Means Clustering \n \n16\nzi argmin\njkµj\u0000xik2\nSi riassegnano le osservazioni al centroide più vicino:\n… e così via ﬁno al raggiungimento di una cond. di terminazione.μ1\nμ2μ3",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#16": "Algoritmo k-means \n \n17\nL’algoritmo può essere pertanto sintetizzato come segue:\nScegliamo il numero kdei cluster\nInizializziamo i centroidi µ1,µ2,...,µ k\nwhile not converged\nfor i=1,. . . ,N\nzi argmin\njkµj\u0000xik2; assegniamo i data points al cluster center pi` u vicino\nfor j=1,. . . ,k\nµj=1\nnjX\ni:zi=jxi; aggiorniamo ciascun cluster center come media dei suoi data points",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#17": "Algoritmo k-means \ncome Coordinate Descent \n \n18µj argmin\nµX\ni:zi=jkµ\u0000xik2\nSi noti che la formula per il calcolo delle medie: \nè equivalente alla seguente espressione: µj=1\nnjX\ni:zi=jxi",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#18": "Algoritmo k-means \ncome Coordinate Descent \n \n19\nAbbiamo dunque la seguente versione equivalente dell’algoritmo:\ndove si alternano le minimizzazioni (a): z dato \n μ\n e (b): \n μ\n dato z. Scegliamo il numero kdei cluster\nInizializziamo i centroidi µ1,µ2,...,µ k\nwhile not converged\nfor i=1,. . . ,N\nzi argmin\njkµj\u0000xik2; assegniamo i data points al cluster center pi` u vicino\nfor j=1,. . . ,k\nµj argmin\nµX\ni:zi=jkµ\u0000xik2; calcolo centroidi che minimizzano la somma del\n; quadrato delle norme per i loro data points",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#19": "In genere k-means converge ad un ottimo locale. \nL’algoritmo è molto sensibile all’inizializzazione dei centroidi. \nVediamo un esempio: \n \n20\nConvergenza di k-means ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#2": "Supervised vs. Unsupervised \nLearning\nCome sappiamo, molti problemi e metodi di Machine Learning \nrientrano in una delle due seguenti categorie: apprendimento \nsupervisionato\n  o \nnon supervisionato\n . \nGli esempi visti ﬁno ad ora rientrano nel dominio \ndell’apprendimento supervisionato: \n•\nIn quei casi (linear regression, logistic regression, ecc.) si \nhanno delle osservazioni che, a fronte di una certa \nconﬁgurazione delle features, ci dicono quale sia la \nsoluzione corretta.\n \n3",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#20": " \n21\nConvergenza di k-means \nData la scelta dei centroidi iniziali mostrata nella ﬁgura a sinistra, \nsi ottiene il risultato mostrato a destra:",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#21": " \n22\nConvergenza di k-means \nAltra scelta dei centroidi iniziali:",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#22": " \n23\nConvergenza di k-means \nAltra scelta dei centroidi iniziali:",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#23": "k-means++ \n \n24Arthur, D. e Vassilvitskii, S. “k-means++: the advantages of careful seeding”, in Proc. of the \n18th ACM-SIAM Symp. on Discrete Algorithms , 2007, pp. 1027-1035.\nBahmani, B., Moseley, B., Vattani, A., Kumar, R. e Vassilvitskii, S. “Scalable k-means++”, in \nProc. of VLDB , 2012.\nCome abbiamo visto, l’inizializzazione di k-means è critica ai ﬁni \ndella qualità dell’ottimo locale trovato. \nOra vediamo k-means++, un metodo che consiste in una \nparticolare inizializzazione dei centroidi che in genere dà buoni \nrisultati. \nRiferimenti:",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#24": "k-means++ \n \n25\nSmart initialization\n : \n1.\n Scegliere il primo centroide in modo casuale tra tutti i data \npoints. \n2.\n Per ogni osservazione \n x\ni\n, calcolare la distanza d(\n x\ni\n) tra \nx\ni\n e il più \nvicino centroide. \n3.\n Scegliere il nuovo centroide tra i data point, con la probabilità \ndi \nx\ni\n di essere scelto proporzionale a d(\n x\ni\n) , ossia al quadrato \ndella distanza tra \n x\ni\n e il centroide più vicino già scelto. \n4.\n Ripeti gli step 2 e 3 ﬁno ad arrivare a scegliere k centroidi.\n2 ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#25": "k-means++: esempio \n \n26\nVediamo un esempio di inizializzazione con k=3, relativo alle \nosservazioni in ﬁgura:",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#26": " \n27\nScelta random del primo cluster center:\nk-means++: esempio ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#27": " \n28\nScelta del secondo cluster center. Si sceglie il punto con la \nprobabilità maggiore, dove la probabilità è proporzionale a d(\n x\n). \nIn ﬁgura sono mostrate le varie distanze. \n2 \nk-means++: esempio ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#28": " \n29\nSupponiamo che venga scelto il secondo cluster center in verde: \nk-means++: esempio ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#29": " \n30\nScelta dell’ultimo cluster center. Di nuovo, si sceglie il punto con \nla probabilità maggiore, dove la probabilità è proporzionale a \nd(\nx\ni\n), quadrato della distanza tra il punto i e il più vicino \ncentroide: \n2 \nk-means++: esempio ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#3": "Supervised vs. Unsupervised \nLearning\nNel caso non supervisionato ci troviamo in una situazione più \nimpegnativa, nella quale abbiamo le varie osservazioni \ncaratterizzate dai vari valori delle \n features\n , ma per le quali non \nabbiamo disponibili le soluzioni. \nIn questa situazione, in un certo senso dobbiamo lavorare alla \ncieca. \nLa situazione è deﬁnita \n unsupervised\n  proprio perché nei \n data \npoints\n  disponibili ci manca la risposta che può supervisionare la \nnostra analisi. \n \n4",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#30": " \n31\nSupponiamo che il cluster center scelto sia quello in blu. I tre \ncentroidi scelti sono quelli con cui inizializziamo l’algoritmo k-\nmeans. \nk-means++: esempio ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#31": "k-means++: pros & cons \n \n32\nEseguire k-means++ per individuare i centroidi iniziali è \ncertamente più oneroso computazionalmente rispetto alla scelta \nrandom dei suddetti centroidi. \nPer contro, l’esecuzione di k-means con l’inizializzazione di k-\nmeans++ è spesso più efﬁciente, nel senso che converge in genere \npiù rapidamente. \nIn generale possiamo dire che k-means++ tende a migliorare la \nqualità dell’ottimo locale trovato e diminuire il tempo di \nesecuzione. ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#32": "Cluster Heterogeneity \n \n33\nL’algoritmo k-means cerca di minimizzare la somma dei quadrati \ndelle distanze (\n distortion\n ): \nCome abbiamo visto, in genere l’algoritmo trova un minimo \nlocale. costo kmeans =kX\nj=1X\ni:zi=jkµj\u0000xik2",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#33": "Cluster Heterogeneity \n \n34\nConfrontiamo i seguenti due risultati: la ﬁgura a destra è \nsicuramente migliore. La ﬁgura a sinistra è più “eterogenea”. \n",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#34": "Cosa accade al crescere di k \n \n35\nConsideriamo il caso estremo k = N: \n•\n Signiﬁca che ogni cluster center è un data point. \n•\n Il costo (heterogeneity) è uguale a zero. \nIl costo (heterogeneity) decresce al crescere di k. ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#35": "Scelta del numero di cluster k \n \n36\n“Elbow Method”: Un’euristica usata è quella di scegliere un punto \nche si trova nel “gomito” della curva: \nk (# di cluster)(minimo della \ncluster heterogeneity)costo_k_means \nminimo\n123456",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#36": "Riferimenti\n \n37\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , Apogeo, 3a edizione, \n2015. \nMachine Learning: Clustering & retrieval\n , University of Washington - Coursera, \n2017. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. \nMurphy, K.P. \n Machine Learning - A Probabilistic Approach\n , The MIT Press, 2012.",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#4": "Clustering \nDobbiamo chiederci quale tipo di analisi sia possibile in tale \ncontesto. \nPossiamo ad esempio cercare di comprendere le relazioni tra le \nosservazioni. \nUn approccio che possiamo usare in tali situazioni è quello della \ncluster analysis\n , o \nclustering\n . \nL’obiettivo del \n clustering\n  è quello di veriﬁcare, date le features in \ninput, se le osservazioni disponibili ricadono all’interno di gruppi \nrelativamente distinti tra di loro. \n \n5",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#5": "Clustering \nIl \nclustering\n  è in effetti una delle tecniche più utilizzate per la \nexploratory data analysis\n . \nIn tante discipline, dalle scienze sociali alla biologia alla computer \nscience, gli studiosi cercano di avere delle prime “intuizioni” sui \ndati di cui dispongono identiﬁcando gruppi signiﬁcativi dei data \npoints: \n•\ni venditori cercano di identiﬁcare cluster di clienti, in base ai loro proﬁli, \nper migliorare l’attività di marketing (\n market segmentation\n ); \n•\ni medici cercano di raggruppare i pazienti in base alle loro condizioni \ncliniche; \n•\ngli astronomi identiﬁcano cluster di stelle in base alla loro prossimità \nspaziale; \n•\necc. ecc.\n \n6",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#6": "Clustering \nEsempio in due dimensioni: individuare la \n cluster structure\n  solo \ndagli input: \n \n7\nfeature 1feature 2",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#7": "Clustering \nOgni cluster è deﬁnito dal \n centroide\n  (\ncluster center\n ) e dalla forma \n(shape/spread): \n \n8\nfeature 1feature 2\n1 2\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#8": "Ciascuna osservazione \n x\ni\n è assegnata al cluster \n k\n se: \n•\n Il punteggio (\n score\n ) di \nx\ni\n sotto il cluster \n k\n è migliore rispetto agli \naltri cluster. \nPer semplicità, spesso si deﬁnisce lo \n score\n  come la distanza dal \ncentroide\n  del cluster (si ignora lo shape). \n \n9\nClustering ",
    "data_test\\rootfolder\\università\\MachineLearning\\22-Clustering-sbloccato.pdf#9": "k-means Clustering \nL’algoritmo \n k-means\n  assume come \n score\n  proprio la distanza di una \nosservazione dal \n centroide\n . Più bassa è la distanza, “migliore” è lo \nscore\n . \nDeﬁnizione dei simboli utilizzati nell’esempio che segue: \n \n10nj: numero di  elementi nel cluster jµj: centroide  del cluster j\nzi: label del cluster a cui appartiene xiN: numero delle osservazioni\nj: indice dei cluster \nk: numero dei clusterxi: osservazione i-esima (              ) xi2Rd",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Clustering (Ex 08)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#1": "Sommario\nPreprocessing: Scaling \nScaling in Scikit-learn \nScaling e classiﬁcazione \nScikit-learn e K-Means  \nEsempi di limiti dell'algoritmo K-Means ",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#10": "Scikit-learn: Scaling\nCosa succede se applicassimo due distinti rescaling sul training e sul test \nset? \nLe istanze nel test set sono state scalate in modo improprio rispetto ai valori \noriginali, e si trovano in posizioni relative diverse da quelle originali.\n11\n",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#11": "Scikit-learn: Scaling\nNota: In scikit-learn, gli scaler hanno spesso il metodo ﬁt_transform() che \ncombina le 2 operazioni: \nfrom \nsklearn.preprocessing \n import \nStandardScaler\nscaler \n= \nStandardScaler\n ()\nX_scaled \n = \nscaler\n.\nfit\n(\nX\n)\n.\ntransform\n (\nX\n)\n# stesso risultato ma più efficient\nX_scaled_d \n = \nscaler\n.\nfit_transform\n (\nX\n)\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#12": "Scikit-learn: Scaling e Classiﬁcazione\nEsercizio: Impiega il MinMaxScaler sul dataset breast cancer e impiega \nl'algoritmo di classiﬁcazione SVC(C=100). Confronta la performance senza \nscaling. \nfrom \nsklearn.svm \n import \nSVC\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\ncancer\n.\ndata\n, \ncancer\n.\ntarget\n, \nrandom_state\n =\n0\n)\n...\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#13": "Scikit-learn: Scaling e Classiﬁcazione\nEsercizio: Impiega il MinMaxScaler e StandardScaler sul dataset breast cancer \ne impiega l'algoritmo SVC(C=100). Confronta la performance senza scaling. \nfrom \nsklearn.svm \n import \nSVC\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\ncancer\n.\ndata\n, \ncancer\n.\ntarget\n, \nrandom_state\n =\n0\n)\nsvm \n= \nSVC\n(\nC\n=\n100\n)\nsvm\n.\nfit\n(\nX_train\n, \ny_train\n)\nprint\n(\n\"Test set accuracy: {:.2f}\"\n .\nformat\n(\nsvm\n.\nscore\n(\nX_test\n, \ny_test\n)))\n>> Test set accuracy: 0.63\n# con scaling\nscaler \n= \nMinMaxScaler\n ()\nscaler\n.\nfit\n(\nX_train\n)\nX_train_scaled \n = \nscaler\n.\ntransform\n (\nX_train\n)\nX_test_scaled \n = \nscaler\n.\ntransform\n (\nX_test\n)\nsvm\n.\nfit\n(\nX_train_scaled\n , \ny_train\n)\nprint\n(\n\"Scaled test set accuracy: {:.2f}\"\n .\nformat\n(\nsvm\n.\nscore\n(\nX_test_scaled\n , \ny_test\n)))\n>> Scaled test set accuracy: 0.97 (con StandardScaler si ottiene 0.96)\n14",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#14": "Scikit-learn: K-means\nScikit-learn implementa l'algoritmo con la classe \n KMeans\n . Il parametro \nn_clusters\n  è richiesto per speciﬁcare il numero di cluster.  \nSupponiamo di avere il seguente  \ndataset: \nL'output dell'algoritmo può essere  \nrappresentato col diagramma  \nVoronoi Tesselation. \nfrom \nsklearn.cluster \n import \nKMeans\nk \n= \n5\nkmeans \n= \nKMeans\n(\nn_clusters\n =\nk\n)\ny_pred \n= \nkmeans\n.\nfit_predict\n (\nX\n)\nprint (\ny_pred)\n>> array([4, 0, 1, ..., 2, 1, 0],  \ndtype=int32)\nprint (y_pred \n is \nkmeans\n.\nlabels_)\n>> True\n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#15": "Scikit-learn: Limiti K-means\nPossiamo ottenere le coordinate dei 5 centroidi: \nkmeans\n.\ncluster_centers_\n>> array([[-2.80389616, 1.80117999],\n[ 0.20876306, 2.25551336],\n[-2.79290307, 2.79641063],\n[-1.46679593, 2.28585348],\n[-2.80037642, 1.30082566]])\nE predire la classe di nuove istanze: \nX_new \n= \nnp\n.\narray\n([[\n0\n, \n2\n], [\n3\n, \n2\n], [\n-\n3\n, \n3\n], [\n-\n3\n, \n2.5\n]])\nkmeans\n.\npredict\n(\nX_new\n)\n>> array([1, 1, 2, 2], dtype=int32)\nNota\n : K-Means non si comporta molto bene con cluster che hanno \ndiametri molto distinti tra loro, poiché l'algoritmo valuta solo la distanza \ncol centroide.\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#16": "Scikit-learn: K-means\nInvece dell'\n hard clustering\n  visto ﬁnora, dove l'output è un singolo cluster, \npossiamo ottenere uno score (anche chiamato \n similarity score\n  o \nafﬁnity\n ) per \nogni cluster col \n soft clustering\n  mediante la funzione \n transform\n (): \nkmeans\n.\ntransform\n (\nX_new\n)\n>> array([[2.81093633, 0.32995317, 2.9042344 , 1.49439034, 2.88633901],\n[5.80730058, 2.80290755, 5.84739223, 4.4759332 , 5.84236351],\n[1.21475352, 3.29399768, 0.29040966, 1.69136631, 1.71086031],\n[0.72581411, 3.21806371, 0.36159148, 1.54808703, 1.21567622]])\nÈ possibile impostare i centroidi iniziali in modo manuale col parametro \ninit\n: \ngood_init \n = \nnp\n.\narray\n([[\n-\n3\n, \n3\n], [\n-\n3\n, \n2\n], [\n-\n3\n, \n1\n], [\n-\n1\n, \n2\n], [\n0\n, \n2\n]])\nkmeans \n= \nKMeans\n(\nn_clusters\n =\n5\n, \ninit\n=\ngood_init\n , \nn_init\n=\n1\n)\nL'iperparametro \n n_init\n  speciﬁca quante volte l'algoritmo deve essere \neseguito prima di selezionare la soluzione migliore ottenuta.\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#17": "Scikit-learn: K-means\nPer valutare la bontà della soluzione si misura il costo basato sulla cluster \nheterogeneity, chiamato anche \n inertia\n  del modello, cioè la distanza \nquadratica media con i centroidi. \nkmeans\n.\ninertia_\n>> 211.59853725816856\nkmeans\n.\nscore\n(\nX\n)\n>> -211.59853725816856\nNota\n : di default KMeans() usa l'inizializzazione dei centroidi proposta in K-\nMeans++. Se vuoi impiegare quella dell'algoritmo originale, imposta il \nparametro \n init='random'\n .\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#18": "Scikit-learn: K-means\nEsempio con un dataset toy: \nfrom \nsklearn.datasets \n import \nmake_blobs\nfrom \nsklearn.cluster \n import \nKMeans\n# generate synthetic two-dimensional data\nX\n, \ny \n= \nmake_blobs\n (\nrandom_state\n =\n1\n)\nkmeans \n= \nKMeans\n(\nn_clusters\n =\n3\n)\nkmeans\n.\nfit\n(\nX\n)\n19\nn_clusters=2 n_clusters=4 n_clusters=3",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#19": "Scikit-learn: Limiti K-means\nX_varied\n , \ny_varied \n = \nmake_blobs\n (\nn_samples\n =\n200\n,\ncluster_std\n =\n[\n1.0\n, \n2.5\n, \n0.5\n],\nrandom_state\n =\n170\n)\ny_pred \n= \nKMeans\n(\nn_clusters\n =\n3\n, \nrandom_state\n =\n0\n)\n.\nfit_predict\n (\nX_varied\n )\nmglearn\n.\ndiscrete_scatter\n (\nX_varied\n [:, \n0\n], \nX_varied\n [:, \n1\n], \ny_pred\n)\nplt\n.\nlegend\n([\n\"cluster 0\"\n , \n\"cluster 1\"\n , \n\"cluster 2\"\n ], \nloc\n=\n'best'\n)\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\n20Secondo te è un output ideale?\n",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#2": "Clustering\nCi focalizziamo sugli algoritmi di \n clustering\n . Esistono anche \n trasformazioni \nunsupervised\n , utili per creare nuove rappresentazioni utili per analizzare \ndati o per darli in input a successivi algoritmi. Un approccio comune è la \nriduzione di dimensionalità\n , dove le N dimensioni corrispondenti alle \nfeatures vengono \"compresse\" in poche dimensione (es. 2 o 3). \nLa challenge del clustering è capire se l'algoritmo applicato su dati non \netichettati (cioè senza output) riesce comunque a trovare qualcosa di utile. \nEsempio: Classiﬁcation (sx) e Clustering senza label (dx) \n3\n",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#20": "Scikit-learn: Limiti K-means\nX_varied\n , \ny_varied \n = \nmake_blobs\n (\nn_samples\n =\n200\n,\ncluster_std\n =\n[\n1.0\n, \n2.5\n, \n0.5\n],\nrandom_state\n =\n170\n)\ny_pred \n= \nKMeans\n(\nn_clusters\n =\n3\n, \nrandom_state\n =\n0\n)\n.\nfit_predict\n (\nX_varied\n )\nmglearn\n.\ndiscrete_scatter\n (\nX_varied\n [:, \n0\n], \nX_varied\n [:, \n1\n], \ny_pred\n)\nplt\n.\nlegend\n([\n\"cluster 0\"\n , \n\"cluster 1\"\n , \n\"cluster 2\"\n ], \nloc\n=\n'best'\n)\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\n21K-means assume che ogni cluster abbia lo \nstesso diametro, e deﬁnisce la boundary tra i \ncluster esattamente a metà tra i due centroidi. \nAlcuni punti del graﬁco potevano essere \nclassiﬁcati in modo diverso.\n",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#21": "Scikit-learn: Limiti K-means\nX\n, \ny \n= \nmake_blobs\n (\nrandom_state\n =\n170\n, \nn_samples\n =\n600\n)\nrng \n= \nnp\n.\nrandom\n.\nRandomState\n (\n74\n)\n# trasforma i dati per mezzo di una distribuzione gaussiana\ntransformation \n = \nrng\n.\nnormal\n(\nsize\n=\n(\n2\n, \n2\n))\nX \n= \nnp\n.\ndot\n(\nX\n, \ntransformation\n )\nkmeans \n= \nKMeans\n(\nn_clusters\n =\n3\n)\nkmeans\n.\nfit\n(\nX\n)\ny_pred \n= \nkmeans\n.\npredict\n(\nX\n)\nplt\n.\nscatter\n(\nX\n[:, \n0\n], \nX\n[:, \n1\n], \nc\n=\ny_pred\n, \ncmap\n=\nmglearn\n.\ncm3\n)\nplt\n.\nscatter\n(\nkmeans\n.\ncluster_centers_\n [:, \n0\n], \nkmeans\n.\ncluster_centers_\n [:, \n1\n],\nmarker\n=\n'^'\n, \nc\n=\n[\n0\n, \n1\n, \n2\n], \ns\n=\n100\n, \nlinewidth\n =\n2\n, \ncmap\n=\nmglearn\n.\ncm3\n)\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\n22\nSecondo te è un output ideale?",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#22": "Scikit-learn: Limiti K-means\nX\n, \ny \n= \nmake_blobs\n (\nrandom_state\n =\n170\n, \nn_samples\n =\n600\n)\nrng \n= \nnp\n.\nrandom\n.\nRandomState\n (\n74\n)\n# trasforma i dati per mezzo di una distribuzione gaussiana\ntransformation \n = \nrng\n.\nnormal\n(\nsize\n=\n(\n2\n, \n2\n))\nX \n= \nnp\n.\ndot\n(\nX\n, \ntransformation\n )\nkmeans \n= \nKMeans\n(\nn_clusters\n =\n3\n)\nkmeans\n.\nfit\n(\nX\n)\ny_pred \n= \nkmeans\n.\npredict\n(\nX\n)\nplt\n.\nscatter\n(\nX\n[:, \n0\n], \nX\n[:, \n1\n], \nc\n=\ny_pred\n, \ncmap\n=\nmglearn\n.\ncm3\n)\nplt\n.\nscatter\n(\nkmeans\n.\ncluster_centers_\n [:, \n0\n], \nkmeans\n.\ncluster_centers_\n [:, \n1\n],\nmarker\n=\n'^'\n, \nc\n=\n[\n0\n, \n1\n, \n2\n], \ns\n=\n100\n, \nlinewidth\n =\n2\n, \ncmap\n=\nmglearn\n.\ncm3\n)\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\n23\nI dati sono distribuiti (\"allungati\") sulla diagonale, \nnon seguono una distribuzione sferica. \nL'algoritmo valuta solo la distanza dal centroide.",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#23": "Scikit-learn: Limiti K-means\nfrom \nsklearn.datasets \n import \nmake_moons\nX\n, \ny \n= \nmake_moons\n (\nn_samples\n =\n200\n, \nnoise\n=\n0.05\n, \nrandom_state\n =\n0\n)\nkmeans \n= \nKMeans\n(\nn_clusters\n =\n2\n)\nkmeans\n.\nfit\n(\nX\n)\ny_pred \n= \nkmeans\n.\npredict\n(\nX\n))\nplt\n.\nscatter\n(\nX\n[:, \n0\n], \nX\n[:, \n1\n], \nc\n=\ny_pred\n, \ncmap\n=\nmglearn\n.\ncm2\n, \ns\n=\n60\n)\nplt\n.\nscatter\n(\nkmeans\n.\ncluster_centers_\n [:, \n0\n], \nkmeans\n.\ncluster_centers_\n [:, \n1\n],\nmarker\n=\n'^'\n, \nc\n=\n[\nmglearn\n.\ncm2\n(\n0\n), \nmglearn\n.\ncm2\n(\n1\n)], \ns\n=\n100\n, \nlinewidth\n =\n2\n)\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\n24\nShape complesse non sono \nvalutate correttamente.",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#24": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n25",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#3": "Preprocessing: Scaling\nAlcuni algoritmi di ML sono sensibili allo \n scaling\n  dei dati. Per tale motivo \nspesso si opera un rescaling e shifting. \nVediamo qualche esempio dalla libreria mglearn: \nmglearn\n.\nplots\n.\nplot_scaling\n ()\n4\n",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#4": "Preprocessing: Scaling\nIl diagramma mostra 4 scaler della libreria scikit-learn.  \nStandardScaler\n : garantisce media 0 e varianza 1  \nNon garantisce alcun intervallo max e min \nRobustScaler\n : approccio statistico simile,  \nusa mediana e quartili, è meno sensibile  \nagli \noutliers\n . \nMinMaxScaler\n : sposta i dati nell'intervallo [0,1] \nNormalizer\n : effettua un rescaling in modo che  \nla distanza euclidea sia pari a 1, cioè proietta  \ni punti su una circonferenza (o sfera) di raggio 1.  \nOgni punto è scalato per l'inverso della lunghezza.  \nUtile quando si ha interesse soprattutto riguardo la direzione, piuttosto \nche della lunghezza del feature vector.\n5\n",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#5": "Scikit-learn: Scaling\nUsiamo il breast cancer dataset per testare i vari scaling su un contesto \nsupervised con algoritmo SVM/SVC: \nfrom \nsklearn.datasets \n import \nload_breast_cancer\nfrom \nsklearn.model_selection \n import \ntrain_test_split\ncancer \n= \nload_breast_cancer\n ()\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\ncancer\n.\ndata\n, \ncancer\n.\ntarget\n,\nrandom_state\n =\n1\n)\nprint\n(\nX_train\n.\nshape\n)\nprint\n(\nX_test\n.\nshape\n)\n>> (426, 30)\n>> (143, 30)\nfrom \nsklearn.preprocessing \n import \nMinMaxScaler\nscaler \n= \nMinMaxScaler\n ()\n# consideriamo solo X_train, \n non il y_train\nscaler\n.\nfit\n(\nX_train\n)\n>> MinMaxScaler(copy=True, feature_range=(0, 1))\n# trasformiamo i dati\nX_train_scaled \n = \nscaler\n.\ntransform\n (\nX_train\n)\n6",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#6": "Scikit-learn: Scaling\n# stampa i valori delle features prima e dopo il rescaling\nprint\n(\n\"transformed shape: {}\"\n .\nformat\n(\nX_train_scaled\n .\nshape\n))\nprint\n(\n\"per-feature minimum before scaling:\\n {}\"\n .\nformat\n(\nX_train\n.\nmin\n(\naxis\n=\n0\n)))\nprint\n(\n\"per-feature maximum before scaling:\\n {}\"\n .\nformat\n(\nX_train\n.\nmax\n(\naxis\n=\n0\n)))\nprint\n(\n\"per-feature minimum after scaling:\\n {}\"\n .\nformat\n(\nX_train_scaled\n .\nmin\n(\naxis\n=\n0\n)))\nprint\n(\n\"per-feature maximum after scaling:\\n {}\"\n .\nformat\n(\nX_train_scaled\n .\nmax\n(\naxis\n=\n0\n)))\n>> transformed shape: (426, 30)\nper-feature minimum before scaling:\n[ 6.98 9.71 43.79 143.50 0.05 0.02 0. 0. 0.11\n0.05 0.12 0.36 0.76 6.80 0. 0. 0. 0.\n0.01 0. 7.93 12.02 50.41 185.20 0.07 0.03 0.\n0. 0.16 0.06]\nper-feature maximum before scaling:\n[ 28.11 39.28 188.5 2501.0 0.16 0.29 0.43 0.2\n0.300 0.100 2.87 4.88 21.98 542.20 0.03 0.14\n0.400 0.050 0.06 0.03 36.04 49.54 251.20 4254.00\n0.220 0.940 1.17 0.29 0.58 0.15]\nper-feature minimum after scaling:\n[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\nper-feature maximum after scaling:\n[ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#7": "Scikit-learn: Scaling\nApplichiamo lo scaling anche sul X_test \n# transform test data\nX_test_scaled \n = \nscaler\n.\ntransform\n (\nX_test\n)\n# print test data properties after scaling\nprint\n(\n\"per-feature minimum after scaling:\n\\n{}\"\n.\nformat\n(\nX_test_scaled\n .\nmin\n(\naxis\n=\n0\n)))\nprint\n(\n\"per-feature maximum after scaling:\n\\n{}\"\n.\nformat\n(\nX_test_scaled\n .\nmax\n(\naxis\n=\n0\n)))\n>> per-feature minimum after scaling:\n[ 0.034 0.023 0.031 0.011 0.141 0.044 0. 0. 0.154 -0.006\n-0.001 0.006 0.004 0.001 0.039 0.011 0. 0. -0.032 0.007\n0.027 0.058 0.02 0.009 0.109 0.026 0. 0. -0. -0.002]\nper-feature maximum after scaling:\n[ 0.958 0.815 0.956 0.894 0.811 1.22 0.88 0.933 0.932 1.037\n0.427 0.498 0.441 0.284 0.487 0.739 0.767 0.629 1.337 0.391\n0.896 0.793 0.849 0.745 0.915 1.132 1.07 0.924 1.205 1.631]\nNon sono nel range [0,1], è corretto?\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#8": "Scikit-learn: Scaling\nApplichiamo lo scaling anche sul X_test \n# transform test data\nX_test_scaled \n = \nscaler\n.\ntransform\n (\nX_test\n)\n# print test data properties after scaling\nprint\n(\n\"per-feature minimum after scaling:\n\\n{}\"\n.\nformat\n(\nX_test_scaled\n .\nmin\n(\naxis\n=\n0\n)))\nprint\n(\n\"per-feature maximum after scaling:\n\\n{}\"\n.\nformat\n(\nX_test_scaled\n .\nmax\n(\naxis\n=\n0\n)))\n>> per-feature minimum after scaling:\n[ 0.034 0.023 0.031 0.011 0.141 0.044 0. 0. 0.154 -0.006\n-0.001 0.006 0.004 0.001 0.039 0.011 0. 0. -0.032 0.007\n0.027 0.058 0.02 0.009 0.109 0.026 0. 0. -0. -0.002]\nper-feature maximum after scaling:\n[ 0.958 0.815 0.956 0.894 0.811 1.22 0.88 0.933 0.932 1.037\n0.427 0.498 0.441 0.284 0.487 0.739 0.767 0.629 1.337 0.391\n0.896 0.793 0.849 0.745 0.915 1.132 1.07 0.924 1.205 1.631]\nNon sono nel range [0,1], è corretto?  \nSì, perché il max e min sono stati ricavati dal training set, e possono \nessere distinti da quelli nel X_test.\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\23-Ex_08 Esercitazione Cluster-sbloccato.pdf#9": "Scikit-learn: Scaling\nCosa succede se applicassimo due distinti rescaling sul training e sul test \nset?\n10\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Clustering (Ex 09)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#1": "Sommario\nAgglomerative clustering \nHierarchical clustering \nDendograms \nDBSCAN \nAccelerated K-Means e Mini-batch K-Means \nSilhoutte score",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#10": "DBSCAN\nDBSCAN (density-based spatial clustering of applications with noise) è un \nalgoritmo che non richiede la scelta del numero di cluster a priori, inoltre può \ngestire conﬁgurazioni complesse dei dati (es. non sferiche). a differenza degli \napprocci visti ﬁnora. \nÈ generalmente più lento ma può scalare su dataset molto grandi. \nL'algoritmo identiﬁca i punti nel feature space che si trovano in regioni \n\"popolate\" o \n dense \n e costruisce i cluster in base ad esse. I punti in queste \nregioni si chiamano \n core samples\n .  \nCi sono 2 iperparametri: \n min_samples\n  e \neps\n. Se esistono almeno \n min_samples  \npunti con distanza inferiore a \n eps\n rispetto a un punto X, allora  X è un \n core \nsample\n . I core sample che sono vicini tra loro (distanza < eps) sono inseriti \nnello stesso cluster. Un cluster deve avere almeno min_samples punti. \nI punti che non sono assegnati a nessun cluster diventano i punti di partenza \nper una nuova iterazione. Quelli che non sono assegnati ad alcun cluster \nsono considerati rumore.\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#11": "DBSCAN\nNota\n : anche in DBSCAN la funzione predict() non è implementata. \nEsempio: \nfrom \nsklearn.cluster \n import \nDBSCAN\nX\n, \ny \n= \nmake_blobs\n (\nrandom_state\n =\n0\n, \nn_samples\n =\n12\n)\ndbscan \n= \nDBSCAN\n()\nclusters \n = \ndbscan\n.\nfit_predict\n (\nX\n)\nprint\n(\n\"Cluster memberships:\\n{}\"\n .\nformat\n(\nclusters\n ))\nCluster memberships:\n[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\nPerché l'output è sempre -1?\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#12": "DBSCAN\nfrom \nsklearn.cluster \n import \nDBSCAN\nX\n, \ny \n= \nmake_blobs\n (\nrandom_state\n =\n0\n, \nn_samples\n =\n12\n)\ndbscan \n= \nDBSCAN\n()\nclusters \n = \ndbscan\n.\nfit_predict\n (\nX\n)\nprint\n(\n\"Cluster memberships:\\n{}\"\n .\nformat\n(\nclusters\n ))\nCluster memberships:\n[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\nL'algoritmo usa il valore di default per eps che non è adatto per il piccolo dataset \nanalizzato. \nmglearn\n.\nplots\n.\nplot_dbscan\n ()\nmin_samples: 2 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1]\nmin_samples: 2 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0]\nmin_samples: 2 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0]\nmin_samples: 2 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]\nmin_samples: 3 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1]\nmin_samples: 3 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0]\nmin_samples: 3 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0]\nmin_samples: 3 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]\nmin_samples: 5 eps: 1.000000 cluster: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\nmin_samples: 5 eps: 1.500000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1]\nmin_samples: 5 eps: 2.000000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1]\nmin_samples: 5 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0]\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#13": "DBSCAN\nDiverse conﬁgurazioni variando gli iperparametri (i punti in bianco sono \nconsiderati rumore). Cosa noti? \n14\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#14": "DBSCAN\nIncrementando \n eps\n ci sono più punti che appartengono a clusters, e si \nriducono anche il numero di clusters. \nNota: è più facile impostare il valore di eps operando prima la normalizzazione delle features con \nStandardScaler\n  o \nMinMaxScaler.  \nIncrementando \n min_samples\n , meno punti saranno core points, e più punti \nsaranno etichettati come rumore. \n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#15": "DBSCAN - Esercizio\nEsercizio\n : impiega l'algoritmo DBSCAN sul moon dataset, con o senza la \nnormalizzazione. Valuta i cluster ottenuti.  \nX\n, \ny \n= \nmake_moons\n (\nn_samples\n =\n200\n, \nnoise\n=\n0.05\n, \nrandom_state\n =\n0\n)\n...\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#16": "DBSCAN - Esercizio\nEsercizio: impiega l'algoritmo DBSCAN sul moon dataset.  \nX\n, \ny \n= \nmake_moons\n (\nn_samples\n =\n200\n, \nnoise\n=\n0.05\n, \nrandom_state\n =\n0\n)\n# media 0 e varianza unitaria\nscaler \n= \nStandardScaler\n ()\nscaler\n.\nfit\n(\nX\n)\nX_scaled \n = \nscaler\n.\ntransform\n (\nX\n)\ndbscan \n= \nDBSCAN\n()\nclusters \n = \ndbscan\n.\nfit_predict\n (\nX_scaled\n )\nplt\n.\nscatter\n(\nX_scaled\n [:, \n0\n], \nX_scaled\n [:, \n1\n], \nc\n=\nclusters\n , \ncmap\n=\nmglearn\n.\ncm2\n, \ns\n=\n60\n)\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#17": "DBSCAN - Esercizio\nQuesta volta il clustering ottimale è identiﬁcato. \nEsercizio\n : Cosa succede se decrementiamo il valore di default di eps (0.5) a \n0.2, o lo incrementiamo a 0.7?\n18\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#18": "DBSCAN - Esercizio\nQuesta volta il clustering ottimale è identiﬁcato. \neps = 0.2 -> 8 clusters \neps = 0.7 -> 1 cluster\n19\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#19": "Accelerated K-Means e Mini-batch K-Means\nL'algoritmo \n accelerated\n  K-Means evita di calcolare distanze non \nnecessarie.  \nImpiega la \n triangle inequality \n  AC< AB+BC, dove A,B e C sono 3 punti, e \ntiene traccia del valore del upper e lower bounds delle distanze tra \ncentroidi e istanze. È l'approccio normalmente impiegato \nnell'implementazione KMeans di scikit-learn. \nL'approccio \n Mini-batch\n  seleziona un piccolo insieme di istanze su cui \nvalutare le distanze, creando una \n inerzia\n  nella modiﬁca dei clusters. \nIncrementa la velocità, ma se il numero di cluster è elevato si ottengono \nconﬁgurazioni meno ottimali. \nfrom \nsklearn.cluster \n import \nMiniBatchKMeans\nminibatch_kmeans \n = \nMiniBatchKMeans\n (\nn_clusters\n =\n5\n)\nminibatch_kmeans\n .\nfit\n(\nX\n)\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#2": "Agglomerative Clustering\nL'algoritmo segue i seguenti passi: \nDeﬁniamo una serie di cluster, ognuno con una serie di istanze al suo \ninterno.  \nAd ogni iterazione \n uniamo\n  i due cluster valutati maggiormente simili.  \nAl raggiungimento di un certo \n criterio di stop\n  ci fermiamo. Tipicamente \nil criterio è basato sul numero di cluster desiderato. \nQuali criteri di unione (merge) puoi immaginare?\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#20": "Accelerated K-Means e Mini-batch K-Means\nMini-batch vs K-Means tradizionale impiegando diversi numeri di clusters \nk. Con un numero elevato di clusters l'inerzia si riduce notevolmente, e si \nlimita il tempo di training. \nRicordiamo che l'\n inertia\n  del modello e' la distanza quadratica media con i \ncentroidi, cioè la\n  cluster heterogeneity \n (vedi lezione sul clustering).\n21\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#21": "Il numero ottimale di clusters\nAlcuni algoritmi richiedono di speciﬁcare il numero di clusters, che \npossono produrre risultati molto diversi anche con valori simili: \nPotremmo scegliere il modello con minore inertia, ma nell'esempio con \nk=3 otteniamo 653.2, mentre con k=8 si ha inertia=119.1. Più cluster \nabbiamo, più si riduce la distanza col rispettivo centroide e la rispettiva \ninertia del modello. \n22\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#22": "Richiami: elbow method\nSe graﬁchiamo il valore dell'inertia in funzione del numero di clusters \n k\n si \nvede chiaramente con dopo un \"drop\" elevato, il decremento si riduce \nnotevolmente. \n23\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#23": "Silhoutte score\nUn metodo più formale è il calcolo del valore della silhoutte su tutte le \nistanze. Si ricava con\n  (b-a)/max(a,b)\n  dove \n a\n è la distanza media rispetto \nalle altre istanze nel cluster, \n b\n è la \n mean nearest-cluster distance\n , cioè la \ndistanza media delle istanze rispetto al cluster più vicino. \nIl coefﬁciente varia in [-1,+1], dove un valore vicino:  \na +1 indica una istanza vicina al proprio cluster e lontana dagli altri,  \nallo 0, istanza vicina al boundary del cluster \na -1 l'istanza potrebbe essere stata assegnata al cluster sbagliato. \nfrom \nsklearn.metrics \n import \nsilhouette_score\nsilhouette_score\n (\nX\n, \nkmeans\n.\nlabels_\n)\n0.655517642572828\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#24": "Silhoutte score\nUn valore pari a 4 di cluster massimizza il valore della silhoutte\n25\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#25": "Silhoutte diagram\nGraﬁci del valore di silhoutte per ogni istanza, ordinati per il cluster di \nappartenenza. Per k=4 abbiamo che gran parte delle istanze sorpassano il \nvalore di silhoutte associato a quella conﬁgurazione (linea rossa)\n26\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#26": "Silhoutte: Esercizio\nEsercizio\n : riprendi il dataset blobs e l'approccio agglomerative e ricava il \nnumero ottimale di cluster col approccio \n Agglomerative\n . \nfrom \nsklearn.cluster \n import \nAgglomerativeClustering\nX\n, \ny \n= \nmake_blobs\n (\nrandom_state\n =\n1\n)\n...\n27",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#27": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n28",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#3": "Agglomerative Clustering\nL'algoritmo segue i seguenti passi: \nDeﬁniamo una serie di cluster, ognuno con una serie di istanze al suo \ninterno.  \nAd ogni iterazione \n uniamo\n  i due cluster valutati maggiormente simili.  \nAl raggiungimento di un certo \n criterio di stop\n  ci fermiamo. Tipicamente \nil criterio è basato sul numero di cluster desiderato. \nIn scikit-learn la fusione di cluster può seguire uno dei seguenti criteri: \nward\n  (default): si scelgono i cluster i cui merge riducono al massimo \nl'incremento di varianza tra tutti i cluster. Di solito porta ad avere \ncluster di dimensione confrontabile. \naverage\n : i due cluster che hanno distanza media tra tutti punti minore \ncomplete\n : i due cluster che hanno distanza massima tra due punti \nminore.\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#4": "Agglomerative Clustering\nEsempio libreria \n mglearn\n : \nmglearn\n.\nplots\n.\nplot_agglomerative_algorithm\n ()\n5\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#5": "Scikit-learn: Agglomerative Clustering\nEsempio scikit-learn: \nfrom \nsklearn.cluster \n import \nAgglomerativeClustering\nX\n, \ny \n= \nmake_blobs\n (\nrandom_state\n =\n1\n)\nagg \n= \nAgglomerativeClustering\n (\nn_clusters\n =\n3\n) # parametro obbligatorio\nassignment \n = \nagg\n.\nfit_predict\n (\nX\n)\nmglearn\n.\ndiscrete_scatter\n (\nX\n[:, \n0\n], \nX\n[:, \n1\n], \nassignment\n )\nplt\n.\nxlabel\n(\n\"Feature 0\"\n )\nplt\n.\nylabel\n(\n\"Feature 1\"\n )\nNota\n : l'agglomerative clustering non può predire un cluster per nuovi dati, \nperciò non è possibile usare la funzione predict().\n6\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#6": "Hierarchical clustering\nAd ogni passo dell'algoritmo agglomerative si creano diverse \nconﬁgurazioni che possono essere rilevanti per analizzare i dati, soprattutto \nse si hanno poche features. \nmglearn\n.\nplots\n.\nplot_agglomerative\n ()\n7\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#7": "Dendrograms\nPer dataset con molte features è comunque possibile rappresentare i dati \nsottoforma di dendogrammi. Scikit-learn non implementa tale funzionalità, \nusiamo la libreria \n scipy\n : \nfrom \nscipy.cluster.hierarchy \n import \ndendrogram\n , \nward\nX\n, \ny \n= \nmake_blobs\n (\nrandom_state\n =\n0\n, \nn_samples\n =\n12\n)\n# ward clustering sui dati\n# la funzione restituisce un array che contiene le distanze ricavate\n# durante il clustering agglomerative\nlinkage_array \n = \nward\n(\nX\n)\n# Visualizziamo il dendogramma con le distanze tra i cluster\ndendrogram\n (\nlinkage_array\n )\n# Nel plot aggiungiamo il numero di clsuter\nax \n= \nplt\n.\ngca\n()\nbounds \n= \nax\n.\nget_xbound\n ()\nax\n.\nplot\n(\nbounds\n, [\n7.25\n, \n7.25\n], \n'--'\n, \nc\n=\n'k'\n)\nax\n.\nplot\n(\nbounds\n, [\n4\n, \n4\n], \n'--'\n, \nc\n=\n'k'\n)\nax\n.\ntext\n(\nbounds\n[\n1\n], \n7.25\n, \n' two clusters'\n , \nva\n=\n'center'\n , \nfontdict\n =\n{\n'size'\n: \n15\n})\nax\n.\ntext\n(\nbounds\n[\n1\n], \n4\n, \n' three clusters'\n , \nva\n=\n'center'\n , \nfontdict\n =\n{\n'size'\n: \n15\n})\nplt\n.\nxlabel\n(\n\"Sample index\"\n )\nplt\n.\nylabel\n(\n\"Cluster distance\"\n )\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#8": "Dendrograms\nDal seguente diagramma come immagini che si sia comportato l'algoritmo \ndi clustering?\n9\n",
    "data_test\\rootfolder\\università\\MachineLearning\\24-Ex_09 Esercitazione Cluster-sbloccato.pdf#9": "Dendrograms\nSulle ascisse abbiamo le istanze numerate (da 0 a 11). Salendo si notano i \nnuovi cluster che uniscono le istanze, oppure cluster già presenti. \nEs. al principio si uniscono 1 e 4 in un cluster, poi 6 e 9 in un altro, etc. \nIn cima abbiamo 2 cluster, uno con 11,0,5,10,7,6 e 9; l'altro coi \nrestanti punti. \nLa lunghezza in verticale delle linee rappresentano le distanze tra i due \ncluster o punti che si fondono. \n10\n",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Clustering (Ex 10)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#1": "Sommario\nImage segmentation \nClustering per il preprocessing \nGrid search \nActive learning \nGaussian Mixtures",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#10": "Clustering per il semi-supervised learning\nSoluzione: \nk \n= \n50\nkmeans \n= \nKMeans\n(\nn_clusters\n =\nk\n)\nX_digits_dist \n = \nkmeans\n.\nfit_transform\n (\nX_train\n)\nrepresentative_digit_idx \n = \nnp\n.\nargmin\n(\nX_digits_dist\n , \naxis\n=\n0\n)\nX_representative_digits \n = \nX_train\n[\nrepresentative_digit_idx\n ]\n# facciamo un labeling manuale delle 50 cifre\ny_representative_digits \n = \nnp\n.\narray\n([\n4\n, \n8\n, \n0\n, \n6\n, \n8\n, \n3\n, \n...\n, \n7\n, \n6\n, \n2\n, \n3\n, \n1\n, \n1\n])\nl\nog_reg \n= \nLogisticRegression\n ()\nlog_reg\n.\nfit\n(\nX_representative_digits\n , \ny_representative_digits\n )\nlog_reg\n.\nscore\n(\nX_test\n, \ny_test\n)\n>> 0.9244444444444444\n11\n",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#11": "Clustering per il preprocessing\nEtichettiamo le restanti istanze nei cluster con le label che abbiamo creato \nin modo manuale (\n label propagation\n ), e proviamo nuovamente ad \naddestrare la logistic regression: \ny_train_propagated \n = \nnp\n.\nempty\n(\nlen\n(\nX_train\n), \ndtype\n=\nnp\n.\nint32\n)\nfor \ni \nin \nrange\n(\nk\n):\n  \ny_train_propagated\n [\nkmeans\n.\nlabels_\n==\ni\n] \n= \ny_representative_digits\n [\ni\n]\nlog_reg \n = \nLogisticRegression\n ()\nlog_reg\n.\nfit\n(\nX_train\n, \ny_train_propagated\n )\nlog_reg\n.\nscore\n(\nX_test\n, \ny_test\n)\n>> 0.9288888888888889\nUn leggero incremento. Non conviene propagare le label alle istanze \nlontano dal centroide e vicine al boundary.\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#12": "Clustering per il preprocessing\nProviamo a fare propagation solo al 20% delle istanze più vicine al centroide \npercentile_closest \n = \n20\nX_cluster_dist \n = \nX_digits_dist\n [\nnp\n.\narange\n(\nlen\n(\nX_train\n)), \nkmeans\n.\nlabels_\n]\nfor \ni \nin \nrange\n(\nk\n):\nin_cluster \n = \n(\nkmeans\n.\nlabels_ \n == \ni\n)\ncluster_dist \n = \nX_cluster_dist\n [\nin_cluster\n ]\ncutoff_distance \n = \nnp\n.\npercentile\n (\ncluster_dist\n , \npercentile_closest\n )\nabove_cutoff \n = \n(\nX_cluster_dist \n > \ncutoff_distance\n )\nX_cluster_dist\n [\nin_cluster \n & \nabove_cutoff\n ] \n= -\n1\npartially_propagated \n = \n(\nX_cluster_dist \n != -\n1\n)\nX_train_partially_propagated \n = \nX_train\n[\npartially_propagated\n ]\ny_train_partially_propagated \n = \ny_train_propagated\n [\npartially_propagated\n ]\nlog_reg \n = \nLogisticRegression\n ()\nlog_reg\n.\nfit\n(\nX_train_partially_propagated\n , \ny_train_partially_propagated\n )\nlog_reg\n.\nscore\n(\nX_test\n, \ny_test\n)\n>> 0.9422222222222222\n94.2% è molto vicino al risultato ottenuto con l'addestramento sull'interno \ndataset etichettato (96.7%). In effetti le istanze etichettate automatichemente \ncon \nlabel propagation\n  sono corrette al 99%.\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#13": "Active Learning\nÈ un approccio iterativo dove l'algoritmo propone alcune istanze per essere \netichettate manualmente. Ci sono diverse strategie per selezionare queste \nistanze: \nquelle su cui l'algoritmo mostra maggiore incertezza,  \nquelle che potenzialmente riducono maggiormente il tasso di errore, \nquelle su cui diversi modelli (es. SVM, Random forest, etc) trovano \nmaggiore disaccordo. \nIl procedimento continua ﬁnché non si hanno miglioramenti di \nperformance tangibili. \n14",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#14": "Gaussian Mixtures\nIl \nGaussian mixture model (GMM)\n  suppone che le istanze siano generate \nda un mix di diverse distribuzioni gaussiano i cui parametri sono incogniti. \nLe istanze generate da una singola distribuzione formano un cluster a \nforma di ellissoide, con diverse forme, dimensioni, densità e orientamenti.  \nAl principio non sappiamo quali distribuzioni generino una speciﬁca \nistanza. Occorre stimarle durante la fase di training. \n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#15": "Gaussian Mixtures\nLa classe \n GaussianMixture\n  suppone di conoscere in anticipo il numero \n k\n di \ndistribuzioni. \nPer ogni istanza, prendiamo casualmente un cluster dei \n k\n. La probabilità di \nscegliere il \n j\n-mo cluster e deﬁnita dal peso del cluster \n ϕ\n(j)\n. L'indice del \ncluster selezionato per l'istanza \n i\n-ma è \n z\n(i)\n. \nSe \nz\n(i)\n=\nj\n, la posizione della istanza \n x\n(i)\n è campionata in modo casuale da \nuna distribuzione gaussiana con media \n μ\n(j)\n e matrice di covarianza \n Σ\n(j)\n, e la \nindichiamo con:\n16\n",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#16": "Gaussian Mixtures\nRappresentiamo il modello graﬁcamente dove si notano le dipendenze tra le \nvariabili casuali. Le circonferenze sono le variabili casuali, i quadrati i parametri. \nI rettangoli sono \n plates\n , e indicano che i loro contenuti sono ripetuti diverse volte \n(es. \nm\n volte corrispondenti al numero di variabili casuali, o \n k\n volte, cioè il \nnumero di medie e covarianze, ed un solo array di parametri \n ϕ\n). \nOgni variabile \n z\n(i) \nè ricavata da una distribuzione \n categorical\n  con pesi \n ϕ\n. \nOgni \nvariabile \n x\n(i)\n è ricavata da una distribuzione gaussiana con media e matrice di \ncovarianza deﬁnita dal suo cluster \n z\n(i)\n.\n17\n",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#17": "Gaussian Mixtures\n(cont...) Le frecce rappresentano dipendenze tra le variabili. Ad esempio, \nz\n(i)\n dipende dal vettore dei pesi \n ϕ\n, per ogni \n i\n. \nA seconda del valore di \n z\n(i)\n, l'istanza \n x\n(i)\n è campionata da una diversa \ndistribuzione (freccia ondulata).  \nI nodi colorati rappresentano dati noti, gli altri contengono parametri da \nstimare.\n18\n",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#18": "Scikit-learn: Gaussian Mixtures\nUna volta addestrato il modello impiegando la classe \n GaussianMixture\n () \npossiamo ottenere facilmente i parametri \n ϕ\n, \nμ\n e \nΣ\n: \nfrom \nsklearn.mixture \n import \nGaussianMixture\ngm \n= \nGaussianMixture\n (\nn_components\n =\n3\n, \nn_init\n=\n10\n)\ngm\n.\nfit\n(\nX\n)\n# mostriamo i parametri stimati\ngm\n.\nweights_\n>>> array([0.20965228, 0.4000662 , 0.39028152])\ngm\n.\nmeans_\n>>> array([[ 3.39909717, 1.05933727],\n[-1.40763984, 1.42710194],\n[ 0.05135313, 0.07524095]])\ngm\n.\ncovariances_\n>>> array([[[ 1.14807234, -0.03270354],\n[-0.03270354, 0.95496237]],\n[[ 0.63478101, 0.72969804],\n[ 0.72969804, 1.1609872 ]],\n[[ 0.68809572, 0.79608475],\n[ 0.79608475, 1.21234145]]])\nE ora?\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#19": "Scikit-learn: Gaussian Mixtures\nImpieghiamo l'algoritmo di Expectation Maximization (EM), simile come \nidea al K-Means. Inizializza i parametri dei cluster in modo casuale, e \niterativamente raggiunge lo stato di convergenza. Assegna le istanze ai \ncluter (\n expectation step\n ) e poi aggiorna i cluster (\n maximization step\n ). Ricava \ni valori del centro dei cluster (medie), la loro dimensione, forma e \norientazione (matrice di covarianze) e il relativo peso (\n Φ\n). \nEM usa un soft clustering, stimando la probabilità di appartenenza. Durante \nil \nmaximization step\n  ogni cluster è aggiornato con tutte le istanze nel \ndataset, dove ogni istanza è pesata con la relativa probabilità di \nappartenenza (chiamata anche \n responsability\n  del cluster per l'istanza). \nPerciò ogni cluster viene aggiornato maggiormente dalle istanze che più \nverosimilmente appartengono ad esso. \nL'algoritmo richiede diversi run (es. n_init=10), poiché può facilmente \nprodurre cattive conﬁgurazioni.\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#2": "Image segmentation e Instance segmentation\nNella \n Image segmentation\n  si suddivide una immagine in porzioni, dove \nogni porzione contiene pixel che rappresentano un oggetto associato alla \nporzione (es. pedone, portiera di un auto, etc). Una porzione può \ncontenere istanze multiple di un oggetto. \nNella Instance segmentation ogni porzione contiene una singola istanza \n(es. ogni pedone ha una segmentation distinta). \nAffrontiamo il problema con un approccio basato sulla \n color segmentation.  \nNon è il più efﬁcace, ma per alcuni domini è sufﬁciente (es. analizzare la \npercentuale di zone verdi da immagini satellitari). \nAssociamo un pixel ad un segmento se ha colore simile. \n3",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#20": "Scikit-learn: Gaussian Mixtures\nPossiamo valutare la convergenza e il numero di iterazioni: \ngm\n.\nconverged_\n>> True\ngm\n.\nn_iter_\n>> 3\nUna volta ricavati i parametri possiamo predire il cluster (hard clustering) o \ni clusters (soft clustering) più adatti per una certa istanza: \ngm\n.\npredict\n(\nX\n)\n>> array([2, 2, 1, ..., 0, 0, 0])\ngm\n.\npredict_proba\n (\nX\n)\n>> array([[2.32389467e-02, 6.77397850e-07, 9.76760376e-01],\n[1.64685609e-02, 6.75361303e-04, 9.82856078e-01],\n[2.01535333e-06, 9.99923053e-01, 7.49319577e-05],\n...,\n[9.99999571e-01, 2.13946075e-26, 4.28788333e-07],\n[1.00000000e+00, 1.46454409e-41, 5.12459171e-16],\n[1.00000000e+00, 8.02006365e-41, 2.27626238e-15]])\n21",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#21": "Scikit-learn: Gaussian Mixtures\nEssendo un modello generativo, puoi anche generare nuove istanze dal \nmodello: \nX_new\n, \ny_new \n= \ngm\n.\nsample\n(\n6\n)\nX_new\n>> array([[ 2.95400315, 2.63680992],\n[-1.16654575, 1.62792705],\n[-1.39477712, -1.48511338],\n[ 0.27221525, 0.690366 ],\n[ 0.54095936, 0.48591934],\n[ 0.38064009, -0.56240465]])\ny_new\n>>array([0, 1, 2, 2, 2, 2])\noppure stimare la densità del modello per un certo punto. Col metodo \nscore_samples\n () si ricava la log della \n probability density function \n (PDF): \ngm\n.\nscore_samples\n (\nX\n)\n>> array([-2.60782346, -3.57106041, -3.33003479, ..., -3.51352783,\n-4.39802535, -3.80743859])\nPer stimare la prob che una istanza cada in una certa regione occorre \nintegrare la funzione sull'intervallo.\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#22": "Scikit-learn: Gaussian Mixtures\nIl graﬁco precedente rappresenta la densità per mezzo dei colori: \nÈ stato facile rappresentare i dati perché abbiamo usato una gaussiana 2D. \nPer altri dataset occorrono più dimensioni (e molte più istanze). Se \nl'algoritmo non riesce a convergere si possono impostare vincoli sulla \nforma e orientazione delle distribuzioni (es. parametro \n covariance_type\n )\n23\n",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#23": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#3": "Scikit-learn: Image segmentation\nCarichiamo una immagine, che sarà memorizzata in un array 3d, dove la \nprofondità (numero di canali) rappresenta l'intensità RGB in [0,1], o \n[0,255] se si impiega imageio.imread() \nfrom \nmatplotlib.image \n import \nimread\nimport\n urllib2\nf = \nurllib2.urlopen\n (\n'\nhttp://.../image.png\n '\n)\nf = \nos\n.\npath\n.\njoin\n(\n\"images\"\n ,\n\"image.png\"\n )       # in alternativa\nimage \n= \nimread\n(f)\nimage\n.\nshape\n>> (533, 800, 3)\nNota: alcune immagini hanno meno canali (es. scala di grigio), o più canali \n(es. alpha channel, segnale infrared).\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#4": "Scikit-learn: Image segmentation\nIl seguente codice ridimensiona l'array come un array 1D, dove ogni \nelemento è una tripla. Dopodiché fa clustering raggruppando pixel con \ncolori simili. Inﬁne ricava il colore \"medio\" per mezzo del centroide e \nriordina il risultato come le dimensioni dell'immagine iniziale: \nX \n= \nimage\n.\nreshape\n(\n-\n1\n, \n3\n)\nkmeans \n= \nKMeans\n(\nn_clusters\n =\n8\n)\n.\nfit\n(\nX\n)\nsegmented_img \n = \nkmeans\n.\ncluster_centers_\n [\nkmeans\n.\nlabels_\n]\nsegmented_img \n = \nsegmented_img\n .\nreshape\n(\nimage\n.\nshape\n)\n5\n",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#5": "Clustering per il preprocessing\nIl clustering può essere usato anche come tecnica di \n dimensionality \nreduction\n , ad esempio per rendere più adatto un dataset per un approccio \nsupervised, riducendo il numero di features e la dimensione totale.  \nEs. prendiamo il MNIST dataset (1797 immagini 8x8 in scala di grigio) e \nimpieghiamo la logistic regression per la classiﬁcazione: \nfrom \nsklearn.datasets \n import \nload_digits\nX_digits\n , \ny_digits \n = \nload_digits\n (\nreturn_X_y\n =\nTrue\n)\nfrom \nsklearn.model_selection \n import \ntrain_test_split\nX_train\n, \nX_test\n, \ny_train\n, \ny_test \n= \ntrain_test_split\n (\nX_digits\n , \ny_digits\n )\nfrom \nsklearn.linear_model \n import \nLogisticRegression\nlog_reg \n = \nLogisticRegression\n (\nrandom_state\n =\n42\n)\nlog_reg\n.\nfit\n(\nX_train\n, \ny_train\n)\nlog_reg\n.\nscore\n(\nX_test\n, \ny_test\n)\n0.9666666666666667\n6",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#6": "Clustering per il preprocessing\nUsiamo inizialmente il cluster per raggruppare le immagini simili usando \n50 clusters (usarne solo 10 non è ottimale poiché esistono molti modi per \nrappresentare la stessa cifra), e usiamo la distanza da questi cluster come \ninput al posto dell'immagine originale: \nfrom \nsklearn.pipeline \n import \nPipeline\npipeline \n = \nPipeline\n ([\n    (\n\"kmeans\"\n , \nKMeans\n(\nn_clusters\n =\n50\n)),\n    (\n\"log_reg\"\n , \nLogisticRegression\n ()),\n])\npipeline\n .\nfit\n(\nX_train\n, \ny_train\n)\npipeline\n .\nscore\n(\nX_test\n, \ny_test\n)\n0.9822222222222222\nAbbiamo dimezzato il tasso d'errore! \nNota: Pipeline combina più operazioni di \n trasformazione\n  sui dati, cioè \ndevono comparire classi che implementano \n ﬁt\n() e \ntransform\n (). Per ultimo \nc'è l'estimator che deve includere l'implementazione di \n ﬁt\n().\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#7": "Tuning degli iperparametri: grid search\nPer il tuning degli iperparametri (numero di cluster) possiamo impiegare lo \nscore della fase supervised, senza il bisogno di calcolare la silhoutte. \nLa classe GridSearchCV ottimizza il valore degli iperparametri in modo \nesaustivo iterando su intervalli (approccio grid-search con cross-\nvalidazione). \nfrom \nsklearn.model_selection \n import \nGridSearchCV\n# dizionario chiave->valore, dove la chiave è il nome del iperparametro,\n# il valore è il range di valori da valutare\nparam_grid \n = \ndict\n(\nkmeans__n_clusters\n =\nrange\n(\n2\n, \n100\n))\ngrid_clf \n = \nGridSearchCV\n (\npipeline\n , \nparam_grid\n , \ncv\n=\n3\n, \nverbose\n=\n2\n)\ngrid_clf\n .\nfit\n(\nX_train\n, \ny_train\n)\ngrid_clf\n .\nbest_params_\n>> {'kmeans__n_clusters': 90}\ngrid_clf\n .\nscore\n(\nX_test\n, \ny_test\n)\n>> 0.9844444444444445\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#8": "Clustering per il semi-supervised learning\nPotremmo avere dataset poche istanze con label (etichettate), e molte \nistanze senza label. Non è sufﬁciente per l'addestramento supervised. \nAd esempio, impiegando solo 50 istanze dal dataset delle cifre otteniamo \nuna accuracy piuttosto bassa: \nn_labeled \n = \n50\nlog_reg \n = \nLogisticRegression\n ()\nlog_reg\n.\nfit\n(\nX_train\n[:\nn_labeled\n ], \ny_train\n[:\nn_labeled\n ])\nlog_reg\n.\nscore\n(\nX_test\n, \ny_test\n)\n>> 0.826666666666666\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\25-Ex_10 Esercitazione Cluster-sbloccato.pdf#9": "Clustering per il semi-supervised learning\nEsercizio: prova a fare il clustering del dataset delle cifre (split X_train) \nusando 50 clusters impiegando KMeans. Per ogni cluster trova la cifra con \ndistanza minima dal centroide dal cluster. Usa queste cifre come il nuovo \ndataset di 50 immagini per addestrare la logistic regressione e valuta la \ndifferena nelle performance. \nk \n= \n50\nkmeans \n= \nKMeans\n(\nn_clusters\n =\nk\n)\n...\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nIntroduzione alle  \nReti Neurali Artiﬁciali\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#1": "Sommario\nIntroduzione alle Reti Neurali Artiﬁciali \nUnità di Calcolo nelle Reti Neurali  \nReti Neurali a uno strato alimentate in avanti (percettroni) \nReti Neurali multistrato alimentate in avanti \nAlgoritmo di Back-propagation \nEsempio di esecuzione dell’algoritmo\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#10": "ReLU \n(Rectiﬁed Linear Unit)\ngg(in i) = max(in i,0)\n<latexit sha1_base64=\"fdZuD83MuMKqvRY6gR2pKYYhfhM=\">AAACH3icbVDLTgJBEJzFF+IL9ehlIjGBaMgumujFhOjFIybySICQ3qHBibOPzPQaCOEj/AS/wquevBmvHPwXl8cBwTrVVHWnp8oNlTRk2yMrsbK6tr6R3Extbe/s7qX3DyomiLTAsghUoGsuGFTSxzJJUlgLNYLnKqy6T7djv/qM2sjAf6B+iE0Pur7sSAEUS630aTfbIOzRQPrDlszxaz59etAbzjtn3M610hk7b0/Al4kzIxk2Q6mV/mm0AxF56JNQYEzdsUNqDkCTFAqHqUZkMATxBF2sx9QHD01zMAk15CeRAQp4iJpLxScizm8MwDOm77nxpAf0aBa9sfifV4+oc9WMU4URoS/Gh0gqnBwyQsu4LeRtqZEIxj9HLn0uQAMRaslBiFiM4vpScR/OYvplUinknfN84f4iU7yZNZNkR+yYZZnDLlmR3bESKzPBXtgbe2cf1qv1aX1Z39PRhDXbOWR/YI1+AVy+orM=</latexit>\nini 0\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#11": "Funzione Gradino\nLa motivazione biologica è che un 1 rappresenta \nl’emissione di un impulso lungo l’assone, mentre uno 0 \nrappresenta l’assenza di una tale emissione.\nLa soglia individua l’ingresso pesato minimo che fa in \nmodo che il neurone invii l’impulso.\nLa funzione a gradino ha una soglia t tale che il \nrisultato è 1 quando l’ingresso supera questa soglia.\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#12": "Funzione Gradino\nIn molti casi risulterà dal punto di vista matematico \nconveniente sostituire la soglia con un peso d’ingresso \nextra.\nQuesto consentirà di avere un elemento di \napprendimento più semplice in quanto si dovrà \npreoccupare solo di modiﬁcare dei pesi anziché \nmodiﬁcare sia dei pesi che delle soglie.\nQuindi, invece di avere una soglia t, considereremo per \nciascuna unità un ingresso aggiuntivo, la cui attivazione \na\n0\n è ﬁssata a -1.\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#13": "Da altri\nneuroni\nUnità di Calcolo nelle Reti Neurali\n14",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#14": "Unità di Calcolo nelle Reti Neurali \nIl peso extra W\n 0,i\n associato ad a\n 0\n ricopre il ruolo della \nsoglia t, dove W\n 0,i\n = t e a\n 0 \n= -1. \nIn questo modo tutte le unità possono avere una soglia \nﬁssata a 0.ai=gradinot0\n@nX\nj=1Wj,iaj1\nA=gradino00\n@nX\nj=0Wj,iaj1\nA\n<latexit sha1_base64=\"bnb4YwLA9yDvbdcHkbSf+9auugw=\">AAACfXicfVFNb9NAEF2brxI+moI4IcGIqFKRosgulcqlUgUXjkUiTaU4WOPNJJ12vbZ2x4jK8g/gJ3LgN/ATwA45QFrxTk9v5r3ZnclKw16i6HsQ3rp95+69rfu9Bw8fPd7u7zw59UXlNI11YQp3lqEnw5bGwmLorHSEeWZokl2+7+qTL+Q8F/aTXJU0y3FpecEapZXS/jdMGY4gEfrauuulwznbokkFEkML2YPEV3laXxzFzefaNjBp+ZAbSIaA6QUkjpfn8vqmhGgzIfpvQi/tD6JRtAJcJ/GaDNQaJ2n/RzIvdJWTFW3Q+2kclTKr0QlrQ00vqTyVqC9xSdOWWszJz+rVyhrYrTxKASU5YAMrkf521Jh7f5VnbWeOcu43a514U21ayeLtrGZbVkJWd4OEDa0Gee24vQXBnB2JYPdyArag0aEIOQbUuhWr9jjdPuLN318np/uj+M1o/+PB4PjdejNb6rl6pfZUrA7VsfqgTtRYafUzeBa8CF4Gv8LdcBiO/rSGwdrzVP2D8PA3NkzAIQ==</latexit>\n15",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#15": "Funzione Gradino \n(con soglia zero)\ng\n0g(in i)=⇢1i f i n i\u00000\n0 otherwise\n<latexit sha1_base64=\"xUm3gk/S64XZW4FVFriL5T2ehIM=\">AAACfnicbVHLbtNAFB2bR4t5BSqxYcEVKVVZkNoFqd0gVbBhWSTSVspE0Xhy41x1PDYz19DI8g/whyz4Bz4BO7VQaTmro3PuY+bctDTkOY5/BuGt23fubmzei+4/ePjo8eDJ0xNfVE7jWBemcGep8mjI4piJDZ6VDlWeGjxNzz92/uk3dJ4K+4VXJU5zlVlakFbcSrPBj2xXMl5wTbaZ0WuA9yANLljWADLFjGytnFOrpjamgQhaJLADMk+Li5oWsH2lG2SGXyHebkDKy9L4b2nBS3TfyWNnRhLtvJ8L0lG25BFEs8EwHsVrwE2S9GQoehzPBr/kvNBVjpa1Ud5PkrjkaTuXSRtsIll5LJU+VxlOWmpVjn5arzNr4FXlFRdQogMysBbxaketcu9XedpW5oqX/rrXif/zJhUvDqdtIGXFaHW3iMngepHXjtpjIMzJIbPqXo5AFrRyihkdgdK6Fav2Ol0eyfXf3yQn+6Pk7Wj/87vh0Yc+mU3xXLwUuyIRB+JIfBLHYiy0+B08C14EEIpwJ3wT7l2WhkHfsyX+QXj4B8OsvNA=</latexit>\nini\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#16": " Vediamo adesso alcuni semplici esempi di \nreti neurali per la realizzazione di\nPorte Logiche\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#17": "Porte logiche\nLavorando in modo  adeguato sui pesi si possono realizzare \nporte logiche con una rete neurale formata da un solo \nneurone:\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#18": "Porta AND\n•\n(Soglia t =1.5) \n•\n W\n0\n=1.5 \n•\nW\n1\n=1 \n•\nW\n2\n=1 \n•\na\n0\n= -1 \n•\nPer a\n1\n=1 e a\n2\n= 1si ha: in=0.5 => \n g(in)=1\n  (funzione g a gradino) \n•\nPer a\n1\n=1 e a\n2\n= 0 si ha: in=-0,5 => \n g(in)=0   \n19",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#19": "Porta OR\n•\n(Soglia t = 0.5)\n•\n W\n0\n=0.5\n•\nW\n1\n=1\n•\nW\n2\n=1\n•\na\n0\n= -1\n•\nPer a\n1\n=1 e a\n2\n= 1si ha: in=1.5 => \n g(in)=1\n  (funzione g a gradino)\n•\nPer a\n1\n=1 e a\n2\n= 0 si ha: in=0.5 => \n g(in)=1\n•\n Per a\n1\n=0 e a\n2\n= 0 si ha: in=-0.5 => \n g(in)=0\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#2": "Il cervello\n•Costituito da circa 1011 neuroni\n•1014 sinapsi\n•Segnali basati su potenziale elettrochimico\n Quando il potenziale \nsinaptico supera una certa \nsoglia la cellula emette un \nimpulso\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#20": "Porta NOT\n•\n(Soglia t = - 0.5)\n•\n W\n0\n= - 0.5\n•\nW\n1\n= - 1\n•\na\n0\n= -1\n•\nPer a\n1\n=1 => \n g(in)=0\n  (funzione g a gradino)\n•\nPer a\n1\n=0 si ha: in=0.5 => \n g(in)=1\n21",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#21": "Strutture di Rete\n•\nCi sono due categorie principali di strutture di reti \nneurali:\n•\nFeed-forward \n (o acicliche o alimentate in avanti)\n•\nRicorrenti\n  (o cicliche)\n•\nNoi ci occuperemo solo di reti feed-forward.\n•\nEsse sono una tipologia di reti neurali caratterizzate \ndall’avere un verso delle sinapsi, dallo strato di input allo \nstrato di output.\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#22": "Esempio di Rete Feed-Forward\n•\nUna rete alimentata in avanti rappresenta una funzione dei \nsuoi input:\na5\n23",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#23": "•\nL’output dell’intera rete \n a\n5\n è funzione dei suoi input \n a \n•\nI pesi \n W\n agiscono da parametri della funzione. \n•\nLa rete calcola una funzione \n f\nW\n(x) \n•\nLa funzione \n f\nW \nrappresenta una funzione dello \n spazio \ndelle ipotesi \n H \nche può essere booleana o continua. \n•\nSe i pesi vengono modificati, cambia la funzione \nrappresentata dalla rete. \n•\nLe reti feed-forward sono in genere organizzate a strati, \nin modo tale che ogni unità riceva gli input solo dalle \nunità dello strato immediatamente precedente.\nEsempio di Rete Feed-Forward\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#24": "•\nSi tratta di una rete feed-forward in cui \n tutti\n gli input sono \ncollegati direttamente a \n tutti\n gli output.\n•\nEsempio:\n• 3 unità di output\n• 5 unità di input\n• 1 unità di output\n• 2 unità di input\nReti Feed-Forward a Strato Singolo \n(percettroni)\n25",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#25": "•\nEsaminiamo lo spazio delle ipotesi che un percettrone \npuò rappresentare.\n•\nSe ha una funzione di attivazione a soglia, si può \npensare che il percettrone rappresenti una funzione \nbooleana. \n•\nOltre alle funzioni elementari AND, OR e NOT viste \nprima, un percettrone può rappresentare funzioni \nbooleane “complesse” in modo molto compatto. \n•\nVedi, ad esempio, la \n funzione di maggioranza\n .\nReti Feed-Forward a Strato Singolo \n(percettroni)\n26",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#26": "La Funzione di Maggioranza\n•\nPercettrone a soglia \n•\nRestituisce 1 se e solo se più della metà dei suoi \n n\n input binari \nvale 1 \n•\nBasta porre: W\nj\n=1 per ogni input e W\n0\n=n/2 \n•\nUn albero di decisione necessiterebbe di \n O(2\nn\n)\n nodi per \nrappresentare la stessa funzione. \n27",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#27": "•Un percettrone a soglia non può rappresentare tutte le \nfunzioni booleane. \n•Infatti restituisce 1 se e solo se la somma pesata dei suoi \ninput è positiva: \n•L’equazione                 deﬁnisce un iperpiano  nello spazio \ndegli input. \n•Il percettrone restituisce 1 se e solo se l’input si trova da \nuna parte speciﬁca rispetto a tale iperpiano. \n•Per questo il percettore a soglia è chiamato anche \nseparatore lineare .nX\nj=0Wjxj>0 oppure:\nSeparabilità Lineare di un Percettrone a Soglia\nWT·x>0\n<latexit sha1_base64=\"d9P2mD7Jg+O+gyHjQQ5KI5NUFrA=\">AAACFnicbVC7TsNAEDyHVwgvAyXNKRESVWQHJKhQBA1lkPKSkhCdL5twyvmhuzVKZKXnE/gKWqjoEC0tBf+CbYwECVONZna1O+MEUmi0rA8jt7S8srqWXy9sbG5t75i7e03th4pDg/vSV22HaZDCgwYKlNAOFDDXkdByxpeJ37oDpYXv1XEaQM9lI08MBWcYS32z2EWYoDOMWrObOu3ygY/0R5rM6Dm1Cn2zZJWtFHSR2BkpkQy1vvnZHfg8dMFDLpnWHdsKsBcxhYJLmBW6oYaA8TEbQSemHnNB96I0y4wehpqhTwNQVEiaivB7I2Ku1lPXiSddhrd63kvE/7xOiMOzXiS8IETweHIIhYT0kOZKxCUBHQgFiCz5HKjwKGeKIYISlHEei2HcWtKHPZ9+kTQrZfu4XLk+KVUvsmby5IAUyRGxySmpkitSIw3CyT15JE/k2XgwXoxX4+17NGdkO/vkD4z3LwRxnsk=</latexit>\nWT·x=0\n<latexit sha1_base64=\"ChE2zA/JsnaGrMeC8O8z0h7ASAE=\">AAACFnicbVC7SgNBFJ2Nrxhfq5Y2Q4JgFXajoI0QtLGMkBckMcxObuKQ2QczdyVhSe8n+BW2WtmJra2F/+LuuoImnupwzr3ce44TSKHRsj6M3NLyyupafr2wsbm1vWPu7jW1HyoODe5LX7UdpkEKDxooUEI7UMBcR0LLGV8mfusOlBa+V8dpAD2XjTwxFJxhLPXNYhdhgs4was1u6rTLBz7SH2kyo+fUKvTNklW2UtBFYmekRDLU+uZnd+Dz0AUPuWRad2wrwF7EFAouYVbohhoCxsdsBJ2YeswF3YvSLDN6GGqGPg1AUSFpKsLvjYi5Wk9dJ550Gd7qeS8R//M6IQ7PepHwghDB48khFBLSQ5orEZcEdCAUILLkc6DCo5wphghKUMZ5LIZxa0kf9nz6RdKslO3jcuX6pFS9yJrJkwNSJEfEJqekSq5IjTQIJ/fkkTyRZ+PBeDFejbfv0ZyR7eyTPzDevwAC357I</latexit>\n28",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#28": "• Percettrone elementare (senza strati nascosti): non può classificare \npattern che non siano linearmente separabili.\n• Questi casi però sono frequenti: ad esempio problema dello XOR .\n• Caso particolare della classificazione di punti nell’ipercubo unitario: \nogni punto è in classe 0 o in classe 1.\n• Per lo XOR si considerano gli angoli del quadrato unitario (i punti \n(0,0), (0,1), (1,0) e (1,1))\nSeparabilità Lineare di un Percettrone a Soglia\n29",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#29": "Marvin Minsky\nLimiti del Percettrone \n30",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#3": " Warren Sturgis McCulloch  (1899 – 1969) Neurofisiologo e cibernetico \namericano.  \n Walter Pitts  (1923 – 1969) fu un logico che lavorò nel campo della \npsicologia conoscitiva.  \nPrimo modello matematico di una cellula nervosa descritto in un famoso \narticolo: A Logical Calculus of the Ideas Immanent in Nervous Activity \n(1943).  \n Nello scritto del 1943 tentarono di dimostrare che il programma della \nmacchina di Turing poteva essere effettuato anche in una rete finita di \nneuroni  e che il neurone fosse l’unità logica di base del cervello. I pionieri\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#30": "Marvin Minsky\n1969 : Minsky e Papert, Perceptrons\nLimiti del Percettrone \n31",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#31": "Apprendimento nel Percettrone\n•\nNonostante il loro potere espressivo limitato, esiste un semplice \nalgoritmo di apprendimento capace di adattare un percettrone a \nsoglia a qualsiasi insieme di addestramento linearmente \nseparabile (noi vedremo una versione dell’algoritmo per \nl’apprendimento nei percettroni a sigmoide). \n•\nL’idea base dell’algoritmo è quella di calcolare i pesi della rete in \nmodo tale da minimizzare una determinata funzione di costo \nsull’insieme di training. \n•\nIn tal modo il processo di apprendimento è formulato come una \nricerca di ottimizzazione nello spazio dei pesi.\n32",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#32": "•\nLa funzione di costo sull’insieme di training che viene usata \ntradizionalmente è la \n somma dei quadrati degli errori\n , dove \nil singolo errore è la differenza tra l’output desiderato y e \nl’output della rete f\nW\n(\nx\n)\n. \nIl quadrato dell’errore per un singolo \nesempio di training è il seguente: \nessendo \n x\n il vettore relativo ai dati di input dell’esempio,            \ny il valore corretto della funzione di output e f\n w\n(\nx\n) il valore di \noutput ottenuto dalla rete avente in input \n x\n.\nE=1\n2Err2=1\n2(y\u0000fw(x))2\nApprendimento nel Percettrone\n33",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#33": "Possiamo usare tale metodo per ridurre il quadrato dell’errore \n(ricerca del minimo globale) calcolando la derivata parziale di E \nrispetto ad ogni peso:\ndove g’ è la derivata della funzione di attivazione.\nPer la sigmoide:\nMetodo della Discesa del Gradiente\n34",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#34": " α = step size  o tasso di apprendimento .Il peso deve essere aggiornato in questo modo:\nL’idea è quella di modificare il peso proporzionalmente \nal negativo della derivata dell’errore E vista in precedenza:\nL’aggiornamento del peso è pertanto il seguente:\nMetodo della Discesa del Gradiente\n35",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#35": "Algoritmo completo di apprendimento \na discesa di gradiente per percettroni\nMetodo della discesa del gradiente\n36",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#36": " Gli esempi di addestramento vengono fatti passare attraverso la \nrete uno per volta, modificando leggermente i pesi a ogni \niterazione per ridurre l’errore.  \n Ogni ciclo attraverso tutti gli esempi prende il nome di epoca . \n Le epoche sono ripetute secondo un ben preciso criterio di \nterminazione (e.g., quando le modifiche dei pesi sono piccole). \nAltri metodi calcolano il gradiente per l’intero training set, \nsommando tutti i contributi dati dall’equazione precedente prima \ndi aggiornare i pesi. \nMetodo della Discesa del Gradiente\n37",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#37": "Percettrone a soglia\n Per percettroni a soglia  la g’(in)  è indefinita.\n In questo caso la regola di apprendimento del percettrone \noriginale sviluppata da Rosenblatt (1957) è la seguente:\nEssa è simile a quella vista, tranne per il fatto che la g’(in) è \nomessa. \nPoiché g’(in) è la stessa per tutti i pesi, la sua omissione \ncambia solo la dimensione e non la direzione \ndell’aggiornamento globale dei pesi.\n38",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#38": "Il Percettrone di Rosemblatt\n39",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#39": "Reti Feed-Forward Multistrato\n Si tratta di reti con unità nascoste, in cui esiste un \nverso di propagazione del segnale dall’input \nall’output. \n Ciascun nodo dello strato i-mo è collegato con tutti \ni nodi dello strato i+1-mo. \n Percettrone multistrato . \n40",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#4": "John McCarthy ha indicato il lavoro di Nicolas Rashevsky  (1936, \n1938) come il primo modello matematico di apprendimento neurale. \n Alan Turing  (1948) scrisse un rapporto di ricerca intitolato Intelligent \nMachinery  che inizia con la frase \" I propose to investigate the \nquestion as to whether it is possible for machinery to show intelligent \nbehaviour \" e prosegue descrivendo un'architettura di rete neurale \nricorrente che ha definito \" B-type unorganized machines  \"e un \napproccio per addestrarla. \nSfortunatamente, tale rapporto non è stato pubblicato fino al 1969 ed \nè stato quasi ignorato fino a poco tempo fa.I pionieri\n5",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#40": "Esempio di Rete Neurale Feed-Forward Multistrato \n41",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#41": "Spazio delle ipotesi H per il  \npercettrone multistrato\n•\nIl vantaggio di aggiungere strati nascosti è quello di \nampliare lo spazio delle ipotesi rappresentabili dalla rete. \n•\nPossiamo infatti considerare ogni unità nascosta come un \npercettrone che rappresenta una funzione a soglia \nmorbida nello spazio di input (vedi figura seguente). \n•\nOgni unità di output può dunque rappresentare una \ncombinazione lineare (a soglia morbida) di molte \nfunzioni simili.\n42",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#42": "Output di un Percettrone  \na due Input (con sigmoide)\n43",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#43": "• Fig. (a): cresta  prodotta da due funzioni a \nsoglia morbida rivolte in direzioni opposte \ne limitando il risultato con un’altra soglia.\n• Fig. (b): protuberanza  prodotta dalla \ncombinazione di due creste ad angolo retto \n(cioè, combinando le uscite di quattro unità \nnascoste).\n(a) (b)⇓\nCombinazione di Funzioni  \na Soglia Morbida\nfw(x 1,x2) fw(x 1,x2)\n44",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#44": "Con un solo strato nascosto sufficientemente grande \npossiamo rappresentare qualsiasi funzione continua degli \ninput con accuratezza arbitraria. \nCon due strati nascosti possono essere rappresentate anche \nfunzioni discontinue (il numero delle unità nascoste cresce \nesponenzialmente con il numero degli input).\nPurtroppo, data una qualsiasi struttura di rete prefissata , è \ndifficile stabilire esattamente quali funzioni possano essere \nrappresentate e quali non possano esserlo.\nReti Feed-Forward Multistrato\n45",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#45": "Apprendimento nelle Reti  \nMultistrato Feed-Forward \nGli algoritmi per l’apprendimento per le reti multistrato sono \nsimili all’algoritmo di apprendimento per i percettroni visto in \nprecedenza.\nUna differenza è costituita dal fatto che nelle reti multistrato \navremo in generale più unità di output.\nCiò comporta che avremo un vettore di output fw(x) calcolato \ndalla rete anziché un valore singolo e, per ogni esempio, un \nvettore di output y.\n46",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#46": "•L’idea base rimane la stessa, che è quella di calcolare i pesi della \nrete in modo da minimizzare la somma dei quadrati degli errori che, \nper un singolo esempio, è definita come segue:\n•Dato un certo esempio, il vettore di errore in output è il seguente:\n•Indichiamo come segue l’i-esimo componente del suddetto vettore:\n•E’ inoltre utile definire come segue un errore modificato:\n \nApprendimento nelle Reti  \nMultistrato Feed-Forward \ny\u0000fw(x)\n47",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#47": "Back-propagation\n : strato di output\nPer lo strato di output, il peso deve essere aggiornato\n in questo modo:\nL’idea è quella di modificare il peso proporzionalmente \nal negativo della derivata dell’errore E \n(vedi lucido n. 52 per i dettagli della derivazione ):\nL’aggiornamento del peso è pertanto il seguente:\n48",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#48": "Back-propagation\n : strato nascosto  \n(versione intuitiva)\nAnche per lo strato nascosto il generico peso deve essere aggiornato in \nquesto modo:\nDobbiamo però definire una quantità analoga all’errore per i nodi di \noutput.\nE’ a questo punto che entra in gioco la retropropagazione :\nL’idea  è  che  il  nodo  nascosto  j  sia  “responsabile”  per  una  parte  \ndell’errore ∆i in ognuno dei nodi di output ai quali è collegato.\nIn tal modo i valori ∆ sono suddivisi in base alla forza delle connessioni \ntra nodo nascosto e nodo di output e passati all’indietro per fornire i \nvalori ∆j allo strato nascosto.\n49",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#49": "La regola di propagazione per i valori       è dunque la seguente:\nL’aggiornamento del peso è pertanto il seguente, identica a quella \nche riguarda lo strato di output:\nBack-propagation\n : strato nascosto  \n(versione intuitiva)\n50",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#5": "Da altri\nneuroni\nUnità di Calcolo nelle Reti Neurali\n6",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#50": "Anche per lo strato nascosto il generico peso deve essere aggiornato in \nquesto modo:\nL’idea è, di nuovo, quella di modificare il peso proporzionalmente \nal negativo della derivata dell’errore E \n(vedi lucido n. 53 per i dettagli della derivazione ):\nL’aggiornamento del peso è pertanto il seguente:\nBack-propagation\n : strato nascosto  \n(versione formale)\n51",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#51": "Calcolo del gradiente  \n(strato di output)\n52",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#52": "Calcolo del gradiente  \n(strato nascosto)\n53",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#53": "Processo di Retropropagazione\nIn sintesi, il processo di retropropagazione può essere descritto \ncome segue: \n•\nSi calcolano i valori \n ∆ \nper le unità di output usando l’errore \nosservato. \n•\nCominciando dallo strato di output, si ripete quanto segue per \nogni strato della rete fino a raggiungere l’ultimo strato \nnascosto: \no\nsi propagano all’indietro i valori ∆ verso lo strato \nprecedente; \no\nsi aggiornano i pesi tra i due strati.\n54",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#54": "Back-propagation\n1. Presentazione pattern d’ingresso \nUnità di input akUnità di output ai\nUnità nascoste aj\nWk,jWj,i\n55",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#55": "Unità di input akUnità di output ai\nUnità nascoste aj2. Propagazione dell’input in avanti sullo strato nascosto \nWk,jWj,i\nBack-propagation\n56",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#56": "3. Propagazione dallo strato nascosto allo strato di output\nUnità di input akUnità di output ai\nUnità nascoste aj\nWk,jWj,i\nBack-propagation\n57",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#57": "4. Calcolo dei valori DELTA per lo strato di output\nUnità di input akUnità di output ai\nUnità nascoste aj\nWk,jWj,i\nBack-propagation\n58",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#58": "5. Retropropagazione dell’errore\nUnità di input akUnità di output ai\nUnità nascoste aj\nWk,jWj,i\nL’errore si retropropaga  su \nciascun nodo proporzionalmente  \nalla forza  di connessione tra il \nnodo nascosto e il nodo di output\nBack-propagation\n59",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#59": "6. Aggiornamento dei pesi\nUnità di input akUnità di output ai\nUnità nascoste aj\nWk,jWj,i\nBack-propagation\n60",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#6": " Ogni unità i calcola per prima cosa una somma pesata \ndei propri input:\n Successivamente si applica una funzione di attivazione  \ng alla somma per derivare l’output:\nUnità di Calcolo nelle Reti Neurali\nini=nX\nj=1Wj,iaj\n<latexit sha1_base64=\"eWDCyQ6ONiLa3NNG6gCYSqPL4Ko=\">AAACI3icbVC7TsNAEDzzDOEVoKQ5ESFRoGADEjRIETSUIBGCFAdrfSxwcD5bd2sEsvwZfAJfQQsVHaKh4F+4hBS8phrN7Gp3Js6UtOT7797Q8Mjo2Hhlojo5NT0zW5ubP7ZpbgS2RKpScxKDRSU1tkiSwpPMICSxwnZ8vdfz2zdorEz1Ed1l2E3gQstzKYCcFNXWQsJbt1dIXUaS73Ae2jyJiqudoDwtdMnbjq/KkoerHKIrHtXqfsPvg/8lwYDU2QAHUe0jPEtFnqAmocDaTuBn1C3AkBQKy2qYW8xAXMMFdhzVkKDtFv1gJV/OLVDKMzRcKt4X8ftGAYm1d0nsJhOgS/vb64n/eZ2czre7LnOWE2rRO0RSYf+QFUa6xpCfSYNE0PscudRcgAEiNJKDEE7MXYVV10fwO/1fcrzeCDYa64eb9ebuoJkKW2RLbIUFbIs12T47YC0m2D17ZE/s2XvwXrxX7+1rdMgb7CywH/A+PgGXqaO/</latexit>\nai=g(ini)=g0\n@nX\nj=1Wj,iaj1\nA\n<latexit sha1_base64=\"L8MWGsH2A4rKpI1HGBXATIbImqQ=\">AAACOnicbVDBShxBEO3RxOjG6MYcvTRZAivIMqOB5CKIguRoIOsKO+tQ09aOpT09Q3dNUIb5o3xCvsKbJF68idd8QHo3e0g07/R4rx5V9dJSk+MwvAnm5p89X3ixuNR6ufxqZbX9eu3IFZVV2FeFLuxxCg41Gewzscbj0iLkqcZBerE/8Qdf0ToqzBe+KnGUQ2ZoTArYS0n7ABKSOzLrxoyXPl+TaRLa8JLMYo1j7srYVXlSn+9EzUltGjnwfJMaGW9KSM5jS9kZbyTtTtgLp5BPSTQjHTHDYdK+jU8LVeVoWGlwbhiFJY9qsExKY9OKK4clqAvIcOipgRzdqJ7+28h3lQMuZIlWkpZTEf9O1JA7d5WnfjIHPnOPvYn4P29Y8fjjyFdQVoxGTRYxaZwucsqSLxLlKVlkhsnlKMlIBRaY0ZIEpbxY+WZbvo/o8fdPydFWL9rubX1+39ndmzWzKNbFW9EVkfggdsUncSj6Qolv4lr8ED+D78FdcB88/BmdC2aZN+IfBL9+A3R4rDw=</latexit>\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#60": "7. Aggiornamento dei pesi\nUnità di input akUnità di output ai\nUnità nascoste aj\nWk,jWj,i\nBack-propagation\n61",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#61": "Esempio di Esecuzione\n• Vediamo un esempio di esecuzione dell’algoritmo di Back-\npropagation applicato sulla seguente rete:\na1 a2\n0 1U1 U2\n1 1U3 U4U5\n1a5\nW3,5=1.5 W4,5=-1.0\na3 a4\nW1,3=1 W2,4=2W1,4=-1 W2,3=0.51 11Target = 1\nOutput Layer\nHidden Layer\nInput Layer\n62",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#62": "Esempio di Esecuzione\n•Eseguiamo l’algoritmo su un solo esempio di addestramento e, per il \nquale dunque conosciamo l’output corretto ( Target = 1 ) a fronte di un \ncerto input  X.\n• Supponiamo che i valori dell’input per l’esempio e in questione \nsiano i seguenti:\n•  Input U1: \n•  Input U2:  \n63",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#63": "Esempio di Esecuzione\n1. Presentazione del pattern in ingresso :\n64",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#64": "Esempio di Esecuzione\n2. Passo Feed-Forward ( hidden layer ):\n65",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#65": "Esempio di Esecuzione\n3. Passo Feed-Forward ( output layer ):\n66",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#66": "Esempio di Esecuzione\n• A fronte di questo risultato in uscita possiamo calcolare il quadrato \ndell’errore:  \n• L’errore non è molto alto, ma applicando l’algoritmo alla rete \npossiamo cercare di ridurlo.  \n67",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#67": "Esempio di Esecuzione\n4. Calcolo del valore ∆ in uscita ( output layer ):\n68",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#68": "Esempio di Esecuzione\n  5. Passo di Backward Propagation dell’errore ( hidden layer ):\n69",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#69": "Esempio di Esecuzione\n6. Passo di aggiornamento dei pesi ( link in ingresso all’output layer ):\n70",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#7": "Unità di Calcolo nelle Reti Neurali\nUsando funzioni diverse come \n g\n si possono ottenere \nmodelli differenti. Ad esempio:\ng(in i)=⇢1i f i n i\u0000t\n0i f i n i<t\n<latexit sha1_base64=\"3dhiPmh/49rcUH3TuNXPStviJU0=\">AAACfHicdVHLbtNAFB2bVzGPhscOga5IQEWokV0QdAFSBRuWRSJtpUwUjSc37lXHYzNzjRpZ3vOLXfALfALCDl6UFu7q6Jxz32lpyHMcnwXhlavXrt/YuBndun3n7ubg3v0DX1RO40QXpnBHqfJoyOKEiQ0elQ5Vnho8TE8+dvrhN3SeCvuFVyXOcpVZWpJW3FLzwfdsSzKeck22mdMLeA/S4JJlDTLFjGytnFOrpjamiRKA5yDztDitaQmjc3kgM/wKPGpAyij+v+1d54kk2kVfN5KOsmMeR9F8MIzH8TrgMkh6MBR97M8HP+Si0FWOlrVR3k+TuORZW5dJG2wrVx5LpU9UhtMWWpWjn9XrizXwrPKKCyjRARlYk3g+o1a596s8bZ254mN/UevIf2nTipe7s3bbsmK0umvEZHDdyGtH7SsQFuSQWXWTI5AFrZxiRkegtG7Jqv1Nd4/k4vaXwcHOOHk13vn8erj3ob/MhngknootkYi3Yk98EvtiIrT4GTwMHgdPgl/hKHwZbv+xhkGf80D8FeGb33pBvsA=</latexit>\nFunzione a gradino:\ng(in i) = tanh(in i)\n<latexit sha1_base64=\"Cms3QN8iP8ejsRthjNVvwV/Syf0=\">AAACH3icbVDLSgNBEJz1GeMr6tHLYBAUIexGQS9C0ItHBRMDSQi9Y5sMmZ1dZnrFEPIRfoJf4VVP3sSrB//F3c0ejFqnmqpueqr8SElLrvvpzMzOzS8sFpaKyyura+uljc2GDWMjsC5CFZqmDxaV1FgnSQqbkUEIfIU3/uA89W/u0VgZ6msaRtgJoKflnRRAidQtHfT22oQPNJJ63JX7nJ/yyZtA98dTXrFbKrsVNwP/S7yclFmOy27pq30bijhATUKBtS3PjagzAkNSKBwX27HFCMQAethKqIYAbWeUhRrz3dgChTxCw6XimYg/N0YQWDsM/GQyAOrb314q/ue1Yro76SSZophQi/QQSYXZISuMTNpCfisNEkH6c+RScwEGiNBIDkIkYpzUl/bh/U7/lzSqFe+wUr06KtfO8mYKbJvtsD3msWNWYxfsktWZYI/smb2wV+fJeXPenY/J6IyT72yxKTif33PtosY=</latexit>\n Tangente iperbolica:\nSigmoide: g(in i)=1\n1+e\u0000ini\n<latexit sha1_base64=\"of82qDQd5scNysrZocadTZaCmmw=\">AAACI3icbVDLSgNBEJyN7/iKevQyGISIGHdV0IsgevGoYBIhG0PvpBMHZx/M9Iqy7Gf4CX6FVz15Ey8e8i9u4h6isU5FVTfdVV6kpCHb/rIKE5NT0zOzc8X5hcWl5dLKat2EsRZYE6EK9bUHBpUMsEaSFF5HGsH3FDa8u7OB37hHbWQYXNFjhC0feoHsSgGUSe3Sbq/iEj5QIoO0Lbf4MXe7GkTipInDtzneJDsjfpq2S2W7ag/Bx4mTkzLLcdEu9d1OKGIfAxIKjGk6dkStBDRJoTAturHBCMQd9LCZ0QB8NK1kGCzlm7EBCnmEmkvFhyKObiTgG/Poe9mkD3Rr/noD8T+vGVP3qJVlimLCQAwOkVQ4PGSEllljyDtSIxEMPkcuAy5AAxFqyUGITIyzCotZH87f9OOkvld19qt7lwflk9O8mVm2zjZYhTnskJ2wc3bBakywJ/bCXtmb9Wy9Wx/W589owcp31tgvWP1vXhWkTA==</latexit>\nReLU:g(in i) = max(in i,0)\n<latexit sha1_base64=\"fdZuD83MuMKqvRY6gR2pKYYhfhM=\">AAACH3icbVDLTgJBEJzFF+IL9ehlIjGBaMgumujFhOjFIybySICQ3qHBibOPzPQaCOEj/AS/wquevBmvHPwXl8cBwTrVVHWnp8oNlTRk2yMrsbK6tr6R3Extbe/s7qX3DyomiLTAsghUoGsuGFTSxzJJUlgLNYLnKqy6T7djv/qM2sjAf6B+iE0Pur7sSAEUS630aTfbIOzRQPrDlszxaz59etAbzjtn3M610hk7b0/Al4kzIxk2Q6mV/mm0AxF56JNQYEzdsUNqDkCTFAqHqUZkMATxBF2sx9QHD01zMAk15CeRAQp4iJpLxScizm8MwDOm77nxpAf0aBa9sfifV4+oc9WMU4URoS/Gh0gqnBwyQsu4LeRtqZEIxj9HLn0uQAMRaslBiFiM4vpScR/OYvplUinknfN84f4iU7yZNZNkR+yYZZnDLlmR3bESKzPBXtgbe2cf1qv1aX1Z39PRhDXbOWR/YI1+AVy+orM=</latexit>\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#70": "Esempio di Esecuzione\n7. Passo di aggiornamento dei pesi ( link in ingresso all’hidden layer ):\n71",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#71": "Esempio di Esecuzione\n7. Passo di aggiornamento dei pesi ( link in ingresso all’hidden layer ):\n72",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#72": "Esempio di Esecuzione\n• Ciò completa l’aggiornamento dei pesi per il training example \ncorrente.\n• Per verificare che l’algoritmo abbia effettivamente ridotto \nl’errore in output, eseguiamo la parte feed-forward ancora una \nvolta per confrontare l’uscita attuale con la precedente.\n73",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#73": "Esempio di Esecuzione\n• Nuovo  Passo Feed-Forward ( hidden layer ):\n74",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#74": "Esempio di Esecuzione\n• Nuovo Passo Feed-Forward ( output layer ):\n75",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#75": "Esempio di Esecuzione\n• Il nuovo quadrato dell’errore è il seguente:\n• La differenza con il vecchio valore è:\n76",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#76": "Esempio di Esecuzione\n• L’esecuzione dell’algoritmo di Backpropagation che abbiamo \nvisto è relativo ad un solo passaggio per un solo esempio di \naddestramento.  \n• Si ricorda che l’algoritmo completo fa passare gli esempi di \naddestramento attraverso la rete uno per volta, modificando \nleggermente i pesi a ogni iterazione per ridurre l’errore.  \n  \n• Ogni ciclo attraverso tutti gli esempi prende il nome di epoca .  \n• Le epoche sono ripetute fino a quando non viene soddisfatto un \ncriterio di terminazione (in genere, quando le modifiche ai pesi \nsono diventate molto piccole).  \n77",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#77": "Sintesi degli Argomenti \nTrattati nella Lezione \nUna Rete Neurale è un modello computazionale che presenta alcune proprietà del cervello: consiste di molte \nunità semplici che lavorano in parallelo senza alcun controllo centralizzato.  Le connessioni tra le unità hanno \npesi numerici che possono essere modiﬁcati dall’elemento di apprendimento.  \nIl comportamento di una rete neurale è determinato dalla topologia delle connessioni e dalla natura delle \nsingole unità. Le reti alimentate in avanti  in cui le connessioni formano un grafo diretto aciclico, sono le più \nsemplici da analizzare. Le reti alimentate in avanti implementano funzioni senza stato. \nUn percettrone è una rete alimentata in avanti con un singolo strato di unità e può rappresentare solo funzioni \nlinearmente separabili . Se i dati sono linearmente separabili si può utilizzare la regola di apprendimento del \npercettrone  per modiﬁcare i pesi della rete in modo da farli corrispondere esattamente ai dati. \nLe reti alimentate in avanti multistrato possono rappresentare qualsiasi funzione, dato un sufﬁciente numero di \nunità. \nL’algoritmo di apprendimento backpropagation (propagazione all’indietro ) funziona su reti multistrato \nalimentate in avanti effettuando una discesa del gradiente nello spazio dei pesi per minimizzare l’errore in \nuscita. Esso converge a una soluzione localmente ottima ed è stato usato con successo in un’ampia varietà di \napplicazioni. La sua convergenza è spesso molto lenta.\n78",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#8": "Funzione Gradino\ng\nt0g(in i)=⇢1i f i n i\u0000t\n0i f i n i<t\n<latexit sha1_base64=\"3dhiPmh/49rcUH3TuNXPStviJU0=\">AAACfHicdVHLbtNAFB2bVzGPhscOga5IQEWokV0QdAFSBRuWRSJtpUwUjSc37lXHYzNzjRpZ3vOLXfALfALCDl6UFu7q6Jxz32lpyHMcnwXhlavXrt/YuBndun3n7ubg3v0DX1RO40QXpnBHqfJoyOKEiQ0elQ5Vnho8TE8+dvrhN3SeCvuFVyXOcpVZWpJW3FLzwfdsSzKeck22mdMLeA/S4JJlDTLFjGytnFOrpjamiRKA5yDztDitaQmjc3kgM/wKPGpAyij+v+1d54kk2kVfN5KOsmMeR9F8MIzH8TrgMkh6MBR97M8HP+Si0FWOlrVR3k+TuORZW5dJG2wrVx5LpU9UhtMWWpWjn9XrizXwrPKKCyjRARlYk3g+o1a596s8bZ254mN/UevIf2nTipe7s3bbsmK0umvEZHDdyGtH7SsQFuSQWXWTI5AFrZxiRkegtG7Jqv1Nd4/k4vaXwcHOOHk13vn8erj3ob/MhngknootkYi3Yk98EvtiIrT4GTwMHgdPgl/hKHwZbv+xhkGf80D8FeGb33pBvsA=</latexit>\nini\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\26-Reti-Neurali-sbloccato.pdf#9": "Sigmoide\ng\n01g(in i)=1\n1+e\u0000ini\n<latexit sha1_base64=\"of82qDQd5scNysrZocadTZaCmmw=\">AAACI3icbVDLSgNBEJyN7/iKevQyGISIGHdV0IsgevGoYBIhG0PvpBMHZx/M9Iqy7Gf4CX6FVz15Ey8e8i9u4h6isU5FVTfdVV6kpCHb/rIKE5NT0zOzc8X5hcWl5dLKat2EsRZYE6EK9bUHBpUMsEaSFF5HGsH3FDa8u7OB37hHbWQYXNFjhC0feoHsSgGUSe3Sbq/iEj5QIoO0Lbf4MXe7GkTipInDtzneJDsjfpq2S2W7ag/Bx4mTkzLLcdEu9d1OKGIfAxIKjGk6dkStBDRJoTAturHBCMQd9LCZ0QB8NK1kGCzlm7EBCnmEmkvFhyKObiTgG/Poe9mkD3Rr/noD8T+vGVP3qJVlimLCQAwOkVQ4PGSEllljyDtSIxEMPkcuAy5AAxFqyUGITIyzCotZH87f9OOkvld19qt7lwflk9O8mVm2zjZYhTnskJ2wc3bBakywJ/bCXtmb9Wy9Wx/W589owcp31tgvWP1vXhWkTA==</latexit>\nini\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Reti Neurali (Ex 11)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#1": "Sommario\nRichiami percettrone e MLP \nSci-kit learn e percettrone \nMLP e regressione \nMLP e classiﬁcazione \nKeras \nEsempio fashion_mnist \nKeras: Sequential models, parametri, metriche, training, predizione",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#10": "Richiami: Multi-Layer Perceptron (MLP)\nPerché è fondamentale inserire una funzione di attivazione? \nSe combiniamo diversi layer e unità otteniamo semplicemente una \nsequenza di combinazioni lineari, perciò una trasformazione lineare \ninput-output. È come ottenere un singolo layer. Non possiamo \nrappresentare funzioni complesse non lineari.\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#11": "Richiami: Multi-Layer Perceptron (MLP)\nDomanda: Perché nella MLP si preferisce la funzione logistica (o sigmoide) \nalla funzione gradino (o step function)?\n12g(in i)=⇢1i f i n i\u0000t\n0i f i n i<t\n<latexit sha1_base64=\"3dhiPmh/49rcUH3TuNXPStviJU0=\">AAACfHicdVHLbtNAFB2bVzGPhscOga5IQEWokV0QdAFSBRuWRSJtpUwUjSc37lXHYzNzjRpZ3vOLXfALfALCDl6UFu7q6Jxz32lpyHMcnwXhlavXrt/YuBndun3n7ubg3v0DX1RO40QXpnBHqfJoyOKEiQ0elQ5Vnho8TE8+dvrhN3SeCvuFVyXOcpVZWpJW3FLzwfdsSzKeck22mdMLeA/S4JJlDTLFjGytnFOrpjamiRKA5yDztDitaQmjc3kgM/wKPGpAyij+v+1d54kk2kVfN5KOsmMeR9F8MIzH8TrgMkh6MBR97M8HP+Si0FWOlrVR3k+TuORZW5dJG2wrVx5LpU9UhtMWWpWjn9XrizXwrPKKCyjRARlYk3g+o1a596s8bZ254mN/UevIf2nTipe7s3bbsmK0umvEZHDdyGtH7SsQFuSQWXWTI5AFrZxiRkegtG7Jqv1Nd4/k4vaXwcHOOHk13vn8erj3ob/MhngknootkYi3Yk98EvtiIrT4GTwMHgdPgl/hKHwZbv+xhkGf80D8FeGb33pBvsA=</latexit>\nFunzione a gradino:\nSigmoide: g(in i)=1\n1+e\u0000ini\n<latexit sha1_base64=\"of82qDQd5scNysrZocadTZaCmmw=\">AAACI3icbVDLSgNBEJyN7/iKevQyGISIGHdV0IsgevGoYBIhG0PvpBMHZx/M9Iqy7Gf4CX6FVz15Ey8e8i9u4h6isU5FVTfdVV6kpCHb/rIKE5NT0zOzc8X5hcWl5dLKat2EsRZYE6EK9bUHBpUMsEaSFF5HGsH3FDa8u7OB37hHbWQYXNFjhC0feoHsSgGUSe3Sbq/iEj5QIoO0Lbf4MXe7GkTipInDtzneJDsjfpq2S2W7ag/Bx4mTkzLLcdEu9d1OKGIfAxIKjGk6dkStBDRJoTAturHBCMQd9LCZ0QB8NK1kGCzlm7EBCnmEmkvFhyKObiTgG/Poe9mkD3Rr/noD8T+vGVP3qJVlimLCQAwOkVQ4PGSEllljyDtSIxEMPkcuAy5AAxFqyUGITIyzCotZH87f9OOkvld19qt7lwflk9O8mVm2zjZYhTnskJ2wc3bBakywJ/bCXtmb9Wy9Wx/W589owcp31tgvWP1vXhWkTA==</latexit>",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#12": "Richiami: Multi-Layer Perceptron (MLP)\nPerché nella MLP si preferisce la funzione logistica (o sigmoide) alla \nfunzione gradino (o step function)? \nCon la funzione gradino i gradienti genererebbero una superﬁcie piatta, \nche non permetterebbe di adattare i parametri. \nLa funzione logistica è deﬁnita ed ha derivata ovunque.  \nLa ReLU non è differenziabile per \n in=0\n, e ha derivata 0 per \n in<0\n. Ma \nempiricamente mostra buone performance ed è rapido il calcolo della \nderivata. Inoltre non avendo un valore max in output riduce alcune \nproblematiche nelle architetture più complesse.\n13\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#13": "MLP e regressione\nUna MLP può essere usata per produrre un singolo valore, es. creando un \nlayer di output con una singola unità. Nel caso di \n multivariate regression\n , il \nlayer può contenere più unità. \nSolitamente non si inserisce la funzione di attivazione in output in modo da \nnon imporre intervalli. Se c'è bisogno di valori positivi si può inserire una \nReLU\n  o una \n softplus activation function\n  (una versione smooth della ReLU). \nLa loss function usata durante il training è la \n mean squared error\n . Nel caso \ndi molti outlier nel training set è possibile considerare anche la \n mean \nabsolute error\n . La Huber loss è una combinazione di entrambe.\n14",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#14": "MLP e regressione: architettura tipica\nConﬁgurazione tipica degli iperparametri di una MLP usata per la \nregressione:\n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#15": "MLP e classiﬁcazione\nInserendo un layer con una singola unità e con funzione di attivazione \nlogistica possiamo stimare la probabilità di appartenenza dell'input a una \ncerta classe (binary classiﬁcation). Nel caso \n multilabel binary classiﬁcation\n , \n(es. email spam/no_spam, urgent/no_urgent) si avranno più unità di output. \nSe una istanza può appartenere ad una di n possibili classi (es. una cifra da \n0 a 9), l'output layer conterrà n unità con una funzione \n softmax\n  che \ngarantisce che ogni unità produca una probabilità la cui somma sia 1. In \nquesto caso si impiega la \n cross-entropy\n  come funzione di loss. \n16\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#16": "Keras\nKeras (\n https://keras.io\n ) \nsono API per il Deep Learning ad alto livello per \ncostruire ed addestrare architetture di reti neurali. \nSi basa a sua volta su librerie che permettono di eseguire le reti su varie \npiattaforme, es. TensorFlow, Microsoft Cognitive Toolkit (CNTK), Theano; \nApache MXNet, Apple’s Core ML, Javascript o Typescript (Keras code in \nweb browsers), or PlaidML (on GPUs). \nTensorFlow integra Keras e lo arricchisce di altre funzionalità (es. \nTensorFlow’s Data API) \nInstallazione (via PIP):  \npython3 -m pip install --upgrade tensorﬂow\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#17": "Keras: esempio \n fashion_mnist\nEntrambe le versioni corrispondono alla 2.8.0 \nimport\n tensorflow \n as\n tf\nfrom\n tensorflow \n import\n keras\nprint\n(tf.__version__)\nprint\n(keras.__version__)\nImpieghiamo il dataset fashion_mnist: \nfashion_mnist = keras.datasets.fashion_mnist\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\nprint\n(X_train_full.shape)\nprint\n(X_train_full.dtype)\n>> (60000, 28, 28)\n>> uint8\nX_valid, X_train = X_train_full[:\n 5000\n] / \n255.0\n, X_train_full[\n 5000\n:] / \n255.0\ny_valid, y_train = y_train_full[:\n 5000\n], y_train_full[\n 5000\n:]\nclass_names = [\n \"T-shirt/top\"\n , \n\"Trouser\"\n , \n\"Pullover\"\n , \n\"Dress\"\n, \n\"Coat\"\n,\n\"Sandal\"\n , \n\"Shirt\"\n, \n\"Sneaker\"\n , \n\"Bag\"\n, \n\"Ankle boot\"\n ]\nprint\n(class_names[y_train[\n 0\n]])\n>> \n'Coat'\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#18": "Keras: sequential models\nIl modello \n Sequential\n  è il più semplice e consiste in una singolo stack di \nlayers connessi sequenzialmente: \nmodel = keras.models.Sequential()\n# converto le istanze in input in array 1D\n# equivale a una operazione: X.reshape(-1,1)\n# è obbligatorio specificare il input_shape\nmodel.add(keras.layers.Flatten(input_shape=[\n 28\n, \n28\n]))\n# layer denso con 300 unità e ReLU come activation function\n# ogni layer contiene i propri parametri (pesi e bias) riferiti alle \nconnessioni\n# con il layer precedente\nmodel.add(keras.layers.Dense(\n 300\n, activation=\n \"relu\"\n))\n# layer denso di 100 unità\nmodel.add(keras.layers.Dense(\n 100\n, activation=\n \"relu\"\n))\n# layer di output con 10 unità (una per classe) e softmax activation function\nmodel.add(keras.layers.Dense(\n 10\n, activation=\n \"softmax\"\n ))\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#19": "Keras: sequential models\nIn alternativa, invece di creare un layer alla volta, possiamo passare una \nlista al costruttore:  \nmodel = keras.models.Sequential([\nkeras.layers.Flatten(input_shape=[\n 28\n, \n28\n]),\nkeras.layers.Dense(\n 300\n, activation=\n \"relu\"\n),\nkeras.layers.Dense(\n 100\n, activation=\n \"relu\"\n),\nkeras.layers.Dense(\n 10\n, activation=\n \"softmax\"\n )\n])\nSono possibile varie forme di import, tutte equivalenti: \nfrom \nkeras.layers \n import \nDense\noutput_layer \n = \nDense\n(\n10\n)\nfrom \ntensorflow.keras.layers \n import \nDense\noutput_layer \n = \nDense\n(\n10\n)\nfrom \ntensorflow \n import \nkeras\noutput_layer \n = \nkeras\n.\nlayers\n.\nDense\n(\n10\n)\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#2": "Richiami: Percettrone\nUna delle architetture più semplici, dove un singolo layer è connesso con \ntutti gli input dello strato precedente (\n fully connected \n o\n dense layer\n ), cioè \nl'\ninput layer\n : \nNota\n : nei precedenti lucidi si è usata la notazione dove gli input \n x\n sono \nanche indicati con la lettera \n a\n. La step function \n step()\n  corrisponde alla \nfunzione di attivazione \n g(in).\n3\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#20": "Keras: parametri\nPer monitorare l'architettura creata usiamo la funzione summary():  \nmodel\n.\nsummary()\nNota: i layer densi contengono molti parametri (es. 235.500!)\n21\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#21": "Keras: parametri\nPer accedere ai singoli layers usiamo il parametro \n layers\n , e le funzioni \nget_weights\n () e \nset_weights\n (): \n>>> \nmodel\n.\nlayers\n[<tensorflow.python.keras.layers.core.Flatten at 0x132414e48>,\n<tensorflow.python.keras.layers.core.Dense at 0x1324149b0>,\n<tensorflow.python.keras.layers.core.Dense at 0x1356ba8d0>,\n<tensorflow.python.keras.layers.core.Dense at 0x13240d240>]\n>>> \nmodel\n.\nlayers\n[\n1\n]\n.\nname\n'dense_3'\n>>> \nmodel\n.\nget_layer\n (\n'dense_3'\n )\n.\nname\n'dense_3'\n>>> \nweights\n, \nbiases \n= \nhidden1\n.\nget_weights\n ()\n>>> \nweights\narray([[ 0.03854964, -0.04054524, 0.00599282, ..., 0.02566582,\n0.01032123, 0.06914985],\n...,\n[ 0.02632413, -0.05105981, -0.00332005, ..., 0.04175945,\n0.0443138 , -0.05558084]], dtype=float32)\n>>> \nweights\n.\nshape\n(784, 300)\n>>> \nbiases\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., ..., 0., 0., 0.], dtype=float32)\n>>> \nbiases\n.\nshape\n(300,)\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#22": "Keras: parametri\nA cosa può servire una funzione set_weights()?\n23",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#23": "Keras: parametri\nA cosa può servire una funzione set_weights()? \nPossiamo operare regolarizzazioni manuali, oppure sovrascrivere i \nvalori iniziali random con valori ottenuti da precedenti fasi di training. \nPer impiegare altri criteri di inizializzazione dei kernel (cioè delle matrici \ndei parametri della rete) consultare \n https://keras.io/initializers/\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#24": "Keras: metriche\nLa funzione compile() prende in input la \n loss \nfunction\n  e il \noptimizer\n , cioè \nl'algoritmo per stimare i parametri, ed eventuali altri parametri, come la \nmetrica per stimare l'errore:  \nmodel\n.\ncompile\n(\nloss\n=\n\"sparse_categorical_crossentropy\"\n ,\noptimizer\n =\n\"sgd\"\n,\nmetrics\n=\n[\n\"accuracy\"\n ])\nDove:  \nloss=\"sparse_categorical_crossentropy\" è equivalente a  \nloss=keras.losses.sparse_categorical_crossentropy.  \noptimizer=\"sgd\" è equivalente a optimizer=keras.optimizers.SGD()  \nmetrics=[\"accuracy\"] è equivalente a \nmetrics=[keras.metrics.sparse_categorical_accuracy]  \nPer una lista completa consultare \n https://keras.io/losses/  \nhttps://keras.io/\noptimizers/\n   e  \nhttps://keras.io/metrics/  \n25",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#25": "Keras: metriche\nNell'esempio impieghiamo \n sparse_categorical_crossentropy\n  loss perché \nabbiamo label sparse, cioè per ogni istanza abbiamo solo una target class \nda 0 a 9, e ogni classe è esclusiva.  \nSe avessimo avuto un target on vettore di 10 reali, es [0,0,...,1.0,...,0] \navremmo dovuto impiegare la \n categorical_crossentropy \n loss. Per convertire \nlabel sparse in vettori impiegare \n keras.utils.to_categorical()\n . \nPer la binary classiﬁcation avremmo usato la \n sigmoid\n  activation invece \ndella softmax, e la \n binary_crossentropy\n  loss.\n26",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#26": "Keras: training\nInﬁne non ci resta che addestrare il modello: \n# il validation set è opzionale\n>>> \nhistory \n = \nmodel\n.\nfit\n(\nX_train\n, \ny_train\n, \nepochs\n=\n30\n,\n... \nvalidation_data\n =\n(\nX_valid\n, \ny_valid\n))\n...\nTrain on 55000 samples, validate on 5000 samples\nEpoch 1/30\n55000/55000 [==========] - 3s 55us/sample - loss: 1.4948 - acc: 0.5757\n- val_loss: 1.0042 - val_acc: 0.7166\nEpoch 2/30\n55000/55000 [==========] - 3s 55us/sample - loss: 0.8690 - acc: 0.7318\n- val_loss: 0.7549 - val_acc: 0.7616\n[...]\nEpoch 50/50\n55000/55000 [==========] - 4s 72us/sample - loss: 0.3607 - acc: 0.8752\n- val_loss: 0.3706 - val_acc: 0.8728\nOtteniamo una accuracy del 87% sul validation set dopo 50 epoche, simile \nall'accuracy del training set, perciò non dovrebbe esserci overﬁtting. \n27",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#27": "Keras: training\nSel nel dataset ci sono classi meno frequenti di altre, si può impiegare il \nparametro \n class_weight\n  nella funzione \n ﬁt\n() in modo da diminuire l'effetto \ndelle classi più rappresentate.  \nSi può fare lo stesso ma per le singole istanze col parametro \n sample_weight \nIl parametro \n history\n  è creato dopo il ﬁt, e contiene un oggetto \n History\n  con \ndati utili relativi all'addestramento: \nimport \npandas \nas \npd\npd\n.\nDataFrame\n (\nhistory\n.\nhistory\n)\n.\n     \nplot\n(\nfigsize\n=\n(\n8\n, \n5\n))\nplt\n.\ngrid\n(\nTrue\n)\n# set the vertical range to [0-1]\nplt\n.\ngca\n()\n.\nset_ylim\n (\n0\n, \n1\n) \nplt\n.\nshow\n()\nCosa puoi dire dal graﬁco?\n28\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#28": "Keras: training\nConferma il probabile scarso overﬁtting.  \nAl principio il modello si comporta meglio col validation set, ma spesso è \ndovuto al caso. \nIl ﬁtting termina con l'accuracy sul training leggermente migliori rispetto al \nvalidation, fenomeno che capita spesso per training lunghi. \nIl validation error è ancora in discesa quando termina il training. Conviene \naumentare le epoche.\n29\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#29": "Keras: training e test\nUna volta terminato il training è possibile validare il modello sul test set: \n>>> \nmodel\n.\nevaluate\n (\nX_test\n, \ny_test\n)\n8832/10000 [==========================] - ETA: 0s - loss: 0.4074 - acc: \n0.8540\n[0.40738476498126985, 0.854]\nLe performance sono leggermente minori poiché gli iperparametri li \nabbiamo scelti in base al training e validation set. \nRicordati di non modiﬁcarli in base al test set.\n30",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#3": "Richiami: Percettrone\nUn singolo percettrone, indicato anche con Threshold logic unit (TLU) o \nLinear threshold unit (LTU), può essere usato come classiﬁcatore.  \nSe la combinazione lineare degli input è oltre una certa soglia l'output \nassumerà la classe \"positiva\", altrimenti \"negativa\". \nIl training consiste nel trovare i pesi \n w\n (parametri). \nUna rappresentazione alternativa indica esplicitamente un layer \npassthtough\n  per i valori in input, e una unità \n bias\n che restituisce sempre 1. \nNell'esempio ci sono 3 outputs, perciò 3 distinte classi binarie in output: \n4\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#30": "Keras: predizione\nUna volta addestrato possiamo fare predizione: \n>>> \nX_new \n= \nX_test\n[:\n3\n]\n>>> \ny_proba \n = \nmodel\n.\npredict\n(\nX_new\n)\n>>> \ny_proba\n.\nround\n(\n2\n)\narray([[0. , 0. , 0. , 0. , 0. , 0.09, 0. , 0.12, 0. , 0.79],\n[0. , 0. , 0.94, 0. , 0.02, 0. , 0.04, 0. , 0. , 0. ],\n[0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]],\ndtype=float32)\nDall'esempio: class 9 (ankle boot) prob=79%, class 7 (sneaker) prob=12%, \nclass 5 (sandal) prob=9% \nSe ci interessa solo la classe con probabilità più alta: \n>>> \ny_pred \n= \nmodel\n.\npredict_classes\n (\nX_new\n)\n>>> \ny_pred\narray([9, 2, 1])\n>>> \nnp\n.\narray\n(\nclass_names\n )[\ny_pred\n]\narray(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')\n31",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#31": "Esercizio\nImpiegare il dataset MNIST (cifre numeriche) e una architettura simile \nall'esempio precedente.  \nValutare l'accuracy dopo 50 epoche. \n# import dataset\nfrom\n keras.datasets \n import\n mnist\n# load dataset\n(x_train, y_train),(x_test, y_test) \n =\n mnist\n.\nload_data()\n32\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#32": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n33",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#4": "Sci-kit learn: Perceptron\nLa classe Perceptron implementa un singolo TLU: \nimport \nnumpy \nas \nnp\nfrom \nsklearn.datasets \n import \nload_iris\nfrom \nsklearn.linear_model \n import \nPerceptron\niris \n= \nload_iris\n ()\nX \n= \niris\n.\ndata\n[:, (\n2\n, \n3\n)] \n# petal length, petal width\ny \n= \n(\niris\n.\ntarget \n== \n0\n)\n.\nastype\n(\nnp\n.\nint\n) \n# Iris Setosa?\nper_clf \n = \nPerceptron\n ()\nper_clf\n.\nfit\n(\nX\n, \ny\n)\ny_pred \n= \nper_clf\n.\npredict\n([[\n2\n, \n0.5\n]])\nLa classe Perceptron implementa un singolo TLU.  \nL'apprendimento è basato sull'algoritmo Stochastic Gradient Descent, cioè \nsulla classe SGDClassiﬁer con i seguenti parametri: \n loss\n=\"perceptron\", \nlearning_rate\n =\"constant\", \n eta0\n=1 (\nlearning rate\n ), and \n penalty\n =None \n(\nnessuna regolarizzazione\n ). Per ogni istanza in input i pesi sono aggiornati \nin base all'errore prodotto.\n5",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#5": "Richiami: Multi-Layer Perceptron (MLP)\nAl contrario della classiﬁcazione basata sulla logistic regression, il \npercettrone non produce probabilità, ma effettua predizioni in base ad una \nsoglia preﬁssata. Per tale motivo si preferisce la logistic regression. \nPer stimare funzioni anche non lineare, si possono \"impilare\" più TLU \nraggruppati in singoli layer creando architetture \n deep\n . Il ﬂusso dei segnali è \nmonodirezionale (\n feedforward\n ).\n6\n",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#6": "Richiami: Multi-Layer Perceptron (MLP)\nL'algoritmo per stimare i pesi è \n backpropagation\n  training algorithm ed è \nbasato sul calcolo dei gradienti degli errori rispetto ad ogni singolo \nparametro (\n automatic differentation\n  o \nautodiff\n ).  \nIn particolare viene impiegato il \n reverse-mode autodiff\n , adatto quando ci \nsono molte connessioni (pesi) e pochi output. \nIn sintesi si analizzano \n mini-batch\n  di istanze estratte dal training set (es. 32). \nAlla ﬁne di una \n epoca\n  si è analizzato l'intero dataset. Il processo itera ﬁno \nalla convergenza. \nIl mini-batch viene dato in input alla rete e per ogni istanza viene ricavato \nl'output (\n forward pass\n ).  \nPer mezzo della loss function è ricavato l'errore commesso dalla rete. \nLa \nchain rule\n  determina quanto ogni output contribuisce all'errore. Il \nprocesso è ripetuto anche per i layer precedenti, ﬁno all'input (\n reverse pass\n ). \nInﬁne il \n gradient descent\n  impiega tali error gradients per aggiornare i pesi.\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#7": "Richiami: Multi-Layer Perceptron (MLP)\nDomanda: L'inizializzazione dei pesi deve essere random. Se tutti i pesi e \nbias fossero impostati a 0 cosa accadrebbe?\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#8": "Richiami: Multi-Layer Perceptron (MLP)\nL'inizializzazione dei pesi deve essere random. Se tutti i pesi e bias fossero \nimpostati a 0 cosa accadrebbe? \nTutte le unità di un layer si comporterebbero nello stesso modo.  \nIl backpropagation inﬂuenzerebbe tutte le unità allo stesso modo. \nPotremmo avere 100ia di unità per layer, ma è come se ne avessimo \nuna sola. \nL'assegnazione casuale dei pesi evita la simmetria e, il backpropagation \n\"addestra\" gruppi di unità in modo diverso.\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\27-Ex_11 Esercitazione Reti Neurali-sbloccato.pdf#9": "Richiami: Multi-Layer Perceptron (MLP)\nDomanda: Perché è fondamentale inserire una funzione di attivazione?\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Reti Neurali (Ex 12)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#1": "Sommario\nArchitetture non sequenziali e Keras \nOutput multipli \nKeras: Modelli statici e dinamici  \nSave & Restore \nCallbacks \nEarly stopping \nTensorBoard \nFine tuning degli iperparametri \nNumero hidden layers, numero nodi per layers \nTensorFlow playground",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#10": "Keras: Modelli dinamici\nSi crea una subclass di \n Model\n , nel costruttore si deﬁnisce il modello (cioè i \nlayers) e nella funzione \n call()\n  si deﬁnisce come saranno elaborati i dati, e \npuò comprendere loop, istruzioni if-else, etc. \nPer esempio, per il Wide & deep model: \nclass \nWideAndDeepModel\n (\nkeras\n.\nmodels\n.\nModel\n):\ndef \n__init__\n (\nself\n, \nunits\n=\n30\n, \nactivation\n =\n\"relu\"\n, \n**\nkwargs\n):\nsuper\n()\n.\n__init__\n (\n**\nkwargs\n) \n# standard args (e.g., name)\nself\n.\nhidden1 \n = \nkeras\n.\nlayers\n.\nDense\n(\nunits\n, \nactivation\n =\nactivation\n )\nself\n.\nhidden2 \n = \nkeras\n.\nlayers\n.\nDense\n(\nunits\n, \nactivation\n =\nactivation\n )\nself\n.\nmain_output \n = \nkeras\n.\nlayers\n.\nDense\n(\n1\n)\nself\n.\naux_output \n = \nkeras\n.\nlayers\n.\nDense\n(\n1\n)\ndef \ncall\n(\nself\n, \ninputs\n):\ninput_A\n, \ninput_B \n = \ninputs\nhidden1 \n = \nself\n.\nhidden1\n(\ninput_B\n)\nhidden2 \n = \nself\n.\nhidden2\n(\nhidden1\n)\nconcat \n= \nkeras\n.\nlayers\n.\nconcatenate\n ([\ninput_A\n, \nhidden2\n])\nmain_output \n = \nself\n.\nmain_output\n (\nconcat\n)\naux_output \n = \nself\n.\naux_output\n (\nhidden2\n)\nreturn \nmain_output\n , \naux_output\nmodel \n= \nWideAndDeepModel\n ()\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#11": "Keras: Modelli dinamici\nI modelli dinamici hanno lo svantaggio che \n non\n possono essere facilmente \nispezionati da Keras, tantomeno essere salvati o clonati. \nIl metodo summary() restituisce una lista di layer ma non come sono \nconnessi. \n12",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#12": "Keras: Save & Restore\nAddestrare i modelli può richiedere molto tempo. È fondamentale poter \nsalvare i parametri durante (\n checkpoints\n ) o alla ﬁne dell'addestramento. \nmodel\n.\nsave\n(\n\"my_keras_model.h5\"\n )\nmodel \n= \nkeras\n.\nmodels\n.\nload_model\n (\n\"my_keras_model.h5\"\n )\nIl salvataggio interessa i parametri, l'architettura, e gli iperparametri. \nPer il Model subclassing si usano le funzioni save_weights() e \nload_weights(), che interessano però solo i pesi.\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#13": "Keras: callbacks\nÈ possibile deﬁnire una funzione \n callback\n  che verrà invocata al principio e \nalla ﬁne di ogni epoca, o batch. Nell'esempio la funzione \nModelCheckpoint salva il modello a intervalli regolari (default: alla ﬁne di \nogni epoca): \n[\n...\n] \n# dopo la compilazione del modello\ncheckpoint_cb \n = \nkeras\n.\ncallbacks\n .\nModelCheckpoint\n (\n\"my_keras_model.h5\"\n )\nhistory \n = \nmodel\n.\nfit\n(\nX_train\n, \ny_train\n, \nepochs\n=\n10\n, \ncallbacks\n =\n[\ncheckpoint_cb\n ])\nSe impiego un validation set, posso usare il parametro save_best_only=True \nin ModelCheckpoint per salvare il modello quando le prestazioni sono le \nmigliori. Se interrompo e incomincio di nuovo l'addestramento, riparto \ndall'ultimo modello potenzialmente privo di overﬁtting. \nSi può deﬁnire la propria callback agganciandola agli eventi \non_train_begin(), on_train_end(), on_epoch_begin(), on_epoch_begin(), \non_batch_end(), on_batch_end()\n , es.: \nclass \nPrintValTrainRatioCallback\n (\nkeras\n.\ncallbacks\n .\nCallback\n ):\n  \ndef \non_epoch_end\n (\nself\n, \nepoch\n, \nlogs\n):\n      \nprint\n(\n\"\\nval/train: {:.2f}\"\n .\nformat\n(\nlogs\n[\n\"val_loss\"\n ] \n/ \nlogs\n[\n\"loss\"\n]))\n14",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#14": "Keras: early stopping\nCon la stessa tecnica possiamo interrompere il training se, dopo un certo \nnumero di epoche (parametro \n patience\n ), non ci sono incrementi di \nprestazioni tangibili: \ncheckpoint_cb \n = \nkeras\n.\ncallbacks\n .\nModelCheckpoint\n                                    \n (\n\"my_keras_model.h5\"\n ,\nsave_best_only\n =\nTrue\n)\nearly_stopping_cb \n = \nkeras\n.\ncallbacks\n .\nEarlyStopping\n                                    \n (\npatience\n =\n10\n, \nrestore_best_weights\n =\nTrue\n)\nhistory \n = \nmodel\n.\nfit\n(\nX_train\n, \ny_train\n, \nepochs\n=\n100\n, \n                    \n validation_data\n =\n(\nX_valid\n, \ny_valid\n),\n                    \n callbacks\n =\n[\ncheckpoint_cb\n , \nearly_stopping_cb\n ]) \n# rollback al best model \nmodel \n= \nkeras\n.\nmodels\n.\nload_model\n (\n\"my_keras_model.h5\"\n )\n15",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#15": "TensorBoard\nUn tool utile per visualizzare l'andamento dell'addestramento. Aggiorna la \nvisualizzazione in base a un ﬁle binario chiamato event ﬁle.  \nSi possono salvare i dati di ogni training in una directory distinta, così è \npossibile caricarli e confrontarli. Di seguito TensorBoard si occupa di \ncreare la directory e salvarci i dati: \nroot_logdir \n = \nos\n.\npath\n.\njoin\n(\nos\n.\ncurdir\n, \n\"my_logs\"\n )\ndef \nget_run_logdir\n ():\nimport \ntime\nrun_id \n= \ntime\n.\nstrftime\n (\n\"run_\n%Y\n_\n%m\n_\n%d\n-\n%H\n_\n%M\n_\n%S\n\"\n)\nreturn \nos\n.\npath\n.\njoin\n(\nroot_logdir\n , \nrun_id\n)\nrun_logdir \n = \nget_run_logdir\n () \n# es. './my_logs/run_2019_01_16-11_28_43'\n[\n...\n] \n# Build and compile your model\ntensorboard_cb \n = \nkeras\n.\ncallbacks\n .\nTensorBoard\n (\nrun_logdir\n )\nhistory \n = \nmodel\n.\nfit\n(\nX_train\n, \ny_train\n, \nepochs\n=\n30\n,\n                    \n validation_data\n =\n(\nX_valid\n, \ny_valid\n), \n                    \n callbacks\n =\n[\ntensorboard_cb\n ])\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#16": "TensorBoard\nTensorBoard può funzionare come server in locale: \n$ \ntensorboard --logdir\n =\n./my_logs --port\n =\n6006\nTensorBoard 2.0.0 at http://mycomputer.local:6006 \n (\nPress CTRL+C to quit\n )\nPer l'interfacciamento con Colab consultare: \nhttps://colab.research.google.com/github/tensorflow/tensorboard/blob/master/\ndocs/get_started.ipynb\n17\n",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#17": "Fine tuning degli iperparametri\nRispetto ad altri modelli le reti neurali hanno numerosi iperparametri da \ndeﬁnire. Un approccio spesso usato è quello di esplorare lo spazio delle \nconﬁgurazioni con le classi \n GridSearchCV\n  o \nRandomizedSearchCV.  \nDeﬁniamo una funzione che prende in input gli iperparametri da \nottimizzare:  \ndef \nbuild_model\n (\nn_hidden\n =\n1\n, \nn_neurons\n =\n30\n, \nlearning_rate\n =\n3e-3\n, \ninput_shape\n =\n[\n8\n]):\nmodel \n= \nkeras\n.\nmodels\n.\nSequential\n ()\n# necessario per far si che il primo layer sia inizializzato correttamente\noptions \n = \n{\n\"input_shape\"\n : \ninput_shape\n }\nfor \nlayer \nin \nrange\n(\nn_hidden\n ):\nmodel\n.\nadd\n(\nkeras\n.\nlayers\n.\nDense\n(\nn_neurons\n , \nactivation\n =\n\"relu\"\n, \n**\noptions\n))\noptions \n = \n{}\nmodel\n.\nadd\n(\nkeras\n.\nlayers\n.\nDense\n(\n1\n, \n**\noptions\n))\noptimizer \n = \nkeras\n.\noptimizers\n .\nSGD\n(\nlearning_rate\n )\nmodel\n.\ncompile\n(\nloss\n=\n\"mse\"\n, \noptimizer\n =\noptimizer\n )\nreturn \nmodel\n...\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#18": "Fine tuning degli iperparametri\nDopodiché istanziamo una regressione per Keras; \nkeras_reg \n = \nkeras\n.\nwrappers\n .\nscikit_learn\n .\nKerasRegressor\n (\nbuild_model\n )\nNon speciﬁcando altri parametri, build_model() userà quelli di default.  \nAbbiamo appena creato un modello, e possiamo seguire i soliti step: \nkeras_reg\n .\nfit\n(\nX_train\n, \ny_train\n, \nepochs\n=\n100\n, \n              \n validation_data\n =\n(\nX_valid\n, \ny_valid\n),\n              \n callbacks\n =\n[\nkeras\n.\ncallbacks\n .\nEarlyStopping\n (\npatience\n =\n10\n)])\nmse_test \n = \nkeras_reg\n .\nscore\n(\nX_test\n, \ny_test\n)\ny_pred \n= \nkeras_reg\n .\npredict\n(\nX_new\n)\nQualsiasi parametro aggiuntivo passato a ﬁt() sarà inoltrato al modello \nKeras. \n19",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#19": "Fine tuning degli iperparametri\nMiglioriamo l'esplorazione con un comportamento random, e deﬁnendo \ndegli intervallo per i parametri impiegati: \nkeras_reg \n = \nkeras\n.\nwrappers\n .\nscikit_learn\n .\nKerasRegressor\n (\nbuild_model\n )\nNon speciﬁcando altri parametri, build_model() userà quelli di default. \nPossiamo deﬁnire intervalli da cui campionare casualmente i valori degli \niperparametri che abbiamo deﬁnito in build_model(): \nfrom \nscipy.stats \n import \nreciprocal\nfrom \nsklearn.model_selection \n import \nRandomizedSearchCV\nparam_distribs \n = \n{\n\"n_hidden\"\n : [\n0\n, \n1\n, \n2\n, \n3\n],\n\"n_neurons\"\n : \nnp\n.\narange\n(\n1\n, \n100\n),\n\"learning_rate\"\n : \nreciprocal\n (\n3e-4\n, \n3e-2\n),\n}\n# RandomizedSearchCV usa la K-fold cross-validation, ignora X/y_valid\nrnd_search_cv \n = \nRandomizedSearchCV\n (\nkeras_reg\n , \nparam_distribs\n , \nn_iter\n=\n10\n, \ncv\n=\n3\n)\nrnd_search_cv\n .\nfit\n(\nX_train\n, \ny_train\n, \nepochs\n=\n100\n,\nvalidation_data\n =\n(\nX_valid\n, \ny_valid\n),\ncallbacks\n =\n[\nkeras\n.\ncallbacks\n .\nEarlyStopping\n (\npatience\n =\n10\n)]) \n20",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#2": "Architetture non sequenziali: wide & deep\nSi possono impiegare architetture più complesse di quelle viste ﬁnora, ad \nesempio quelle non sequenziali. \nNella \n wide & deep \n l'input è connesso direttamente con l'output. Questo \npermette di apprendere sia patterns \n deep\n  (con la pipeline MLP \ntradizionale), sia regole semplici, per mezzo del percorso breve.\n3\n",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#20": "Fine tuning degli iperparametri\nI valori degli iperparametri si ottengono alle variabili: \n>>> \nrnd_search_cv\n .\nbest_params_\n{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}\n>>> \nrnd_search_cv\n .\nbest_score_\n-0.3189529188278931\n>>> \nmodel \n= \nrnd_search_cv\n .\nbest_estimator_\n .\nmodel\nSi possono impiegare per validare il modello sul test set. \nSe lo spazio degli iperparametri è molto grande, si parte con una \nesplorazione grossolana degli intervalli, e successivamente si rafﬁna lo \nspazio limitandolo agli intervalli potenzialmente più promettenti. \n21",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#21": "Fine tuning degli iperparametri\nAltre librerie per il tuning degli iperparametri: \n• \nHyperopt\n : a popular Python library for optimizing over all sorts of complex \nsearch spaces (including real values such as the learning rate, or discrete values \nsuch as the number of layers).\n• \nHyperas\n , \nkopt \n or \nTalos\n : optimizing hyperparameters for Keras model (the ﬁrst \ntwo are based on Hyperopt).\n• \nScikit-Optimize \n (skopt): a general-purpose optimization library. The \nBayesSearchCV \n class performs Bayesian optimization using an interface \nsimilar to \nGrid\n SearchCV .\n• \nSpearmint\n : a Bayesian optimization library.\n• \nSklearn-Deap\n : a hyperparameter optimization library based on evolutionary \nalgorithms, also with a \n GridSearchCV\n -like interface.\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#22": "Numero di hidden layers\nUna MLP con 1 hidden layer e un numero sufﬁciente di nodi può \nmodellare qualsiasi funzione complessa. Ma le deep networks usano i nodi \nin modo più efﬁcienti, perciò richiedono meno potenza computazionale. \nGli strati più vicini all'input possono rappresentare forme semplici e relative \ncaratteristiche (es. segmenti, orientazioni), i layer intermedi combinano questi \nelementi per forme più complesse (es. quadrati, cerchi), mentre i layer ﬁnali si \nfocalizzano sulle forme ad alto livello (es. viso delle persone). \nInoltre le architetture deep riescono più facilmente a generalizzare a nuovi \ndatasets.  \nUna parte dei layers di una rete addestrata a riconoscere facce possono essere \nimpiegati in una nuova rete per riconoscere tagli di capelli, evitando una scelta \nrandom dei parametri iniziali (\n transfer learning\n ). \nIn generale si parte con pochi hidden layer (1 o 2) per task semplici, \nincrementandoli per task complessi, ﬁnché si raggiunge l'overﬁtting. Per i \ntask molto complessi si cercano modelli pre-addestrati da cui partire con \nnuovi addestramenti. \n23",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#23": "Numero di nodi per layers\nIl numero di nodi per l'input layer è determinato dalle istanze in entrata. \nI restanti layer tipicamente formano una piramide, dove i nodi si riducono \nall'avvicinarsi del layer di output. L'idea è che gli ultimi layer \nrappresentano poche e salienti features ad alto livello. \nMa sperimentazioni più recenti suggeriscono di mantenere costante il \nnumero di nodi per layer, ottenendo un singolo iperparametro da \nottimizzare. \nAnche per il numero di nodi si può partire da un numero basso e \nincrementarlo ﬁno a quando può comparire l'overﬁtting.\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#24": "Altri iperparametri\nLearning rate: il valore ottimale è solitamente la metà di quello massimo, \ncioè quello che genera divergenza nell'algoritmo di training.  \nSi parte da un valore alto, dove si ha sicura divergenza, e poi si divide \nper 3 e si ripete ﬁno a quando la divergenza scompare. \nBatch size: inﬂuisce sia sulle performance che su tempo di addestramento. \nSolitamente inferiore a 32. Un valore basso garantisce una iterazione di \ntraining veloce. Un valore alto più precisione nella stima dei gradienti. \nPer altre raccomandazioni:  \nPractical recommendations for gradient-based training of deep \narchitectures   \n https://arxiv.org/abs/1206.5533  \n25",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#25": "TensorFlow Playground\nTool interattivo per sperimentare reti neurali \nhttps://playground.tensorﬂow.org/   \n26\n",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#26": "Esercitazione\nAddestra la rete di default. Analizza i patterns riconosciuti dai vari layers, \ncosa puoi constatare?  \nRimpiazza la Tanh con la ReLU. Cosa cambia?  \nModiﬁca l'architettura e rendila con 1 solo hidden layer e 3 neuroni. \nAddestrala varie volte, cosa noti? \nRimuovi un nodo (ne rimagono 2). Riprova, cosa noti? \nAumenta i nodi a 8. Riprova. \nUsa il dataset a spirale e una architettura con 4 hidden layers, ognuno con \n8 nodi. Cosa noti?\n27",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#27": "Esercitazione - soluzione\nAddestra la rete di default. Analizza i patterns riconosciuti dai vari layers, cosa puoi constatare?  \nGli strati più vicini all'output sono più complessi. \nRimpiazza la Tanh con la ReLU. Cosa cambia?  \nSi accelera il training, ma ora i boundaries sono lineari. \nModiﬁca l'architettura e rendila con 1 solo hidden layer e 3 neuroni. Addestrala varie volte, cosa noti? \nI tempi di apprendimento variano molto e spesso ci si blocca in minimi locali. \nRimuovi un nodo (ne rimagono 2). Riprova, cosa noti? \nLa rete non trova soluzioni buone. Troppi pochi parametri generano underﬁtting. \nAumenta i nodi a 8. Riprova. \nPiù veloce, e non ferma più come nel caso precedente. Reti più complesse hanno più chance di \ntrovare soluzioni ottime o tendenti all'ottimo, anche se possono comunque rimanere \"bloccate\" su \nplateaus. \nUsa il dataset a spirale e una architettura con 4 hidden layers, ognuno con 8 nodi. Cosa noti? \nTraining time più lungo, spesso rallentanti da plateaus. I nodi nei layer verso l'output si aggiornano \npiù velocemente degli altri. È il \n vanishing gradinets\n  problem. Si può risolvere con una \ninizializzazione più accurata dei pesi, altri ottimizzatori (es. AdaGrad e Adam) e con la Batch \nnormalization.\n28",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#28": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n29",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#3": "Architetture non sequenziali e Keras\nImpieghiamo le \n functional API\n  di Keras.  \nQuando creiamo un layer possiamo passargli un parametro aggiuntivo che \ncorrisponde all'input del layer, es: \nhidden1 \n = \nkeras\n.\nlayers\n.\nDense\n(\n30\n, \nactivation\n =\n\"relu\"\n)(\ninput\n)\nIl layer \n Concatenate\n  permette di concatenare e creare un input composito \nper un certo layer. \ninput \n= \nkeras\n.\nlayers\n.\nInput\n(\nshape\n=\nX_train\n.\nshape\n[\n1\n:])\nhidden1 \n = \nkeras\n.\nlayers\n.\nDense\n(\n30\n, \nactivation\n =\n\"relu\"\n)(\ninput\n)\nhidden2 \n = \nkeras\n.\nlayers\n.\nDense\n(\n30\n, \nactivation\n =\n\"relu\"\n)(\nhidden1\n)\nconcat \n= \nkeras\n.\nlayers\n.\nConcatenate\n ()[\ninput\n, \nhidden2\n])\noutput \n= \nkeras\n.\nlayers\n.\nDense\n(\n1\n)(\nconcat\n)\nmodel \n= \nkeras\n.\nmodels\n.\nModel\n(\ninputs\n=\n[\ninput\n], \noutputs\n=\n[\noutput\n])\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#4": "Architetture non sequenziali e Keras\nSe volessimo suddividere l'input in 2 parti, eventualmente in \nsovrapposizione, e mandare su 2 strati distinti, allora dobbiamo creare 2 \ninput layers: \ninput_A \n = \nkeras\n.\nlayers\n.\nInput\n(\nshape\n=\n[\n5\n])\ninput_B \n = \nkeras\n.\nlayers\n.\nInput\n(\nshape\n=\n[\n6\n])\nhidden1 \n = \nkeras\n.\nlayers\n.\nDense\n(\n30\n, \nactivation\n =\n\"relu\"\n)(\ninput_B\n)\nhidden2 \n = \nkeras\n.\nlayers\n.\nDense\n(\n30\n, \nactivation\n =\n\"relu\"\n)(\nhidden1\n)\nconcat \n= \nkeras\n.\nlayers\n.\nconcatenate\n ([\ninput_A\n, \nhidden2\n])\noutput \n= \nkeras\n.\nlayers\n.\nDense\n(\n1\n)(\nconcat\n)\nmodel \n= \nkeras\n.\nmodels\n.\nModel\n(\ninputs\n=\n[\ninput_A\n, \ninput_B\n]\n, \noutputs\n=\n[\noutput\n])\n5\n",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#5": "Architetture non sequenziali e Keras\nAvendo creato due input, dobbiamo speciﬁcarli esplicitamente nella \nfunzione ﬁt(), dopo aver compilato il modello: \nmodel\n.\ncompile\n(\nloss\n=\n\"mse\"\n, \noptimizer\n =\n\"sgd\"\n)\nX_train_A\n , \nX_train_B \n = \nX_train\n[:, :\n5\n], \nX_train\n[:, \n2\n:]\nX_valid_A\n , \nX_valid_B \n = \nX_valid\n[:, :\n5\n], \nX_valid\n[:, \n2\n:]\nX_test_A\n , \nX_test_B \n = \nX_test\n[:, :\n5\n], \nX_test\n[:, \n2\n:]\nX_new_A\n, \nX_new_B \n = \nX_test_A\n [:\n3\n], \nX_test_B\n [:\n3\n]\nhistory \n = \nmodel\n.\nfit\n(\n(\nX_train_A\n , \nX_train_B\n )\n, \ny_train\n, \nepochs\n=\n20\n,\nvalidation_data\n =\n((\nX_valid_A\n , \nX_valid_B\n ), \ny_valid\n))\nmse_test \n = \nmodel\n.\nevaluate\n ((\nX_test_A\n , \nX_test_B\n ), \ny_test\n)\ny_pred \n= \nmodel\n.\npredict\n((\nX_new_A\n, \nX_new_B\n))\n6",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#6": "Output multipli\nPerché costruire architetture con output multipli? \nIl task lo potrebbe richiedere, es. localizzare e classiﬁcare un oggetto in \nuna foto, cioè un problema di regressione e classiﬁcazione.  \nLo stesso vale per task più distinti. Sebbene si possano addestrare reti \ndistinte, conviene condividere i parametri che in qualche modo \nrappresentano potenziali features che sono di interesse per entrambi i \ntask, in modo da dover addestrare una sola volta la rete. \nImplementare una forma di regolarizzazione dei parametri per ridurre \nl'overﬁtting. Se per esempio aggiungiamo un secondo output in una \ncerta parte della rete, imponiamo che  \nla sottorete si addestri in modo autonomo,  \nsenza dipendere dalla restante parte della rete.\n7\n",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#7": "Output multipli e Keras\nPer aggiungere un secondo output (aux) è sufﬁciente collegarlo al layer \ngiusto e aggiungerlo alla lista degli output: \n[\n...\n] # Stesso codice visto fino al layer di output\noutput \n= \nkeras\n.\nlayers\n.\nDense\n(\n1\n)(\nconcat\n)\naux_output \n = \nkeras\n.\nlayers\n.\nDense\n(\n1\n)(\nhidden2\n)\nmodel \n= \nkeras\n.\nmodels\n.\nModel\n(\ninputs\n=\n[\ninput_A\n, \ninput_B\n],\n                             \n outputs\n=\n[\noutput\n, \naux_output\n ])\nOgni output deve possedere la propria \n loss function\n , da indicare quando \ncompiliamo. Solitamente si da più peso alla loss dell'output ﬁnale: \nmodel\n.\ncompile\n(\nloss\n=\n[\n\"mse\"\n, \n\"mse\"\n], \nloss_weights\n =\n[\n0.9\n, \n0.1\n], \noptimizer\n =\n\"sgd\"\n)\nNella architettura vogliamo che entrambi gli output producano lo stesso \nrisultato (y_train): \nhistory \n = \nmodel\n.\nfit\n([\nX_train_A\n , \nX_train_B\n ], [\ny_train\n, \ny_train\n], \nepochs\n=\n20\n,\n                    \n validation_data\n =\n([\nX_valid_A\n , \nX_valid_B\n ], [\ny_valid\n, \ny_valid\n])) \n8",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#8": "Output multipli e Keras\nDurante l'addestramento, oltre alla loss totale, sarà prodotta anche la loss \ndel layer di output principale e aux: \ntotal_loss\n , \nmain_loss\n , \naux_loss \n = \nmodel\n.\nevaluate\n (\n                             [\n X_test_A\n , \nX_test_B\n ], [\ny_test\n, \ny_test\n])\nAnche la funzione predict() produrrà un doppio output: \ny_pred_main\n , \ny_pred_aux \n = \nmodel\n.\npredict\n([\nX_new_A\n, \nX_new_B\n])\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\28-Ex_12 Esercitazione Reti Neurali-sbloccato.pdf#9": "Keras: Modelli statici e dinamici\nEntrambe le API, sequential e functional, seguono un approccio \ndichiarativo\n , dove prima si deﬁniscono i layer, come sono connessi, e \nsuccessivamente viene avviato il ﬂusso dei dati. Si hanno i seguenti \nvantaggi: \nil modello può facilmente essere salvato, clonato e condiviso \nla struttura può essere visualizzata \nil framework può inferire il tipo di dati e controllare i tipi (favorisce il \ndebug) \nMa non si possono prevedere loop, architetture dinamiche, conditional \nbranching e altri comportamenti dinamici. \nPer tale motivo si impiega il Subclassing API.\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#0": "Machine Learning\nUniversità Roma Tre  \nDipartimento di Ingegneria \nAnno Accademico 2021 -2022\nClassiﬁcatore di Bayes",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#1": "Sommario\n!Approccio parametrico (distribuzione MultiNormale)\n!Approccio non parametrico (Parzen Window) ",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#10": "Classiﬁcatore di Bayes\n3prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneClassificatore di Bayes\nDato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di\ncuisono note:\nle\nprobabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠\nledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠\nlaregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui\nèmassima laprobabilità aposteriori :\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑃𝑤𝑖𝐱\nMassimizzare laprobabilità aposteriori significa massimizzare la\ndensità diprobabilità condizionale tenendo comunque conto della\nprobabilità apriori delle classi .\nLa\nregola sidimostra ottima inquanto minimizza l’errore di\nclassificazione .Adesempio nelcaso di2classi e𝑑=1:\n𝑃𝑒𝑟𝑟𝑜𝑟=න\n1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න\n2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥\n",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#11": "Classiﬁcatore di Bayes\n3prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneClassificatore di Bayes\nDato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di\ncuisono note:\nle\nprobabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠\nledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠\nlaregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui\nèmassima laprobabilità aposteriori :\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑃𝑤𝑖𝐱\nMassimizzare laprobabilità aposteriori significa massimizzare la\ndensità diprobabilità condizionale tenendo comunque conto della\nprobabilità apriori delle classi .\nLa\nregola sidimostra ottima inquanto minimizza l’errore di\nclassificazione .Adesempio nelcaso di2classi e𝑑=1:\n𝑃𝑒𝑟𝑟𝑜𝑟=න\n1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න\n2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥\n",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#12": "Classiﬁcatore di Bayes\n3prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneClassificatore di Bayes\nDato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di\ncuisono note:\nle\nprobabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠\nledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠\nlaregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui\nèmassima laprobabilità aposteriori :\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑃𝑤𝑖𝐱\nMassimizzare laprobabilità aposteriori significa massimizzare la\ndensità diprobabilità condizionale tenendo comunque conto della\nprobabilità apriori delle classi .\nLa\nregola sidimostra ottima inquanto minimizza l’errore di\nclassificazione .Adesempio nelcaso di2classi e𝑑=1:\n𝑃𝑒𝑟𝑟𝑜𝑟=න\n1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න\n2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥\n3prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneClassificatore di Bayes\nDato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di\ncuisono note:\nle\nprobabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠\nledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠\nlaregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui\nèmassima laprobabilità aposteriori :\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑃𝑤𝑖𝐱\nMassimizzare laprobabilità aposteriori significa massimizzare la\ndensità diprobabilità condizionale tenendo comunque conto della\nprobabilità apriori delle classi .\nLa\nregola sidimostra ottima inquanto minimizza l’errore di\nclassificazione .Adesempio nelcaso di2classi e𝑑=1:\n𝑃𝑒𝑟𝑟𝑜𝑟=න\n1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න\n2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥\nℜ1eℜ2rappresentano due regioni disgiunte\ndell’insieme deinumeri reali .\nSipuò dimostrare che esiste unpunto x*per il\nquale l’errore èminimo .\nInfatti per x*=x B(dove Bstaper Bayes) l’area\nindicata come reducible error èpari a0.\nCiascuno dei due integrali esprime laparte\ndella distribuzione diprobabilità diuna classe\nche cade nell’area dell’altra classe (errata) .\nInquesto caso, lasuperficie decisionale (vedi\ndopo) èunpunto sull’asse deinumeri reali .",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#13": "Classificatore di Bayes30 CHAPTER 2. BAYESIAN DECISION THEORY\n2.7 Error Probabilities and Integrals\nWe can obtain additional insight into the operation of a general classiﬁer — Bayes or\notherwise — if we consider the sources of its error. Consider ﬁrst the two-category\ncase, and suppose the dichotomizer has divided the space into two regions R1andR2\nin a possibly non-optimal way. There are two ways in which a classiﬁcation error can\noccur; either an observation xfalls in R2and the true state of nature is ω1, orxfalls\ninR1and the true state of nature is ω2. Since these events are mutually exclusive\nand exhaustive, the probability of error is\nP(error )= P(x∈R2,ω1)+P(x∈R1,ω2)\n=P(x∈R2|ω1)P(ω1)+P(x∈R1|ω2)P(ω2)\n=/integraldisplay\nR2p(x|ω1)P(ω1)dx+/integraldisplay\nR1p(x|ω2)P(ω2)dx. (68)\nThis result is illustrated in the one-dimensional case in Fig. 2.17. The two in-\ntegrals in Eq. 68 represent the pink and the gray areas in the tails of the functions\np(x|ωi)P(ωi). Because the decision point x∗(and hence the regions R1andR2) were\nchosen arbitrarily for that ﬁgure, the probability of error is not as small as it might\nbe. In particular, the triangular area marked “reducible error” can be eliminated if\nthe decision boundary is moved to xB. This is the Bayes optimal decision boundary\nand gives the lowest probability of error. In general, if p(x|ω1)P(ω1)>p(x|ω2)P(ω2),\nit is advantageous to classify xas in R1so that the smaller quantity will contribute\nto the error integral; this is exactly what the Bayes decision rule achieves.\nω2 ω1\nx\nx* R2 R1p(x|ωi)P(ωi)\nreducible\nerror\n∫p(x|ω1)P(ω1)dx\nR2∫p(x|ω2)P(ω2)dx\nR1xB\nFigure 2.17: Components of the probability of error for equal priors and (non-optimal)\ndecision point x∗. The pink area corresponds to the probability of errors for deciding\nω1when the state of nature is in fact ω2; the gray area represents the converse, as\ngiven in Eq. 68. If the decision boundary is instead at the point of equal posterior\nprobabilities, xB, then this reducible error is eliminated and the total shaded area is\nthe minimum possible — this is the Bayes decision and gives the Bayes error rate.\nIn the multicategory case, there are more ways to be wrong than to be right, and\nit is simpler to compute the probability of being correct. Clearly\nP(correct )=c/summationdisplay\ni=1P(x∈Ri,ωi)",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#14": "Esempio\n4prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempio\nUna stima (grossolana) delle probabilità a priori e delle densità può \nessere effettuata a partire dal training set come segue (si vedranno in \nseguito tecniche più rigorose per effettuare tale stima):\nProbabilità a priori\n : si considera semplicemente l’occorrenza dei \npattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18\nDensità di probabilità condizionali\n per un nuovo pattern 𝐱da \nclassificare: si contano le occorrenze dei pattern del training set \ndelle due classi in un intorno di 𝐱:\n𝑝\n𝐱𝑤1=1/8\n𝑝\n𝐱𝑤2=Τ210=1/5\n𝑝\n𝐱=1\n8×8\n18+1\n5×10\n18=1\n18+2\n18=1\n6\nSi ottiene quindi :\n𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1\n𝑝𝐱=𝟏/𝟏𝟖\n𝟏/𝟔=𝟏\n𝟑\n𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2\n𝑝𝐱=𝟐/𝟏𝟖\n𝟏/𝟔=𝟐\n𝟑\nL’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).\nx\nPesoAltezzaClassificare le persone in\nmaschi/femmine in base a \npeso e all’altezza , a partire \ndal training set in figura.\n𝐕\nè uno spazio a 2 \ndimensioni ( 𝑑=2)\nW=𝑤1,𝑤2\n𝑤1= maschi ( blu),\n𝑤2= femmine ( rosso )\n!Vogliamo eseguire la stima (grossolana) delle probabilità a priori \ndelle classi wie delle densità di probabilità condizionali per un nuovo \npattern xdata la classe wi  a partire dal training set (per la seconda \nstima consideriamo l’intorno del pattern xcerchiato in figura)",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#15": "Esempio\n4prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempio\nUna stima (grossolana) delle probabilità a priori e delle densità può \nessere effettuata a partire dal training set come segue (si vedranno in \nseguito tecniche più rigorose per effettuare tale stima):\nProbabilità a priori\n : si considera semplicemente l’occorrenza dei \npattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18\nDensità di probabilità condizionali\n per un nuovo pattern 𝐱da \nclassificare: si contano le occorrenze dei pattern del training set \ndelle due classi in un intorno di 𝐱:\n𝑝\n𝐱𝑤1=1/8\n𝑝\n𝐱𝑤2=Τ210=1/5\n𝑝\n𝐱=1\n8×8\n18+1\n5×10\n18=1\n18+2\n18=1\n6\nSi ottiene quindi :\n𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1\n𝑝𝐱=𝟏/𝟏𝟖\n𝟏/𝟔=𝟏\n𝟑\n𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2\n𝑝𝐱=𝟐/𝟏𝟖\n𝟏/𝟔=𝟐\n𝟑\nL’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).\nx\nPesoAltezzaClassificare le persone in\nmaschi/femmine in base a \npeso e all’altezza , a partire \ndal training set in figura.\n𝐕\nè uno spazio a 2 \ndimensioni ( 𝑑=2)\nW=𝑤1,𝑤2\n𝑤1= maschi ( blu),\n𝑤2= femmine ( rosso )",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#16": "Esempio\n4prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempio\nUna stima (grossolana) delle probabilità a priori e delle densità può \nessere effettuata a partire dal training set come segue (si vedranno in \nseguito tecniche più rigorose per effettuare tale stima):\nProbabilità a priori\n : si considera semplicemente l’occorrenza dei \npattern nel training set: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18\nDensità di probabilità condizionali\n per un nuovo pattern 𝐱da \nclassificare: si contano le occorrenze dei pattern del training set \ndelle due classi in un intorno di 𝐱:\n𝑝\n𝐱𝑤1=1/8\n𝑝\n𝐱𝑤2=Τ210=1/5\n𝑝\n𝐱=1\n8×8\n18+1\n5×10\n18=1\n18+2\n18=1\n6\nSi ottiene quindi :\n𝑃𝑤1𝐱=𝑝𝐱𝑤1∙𝑃𝑤1\n𝑝𝐱=𝟏/𝟏𝟖\n𝟏/𝟔=𝟏\n𝟑\n𝑃𝑤2𝐱=𝑝𝐱𝑤2∙𝑃𝑤2\n𝑝𝐱=𝟐/𝟏𝟖\n𝟏/𝟔=𝟐\n𝟑\nL’approccio Bayesiano assegna il pattern 𝐱alla classe 𝑤2(femmine).\nx\nPesoAltezzaClassificare le persone in\nmaschi/femmine in base a \npeso e all’altezza , a partire \ndal training set in figura.\n𝐕\nè uno spazio a 2 \ndimensioni ( 𝑑=2)\nW=𝑤1,𝑤2\n𝑤1= maschi ( blu),\n𝑤2= femmine ( rosso )",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#17": "Approccio Bayesiano\n5prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes : approccio parametrico e\nnon-parametrico\nMentre\n lastima delle probabilità apriori èabbastanza semplice\n(senon sihanno elementi sipossono ipotizzare leclassi\nequiprobabili) ,laconoscenza delle densità condizionali è\npossibile “solo inteoria”;nella pratica duesoluzioni :\nApproccio\n parametrico :sifanno ipotesi sulla forma delle\ndistribuzioni (es.distribuzione multinormale )esiapprendono i\nparametri fondamentali (vettore medio ,matrice dicovarianza )\ndaltraining set.\nApproccio\n nonparametrico :siapprendono ledistribuzioni dal\ntraining set(es.attraverso ilmetodo Parzen Window ).\nGeneralmente l’approccio parametrico siutilizza quando, oltre ad\navere unaragionevole certezza (osperanza )chelaforma della\ndistruzione siaadeguata, ladimensione deltraining setnon è\nsufficiente perunabuona stima della densità .\nL’approccio\n parametrico èinfatti generalmente caratterizzato\ndaunminor numero digradi dilibertà eilrischio dioverfitting\ndeidati, quando iltraining setèpiccolo, èminore .",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#18": "Sommario\n!Approccio parametrico (distribuzione MultiNormale)\n!Approccio non parametrico (Parzen Window) ",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#19": "Approccio Bayesiano\nGeneralmente l’approccio parametrico siutilizza quando, oltre ad\navere una ragionevole certezza (osperanza )che laforma della\ndistribuzione siaadeguata, ladimensione deltraining setnon è\nsufficiente perunabuona stima della densità .\n!L’approccio parametrico èinfatti generalmente caratterizzato\ndaunminor numero digradi dilibertà eilrischio dioverfitting\ndeidati, quando iltraining setèpiccolo, èminore .",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#2": "Probabilità\nQuando un agente conosce l’ambiente circostante , l’approccio\nlogico gliconsente di derivare piani efficaci . Ma gliagenti non \nhanno quasi maiaccesso a tutta l’informazione necessaria : \ndevono quindi agire in condizioni di incertezza .\nLa teoria della probabilità èilmodo migliore di ragionare in \ncondizioni di incertezza .",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#20": "Distribuzione Normale (d=1)\n6prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDistribuzione Normale (d=1) \nLa\ndensità diprobabilità della distribuzione normale (𝑑=1)è:\n𝑝𝑥=1\n𝜎2𝜋𝑒−𝑥−𝜇2\n2𝜎2\ndove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto\nquadratico medio )eilsuoquadrato 𝜎2lavarianza .\nSolo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+\n2𝜎].\nSolitamente siassume che ladistribuzione valga 0adistanze\nmaggiori di3𝜎dalvalore medio .\n6prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDistribuzione Normale (d=1) \nLa\ndensità diprobabilità della distribuzione normale (𝑑=1)è:\n𝑝𝑥=1\n𝜎2𝜋𝑒−𝑥−𝜇2\n2𝜎2\ndove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto\nquadratico medio )eilsuoquadrato 𝜎2lavarianza .\nSolo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+\n2𝜎].\nSolitamente siassume che ladistribuzione valga 0adistanze\nmaggiori di3𝜎dalvalore medio .\n6prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDistribuzione Normale (d=1) \nLa\ndensità diprobabilità della distribuzione normale (𝑑=1)è:\n𝑝𝑥=1\n𝜎2𝜋𝑒−𝑥−𝜇2\n2𝜎2\ndove𝜇èilvalor medio è𝜎ladeviazione standard (oscarto\nquadratico medio )eilsuoquadrato 𝜎2lavarianza .\nSolo il5%circa del“volume” èesternoall’intervallo [𝜇−2𝜎,𝜇+\n2𝜎].\nSolitamente siassume che ladistribuzione valga 0adistanze\nmaggiori di3𝜎dalvalore medio .\nN.B. La funzione p(x) sopra nonvaconfusa con la densità di probabilità assoluta \nchecompare a denominatore del Teorema di Bayes. Sono due grandezze diverse !",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#21": "Esempio Stima di µes(d=1)\n7prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempio stima di 𝜇e 𝜎(d=1)\nDato\n untraining setdipattern mono -dimensionali composto da\n𝑛=10elementi :\n3,7,9,−2,15,54,−11,0,23,−8\nLa\nstima deiparametri permassima verosimiglianza (maximum\nlikelihood )sidimostra [1]essere :\nStima\n per𝜇:media campionaria deivalori .\nStima\n per𝜎2:varianza campionaria deivalori .\n\u000b\f \u000b\f \u000b\f91090\n108 230 11 54 152 973 1\n1  \u0010\u000e\u000e\u000e\u0010\u000e\u000e\u000e\u0010\u000e\u000e\u000e  ¦\n n\niixnP\n\u000b\f¦\n  \u0010  n\niixn 12 21P V\n\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f8.3181098 9 23 90 911 9 54 9 15 92 99 97 9322 2 2 2 2 2 2 2 2\n \u0010\u0010\u000e\u0010\u000e\u0010\u000e\u0010\u0010\u000e\u0010\u000e\u0010\u000e\u0010\u0010\u000e\u0010\u000e\u0010\u000e\u0010 \n[1] https://it.wikipedia.org/wiki/Metodo_della_massima_verosimiglianza!Vogliamo eseguire la stima dei parametri tramite il Metodo \ndella Massima Verosimiglianza ( Maximum Likelihood )\nIl metodo consiste nel massimizzare la funzione di verosimiglianza, definita in \nbase alla probabilità di osservare una data realizzazione campionaria , \ncondizionatamente ai valori assunti dai parametri statistici oggetto di stima",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#22": "Esempio Stima di µes(d=1)\n7prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempio stima di 𝜇e 𝜎(d=1)\nDato\n untraining setdipattern mono -dimensionali composto da\n𝑛=10elementi :\n3,7,9,−2,15,54,−11,0,23,−8\nLa\nstima deiparametri permassima verosimiglianza (maximum\nlikelihood )sidimostra [1]essere :\nStima\n per𝜇:media campionaria deivalori .\nStima\n per𝜎2:varianza campionaria deivalori .\n\u000b\f \u000b\f \u000b\f91090\n108 230 11 54 152 973 1\n1  \u0010\u000e\u000e\u000e\u0010\u000e\u000e\u000e\u0010\u000e\u000e\u000e  ¦\n n\niixnP\n\u000b\f¦\n  \u0010  n\niixn 12 21P V\n\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f8.3181098 9 23 90 911 9 54 9 15 92 99 97 9322 2 2 2 2 2 2 2 2\n \u0010\u0010\u000e\u0010\u000e\u0010\u000e\u0010\u0010\u000e\u0010\u000e\u0010\u000e\u0010\u0010\u000e\u0010\u000e\u0010\u000e\u0010 \n[1] https://it.wikipedia.org/wiki/Metodo_della_massima_verosimiglianza",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#23": "Esempio Stima di µes(d=1)\n8prof. Davide Maltoni –Università di Bologna\nML\nClassificazione…in forma grafica\n\u000b\f\n01495.07559.441\n1416.32 855.171)25(4015.0 8.31829252\n   \n \u0010 \u0010\u0010e e p\nATTENZIONE SIAMO NEL \nCONTINUO :\n𝑝è unadensità di \nprobabilità : 𝑝(25) non è la \nprobabilità del valore 25 \n(questa vale 0!) ma la \ndensità di probabilità nel\npunto 25. Solo considerando\nun intervallo di valori (anche\npiccolo) sulla base possiamo\nparlare di probabilità . \nIn altre parole l’intervallo\n𝑥,𝑥+𝑑𝑥ha probabilità\n𝑝𝑥𝑑𝑥.N.B. Siamo nelcontinuo: p(25) è una densità di probabilità , non una probabilità !  ",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#24": "Esempio Stima di µes(d=1)\n",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#3": "Spazio di Probabilità\nUno spazio di probabilità èuna terna (Ω, !, P) dove\n!Ωèun insieme qualunque (in genere pensato come l’insieme\ndeirisultati possibili di un esperimento casuale );!!èdetta σ-algebra , ovvero un insieme di insiemi (glieventi ) \nper iquali sipuòcalcolare una probabilit à;\n!P()èappunto una misura di probabilit àsuΩ(P:Ω → [0, 1]).\nPer la precisione , una σ-algebra èuna famiglia di insiemi taliche\n!∅∈!;!se A ∈!allora anche ilsuocomplementare Āèin!;\n!unioni numerabili di elementi di !appartengono ancora ad !.",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#4": "Spazio di Probabilità\nAd esempio : nell’esperimento “lancio di un dado”,\nΩ= {1, 2, 3, 4, 5, 6}, !èla σ-algebra generata dagli\neventi elementari di Ω, cioè di fatto, quelli per iquali è\npossibile calcolare una probabilit à.\nAd esempio E= “numero pari” = {2, 4, 6}, F= “numero\nmaggiore di 4” = {5, 6}. \nG = “ numero 7” appartiene a !?",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#5": "Esempio di Misura di Probabilità\nSe ildado non ètruccato , cioèglieventi elementari sono\nequiprobabili , allora\n\"#=#&'() *'+,-.+,/) '#\n#&'() 0,(()1)/) 2)Ω\ncioè, negli esempi precedenti\n\"#=#2,4,6\n#1,2,3,4,5,6=3\n6=1\n2\n\";=#5,6\n#1,2,3,4,5,6=2\n6=1\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#6": "Probabilità\nUna probabilità (grado di credenza) èuna misura su un insieme di \neventi che soddisfa tre assiomi (assiomi di Kolmogorov [1]):\n!La misura di ogni evento è compresa fra 0 e 1;\n!La misura dell’ intero insieme di eventi è 1;\n!La probabilità dell’ unione di eventi disgiunti (o mutuamente\nesclusivi )è pari alla somma delle probabilità dei singoli eventi .\nDato unospazio di probabilità (Ω, !, P), due eventi Ae Bsidicono\ndisgiunti quando la lorointersezione èvuota .\nDato unospazio di probabilità (Ω, !, P), due eventi Ae Bsidicono\nindipendenti se P(A∩B) = P(A) ⋅P(B). \n[1] S. Russell & P. Norvig, Artificial Intelligence: A Modern Approach (4 ed.) , Pearson, 2020.",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#7": "Probabilità\nUn modello probabilistico consiste in uno spazio di possibili esiti\n(cioè descrizioni complete di stati) mutuamente esclusivi insieme \nalla misura di probabilità associata ad ogni esito. \nProbabilità condizionata P(A/B) , dove Ae Bsono proposizioni (cioè \nenunciati che affermano che qualcosa è verificato): “la probabilità \ndi A, posto che tutto quello che sappiamo èB”.\nIn altritermini, la probabilità condizionata P(A/B) esprime una \n“correzione ” delle aspettative per A, dettata dall’osservazione di B.\nEsempio: P(carie/maldidenti)=0.8 indica che se un paziente ha il mal di \ndenti e non è disponibile nessun’altra informazione, la probabilità che \nabbia una carie sarà 0.8.\nN.B. La probabilità condizionata P(A/B) ha senso solo se Bha \nprobabilità non nulla di verificarsi .",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#8": "Approccio Bayesiano\n2prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneApproccio Bayesiano\nIlproblema èposto intermini probabilistici .Setutte ledistribuzioni\ningioco sono notel’approccio Bayesiano costituisce lamigliore\nregola diclassificazione possibile :soluzione OTTIMA !\nSia\n𝐕unospazio dipattern𝑑-dimensionali eW=𝑤1,𝑤2…𝑤𝑠\nuninsieme di𝑠classi disgiunte costituite daelementi di𝐕\nPer\nogni𝐱∈𝐕eperogni𝑤𝑖∈W,indichiamo con𝑝𝐱𝑤𝑖la\ndensità diprobabilità condizionale (ocondizionata) di𝐱data𝑤𝑖,\novvero ladensità diprobabilità che ilprossimo pattern sia𝐱\nsottol’ipotesi chelasuaclasse diappartenenza sia𝑤𝑖\nPer\nogni𝑤𝑖∈W,indichiamo con𝑃𝑤𝑖laprobabilità apriori di\n𝑤𝑖ovvero laprobabilità, indipendentemente dall’osservazione,\ncheilprossimo pattern daclassificare siadiclasse𝑤𝑖\nPer\n ogni𝐱∈𝐕indichiamo con𝑝𝐱ladensità diprobabilità\nassoluta di𝐱,ovvero ladensità diprobabilità cheilprossimo\npattern daclassificare sia𝐱\nPer\nogni𝑤𝑖∈Weperogni𝐱∈𝐕indichiamo con𝑃𝑤𝑖𝐱la\nprobabilità aposteriori di𝑤𝑖dato𝐱,ovvero laprobabilità che\navendo osservato ilpattern𝐱,laclasse diappartenenza sia𝑤𝑖.\nPerilteorema diBayes :\n𝑃𝑤𝑖𝐱=𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\n𝑝𝐱𝑝𝐱=෍\n𝑖=1𝑠\n𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖 dove ෍\n𝒊=𝟏𝒔\n𝑃𝑤𝑖=1",
    "data_test\\rootfolder\\università\\MachineLearning\\29-CB(1)-sbloccato.pdf#9": "Approccio Bayesiano\n2prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneApproccio Bayesiano\nIlproblema èposto intermini probabilistici .Setutte ledistribuzioni\ningioco sono notel’approccio Bayesiano costituisce lamigliore\nregola diclassificazione possibile :soluzione OTTIMA !\nSia\n𝐕unospazio dipattern𝑑-dimensionali eW=𝑤1,𝑤2…𝑤𝑠\nuninsieme di𝑠classi disgiunte costituite daelementi di𝐕\nPer\nogni𝐱∈𝐕eperogni𝑤𝑖∈W,indichiamo con𝑝𝐱𝑤𝑖la\ndensità diprobabilità condizionale (ocondizionata) di𝐱data𝑤𝑖,\novvero ladensità diprobabilità che ilprossimo pattern sia𝐱\nsottol’ipotesi chelasuaclasse diappartenenza sia𝑤𝑖\nPer\nogni𝑤𝑖∈W,indichiamo con𝑃𝑤𝑖laprobabilità apriori di\n𝑤𝑖ovvero laprobabilità, indipendentemente dall’osservazione,\ncheilprossimo pattern daclassificare siadiclasse𝑤𝑖\nPer\n ogni𝐱∈𝐕indichiamo con𝑝𝐱ladensità diprobabilità\nassoluta di𝐱,ovvero ladensità diprobabilità cheilprossimo\npattern daclassificare sia𝐱\nPer\nogni𝑤𝑖∈Weperogni𝐱∈𝐕indichiamo con𝑃𝑤𝑖𝐱la\nprobabilità aposteriori di𝑤𝑖dato𝐱,ovvero laprobabilità che\navendo osservato ilpattern𝐱,laclasse diappartenenza sia𝑤𝑖.\nPerilteorema diBayes :\n𝑃𝑤𝑖𝐱=𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\n𝑝𝐱𝑝𝐱=෍\n𝑖=1𝑠\n𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖 dove ෍\n𝒊=𝟏𝒔\n𝑃𝑤𝑖=1",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nIntroduzione alla  \nRegressione\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#1": "Sommario\nIntroduzione alla Regressione \nSimple Linear Regression \n•\n Fase di Training (minimizzazione della funzione di \ncosto) \nMultiple Regression \n•\n Fase di Training (minimizzazione della funzione di \ncosto)\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#10": "Il Processo di Training\nDati di \nTraining\nEstrazione \ndelle \nFeatures  \nModello \ndi ML\nComparazione\ntra valori \nosservati e \nprevisti ∀ iyi osservatoxi ŷi previsto\n 11xi\nFunzione  \ndi Costopesi ŵ 0 e ŵ 1  \ncalcolati(N esempi)\nAlgoritmo di \nApprendimento\nCalcolo vettore \ndei pesi ŵ",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#11": " 12Il Processo di Training\n•Dati di training : insieme di esempi ( xi, yi) relativi a casi conosciuti \n(i punti nel piano x-y), da utilizzare per calcolare la funzione di \ncosto RSS. \n•Estrazione di features : in questo caso tale funzione è inattiva, nel \nsenso che riproduce in uscita il suo ingresso xi. \n•Modello di ML : ipotesi f scelta, istanziata con i valori dei pesi più \nopportuni. \n•Comparazione tra dati osservati e dati previsti : per ogni esempio \nabbiamo il valore vero yi e il valore previsto ŷi, da utilizzare per il \ncalcolo della funzione RSS. \n•Algoritmo di Apprendimento : algoritmo che calcola i pesi che \nminimizzano la funzione di costo RSS, da utilizzare per deﬁnire il \nmodello di ML.",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#12": "Minimizzazione  della funzione RSS\nIn sintesi, il processo di apprendimento è formulato come una \nricerca di ottimizzazione (ricerca del minimo) nello \n spazio dei \npesi\n. \nA tal ﬁne possiamo calcolare e avvalerci del \n gradiente\n  della \n“misura d’errore” \n RSS\n deﬁnita in precedenza.  \nSi può dimostrare che la \n RSS\n è una funzione convessa.  \nRicordiamoci che, per funzioni convesse, quando il gradiente è \nuguale a zero si ha un minimo globale. \n \n13",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#13": "Minimo  di una funzione convessa\n \n14\nw0w1g\nŵ\nw\nŵ0ŵ1\ngradiente:ij\nrg(w)=@g(w)\n@w0i+@g(w)\n@w1j\n<latexit sha1_base64=\"UbdTBP63qiqYyxQKEMwdHSMgLt8=\">AAACkniclVFNT9tAEF27UGigEKC3XlaNkIBKkQ1IICQkKJceOIDUAFIcRePNJCys19buGIpW+1f6v3rgv9QOkfgIl77T03sz83Zn0kJJS1H0Nwg/zMx+nJv/1FhY/Ly03FxZvbB5aQR2RK5yc5WCRSU1dkiSwqvCIGSpwsv09qT2L+/QWJnrX/RQYC+DkZZDKYAqqd/8k2hIFSSEv8mN/EaS5mrg7v0mP+TJ0IBwSQGGJCg3XeP9s3vfd5H3nj+Z0jd4he//PSN+nnHjeaPfbEXtaAw+TeIJabEJzvrNx2SQizJDTUKBtd04Kqjn6gCh0DeS0mIB4hZG2K2ohgxtz4336Pl6aYFyXqDhUvGxiC87HGTWPmRpVZkBXdu3Xi2+53VLGu73nNRFSahFHURS4TjICiOrAyEfSINEUL8cudRcgAEiNJKDEJVYVher9xG//f00udhuxzvt7fPd1tGPyWbm2Vf2jW2wmO2xI/aTnbEOE8FMsBXsBLvhl/AgPA5PnkrDYNKzxl4hPP0HqF7LxA==</latexit>\n",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#14": "Gradiente della funzione RSS\nIl gradiente della funzione RSS: \n    \n   è deﬁnito come segue:\n \n15rRSS( w0,w1)=2\n4@RSS\n@w0\n@RSS\n@w13\n5RSS( w0,w1)=NX\ni=1[yi\u0000(w0+w1xi)]2",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#15": "Calcolo del Gradiente  \ndella funzione RSS\n \n16rRSS( w0,w1)=2\n4\u00002PN\ni=1[yi\u0000(w0+w1xi)]\n\u00002PN\ni=1[yi\u0000(w0+w1xi)]xi3\n5@RSS\n@w1=NX\ni=12[yi\u0000(w0+w1xi)]1·(\u0000xi)=\u00002NX\ni=1[yi\u0000(w0+w1xi)]xi@RSS\n@w0=NX\ni=12[yi\u0000(w0+w1xi)]1·(\u00001) =\u00002NX\ni=1[yi\u0000(w0+w1xi)]",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#16": "Algoritmi per adattare il modello \nUna volta calcolato il gradiente della funzione \n RSS\n, ci sono \ndue possibili approcci per minimizzare la funzione di \ncosto: \n“\nForma chiusa\n ”: Si uguaglia il gradiente a zero (ossia al vettore nullo) e si \nrisolvono le equazioni (non sempre è possibile o conveniente dal punto di \nvista computazionale) \nAlgoritmo di Discesa del Gradiente (\n Gradient Descent\n ) (richiede la \ndeﬁnizione del criterio di convergenza e dello “step size”)\n \n17",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#17": "Forma Chiusa (1/4)\nPoniamo il gradiente uguale al vettore nullo: \nossia:\n \n18\u00002NX\ni=1[yi\u0000(w0+w1xi)] = 0\n\u00002NX\ni=1[yi\u0000(w0+w1xi)]xi=0rRSS( w0,w1)=2\n4\u00002PN\ni=1[yi\u0000(w0+w1xi)]\n\u00002PN\ni=1[yi\u0000(w0+w1xi)]xi3\n5=0",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#18": "Forma Chiusa (2/4)\nDalla prima equazione otteniamo:\n \n19PN\ni=1yi\u0000ˆw0PN\ni=11\u0000ˆw1PN\ni=1xi=0\nˆw0=PN\ni=1yi\nN\u0000ˆw1PN\ni=1xi\nN\nda cui si ha:",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#19": "Forma Chiusa (3/4)\nDalla seconda equazione otteniamo: \nda cui si ha:\n \n20PN\ni=1xiyi\u0000ˆw0PN\ni=1xi\u0000ˆw1PN\ni=1x2\ni=0\nˆw1=PN\ni=1xiyi\u0000ˆw0PN\ni=1xiPN\ni=1x2\ni",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#2": "Introduzione alla Regressione\n \n3I modelli a regressione vengono utilizzati per prevedere \nvariabili target su scala continua , il che li rende \ninteressanti per risolvere molte questioni in ambito \nscientiﬁco e anche industriale, come ad esempio:\n• trovare relazioni fra variabili \n• valutare tendenze \n• effettuare previsioni ( e.g., vendite di una azienda nei prossimi mesi )",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#20": "Forma Chiusa (4/4)\ne con facili passaggi otteniamo: \nche, insieme a: \nvista in precedenza, ci consente di calcolare i valori dei due \npesi che minimizzano la funzione RSS.\n \n21ˆw1=PN\ni=1xiyi\u0000PN\ni=1xiPN\ni=1yi\nNPN\ni=1x2\ni\u0000(PN\ni=1xi)2\nN\nˆw0=PN\ni=1yi\nN\u0000ˆw1PN\ni=1xi\nN",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#21": "Gradient Descent (1/3)\nCome sappiamo, con questo approccio dobbiamo \naggiornare i pesi in modo tale da spostarci nella direzione \nopposta al gradiente:\n \n22w(t+1) w(t)\u0000↵·rRSS(w(t))\nw=w0\nw1\u0000\ndove:\nossia:\nw(t+1)\n0 w(t)\n0\u0000↵·@RSS(w(t))\n@w0\nw(t+1)\n1 w(t)\n1\u0000↵·@RSS(w(t))\n@w1",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#22": "Gradient Descent (2/3)\nRivediamo l’espressione del gradiente di RSS: \nL’aggiornamento dei due pesi può dunque essere effettuato \ncome segue, scegliendo un opportuno \n step size\n :\n \n23rRSS( w0,w1)=2\n4\u00002PN\ni=1[yi\u0000(w0+w1xi)]\n\u00002PN\ni=1[yi\u0000(w0+w1xi)]xi3\n5=2\n4\u00002PN\ni=1[yi\u0000ˆyi(w0,w1)]\n\u00002PN\ni=1[yi\u0000ˆyi(w0,w1)]xi3\n5\nw(t+1)\n0 w(t)\n0+2↵·NX\ni=1[yi\u0000ˆyi(w(t))]\nw(t+1)\n1 w(t)\n1+2↵·NX\ni=1[yi\u0000ˆyi(w(t))]xi",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#23": "Gradient Descent (3/3)\nDobbiamo inﬁne scegliere un \n criterio di convergenza\n . \nCome già detto, per funzioni convesse si ha un minimo \nglobale quando il gradiente è uguale a zero. \nIn pratica, possiamo terminare l’elaborazione quando:\n \n24krRSS(w(t))k2✏",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#24": "Algoritmo di Gradient Descent \n \n25w(1)= 0 (oppure lo inizializziamo in modo casuale)\nt=1\nwhilekrRSS( w(t))k2>✏\nw(t+1)\n0 w(t)\n0+2↵·NX\ni=1[yi\u0000ˆyi(w(t))]\nw(t+1)\n1 w(t)\n1+2↵·NX\ni=1[yi\u0000ˆyi(w(t))]xi\nt t+1",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#25": "Multiple Regression \n[caso di Linear Regression con Multiple Features]\nFino ad ora abbiamo ipotizzato, per la funzione \n f(\nx\n)\n, un andamento \nlineare per il nostro caso di studio relativo ai prezzi degli appartamenti. \nTuttavia l’esperienza comune ci induce a pensare che la relazione tra \nle due variabili (area e prezzo di un appartamento) non sia proprio \nlineare. In genere, all’aumentare della metratura il prezzo aumenta ma \nnon in modo esattamente proporzionale. Potremmo ipotizzare ad \nesempio una funzione quadratica o addirittura polinomiale di grado p: \n \n26f(x)=w0+w1x+w2x2\nf(x)=w0+w1x+w2x2+···+wpxpy\nAreax\ny\nAreax\n",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#26": "Multiple Regression \n[caso di Linear Regression con Multiple Features]\nIn quest’ultimo caso avremmo una \n Polinomial Regression\n , \nil cui modello è il seguente: \n \n27yi=w0+w1xi+w2x2\ni+···+wpxp\ni+✏i\nIn genere, le potenze della x sono trattate come differenti \nfeatures\n : \nfeature 1 = 1\nfeature 2 = x\nfeature 3 = x2\n······ ···\nfeature p+1 = xp",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#27": "Multiple Regression \n[caso di Linear Regression con Multiple Features]\nIl caso generale, con un solo input x\n i\n, è il seguente: \n \n28yi=w0\u00000(xi)+w1\u00001(xi)+ ···+wD\u0000D(xi)+✏i=\n=DX\nj=0wj\u0000j(xi)+✏i\ndove le features che compaiono possono assumere forme \ndiverse (non necessariamente solo potenze della x). ",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#28": "Multiple Regression \n[caso di Linear Regression con Multiple Features]\nInoltre, è importante considerare anche il caso in cui ci \nsiano più input. \nPer l’esempio degli appartamenti potremmo voler \nconsiderare non solo l’area ma anche altre caratteristiche \n(#bagni, #camere da letto, anno di costruzione, ecc.). \nIn tal caso avremmo in input un vettore \n x\ni\n per ogni \nesempio noto, le cui componenti sono appunto l’area, il \n#bagni, ecc. \n    \n \n29",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#29": "Multiple Regression \n[caso di Linear Regression con Multiple Features]\nIl caso generale, che ha in input un vettore \n x\ni\n, è pertanto il \nseguente: \n \n30\ndove le features che compaiono, ciascuna delle quali è \nfunzione del vettore \n x\ni\n, possono assumere forme diverse. yi=w0\u00000(xi)+w1\u00001(xi)+ ···+wD\u0000D(xi)+✏i=\n=DX\nj=0wj\u0000j(xi)+✏i",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#3": "Modello a \nRegressione Lineare Semplice\n \n4L’obiettivo di un modello a Regressione Lineare \nSemplice ( univariata ) consiste nell’individuare le \nrelazioni esistenti tra un’unica caratteristica (la variabile \ndescrittiva x) e una risposta continua (variabile target y).",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#30": " \n31Anche in questo caso possiamo utilizzare, come funzione di \ncosto da minimizzare, la RSS deﬁnita come segue, a partire \nda N osservazioni disponibili:\nIl problema di addestrare il nostro modello è dunque quello \ndi trovare i valori dei pesi ŵ0 ,ŵ1 ,…, ŵD che minimizzano la \nfunzione RSS (convessa anche in questo caso).\nMultiple Regression \n[caso di Linear Regression con Multiple Features]\nRSS(w)=NX\ni=1(yi\u0000ˆyi)2=NX\ni=1[yi\u0000(w0\u00000(xi)+ ···+wD\u0000D(xi))]2",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#31": "Il Processo di Training \n[caso di Linear Regression con Multiple Features]\nDati di \nTraining\nEstrazione \ndelle \nFeatures  \nModello \ndi ML\nComparazione \ntra valori \nosservati e \nprevisti ∀ iyi osservato(xi) ŷi previsto\n 32xi\nFunzione  \ndi Costovettore di pesi \n ŵ calcolatoɸ\n(N esempi)\nAlgoritmo di \nApprendimento\nCalcolo vettore \ndei pesi ŵ",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#32": "Regression Model \n in notazione matriciale \n[caso di Linear Regression con Multiple Features]\nIn molti casi può essere conveniente usare una \nnotazione matriciale. \nL’espressione: \n \n33\nrelativa all’i-esimo valore per y, può essere scritta \ncome segue: yi=DX\nj=0wj\u0000j(xi)+✏i",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#33": "Regression Model \n in notazione matriciale \n[caso di Linear Regression con Multiple Features]\n \n34\noppure: yi=[w0w1···wD]·2\n664\u00000(xi)\n\u00001(xi)\n···\n\u0000D(xi)3\n775+✏i\nyi=[\u00000(xi)\u00001(xi)···\u0000D(xi)]·2\n664w0\nw1\n···\nwD3\n775+✏i",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#34": "Regression Model \n in notazione matriciale \n[caso di Linear Regression con Multiple Features]\nIn sintesi: \n \n35yi=DX\nj=0wj\u0000j(xi)+✏i=wT·\u0000(xi)+✏i=\u0000T(xi)·w+✏i\nw=2\n664w0\nw1\n···\nwD3\n775\u0000(xi)=2\n664\u00000(xi)\n\u00001(xi)\n···\n\u0000D(xi)3\n775\ndove: \nxi=2\n664xi,1\nxi,2\n···\nxi,d3\n775",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#35": "Regression Model \n in notazione matriciale \n[caso di Linear Regression con Multiple Features]\nPossiamo inﬁne rappresentare tutte le osservazioni y in \nmodo compatto come segue: \n \n36\n    ossia: \ny=\u0000 ·w+✏2\n664y1\ny2\n···\nyN3\n775=2\n664\u00000(x1)\u00001(x1)... \u0000D(x1)\n\u00000(x2)\u00001(x2)... \u0000D(x2)\n... ... ... ...\n\u00000(xN)\u00001(xN)... \u0000D(xN)3\n775·2\n664w0\nw1\n···\nwD3\n775+2\n664✏1\n✏2\n···\n✏N3\n775",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#36": "Regression Model \n in notazione matriciale \n[caso di Linear Regression con Multiple Features]\ndove: \n    \n \n37✏=2\n664✏1\n✏2\n···\n✏N3\n775 y=2\n664y1\ny2\n···\nyN3\n775\n\u0000=2\n664\u00000(x1)\u00001(x1) ... \u0000D(x1)\n\u00000(x2)\u00001(x2) ... \u0000D(x2)\n... ... ... ...\n\u00000(xN)\u00001(xN) ... \u0000D(xN)3\n775",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#37": "Regression Model \n in notazione matriciale \n[caso di Linear Regression con Multiple Features]\nCalcoliamo ora la funzione RSS: \n \n38RSS(w)=NX\ni=1(yi\u0000ˆyi)2=NX\ni=1✏2\ni=✏T·✏\nche possiamo scrivere anche così: RSS(w)=NX\ni=1(yi\u0000ˆyi)2=NX\ni=1[yi\u0000(\u00000(xi)w0+...+\u0000D(xi)wD)]2=NX\ni=1[yi\u0000\u0000T(xi)·w]2",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#38": "Regression Model \n in notazione matriciale \n[caso di Linear Regression con Multiple Features]\nDa una precedente espressione per \n y\n ricaviamo il vettore \n ε\n: \n \n39✏=y\u0000\u0000w y=\u0000w+✏)\nLa funzione RSS assume pertanto la seguente forma in notazione \nmatriciale: \nRSS(w)=(y\u0000\u0000w)T(y\u0000\u0000w)",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#39": "Gradiente della funzione RSS \n[caso di Linear Regression con Multiple Features]\nCalcoliamo ora il gradiente della funzione RSS, partendo dalla \nprecedente espressione matriciale. \nApplicando una nota regola di calcolo differenziale matriciale \nsi ottiene: \n \n40rRSS(w)=r[(y\u0000\u0000w)T(y\u0000\u0000w)] =\u00002\u0000T(y\u0000\u0000w)",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#4": "Esempio \n \n5A titolo di esempio possiamo considerare il caso della \nprevisione del prezzo di un appartamento (variabile target y) \ndata la sua metratura (variabile descrittiva x).\nTipicamente, in casi come questo abbiamo a disposizione un \ncerto numero di esempi (osservazioni), costituiti da \nappartamenti già venduti per ciascuno dei quali abbiamo a \ndisposizione l’area in mq o in sq.ft. ( x) e il prezzo pagato per \nl’acquisto ( y).\nCiascuna delle suddette osservazioni può essere rappresentata \nda un punto in un piano cartesiano x-y, come illustrato nella \nﬁgura che segue.",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#40": "Algoritmi per adattare il modello \n[caso di Linear Regression con Multiple Features]\nAnche in questo caso, una volta calcolato il gradiente della \nfunzione \n RSS\n, ci sono due possibili approcci per \nminimizzare la funzione di costo: \n“Forma chiusa”: Si uguaglia il gradiente a zero e si risolvono le equazioni \n(non sempre è possibile o conveniente dal punto di vista computazionale) \nAlgoritmo di Discesa del Gradiente (\n Gradient Descent\n ) (richiede la \ndeﬁnizione del criterio di convergenza e dello “step size”)\n \n41",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#41": "Forma Chiusa \n[caso di Linear Regression con Multiple Features]\nPoniamo il gradiente uguale al vettore nullo: \n \n42ˆw=(\u0000T\u0000)\u00001\u0000Ty\nda cui si ha: \u00002\u0000Ty+2\u0000T\u0000ˆw=0\n\u0000T\u0000ˆw=\u0000Ty\n(\u0000T\u0000)\u00001(\u0000T\u0000)ˆw=(\u0000T\u0000)\u00001\u0000Ty\nIˆ w =(\u0000T\u0000)\u00001\u0000TyrRSS(w)=\u00002\u0000T(y\u0000\u0000w)=0",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#42": "Gradient Descent (1/4) \n[caso di Linear Regression con Multiple Features]\nDobbiamo aggiornare il vettore dei pesi in modo tale da \nspostarci nella direzione opposta al gradiente:\n \n43w(t+1) w(t)\u0000↵·rRSS(w(t))\ndove:\nrRSS(w(t))=2\n66664@RSS\n@w0\n@RSS\n@w1\n···\n@RSS\n@wD3\n77775w(t)=2\n6664w(t)\n0\nw(t)\n1\n···\nw(t)\nD3\n7775",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#43": "Gradient Descent (2/4) \n[caso di Linear Regression con Multiple Features]\nI singoli pesi devono dunque essere aggiornati come segue:\n \n44w(t+1)\n0 w(t)\n0\u0000↵·@RSS(w(t))\n@w0\nw(t+1)\n1 w(t)\n1\u0000↵·@RSS(w(t))\n@w1\n······ ·····················\nw(t+1)\nj w(t)\nj\u0000↵·@RSS(w(t))\n@wj\n······ ·····················\nw(t+1)\nD w(t)\nD\u0000↵·@RSS(w(t))\n@wD",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#44": "Gradient Descent (3/4) \n[caso di Linear Regression con Multiple Features]\nPer comprendere gli aggiornamenti da fare per i singoli pesi, \ncalcoliamo la derivata parziale di RSS, espressa in questa \nforma:\n \n45\nrispetto al generico peso j-esimo:\n@RSS(w(t))\n@wj=NX\ni=12[yi\u0000ˆyi(w(t))]·[\u0000@ˆyi(w(t))\n@wj]=\n=2NX\ni=1[yi\u0000ˆyi(w(t))]·[\u0000\u0000j(xi)] =\u00002NX\ni=1\u0000j(xi)[yi\u0000ˆyi(w(t))]RSS(w(t))=NX\ni=1[yi\u0000ˆyi(w(t))]2=NX\ni=1{yi\u0000[\u00000(xi)w(t)\n0+···+\u0000j(xi)w(t)\nj+···+\u0000D(xi)w(t)\nD]}2",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#45": "Gradient Descent (4/4) \n[caso di Linear Regression con Multiple Features]\nAnche in questo caso dobbiamo inﬁne scegliere un \n criterio \ndi convergenza\n . \nSappiamo che per funzioni convesse si ha un minimo \nglobale quando il gradiente è uguale a zero. \nIn pratica, possiamo terminare l’elaborazione quando:\n \n46krRSS(w(t))k2✏",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#46": "Algoritmo di Gradient Descent \n[caso di Linear Regression con Multiple Features]\n \n47w(1)= 0 (oppure lo inizializziamo in modo casuale)\nt=1\nwhilekrRSS( w(t))k2>✏\nfor j=0,1,. . . ,D\nderivata parziale[ j]=\u00002NX\ni=1\u0000j(xi)[yi\u0000ˆyi(w(t))]\nw(t+1)\nj w(t)\nj\u0000↵⇤derivata parziale[ j]\nt t+1",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#47": "Riferimenti\n \n48\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , 3a edizione, \nApogeo, 2015. \nMachine Learning: Regression\n , University of Washington - Coursera, 2015. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. ",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#5": "Esempio\n \n6Il problema da risolvere è il seguente: scegliere lo spazio delle \nipotesi  H (e.g., insieme di polinomi di grado massimo k) e la \nfunzione f(x) (ipotesi) che approssima meglio le osservazioni \ndisponibili di una funzione sconosciuta, da utilizzare per \nprevedere i prezzi di altri appartamenti (diversi dagli esempi).\ny\nArea xy\nArea x\ny\nArea x\n",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#6": "Apprendimento induttivo \n(Inductive Learning method)\nLa difﬁcoltà che si incontra in tale attività è dovuta al \nfatto che non è facile stabilire se una particolare f sia una \nbuona approssimazione della funzione sconosciuta. \nUna buona ipotesi si potrà generalizzare  bene, ossia \npotrà predire correttamente esempi che non ha ancora \nincontrato.Il problema dell’induzione\n 7",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#7": "Simple Linear Regression Model\n \n8In ﬁgura è rappresentato un modello lineare per f(x), dove il \npeso wo rappresenta l’intercetta e il peso w1 rappresenta la \npendenza della retta. Si noti l’offset verticale che costituisce \nl’errore che in genere esiste tra la previsione e il valore effettivo. \nAbbiamo dunque, per il valore vero e quello previsto per un \ncerto valore dell’ascissa:\nyi=w0+w1xi+✏i\nˆyi=f(xi)=w0+w1xiy\nArea x\nPrezzo",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#8": "Simple Linear Regression Model\n \n9Supponiamo di scegliere il modello lineare. Una volta \ndeﬁnito tale modello, ossia la forma della funzione f(x), \noccorre determinare i due pesi incogniti, ossia l’intercetta e la \npendenza, che deﬁniscano la f(x) “migliore” secondo un certo \ncriterio.\nUn criterio possibile è quello di minimizzare gli errori che si \nhanno sulle osservazioni. ",
    "data_test\\rootfolder\\università\\MachineLearning\\3-Regression-Introduzione-sbloccato.pdf#9": "Simple Linear Regression Model\n \n10Una delle funzioni utilizzate a tal ﬁne, che deve essere per \nl’appunto minimizzata, è la Residual Sum of Squares (RSS) , \ndeﬁnita come segue, a partire da N osservazioni disponibili:\nRSS( w0,w1)=NX\ni=1(yi\u0000ˆyi)2=NX\ni=1[yi\u0000(w0+w1xi)]2\nIl problema di addestrare il nostro modello è dunque quello \ndi trovare i valori dei due pesi ŵ0 e ŵ1 che minimizzano la \nfunzione RSS.",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#0": "Distribuzione Normale Multivariata (Multinormale)\n9prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDistribuzione Normale Multivariata \n(Multinormale ) \nNotazione\n :perevitare confusione utilizziamo apedicel’indice del\npattern e(ove necessario) adapice lacomponente (scalare) :\n•𝐱𝑖pattern i-esimo (vettore)\n•𝑥𝑖𝑗componente j-esima delpattern i-esimo (scalare)\nLa\ndensità diprobabilità nella distribuzione multinormale (𝑑>1):\n𝑝𝐱=1\n2𝜋𝑑/2Σ1/2𝑒−1\n2𝐱−𝛍𝑡Σ−1𝐱−𝛍\ndove𝛍=𝜇1,𝜇2…𝜇𝑑èilvettore medio èΣ=𝜎𝑖𝑗lamatrice di\ncovarianza (𝑑×𝑑).\nSi\nassume che ivettori siano ditipo «colonna» .L’apice𝑡\n(trasposto) litrasforma inrighe .\n|6|e6-1sono rispettivamente ildeterminante el’inversa di6.\nLa\nmatrice dicovarianza èsempre simmetrica edefinita\npositiva, pertanto ammette inversa .Essendo simmetrica il\nnumero diparametri cheladefinisce è𝑑∙𝑑+1/2\nGli\nelementi diagonali 𝜎𝑖𝑖sono levarianze deirispettivi 𝑥𝑖\n(ovvero 𝜎𝑖2);glielementi non diagonali 𝜎𝑖𝑗sono le\ncovarianze tra𝑥𝑖e𝑥𝑗:\n•se𝑥𝑖e𝑥𝑗sono statisticamente indipendenti 𝜎𝑖𝑗=0\n•se𝑥𝑖e𝑥𝑗sono correlati positivamente 𝜎𝑖𝑗>0\n•se𝑥𝑖e𝑥𝑗sono correlati negativamente 𝜎𝑖𝑗<0",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#1": "Richiami\n!La Matrice di Covarianza si indica di solito con Σed è una generalizzazione del \nconcetto di varianza al caso di dimensione maggiore di uno\n!E’ una matrice che rappresenta la variazione di ogni variabile rispetto alle altre \n(inclusa se stessa)\n!E’ sempre simmetrica e definita positiva (i.e., ha tutti gli autovalori strettamente \npositivi) ---> ammette sempre Matrice Inversa\n!La Matrice Simmetrica è una matrice quadrata che ha la proprietà di essere la \ntrasposta (vedi sotto) di se stessa \n!La Matrice Inversa di una matrice A è pari alla sua Matrice Aggiunta (i.e., Matrice \nTrasposta Coniugata) diviso il det(A)\n!La Matrice Trasposta di una matrice è la matrice ottenuta scambiando le righe con \nle colonne\n!La Matrice Trasposta Coniugata di una matrice a valori complessi è la matrice \nottenuta effettuando la trasposta e scambiando ogni valore con il suo complesso \nconiugato",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#10": "Esempio Stima di µes(d=2)\n13prof. Davide Maltoni –Università di Bologna\nML\nClassificazione…prosegue\n\u000b\f\u000b\f ¦\n \u0010\u0010  \n»»»»»\n¼º\n«««««\n¬ª\n \nn kj j\nki i\nkij\ndd dd\nx xn ...1\n122 211 12 11\n1       ,  \n... ...... ... ... ...... ......\nP P V\nV VVVV VV\nΣ\n»¼º\n«¬ª »\n¼º\n«\n¬ª 456.1732.2532.25 44.66\n22 2112 11\nVVVVΣ\n\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f44.6659.823 9.81 9.813 9.85.4 9.832 2 2 2 2\n21 11 \u0010\u000e\u0010\u000e\u0010\u000e\u0010\u000e\u0010  VV\n\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f32.25\n52.98.159.8232.949.812.92.79.8132.9129.85.42.979.8321 12 \u0010\u0010\u000e\u0010\u0010\u000e\u0010\u0010\u000e\u0010\u0010\u000e\u0010\u0010  VV\n\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f456.17\n52.98.15 2.94 2.92.7 2.912 2.972 2 2 2 2\n22 22 \u0010\u000e\u0010\u000e\u0010\u000e\u0010\u000e\u0010  VV\n»¼º\n«¬ª\n\u0010\u0010 \u0010\n1281.0 0488.00488.0 0337.01Σ\u000b \f\u000b \f 674.518 32.2532.25 456.1744.66  \u0010 Σo,innotazione vettoriale :\n𝚺=1\n𝑛෍\n𝑖=1…𝑛𝐱𝑖−𝛍𝐱𝑖−𝛍𝑡calcolata come somma dimatrici,\nciascuna ottenuta come vettore\ncolonna pervettore riga.",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#11": "Esempio Stima di µes(d=2)\n13prof. Davide Maltoni –Università di Bologna\nML\nClassificazione…prosegue\n\u000b\f\u000b\f ¦\n \u0010\u0010  \n»»»»»\n¼º\n«««««\n¬ª\n \nn kj j\nki i\nkij\ndd dd\nx xn ...1\n122 211 12 11\n1       ,  \n... ...... ... ... ...... ......\nP P V\nV VVVV VV\nΣ\n»¼º\n«¬ª »\n¼º\n«\n¬ª 456.1732.2532.25 44.66\n22 2112 11\nVVVVΣ\n\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f44.6659.823 9.81 9.813 9.85.4 9.832 2 2 2 2\n21 11 \u0010\u000e\u0010\u000e\u0010\u000e\u0010\u000e\u0010  VV\n\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f32.25\n52.98.159.8232.949.812.92.79.8132.9129.85.42.979.8321 12 \u0010\u0010\u000e\u0010\u0010\u000e\u0010\u0010\u000e\u0010\u0010\u000e\u0010\u0010  VV\n\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f\u000b\f456.17\n52.98.15 2.94 2.92.7 2.912 2.972 2 2 2 2\n22 22 \u0010\u000e\u0010\u000e\u0010\u000e\u0010\u000e\u0010  VV\n»¼º\n«¬ª\n\u0010\u0010 \u0010\n1281.0 0488.00488.0 0337.01Σ\u000b \f\u000b \f 674.518 32.2532.25 456.1744.66  \u0010 Σo,innotazione vettoriale :\n𝚺=1\n𝑛෍\n𝑖=1…𝑛𝐱𝑖−𝛍𝐱𝑖−𝛍𝑡calcolata come somma dimatrici,\nciascuna ottenuta come vettore\ncolonna pervettore riga.",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#12": "Esempio Stima di µes(d=2)\n14prof. Davide Maltoni –Università di Bologna\nML\nClassificazionein forma grafica\nvista \ndall’alto\nvista \nlaterale",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#13": "Classiﬁcatore di Bayes con Distribuzioni Multinormali\n15prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneClassificatore di Bayes con \ndistribuzioni Multinormali\nNell’esempio\n sono visualizzate ledensità condizionali di2classi\ndipattern (distribuiti condistribuzione normale 2-dimensionale)\ncorrette sulla base delle rispettive probabilità apriori .\nLa\nclassificazione èeseguita utilizzando laregola Bayesiana .Lo\nspazio èsuddiviso inregioni nonconnesse .Nelcaso specifico\n2ècostituita daduecomponenti disgiunte .\nUn\ndecision boundary odecision surface (superficie decisionale)\nèunazona diconfine traregioni cheilclassificatore associa a\nclassi diverse .Sulboundary laclassificazione èambigua .\nLe\nsuperfici decisionali possono assumere forme diverse .Nel\ncaso specifico sitratta didueiperboli .Ingenerale :\nSe\nle2matrici dicovarianza sono uguali traloro:lasuperficie\ndecisionale èuniper-piano .\nSe\nle2matrici dicovarianza sono arbitrarie :lasuperficie\ndecisionale èuniper-quadratica .\n",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#14": "15prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneClassificatore di Bayes con \ndistribuzioni Multinormali\nNell’esempio\n sono visualizzate ledensità condizionali di2classi\ndipattern (distribuiti condistribuzione normale 2-dimensionale)\ncorrette sulla base delle rispettive probabilità apriori .\nLa\nclassificazione èeseguita utilizzando laregola Bayesiana .Lo\nspazio èsuddiviso inregioni nonconnesse .Nelcaso specifico\n2ècostituita daduecomponenti disgiunte .\nUn\ndecision boundary odecision surface (superficie decisionale)\nèunazona diconfine traregioni cheilclassificatore associa a\nclassi diverse .Sulboundary laclassificazione èambigua .\nLe\nsuperfici decisionali possono assumere forme diverse .Nel\ncaso specifico sitratta didueiperboli .Ingenerale :\nSe\nle2matrici dicovarianza sono uguali traloro:lasuperficie\ndecisionale èuniper-piano .\nSe\nle2matrici dicovarianza sono arbitrarie :lasuperficie\ndecisionale èuniper-quadratica .\nClassiﬁcatore di Bayes con Distribuzioni Multinormali",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#15": "Altri Esempi di Superfici Decisionali\n16prof. Davide Maltoni –Università di Bologna\nML\nClassificazione…altri esempi di superfici decisionali\nStessa \nmatrice\ndi \ncovarianza:\niper-piani\nDifferenti \nmatrici\ndi covarianza:\niper-\nquadraticheStessa Matrice di Covarianza: Iper-piani\nIper-piano: sottospazio di dimensione inferiore di uno rispetto allo spazio in cui è \ncontenuto",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#16": "Altri Esempi di Superﬁci Decisionali\n16prof. Davide Maltoni –Università di Bologna\nML\nClassificazione…altri esempi di superfici decisionali\nStessa \nmatrice\ndi \ncovarianza:\niper-piani\nDifferenti \nmatrici\ndi covarianza:\niper-\nquadratiche\nDifferenti Matrici di Covarianza: Iper-quadratiche\nIper-quadratica: (iper -)superficie di uno spazio d -dimensionale sui complessi o sui \nreali rappresentata da un'equazione polinomiale del secondo ordine nelle variabili \nspaziali (coordinate)",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#17": "Esempio con Bayes Parametrico (Multinormali)\n17prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes parametrico ( multinormali )\n>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º\n«¬ª ¦9.343.233.232.35\n1 »¼º\n«¬ª ¦0.139.89.81.10\n2\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n11\n1 1 2/1\n12/121exp\nπ21| μxμx xt\ndw p\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n21\n2 2 2/1\n22/221exp\nπ21| μxμx xt\ndw p\nx\nPesoAltezza\n\u000b\f1|w px\n \u000b\f2|w pxStima dei parametri dal training set:\n17prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes parametrico ( multinormali )\n>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º\n«¬ª ¦9.343.233.232.35\n1 »¼º\n«¬ª ¦0.139.89.81.10\n2\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n11\n1 1 2/1\n12/121exp\nπ21| μxμx xt\ndw p\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n21\n2 2 2/1\n22/221exp\nπ21| μxμx xt\ndw p\nx\nPesoAltezza\n\u000b\f1|w px\n \u000b\f2|w pxStima dei parametri dal training set:\nObiettivo: stimare la classe di appartenenza del pattern x (57,168)",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#18": "17prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes parametrico ( multinormali )\n>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º\n«¬ª ¦9.343.233.232.35\n1 »¼º\n«¬ª ¦0.139.89.81.10\n2\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n11\n1 1 2/1\n12/121exp\nπ21| μxμx xt\ndw p\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n21\n2 2 2/1\n22/221exp\nπ21| μxμx xt\ndw p\nx\nPesoAltezza\n\u000b\f1|w px\n \u000b\f2|w pxStima dei parametri dal training set:Esempio con Bayes Parametrico (Multinormali)\n17prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes parametrico ( multinormali )\n>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º\n«¬ª ¦9.343.233.232.35\n1 »¼º\n«¬ª ¦0.139.89.81.10\n2\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n11\n1 1 2/1\n12/121exp\nπ21| μxμx xt\ndw p\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n21\n2 2 2/1\n22/221exp\nπ21| μxμx xt\ndw p\nx\nPesoAltezza\n\u000b\f1|w px\n \u000b\f2|w pxStima dei parametri dal training set:\n17prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes parametrico ( multinormali )\n>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º\n«¬ª ¦9.343.233.232.35\n1 »¼º\n«¬ª ¦0.139.89.81.10\n2\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n11\n1 1 2/1\n12/121exp\nπ21| μxμx xt\ndw p\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n21\n2 2 2/1\n22/221exp\nπ21| μxμx xt\ndw p\nx\nPesoAltezza\n\u000b\f1|w px\n \u000b\f2|w pxStima dei parametri dal training set:",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#19": "18prof. Davide Maltoni –Università di Bologna\nML\nClassificazione…continua\nSupponendo di non avere altre informazioni, si possono stimare le \nprobabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18\n\u000b\f\n\u000b\f\u000b\f\u000b\f0.003321exp\nπ21|11\n1 1 2/1\n12/ 1  »¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010μxμx xt\ndwp\n\u000b\f\n\u000b\f\u000b\f\u000b\f 0045.021exp\nπ21|21\n2 2 2/1\n22/2  »¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010μxμx xt\ndw p\nPesoAltezza\n>@T168 ,57 x\n\u000b\f\u000b\f\u000b\f 0040.0 w w|is\n1ii   ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f36.0w w||w1 1\n1 # xxxpP pP\n\u000b\f\u000b\f\u000b\f\n\u000b\f64.0w w||w2 2\n2 # xxxpP pPEsempio con Bayes Parametrico (Multinormali)\n17prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes parametrico ( multinormali )\n>@T9.170,4.631 μ >@T3.162,5.512 μ »¼º\n«¬ª ¦9.343.233.232.35\n1 »¼º\n«¬ª ¦0.139.89.81.10\n2\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n11\n1 1 2/1\n12/121exp\nπ21| μxμx xt\ndw p\n\u000b\f\n\u000b\f\u000b\f\u000b\f»¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010\n21\n2 2 2/1\n22/221exp\nπ21| μxμx xt\ndw p\nx\nPesoAltezza\n\u000b\f1|w px\n \u000b\f2|w pxStima dei parametri dal training set:",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#2": "Richiami\n!Premessa :lanozione diautovalore siriferisce alle sole matrici\nquadrate ,ossia alle matrici aventi lostesso numero dirighe edi\ncolonne .\n!Chiarito ciò,siaAuna matrice quadrata diordine nacoefficienti in\nuncampo !(dove !potrebbe essere ilcampo ℝdeinumeri reali oil\ncampo ℂdeinumeri complessi ).\n!Sidice cheloscalare λ0∈!èunautovalore della matrice quadrata\nAseesiste unvettore colonna non nullo v∈!ntale che\nAv=λ0v\n!Ilvettore vèdetto autovettore relativo all’autovalore λ0",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#20": "18prof. Davide Maltoni –Università di Bologna\nML\nClassificazione…continua\nSupponendo di non avere altre informazioni, si possono stimare le \nprobabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18\n\u000b\f\n\u000b\f\u000b\f\u000b\f0.003321exp\nπ21|11\n1 1 2/1\n12/ 1  »¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010μxμx xt\ndwp\n\u000b\f\n\u000b\f\u000b\f\u000b\f 0045.021exp\nπ21|21\n2 2 2/1\n22/2  »¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010μxμx xt\ndw p\nPesoAltezza\n>@T168 ,57 x\n\u000b\f\u000b\f\u000b\f 0040.0 w w|is\n1ii   ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f36.0w w||w1 1\n1 # xxxpP pP\n\u000b\f\u000b\f\u000b\f\n\u000b\f64.0w w||w2 2\n2 # xxxpP pPEsempio con Bayes Parametrico (Multinormali)",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#21": "Bayes e Conﬁdenza di Classiﬁcazione\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\nIn figura un \nesempio con\ns=5 classi",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#22": "Bayes e Confidenza di Classificazione\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\n",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#23": "Bayes Parametrico In Pratica\n20prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes parametrico in pratica\nMolto\n spesso sifanno ipotesi azzardate sulla normalità delle\ndensità diprobabilità delle classi delproblema senza aver\nsperimentalmente eseguito nessuna verifica ;ciòporta ad\nottenere cattivi risultati diclassificazione .\nPertanto, dato unproblema con𝑠classi edato untraining set\n(significativo), deve essere innanzitutto valutata larispondenza\nalla“normalità” delle𝑠distribuzioni ;questo puòessere fatto:\nin\nmodo formale (es:teststatistico diMalkovich -Afifi [1]\nbasatosull’indice diKolmogorov -Smirnov )\nin\nmodo empirico ,visualizzando invarimodi lenuvole dei\ndati (esistono deitool giàpredisposti perquesto tipo di\nanalisi finoa3D)ogliistogrammi sulle diverse componenti\neconfrontandoli conlecurve teoriche .\nUna\n volta provata una (seppur vaga) normalità delle\ndistribuzioni, sistimano apartire daidati, vettore medioPe\nmatrice dicovarianza 6(maximum likelihood ).\nPer\n quanto riguarda leprobabilità apriori queste possono\nessere estratte dalle percentuale dicampioni cheneltraining\nsetappartengono allediverse classi, oincaso diassenza di\ninformazioni possono essere poste tutte uguali traloro.\nOgni\n nuovo pattern daclassificare ,èassegnato auna delle\npossibili classi inaccordo conlaregola diBayes nella quale\nmedia ecovarianza sono oranote.\n[1] K. Fukunaga , Statistical Pattern Recognition , Academic Press, 1990.\n20prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes parametrico in pratica\nMolto\n spesso sifanno ipotesi azzardate sulla normalità delle\ndensità diprobabilità delle classi delproblema senza aver\nsperimentalmente eseguito nessuna verifica ;ciòporta ad\nottenere cattivi risultati diclassificazione .\nPertanto, dato unproblema con𝑠classi edato untraining set\n(significativo), deve essere innanzitutto valutata larispondenza\nalla“normalità” delle𝑠distribuzioni ;questo puòessere fatto:\nin\nmodo formale (es:teststatistico diMalkovich -Afifi [1]\nbasatosull’indice diKolmogorov -Smirnov )\nin\nmodo empirico ,visualizzando invarimodi lenuvole dei\ndati (esistono deitool giàpredisposti perquesto tipo di\nanalisi finoa3D)ogliistogrammi sulle diverse componenti\neconfrontandoli conlecurve teoriche .\nUna\n volta provata una (seppur vaga) normalità delle\ndistribuzioni, sistimano apartire daidati, vettore medioPe\nmatrice dicovarianza 6(maximum likelihood ).\nPer\n quanto riguarda leprobabilità apriori queste possono\nessere estratte dalle percentuale dicampioni cheneltraining\nsetappartengono allediverse classi, oincaso diassenza di\ninformazioni possono essere poste tutte uguali traloro.\nOgni\n nuovo pattern daclassificare ,èassegnato auna delle\npossibili classi inaccordo conlaregola diBayes nella quale\nmedia ecovarianza sono oranote.\n[1] K. Fukunaga , Statistical Pattern Recognition , Academic Press, 1990.",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#24": "Bayes Parametrico In Pratica\n",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#25": "Problemi Closed e Open Set\n",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#26": "Problemi Closed e Open Set\n",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#3": "Richiami\n!E’utile osservare chesevèunautovettore relativo all’autovalore λ0,\nallora anche %v,con%∈!e%≠0,èunautovettore relativo aλ0.\n!Infatti moltiplicando ambo imembri della relazione\nAv=λ0v\nperloscalare %≠0,siottiene\n%(Av)=%(λ0v)⟺A(%v)=λ0(%v)\n!Ciòdimostra cheanche %vèunautovettore associato aλ0.",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#4": "9prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDistribuzione Normale Multivariata \n(Multinormale ) \nNotazione\n :perevitare confusione utilizziamo apedicel’indice del\npattern e(ove necessario) adapice lacomponente (scalare) :\n•𝐱𝑖pattern i-esimo (vettore)\n•𝑥𝑖𝑗componente j-esima delpattern i-esimo (scalare)\nLa\ndensità diprobabilità nella distribuzione multinormale (𝑑>1):\n𝑝𝐱=1\n2𝜋𝑑/2Σ1/2𝑒−1\n2𝐱−𝛍𝑡Σ−1𝐱−𝛍\ndove𝛍=𝜇1,𝜇2…𝜇𝑑èilvettore medio èΣ=𝜎𝑖𝑗lamatrice di\ncovarianza (𝑑×𝑑).\nSi\nassume che ivettori siano ditipo «colonna» .L’apice𝑡\n(trasposto) litrasforma inrighe .\n|6|e6-1sono rispettivamente ildeterminante el’inversa di6.\nLa\nmatrice dicovarianza èsempre simmetrica edefinita\npositiva, pertanto ammette inversa .Essendo simmetrica il\nnumero diparametri cheladefinisce è𝑑∙𝑑+1/2\nGli\nelementi diagonali 𝜎𝑖𝑖sono levarianze deirispettivi 𝑥𝑖\n(ovvero 𝜎𝑖2);glielementi non diagonali 𝜎𝑖𝑗sono le\ncovarianze tra𝑥𝑖e𝑥𝑗:\n•se𝑥𝑖e𝑥𝑗sono statisticamente indipendenti 𝜎𝑖𝑗=0\n•se𝑥𝑖e𝑥𝑗sono correlati positivamente 𝜎𝑖𝑗>0\n•se𝑥𝑖e𝑥𝑗sono correlati negativamente 𝜎𝑖𝑗<0Distribuzione Normale Multivariata (Multinormale)",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#5": "10prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneRappresentazione grafica\nNormale Multivariata\nPer\n𝑑=2laforma della distribuzione èquella diun’ellisse .\n𝛍\n=𝜇1,𝜇2controlla laposizione delcentro .\n𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .\n𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi\ncartesiani .\n•se=0(matrice dicovarianza diagonale ),ladistribuzione\nmultinormale èdefinita come prodotto di𝑑normali\nmonodimensionali .Intalcaso gliassidell’ellisse sono\nparalleli agliassicartesiani (es.Naive Bayes Classifier ).\n•Se >0(come nel caso della figura )𝑥1e𝑥2sono\npositivamente correlate (quando aumenta 𝑥1aumenta\nanche𝑥2).\n•Se<0𝑥1e𝑥2sono negativamente correlate (quando\naumenta 𝑥1cala𝑥2).\nGli\nassidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi \nindividuano \nluoghi di punti a \ndensità costante\n𝑥1𝑥2Distribuzione Normale Multivariata (Multinormale)",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#6": "10prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneRappresentazione grafica\nNormale Multivariata\nPer\n𝑑=2laforma della distribuzione èquella diun’ellisse .\n𝛍\n=𝜇1,𝜇2controlla laposizione delcentro .\n𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .\n𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi\ncartesiani .\n•se=0(matrice dicovarianza diagonale ),ladistribuzione\nmultinormale èdefinita come prodotto di𝑑normali\nmonodimensionali .Intalcaso gliassidell’ellisse sono\nparalleli agliassicartesiani (es.Naive Bayes Classifier ).\n•Se >0(come nel caso della figura )𝑥1e𝑥2sono\npositivamente correlate (quando aumenta 𝑥1aumenta\nanche𝑥2).\n•Se<0𝑥1e𝑥2sono negativamente correlate (quando\naumenta 𝑥1cala𝑥2).\nGli\nassidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi \nindividuano \nluoghi di punti a \ndensità costante\n𝑥1𝑥2\nDistribuzione Normale Multivariata (Multinormale)\nN.B. Per quanto l’assunzione chele variabili siano statisticamente indipendenti (!12=0) \nnon siavera in generale , iClassificatori Naïve Bayes sidimostrano lavorare bene su\nmolti dataset. Per tale motivo , taliclassificatori sono fraipiùpopolari",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#7": "Distanza Mahalanobis\n11prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDistanza Mahalanobis\nLa\ndistanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :\n𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍\ndefinisce ibordi adensità costante inuna distribuzione\nmultinormale .Tale distanza viene spesso utilizzata in\nsostituzione della distanza euclidea ,essendo ingrado di\n“pesare”lediverse componenti tenendo conto deirelativi spazi\ndivariazione edella lorocorrelazione .\n𝑟=1\n𝑟=2\n𝑟=3\n𝑟=4\n𝑥1𝑥2\n11prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDistanza Mahalanobis\nLa\ndistanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :\n𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍\ndefinisce ibordi adensità costante inuna distribuzione\nmultinormale .Tale distanza viene spesso utilizzata in\nsostituzione della distanza euclidea ,essendo ingrado di\n“pesare”lediverse componenti tenendo conto deirelativi spazi\ndivariazione edella lorocorrelazione .\n𝑟=1\n𝑟=2\n𝑟=3\n𝑟=4\n𝑥1𝑥2",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#8": "Esempio Stima di µes(d=2)\n12prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempio stima di 𝜇e 𝜎(d=2)\nDato\n untraining setdipattern bi-dimensionali composto da𝑛=\n5elementi :\nLa\nstima deiparametri permassima verosimiglianza (maximum\nlikelihood )è:\no,innotazione vettoriale :\n𝛍=1\n𝑛෍\n𝑖=1…𝑛𝐱𝑖>@>@>@>@>@ ^ ` 8.15,23,1,4 ,2.7,13,12,5.4,3,7 t t t t t\n¦\n  \n»»»»\n¼º\n««««\n¬ª\n \nn ki\nki\ndxn ...121\n1    ,    \n...P\nPPP\nμ »¼º\n«¬ª \n»»»\n¼º\n«««\n¬ª\n\u000e\u000e\u000e\u000e\u000e\u000e\u000e\u000e\n 2.99.8\n58.1542.71275231135.43\nμ!Vogliano eseguire la stima dei parametri tramite il Metodo della \nMassima Verosimiglianza ( Maximum Likelihood )campioni in blu\nvettore medio da \nstimare in rosso",
    "data_test\\rootfolder\\università\\MachineLearning\\30-CB(2)-sbloccato.pdf#9": "Esempio Stima di µes(d=2)\n12prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempio stima di 𝜇e 𝜎(d=2)\nDato\n untraining setdipattern bi-dimensionali composto da𝑛=\n5elementi :\nLa\nstima deiparametri permassima verosimiglianza (maximum\nlikelihood )è:\no,innotazione vettoriale :\n𝛍=1\n𝑛෍\n𝑖=1…𝑛𝐱𝑖>@>@>@>@>@ ^ ` 8.15,23,1,4 ,2.7,13,12,5.4,3,7 t t t t t\n¦\n  \n»»»»\n¼º\n««««\n¬ª\n \nn ki\nki\ndxn ...121\n1    ,    \n...P\nPPP\nμ »¼º\n«¬ª \n»»»\n¼º\n«««\n¬ª\n\u000e\u000e\u000e\u000e\u000e\u000e\u000e\u000e\n 2.99.8\n58.1542.71275231135.43\nμ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#0": "Sommario\n!Approccio parametrico (distribuzione MultiNormale)\n!Approccio non parametrico (Parzen Window) ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#1": "Appr occi Non Parametrici e Stima della Densità\n21prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneApprocci non parametrici e\nStima della Densità\nNon vengono fatte ipotesi sulle distribuzioni deipattern eledensità\ndiprobabilità sono stimate direttamente daltraining set.\nIlproblema della stima accurata della densità èritenuto damolti un\nproblema piùcomplesso della classificazione .Pertanto perché\nrisolvere come sotto -problema unproblema che èpiùcomplesso\ndell’intero compito diclassificazione ?\nIngenerale lastima della densità èaffrontabile inspazi a\ndimensionalità ridotta (es.𝑑=3)ediventa critica alcrescere della\ndimensionalità (curse ofdimensionality ):ilvolume dello spazio\naumenta così tanto cheipattern diventato troppo sparsi .\nStima Densità\nLaprobabilità cheunpattern𝐱cadaall’interno diè:\n𝑃1=න\n𝑝𝐱′𝑑𝐱′\nDati𝑛pattern indipendenti, laprobabilità che𝑘diquesti cadano\nnella regioneècalcolabile attraverso ladistribuzione binomiale :\n𝑃𝑘=𝑛\n𝑘𝑃1𝑘1−𝑃1𝑛−𝑘\nilcuivalor medio è𝑘=𝑛𝑃1(equindi𝑃1=𝑘/𝑛)\nAssumendo che laregione (divolume𝑉)siapiccola eche\nquindi𝑝∙nonvarisignificativamente all’interno diessa :\n𝑃1=න\n𝑝𝐱′𝑑𝐱′≈𝑝𝐱∙𝑉\n𝑝𝐱=𝑃1\n𝑉=𝑘\n𝑛∙𝑉",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#10": "Parzen Window con Soft Kernel\n23prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneParzen Window con Soft kernel\nNella pratica, invece difunzioni finestra ipercubo siutilizzano kernel\nfunction piùsoftgrazie allequali ogni pattern𝐱𝑖contribuisce alla\nstima didensità inunintorno di𝐱inaccordo conladistanza da𝐱.In\nquesto modo lesuperfici decisionali risultano molto piùregolari\n(smoothed ).\nLekernel function devono essere funzioni densità (sempre ≥0e\nconintegrale sututto lospazio uguale a1).Utilizzando lafunzione\nmultinormale (con𝛍=[0…0]eΣ=I):\n𝜑𝐮=1\n2𝜋𝑑/2𝑒−𝐮𝑡𝐮\n2\nn=15\nn=40\nn=120h=3 h=8\n h=15\nRicordiamo che x è il pattern da classificare, xisono i pattern del \nTraining Set",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#11": "Kernel Trick\nSVM Classification\nOvviamente le SVM possono essere\nusate per separare classi che non\npotrebbero essere separate con un\nclassificatore lineare, altrimenti la loro\napplicazione a casi di reale interesse\nnon sarebbe possibile. In questi casi le\ncoordinate degli oggetti sono mappate\nin uno spazio detto “feature space”\nutilizzando funzioni non lineare,\nchiamate “feature function” ϕ.Ilfeature\n chiamate “feature function” ϕ.Ilfeature\nspace è uno spazio fortemente\nmultidimensionale in cui le due classi\npossono essere separate con un\nclassificatore lineare.\nQuindi lo spazio iniziale viene rimappato\nnel nuovo spazio, a questo punto viene\nidentificato il classificatore che poi viene\nriportato nello spazio iniziale, come\nillustrato in figura.Fonte: Stefano Cavuoti\nSVM Classification\nLa funzione ϕcombina quindi lo spazio iniziale (le \ncaratteristiche originali degli oggetti) nello spaz io \ndelle features che potrebbe in linea di principio \navere anche dimensione infinita. A causa del fatto \nche questo spazio ha molte dimensioni non \nsarebbe pratico utilizzare una funzione generica \nper trovare l’iperpiano di separazione, quindi \nvengono usate delle funzioni dette “kernel” e si \nidentifica la funzione ϕtramite una combinazione \ndi funzioni di kernel.\nFonte: http://www.ivanciuc.org/\ndi funzioni di kernel.\nL’implementazione più famosa delle SVM (libSVM) \nusa quattro possibili kernel:\nFonte: http://www.imtech.res.in/raghava/rbpred/svm. jpg\nKernel trick–(1)\n•Possiamo trasformare i dati nell' input space in un nuovo \nspazio, detto feature space , a più alta dimensionalità\n•I vettori che prima non erano linearmente separabili hanno più \nprobabilità di esserlo in uno spazio a più dimensioni\n25\nIdea:trasformare idati nell’Input Space inunnuovo spazio, detto\nFeature Space ,apiùaltadimensionalità .\nIpattern che prima non erano linearmente separabili hanno più\nprobabilità diesserlo inunospazio apiùdimensioni .\nQualsiasi modello lineare può essere trasformato inunmodello non\nlineare applicando ilkernel trick (stratagemma del kernel) almodello :\nsostituendo lesuefeature (predittori) conunafunzione kernel .",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#12": "Kernel Trick\n!Le funzioni kernel sono usate per operare nello spazio delle \nfeature senza calcolare le coordinate dei dati nello spazio di \ninput, ma piuttosto calcolando il prodotto scalare fra le immagini \ndi tutte le copie di dati nello spazio funzione!Tale operazione è spesso computazionalmente più economica \nche l’esplicito calcolo delle coordinate, in quanto il prodotto \nscalare gode di alcune proprietà speciali!Infatti spesso si può calcolare φ(xi)\"φ(xj) senza prima calcolare il \nvalore di φ in ogni punto [dove x è il pattern nell’ input space (con \nddimensioni) e φ(x) è il corrispondente pattern nel feature space \n(con m>d dimensioni)!Le funzioni kernel sono state introdotte per sequenze di dati, \ngrafi, testi, immagini e vettori",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#13": "Parzen Window con Soft Kernel\n23prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneParzen Window con Soft kernel\nNella pratica, invece difunzioni finestra ipercubo siutilizzano kernel\nfunction piùsoftgrazie allequali ogni pattern𝐱𝑖contribuisce alla\nstima didensità inunintorno di𝐱inaccordo conladistanza da𝐱.In\nquesto modo lesuperfici decisionali risultano molto piùregolari\n(smoothed ).\nLekernel function devono essere funzioni densità (sempre ≥0e\nconintegrale sututto lospazio uguale a1).Utilizzando lafunzione\nmultinormale (con𝛍=[0…0]eΣ=I):\n𝜑𝐮=1\n2𝜋𝑑/2𝑒−𝐮𝑡𝐮\n2\nn=15\nn=40\nn=120h=3 h=8\n h=15\nIn questo caso il valore \ndell’iperparametro h\nnon è legato alla \nlunghezza di uno \nspigolo dell’ipercubo, \nma all’ ampiezza della \nfunzione multinormale ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#14": "Esempio con Parzen Window\n24prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes + Parzen Window\nStima non -parametrica della densità attraverso Parzen Window\n(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)\nPesoAltezza\n>@T168 ,57 x\nPesoAltezza\n>@T168 ,57 x\n¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)\n¾Funzione Kernel normale con ℎ=3 (grafico a destra)\u000b\f0.0038 |1 wpx \u000b\f 0040.0 |2 wpx \u000b\f\u000b\f\u000b\f 0039.0 w w|is\n1ii    ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f43.0w w||w1 1\n1 # xxxpP pP \u000b\f\u000b\f\u000b\f\n\u000b\f57.0w w||w2 2\n2 # xxxpP pP\n\u000b\f0.0024 |1 wpx \u000b\f 0041.0 |2 wpx \u000b\f\u000b\f\u000b\f 0033.0 w w|is\n1ii    ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f32.0w w||w1 1\n1 # xxxpP pP \u000b\f\u000b\f\u000b\f\n\u000b\f68.0w w||w2 2\n2 # xxxpP pP(N.B. In questo caso il valore dell’iperparametro hè legato alla lunghezza \ndello spigolo dell’ ipercubo )\n(N.B. In questo caso il valore dell’iperparametro hè legato all’ampiezza della \nfunzione multinormale )",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#15": "Esempio con Parzen Window\n24prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes + Parzen Window\nStima non -parametrica della densità attraverso Parzen Window\n(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)\nPesoAltezza\n>@T168 ,57 x\nPesoAltezza\n>@T168 ,57 x\n¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)\n¾Funzione Kernel normale con ℎ=3 (grafico a destra)\u000b\f0.0038 |1 wpx \u000b\f 0040.0 |2 wpx \u000b\f\u000b\f\u000b\f 0039.0 w w|is\n1ii    ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f43.0w w||w1 1\n1 # xxxpP pP \u000b\f\u000b\f\u000b\f\n\u000b\f57.0w w||w2 2\n2 # xxxpP pP\n\u000b\f0.0024 |1 wpx \u000b\f 0041.0 |2 wpx \u000b\f\u000b\f\u000b\f 0033.0 w w|is\n1ii    ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f32.0w w||w1 1\n1 # xxxpP pP \u000b\f\u000b\f\u000b\f\n\u000b\f68.0w w||w2 2\n2 # xxxpP pP\n24prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes + Parzen Window\nStima non -parametrica della densità attraverso Parzen Window\n(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)\nPesoAltezza\n>@T168 ,57 x\nPesoAltezza\n>@T168 ,57 x\n¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)\n¾Funzione Kernel normale con ℎ=3 (grafico a destra)\u000b\f0.0038 |1 wpx \u000b\f 0040.0 |2 wpx \u000b\f\u000b\f\u000b\f 0039.0 w w|is\n1ii    ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f43.0w w||w1 1\n1 # xxxpP pP \u000b\f\u000b\f\u000b\f\n\u000b\f57.0w w||w2 2\n2 # xxxpP pP\n\u000b\f0.0024 |1 wpx \u000b\f 0041.0 |2 wpx \u000b\f\u000b\f\u000b\f 0033.0 w w|is\n1ii    ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f32.0w w||w1 1\n1 # xxxpP pP \u000b\f\u000b\f\u000b\f\n\u000b\f68.0w w||w2 2\n2 # xxxpP pP\n24prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMaschi/Femmine\ncon Bayes + Parzen Window\nStima non -parametrica della densità attraverso Parzen Window\n(nell’ipotesi che 𝑃𝑤1=8/18, 𝑃𝑤2=10/18)\nPesoAltezza\n>@T168 ,57 x\nPesoAltezza\n>@T168 ,57 x\n¾Funzione Kernel ipercubo con ℎ=10 (grafico a sinistra)\n¾Funzione Kernel normale con ℎ=3 (grafico a destra)\u000b\f0.0038 |1 wpx \u000b\f 0040.0 |2 wpx \u000b\f\u000b\f\u000b\f 0039.0 w w|is\n1ii    ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f43.0w w||w1 1\n1 # xxxpP pP \u000b\f\u000b\f\u000b\f\n\u000b\f57.0w w||w2 2\n2 # xxxpP pP\n\u000b\f0.0024 |1 wpx \u000b\f 0041.0 |2 wpx \u000b\f\u000b\f\u000b\f 0033.0 w w|is\n1ii    ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f32.0w w||w1 1\n1 # xxxpP pP \u000b\f\u000b\f\u000b\f\n\u000b\f68.0w w||w2 2\n2 # xxxpP pP(con hlegato alla lunghezza dello spigolo dell’ ipercubo )\n(con hlegato all’ampiezza della funzione normale )\nSipuò notare come nelcaso della Funzione Kernel normale ,lesuperfici\ndecisionali risultino molto piùregolari (smoothed)",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#16": "Riferimenti\n!S.J. Russell, and P. Norvig, Artificial Intelligence: A Modern \nApproach (4 ed.) , Pearson, 2020.\n!K. Fukunaga, Statistical Pattern Recognition , Academic Press, \n1990.\n!R. O. Duda, P. Hart, and D. G. Stork Pattern Classification , \nWiley -Interscience, 2000.\n!D. Maltoni, Machine Learning , Università di Bologna, 2021.\n!C.M. Bishop, Pattern Recognition and Machine Learning , \nSpringer, 2006.\n!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The \nMIT Press, 2012.",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#17": "Matlab\nQuesto esempio mostra come eseguire la classificazione in Matlab tramite \nNaÏve Bayes Classifier\nMATLAB > Help > Examples > Statistics and Machine Learning Toolbox > \nClassification\nDataset: Fisher’s Iris Data\nFisher's iris data consists of measurements on the sepal length, sepal width, \npetal length, and petal width for 150 iris specimens. There are 50 specimens \nfrom each of three species. Load the data and see how the sepal \nmeasurements differ between species. You can use the two columns \ncontaining sepal measurements.\nload fisheriris\ngscatter(meas(:,1), meas(:,2), species,'rgb','osd');\nxlabel('Sepal length');\nylabel('Sepal width');\nN = size(meas,1);\n",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#18": "Matlab\n",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#19": "Matlab\nApproccio Parametrico: modelliamo ciascuna variabile in ciascuna classe tramite \nuna distribuzione Gaussiana. Ci calcoliamo il resubstitution error (errore sul \ntraining set, di solito stima ottimistica dell’errore reale sul test set) e il cross -\nvalidation error (in cui si suddivide il training set in gruppi di eguale numerosità, \nsi esclude iterativamente un gruppo alla volta e lo si cerca di predire con i gruppi \nnon esclusi)\nnbGau = fitcnb(meas(:,1:2), species);\nnbGauResubErr = resubLoss(nbGau)\n[x,y] = meshgrid(4:.1:8,2:.1:4.5);\nx = x(:);\ny = y(:);\ncp = cvpartition(species,'KFold',10)\nnbGauCV = crossval(nbGau, 'CVPartition',cp);\nnbGauCVErr = kfoldLoss(nbGauCV)\nlabels = predict(nbGau, [x y]);\ngscatter(x,y,labels,'grb','sod')\nnbGauResubErr = 0.2200\nnbGauCVErr = 0.2200\n",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#2": "Appr occi Non Parametrici e Stima della Densità\nL'ipercubo (o n-cubo) è una forma geometrica regolare immersa in \nuno spazio di quattro o piùdimensioni\n",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#20": "Matlab\nApproccio Non Parametrico: in questo caso modelliamo ciascuna variabile in \nciascuna classe tramite una stima della densità di probabilità mediante funzione \nkernel (settata a ‘box’)\nnbKD = fitcnb(meas(:,1:2), species, 'DistributionNames','kernel', 'Kernel','box');\nnbKDResubErr = resubLoss(nbKD)\nnbKDCV = crossval(nbKD, 'CVPartition',cp);\nnbKDCVErr = kfoldLoss(nbKDCV)\nlabels = predict(nbKD, [x y]);\ngscatter(x,y,labels,'rgb','osd')\nlabels = predict(nbGau, [x y]);\ngscatter(x,y,labels,'grb','sod')\nnbKDResubErr = 0.2067\nnbKDCVErr = 0.2133\n",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#21": "Esercizio 1\n5) Date due distribuzioni multinormali identificate dai seguenti parametri:  \n𝝁0=[1,03\n1,03] \n𝚺0−1=[52,56−10,05\n−10,0536,88] \n|𝚺0|=0,000544  \n𝑃(𝑤0)=0,6 𝝁1=[2,02\n1,53] \n𝚺1−1=[100,58−22,34\n−22,3437,85] \n|𝚺1|=0,000302  \n𝑃(𝑤1)=0,4 \nNell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60\n1,25]: \nx le densità di probabilità condizionali;  \nx le probabilità a posteriori ; \nx l’indice della classe restituita in output.  \n \nSi ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  \n𝑝(𝒙)=1\n(2𝜋)𝑑\n2⋅|𝚺|1\n2⋅𝑒−1\n2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) \n \nSvolgimento  \n \n𝒙−𝝁0=[1,60\n1,25]−[1,03\n1,03]=[0,57\n0,22] \n \n𝑝(𝒙|𝑤0)=1\n2𝜋⋅√0,000544⋅𝑒−1\n2⋅[0,570,22]⋅[52,56−10,05\n−10,0536,99]⋅[0,57\n0,22] \n \n[52,56−10,05\n−10,0536,88]⋅[0,57\n0,22]=[52,56⋅0,57+(−10,05)⋅0,22\n(−10,05)⋅0,57+36,88⋅0,22]=[27,7482\n2,3851] \n \n[0,570,22]⋅[27,7482\n2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  \n \n𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412\n2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) \n \n𝒙−𝝁1=[1,60\n1,25]−[2,02\n1,53]=[−0,42\n−0,28] \n \n𝑝(𝒙|𝑤1)=1\n2𝜋⋅√0,000302⋅𝑒−1\n2⋅[−0,42−0,28]⋅[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28] \n \n[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)\n(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884\n−1,2152] \n \n[−0,42−0,28]⋅[−35,9884\n−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  \n \n𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554\n2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) \n \n𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) \n \n𝑝(𝑤0|𝒙)=0,00193⋅0,6\n0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) \n \n𝑝(𝑤1|𝒙)=0,00403⋅0,4\n0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) \n \nIndice della classe restituita: 1 5) Date due distribuzioni multinormali identificate dai seguenti parametri:  \n𝝁0=[1,03\n1,03] \n𝚺0−1=[52,56−10,05\n−10,0536,88] \n|𝚺0|=0,000544  \n𝑃(𝑤0)=0,6 𝝁1=[2,02\n1,53] \n𝚺1−1=[100,58−22,34\n−22,3437,85] \n|𝚺1|=0,000302  \n𝑃(𝑤1)=0,4 \nNell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60\n1,25]: \nx le densità di probabilità condizionali;  \nx le probabilità a posteriori ; \nx l’indice della classe restituita in output.  \n \nSi ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  \n𝑝(𝒙)=1\n(2𝜋)𝑑\n2⋅|𝚺|1\n2⋅𝑒−1\n2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) \n \nSvolgimento  \n \n𝒙−𝝁0=[1,60\n1,25]−[1,03\n1,03]=[0,57\n0,22] \n \n𝑝(𝒙|𝑤0)=1\n2𝜋⋅√0,000544⋅𝑒−1\n2⋅[0,570,22]⋅[52,56−10,05\n−10,0536,99]⋅[0,57\n0,22] \n \n[52,56−10,05\n−10,0536,88]⋅[0,57\n0,22]=[52,56⋅0,57+(−10,05)⋅0,22\n(−10,05)⋅0,57+36,88⋅0,22]=[27,7482\n2,3851] \n \n[0,570,22]⋅[27,7482\n2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  \n \n𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412\n2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) \n \n𝒙−𝝁1=[1,60\n1,25]−[2,02\n1,53]=[−0,42\n−0,28] \n \n𝑝(𝒙|𝑤1)=1\n2𝜋⋅√0,000302⋅𝑒−1\n2⋅[−0,42−0,28]⋅[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28] \n \n[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)\n(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884\n−1,2152] \n \n[−0,42−0,28]⋅[−35,9884\n−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  \n \n𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554\n2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) \n \n𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) \n \n𝑝(𝑤0|𝒙)=0,00193⋅0,6\n0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) \n \n𝑝(𝑤1|𝒙)=0,00403⋅0,4\n0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) \n \nIndice della classe restituita: 1 ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#22": "Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  \n𝝁0=[1,03\n1,03] \n𝚺0−1=[52,56−10,05\n−10,0536,88] \n|𝚺0|=0,000544  \n𝑃(𝑤0)=0,6 𝝁1=[2,02\n1,53] \n𝚺1−1=[100,58−22,34\n−22,3437,85] \n|𝚺1|=0,000302  \n𝑃(𝑤1)=0,4 \nNell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60\n1,25]: \nx le densità di probabilità condizionali;  \nx le probabilità a posteriori ; \nx l’indice della classe restituita in output.  \n \nSi ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  \n𝑝(𝒙)=1\n(2𝜋)𝑑\n2⋅|𝚺|1\n2⋅𝑒−1\n2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) \n \nSvolgimento  \n \n𝒙−𝝁0=[1,60\n1,25]−[1,03\n1,03]=[0,57\n0,22] \n \n𝑝(𝒙|𝑤0)=1\n2𝜋⋅√0,000544⋅𝑒−1\n2⋅[0,570,22]⋅[52,56−10,05\n−10,0536,99]⋅[0,57\n0,22] \n \n[52,56−10,05\n−10,0536,88]⋅[0,57\n0,22]=[52,56⋅0,57+(−10,05)⋅0,22\n(−10,05)⋅0,57+36,88⋅0,22]=[27,7482\n2,3851] \n \n[0,570,22]⋅[27,7482\n2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  \n \n𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412\n2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) \n \n𝒙−𝝁1=[1,60\n1,25]−[2,02\n1,53]=[−0,42\n−0,28] \n \n𝑝(𝒙|𝑤1)=1\n2𝜋⋅√0,000302⋅𝑒−1\n2⋅[−0,42−0,28]⋅[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28] \n \n[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)\n(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884\n−1,2152] \n \n[−0,42−0,28]⋅[−35,9884\n−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  \n \n𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554\n2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) \n \n𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) \n \n𝑝(𝑤0|𝒙)=0,00193⋅0,6\n0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) \n \n𝑝(𝑤1|𝒙)=0,00403⋅0,4\n0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) \n \nIndice della classe restituita: 1 ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#23": "Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  \n𝝁0=[1,03\n1,03] \n𝚺0−1=[52,56−10,05\n−10,0536,88] \n|𝚺0|=0,000544  \n𝑃(𝑤0)=0,6 𝝁1=[2,02\n1,53] \n𝚺1−1=[100,58−22,34\n−22,3437,85] \n|𝚺1|=0,000302  \n𝑃(𝑤1)=0,4 \nNell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60\n1,25]: \nx le densità di probabilità condizionali;  \nx le probabilità a posteriori ; \nx l’indice della classe restituita in output.  \n \nSi ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  \n𝑝(𝒙)=1\n(2𝜋)𝑑\n2⋅|𝚺|1\n2⋅𝑒−1\n2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) \n \nSvolgimento  \n \n𝒙−𝝁0=[1,60\n1,25]−[1,03\n1,03]=[0,57\n0,22] \n \n𝑝(𝒙|𝑤0)=1\n2𝜋⋅√0,000544⋅𝑒−1\n2⋅[0,570,22]⋅[52,56−10,05\n−10,0536,99]⋅[0,57\n0,22] \n \n[52,56−10,05\n−10,0536,88]⋅[0,57\n0,22]=[52,56⋅0,57+(−10,05)⋅0,22\n(−10,05)⋅0,57+36,88⋅0,22]=[27,7482\n2,3851] \n \n[0,570,22]⋅[27,7482\n2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  \n \n𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412\n2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) \n \n𝒙−𝝁1=[1,60\n1,25]−[2,02\n1,53]=[−0,42\n−0,28] \n \n𝑝(𝒙|𝑤1)=1\n2𝜋⋅√0,000302⋅𝑒−1\n2⋅[−0,42−0,28]⋅[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28] \n \n[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)\n(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884\n−1,2152] \n \n[−0,42−0,28]⋅[−35,9884\n−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  \n \n𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554\n2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) \n \n𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) \n \n𝑝(𝑤0|𝒙)=0,00193⋅0,6\n0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) \n \n𝑝(𝑤1|𝒙)=0,00403⋅0,4\n0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) \n \nIndice della classe restituita: 1 ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#24": "Esercizio 15) Date due distribuzioni multinormali identificate dai seguenti parametri:  \n𝝁0=[1,03\n1,03] \n𝚺0−1=[52,56−10,05\n−10,0536,88] \n|𝚺0|=0,000544  \n𝑃(𝑤0)=0,6 𝝁1=[2,02\n1,53] \n𝚺1−1=[100,58−22,34\n−22,3437,85] \n|𝚺1|=0,000302  \n𝑃(𝑤1)=0,4 \nNell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[1,60\n1,25]: \nx le densità di probabilità condizionali;  \nx le probabilità a posteriori ; \nx l’indice della classe restituita in output.  \n \nSi ricorda che  la densità di probabilità , nel caso della  distribuzione multinormale è:  \n𝑝(𝒙)=1\n(2𝜋)𝑑\n2⋅|𝚺|1\n2⋅𝑒−1\n2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) \n \nSvolgimento  \n \n𝒙−𝝁0=[1,60\n1,25]−[1,03\n1,03]=[0,57\n0,22] \n \n𝑝(𝒙|𝑤0)=1\n2𝜋⋅√0,000544⋅𝑒−1\n2⋅[0,570,22]⋅[52,56−10,05\n−10,0536,99]⋅[0,57\n0,22] \n \n[52,56−10,05\n−10,0536,88]⋅[0,57\n0,22]=[52,56⋅0,57+(−10,05)⋅0,22\n(−10,05)⋅0,57+36,88⋅0,22]=[27,7482\n2,3851] \n \n[0,570,22]⋅[27,7482\n2,3851]=0,57⋅27,7482+0,22⋅2,3851=16,3412  \n \n𝑝(𝒙|𝑤0)=6,8237⋅𝑒−16,3412\n2=0,00193  (Densità di probabilità condizionale di 𝒙 data 𝑤0) \n \n𝒙−𝝁1=[1,60\n1,25]−[2,02\n1,53]=[−0,42\n−0,28] \n \n𝑝(𝒙|𝑤1)=1\n2𝜋⋅√0,000302⋅𝑒−1\n2⋅[−0,42−0,28]⋅[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28] \n \n[100,58−22,34\n−22,3437,85]⋅[−0,42\n−0,28]=[100,58⋅(−0,42)+(−22,34)⋅(−0,28)\n(−22,34)⋅(−0,42)+37,85⋅(−0,28)]=[−35,9884\n−1,2152] \n \n[−0,42−0,28]⋅[−35,9884\n−1,2152]=(−0,42)⋅(−35,9884)+(−0,28)⋅(−1,2152)=15,4554  \n \n𝑝(𝒙|𝑤1)=9,1583⋅𝑒−15,4554\n2=0,00403  (Densità di probabilità condizionale di 𝒙 data 𝑤1) \n \n𝑝(𝒙)=0,00193⋅0,6+0,00403⋅0,4=0,00277  (Densità di probabilità assoluta dato 𝒙) \n \n𝑝(𝑤0|𝒙)=0,00193⋅0,6\n0,00277=0,418 (Probabilità a posteriori di 𝑤0 dato 𝒙) \n \n𝑝(𝑤1|𝒙)=0,00403⋅0,4\n0,00277=0,582 (Probabilità a posteriori di 𝑤1 dato 𝒙) \n \nIndice della classe restituita: 1 ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#25": "Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  \n \nx 6 neuroni per l’input layer  \nx 8 neuroni per l’hidden layer  \nx 5 neuroni di output  \n \nQuante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le \noperazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di \noperazioni per livello.  \n \nSvolgimento  \n \nPer ogni neurone del livello corrente si deve calcolare la seguente formula:  \n𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗\n𝑗=1..𝑑+𝑤0𝑖 \n \nche comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale \ndel bias. Pertanto:  \n \n \n \n \n \nNumero operazioni l ivello hidden: 8⋅(6+6+1)=104 \n \nNumero operazioni livello di output: 5⋅(8+8+1)=85 \n \nTotale: 189 \n \n \n6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  \n \n{[6,1\n8,1],[6,5\n1,9],[8,8\n4,2],[5,2\n9,7],[0,8\n5,4]} \n \nCalcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  \n \nSi ricorda che ogni elemento della matrice di covarianza può essere calcolato come  \n𝜎𝑖𝑗=1\n𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛\n𝑘=1   \ndove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  \n \nSvolgimento  \n \n𝛍=[6,1+6,5+8,8+5,2+0,8\n5\n8,1+1,9+4,2+9,7+5,4\n5]=[5,5\n5,9] \n \n𝚺=[6,9−1,4\n−1,47,7] \n \n Machine Learning                        Matricola: ___________________  \n20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n \nNeuroni livello \ncorrente  Somma Bias  Una somma  per ogni \nneurone livello \nprecedente  Una moltiplicazione \nper ogni neurone \nlivello precedente  \nNOTA:  Il calcolo a lato è eseguito t rascurando il fatto che \nun’implementazione ottimizzata della sommatoria potrebbe \nevitare una somma per il primo elemento della sommatoria \n(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  \n \nx 6 neuroni per l’input layer  \nx 8 neuroni per l’hidden layer  \nx 5 neuroni di output  \n \nQuante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le \noperazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di \noperazioni per livello.  \n \nSvolgimento  \n \nPer ogni neurone del livello corrente si deve calcolare la seguente formula:  \n𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗\n𝑗=1..𝑑+𝑤0𝑖 \n \nche comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale \ndel bias. Pertanto:  \n \n \n \n \n \nNumero operazioni l ivello hidden: 8⋅(6+6+1)=104 \n \nNumero operazioni livello di output: 5⋅(8+8+1)=85 \n \nTotale: 189 \n \n \n6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  \n \n{[6,1\n8,1],[6,5\n1,9],[8,8\n4,2],[5,2\n9,7],[0,8\n5,4]} \n \nCalcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  \n \nSi ricorda che ogni elemento della matrice di covarianza può essere calcolato come  \n𝜎𝑖𝑗=1\n𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛\n𝑘=1   \ndove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  \n \nSvolgimento  \n \n𝛍=[6,1+6,5+8,8+5,2+0,8\n5\n8,1+1,9+4,2+9,7+5,4\n5]=[5,5\n5,9] \n \n𝚺=[6,9−1,4\n−1,47,7] \n \n Machine Learning                        Matricola: ___________________  \n20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n \nNeuroni livello \ncorrente  Somma Bias  Una somma  per ogni \nneurone livello \nprecedente  Una moltiplicazione \nper ogni neurone \nlivello precedente  \nNOTA:  Il calcolo a lato è eseguito t rascurando il fatto che \nun’implementazione ottimizzata della sommatoria potrebbe \nevitare una somma per il primo elemento della sommatoria \n(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  \n \nx 6 neuroni per l’input layer  \nx 8 neuroni per l’hidden layer  \nx 5 neuroni di output  \n \nQuante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le \noperazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di \noperazioni per livello.  \n \nSvolgimento  \n \nPer ogni neurone del livello corrente si deve calcolare la seguente formula:  \n𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗\n𝑗=1..𝑑+𝑤0𝑖 \n \nche comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale \ndel bias. Pertanto:  \n \n \n \n \n \nNumero operazioni l ivello hidden: 8⋅(6+6+1)=104 \n \nNumero operazioni livello di output: 5⋅(8+8+1)=85 \n \nTotale: 189 \n \n \n6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  \n \n{[6,1\n8,1],[6,5\n1,9],[8,8\n4,2],[5,2\n9,7],[0,8\n5,4]} \n \nCalcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  \n \nSi ricorda che ogni elemento della matrice di covarianza può essere calcolato come  \n𝜎𝑖𝑗=1\n𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛\n𝑘=1   \ndove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  \n \nSvolgimento  \n \n𝛍=[6,1+6,5+8,8+5,2+0,8\n5\n8,1+1,9+4,2+9,7+5,4\n5]=[5,5\n5,9] \n \n𝚺=[6,9−1,4\n−1,47,7] \n \n Machine Learning                        Matricola: ___________________  \n20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n \nNeuroni livello \ncorrente  Somma Bias  Una somma  per ogni \nneurone livello \nprecedente  Una moltiplicazione \nper ogni neurone \nlivello precedente  \nNOTA:  Il calcolo a lato è eseguito t rascurando il fatto che \nun’implementazione ottimizzata della sommatoria potrebbe \nevitare una somma per il primo elemento della sommatoria \n(somma con 0).  ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#26": "Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  \n \nx 6 neuroni per l’input layer  \nx 8 neuroni per l’hidden layer  \nx 5 neuroni di output  \n \nQuante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le \noperazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di \noperazioni per livello.  \n \nSvolgimento  \n \nPer ogni neurone del livello corrente si deve calcolare la seguente formula:  \n𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗\n𝑗=1..𝑑+𝑤0𝑖 \n \nche comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale \ndel bias. Pertanto:  \n \n \n \n \n \nNumero operazioni l ivello hidden: 8⋅(6+6+1)=104 \n \nNumero operazioni livello di output: 5⋅(8+8+1)=85 \n \nTotale: 189 \n \n \n6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  \n \n{[6,1\n8,1],[6,5\n1,9],[8,8\n4,2],[5,2\n9,7],[0,8\n5,4]} \n \nCalcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  \n \nSi ricorda che ogni elemento della matrice di covarianza può essere calcolato come  \n𝜎𝑖𝑗=1\n𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛\n𝑘=1   \ndove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  \n \nSvolgimento  \n \n𝛍=[6,1+6,5+8,8+5,2+0,8\n5\n8,1+1,9+4,2+9,7+5,4\n5]=[5,5\n5,9] \n \n𝚺=[6,9−1,4\n−1,47,7] \n \n Machine Learning                        Matricola: ___________________  \n20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n \nNeuroni livello \ncorrente  Somma Bias  Una somma  per ogni \nneurone livello \nprecedente  Una moltiplicazione \nper ogni neurone \nlivello precedente  \nNOTA:  Il calcolo a lato è eseguito t rascurando il fatto che \nun’implementazione ottimizzata della sommatoria potrebbe \nevitare una somma per il primo elemento della sommatoria \n(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  \n \nx 6 neuroni per l’input layer  \nx 8 neuroni per l’hidden layer  \nx 5 neuroni di output  \n \nQuante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le \noperazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di \noperazioni per livello.  \n \nSvolgimento  \n \nPer ogni neurone del livello corrente si deve calcolare la seguente formula:  \n𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗\n𝑗=1..𝑑+𝑤0𝑖 \n \nche comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale \ndel bias. Pertanto:  \n \n \n \n \n \nNumero operazioni l ivello hidden: 8⋅(6+6+1)=104 \n \nNumero operazioni livello di output: 5⋅(8+8+1)=85 \n \nTotale: 189 \n \n \n6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  \n \n{[6,1\n8,1],[6,5\n1,9],[8,8\n4,2],[5,2\n9,7],[0,8\n5,4]} \n \nCalcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  \n \nSi ricorda che ogni elemento della matrice di covarianza può essere calcolato come  \n𝜎𝑖𝑗=1\n𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛\n𝑘=1   \ndove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  \n \nSvolgimento  \n \n𝛍=[6,1+6,5+8,8+5,2+0,8\n5\n8,1+1,9+4,2+9,7+5,4\n5]=[5,5\n5,9] \n \n𝚺=[6,9−1,4\n−1,47,7] \n \n Machine Learning                        Matricola: ___________________  \n20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n \nNeuroni livello \ncorrente  Somma Bias  Una somma  per ogni \nneurone livello \nprecedente  Una moltiplicazione \nper ogni neurone \nlivello precedente  \nNOTA:  Il calcolo a lato è eseguito t rascurando il fatto che \nun’implementazione ottimizzata della sommatoria potrebbe \nevitare una somma per il primo elemento della sommatoria \n(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  \n \nx 6 neuroni per l’input layer  \nx 8 neuroni per l’hidden layer  \nx 5 neuroni di output  \n \nQuante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le \noperazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di \noperazioni per livello.  \n \nSvolgimento  \n \nPer ogni neurone del livello corrente si deve calcolare la seguente formula:  \n𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗\n𝑗=1..𝑑+𝑤0𝑖 \n \nche comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale \ndel bias. Pertanto:  \n \n \n \n \n \nNumero operazioni l ivello hidden: 8⋅(6+6+1)=104 \n \nNumero operazioni livello di output: 5⋅(8+8+1)=85 \n \nTotale: 189 \n \n \n6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  \n \n{[6,1\n8,1],[6,5\n1,9],[8,8\n4,2],[5,2\n9,7],[0,8\n5,4]} \n \nCalcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  \n \nSi ricorda che ogni elemento della matrice di covarianza può essere calcolato come  \n𝜎𝑖𝑗=1\n𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛\n𝑘=1   \ndove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  \n \nSvolgimento  \n \n𝛍=[6,1+6,5+8,8+5,2+0,8\n5\n8,1+1,9+4,2+9,7+5,4\n5]=[5,5\n5,9] \n \n𝚺=[6,9−1,4\n−1,47,7] \n \n Machine Learning                        Matricola: ___________________  \n20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n \nNeuroni livello \ncorrente  Somma Bias  Una somma  per ogni \nneurone livello \nprecedente  Una moltiplicazione \nper ogni neurone \nlivello precedente  \nNOTA:  Il calcolo a lato è eseguito t rascurando il fatto che \nun’implementazione ottimizzata della sommatoria potrebbe \nevitare una somma per il primo elemento della sommatoria \n(somma con 0).  5) Data una rete neurale MLP a 3 livelli con bias composta da:  \n \nx 6 neuroni per l’input layer  \nx 8 neuroni per l’hidden layer  \nx 5 neuroni di output  \n \nQuante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le \noperazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di \noperazioni per livello.  \n \nSvolgimento  \n \nPer ogni neurone del livello corrente si deve calcolare la seguente formula:  \n𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗\n𝑗=1..𝑑+𝑤0𝑖 \n \nche comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale \ndel bias. Pertanto:  \n \n \n \n \n \nNumero operazioni l ivello hidden: 8⋅(6+6+1)=104 \n \nNumero operazioni livello di output: 5⋅(8+8+1)=85 \n \nTotale: 189 \n \n \n6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  \n \n{[6,1\n8,1],[6,5\n1,9],[8,8\n4,2],[5,2\n9,7],[0,8\n5,4]} \n \nCalcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  \n \nSi ricorda che ogni elemento della matrice di covarianza può essere calcolato come  \n𝜎𝑖𝑗=1\n𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛\n𝑘=1   \ndove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  \n \nSvolgimento  \n \n𝛍=[6,1+6,5+8,8+5,2+0,8\n5\n8,1+1,9+4,2+9,7+5,4\n5]=[5,5\n5,9] \n \n𝚺=[6,9−1,4\n−1,47,7] \n \n Machine Learning                        Matricola: ___________________  \n20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n \nNeuroni livello \ncorrente  Somma Bias  Una somma  per ogni \nneurone livello \nprecedente  Una moltiplicazione \nper ogni neurone \nlivello precedente  \nNOTA:  Il calcolo a lato è eseguito t rascurando il fatto che \nun’implementazione ottimizzata della sommatoria potrebbe \nevitare una somma per il primo elemento della sommatoria \n(somma con 0).  ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#27": "Esercizio 25) Data una rete neurale MLP a 3 livelli con bias composta da:  \n \nx 6 neuroni per l’input layer  \nx 8 neuroni per l’hidden layer  \nx 5 neuroni di output  \n \nQuante somme e moltiplicazioni sono necessarie per il passo forward di un generico pattern trascurando le \noperazioni effettuate dalla funzione di attivazione? Motivare la rispost a riportando anche il numero di \noperazioni per livello.  \n \nSvolgimento  \n \nPer ogni neurone del livello corrente si deve calcolare la seguente formula:  \n𝑛𝑒𝑡𝑖=∑𝑤𝑗𝑖⋅𝑖𝑛𝑗\n𝑗=1..𝑑+𝑤0𝑖 \n \nche comprende una moltiplicazione e una somma per ogni neurone del livello precedente più la somma finale \ndel bias. Pertanto:  \n \n \n \n \n \nNumero operazioni l ivello hidden: 8⋅(6+6+1)=104 \n \nNumero operazioni livello di output: 5⋅(8+8+1)=85 \n \nTotale: 189 \n \n \n6) Dato un insieme  di pattern bi -dimensionali composto da 5 elementi:  \n \n{[6,1\n8,1],[6,5\n1,9],[8,8\n4,2],[5,2\n9,7],[0,8\n5,4]} \n \nCalcolare il vettore medio ( 𝛍) e la matrice di covarianza ( 𝚺=[𝜎𝑖𝑗]).  \n \nSi ricorda che ogni elemento della matrice di covarianza può essere calcolato come  \n𝜎𝑖𝑗=1\n𝑛∑(x𝑘𝑖−μ𝑖)⋅(x𝑘𝑗−μ𝑗)𝑛\n𝑘=1   \ndove x𝑘𝑚 è l’m-esimo elemento del k-esimo pattern, e n il numero di pattern.  \n \nSvolgimento  \n \n𝛍=[6,1+6,5+8,8+5,2+0,8\n5\n8,1+1,9+4,2+9,7+5,4\n5]=[5,5\n5,9] \n \n𝚺=[6,9−1,4\n−1,47,7] \n \n Machine Learning                        Matricola: ___________________  \n20-Gen-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n \nNeuroni livello \ncorrente  Somma Bias  Una somma  per ogni \nneurone livello \nprecedente  Una moltiplicazione \nper ogni neurone \nlivello precedente  \nNOTA:  Il calcolo a lato è eseguito t rascurando il fatto che \nun’implementazione ottimizzata della sommatoria potrebbe \nevitare una somma per il primo elemento della sommatoria \n(somma con 0).  ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#28": "Esercizio 3\n7) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  \n𝝁1=[0,75\n4,69\n9,57] \n 𝝁2=[1,74\n0,80\n9,59] \n 𝝁3=[6,32\n7,94\n1,82] \n \n𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). \nIndicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la \nrisposta):  \n \n𝐩1=[0,85\n5,12\n9,52],𝐩2=[9,73\n4,30\n5,41] \n \nSvolgimento  \n \nLa regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a \nposteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)\n𝑝(𝐱). \nDato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a \nposteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . \nPertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  \n𝑝(𝐱|𝑤𝑖)=1\n(2𝜋)𝑑\n2⋅|𝚺𝑖|1\n2⋅𝑒−1\n2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) \ne che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di \nBayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al \nquadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). \n \n𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 \n \n𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 \n \n𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  7) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  \n𝝁1=[0,75\n4,69\n9,57] \n 𝝁2=[1,74\n0,80\n9,59] \n 𝝁3=[6,32\n7,94\n1,82] \n \n𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). \nIndicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la \nrisposta):  \n \n𝐩1=[0,85\n5,12\n9,52],𝐩2=[9,73\n4,30\n5,41] \n \nSvolgimento  \n \nLa regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a \nposteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)\n𝑝(𝐱). \nDato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a \nposteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . \nPertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  \n𝑝(𝐱|𝑤𝑖)=1\n(2𝜋)𝑑\n2⋅|𝚺𝑖|1\n2⋅𝑒−1\n2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) \ne che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di \nBayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al \nquadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). \n \n𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 \n \n𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 \n \n𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#29": "Esercizio 37) Date tre distribuzioni  multinormali identificate dai seguenti parametri:  \n𝝁1=[0,75\n4,69\n9,57] \n 𝝁2=[1,74\n0,80\n9,59] \n 𝝁3=[6,32\n7,94\n1,82] \n \n𝚺1=𝚺2=𝚺3=I (matrice identità) e 𝑃(𝑤1)=𝑃(𝑤2)=𝑃(𝑤3). \nIndicare la classe assegnata ai seguenti pattern da un classificatore di Bayes multinormale (motivandone la \nrisposta):  \n \n𝐩1=[0,85\n5,12\n9,52],𝐩2=[9,73\n4,30\n5,41] \n \nSvolgimento  \n \nLa regola di classificazione di Bayes assegna un pattern 𝐱 alla classe 𝑤𝑖 per cui è massima la probabilità a \nposteriori 𝑃(𝑤𝑖|𝐱)=𝑝(𝐱|𝑤𝑖)⋅𝑃(𝑤𝑖)\n𝑝(𝐱). \nDato  che la probabilità a priori delle tre distribuzioni è la stessa,  determinare la classe con  probabilità a \nposteriori  massima  equivale a individuare  la classe con  densità di probabilità condizionale 𝑝(𝐱|𝑤𝑖) massima . \nPertanto, sapendo che la densità di probabilità condizionale nella distribuzione multinormale è:  \n𝑝(𝐱|𝑤𝑖)=1\n(2𝜋)𝑑\n2⋅|𝚺𝑖|1\n2⋅𝑒−1\n2⋅(𝐱−𝝁𝑖)𝑡⋅𝚺𝑖−1⋅(𝐱−𝝁𝑖) \ne che le tre matrici di covarianza sono uguali  alla matrice  identità , la classe restituita dal classificatore di \nBayes sarà quella con il valore (𝐱−𝝁𝑖)𝑡⋅(𝐱−𝝁𝑖) minimo (che corrisponde alla distanza euclidea al \nquadrato  𝐷2 tra il pattern  𝐱 e il vettore medio  𝝁𝑖). \n \n𝐷2(𝐩1,𝝁1)=𝟎,𝟐𝟎  𝐷2(𝐩1,𝝁2)=19,46  𝐷2(𝐩1,𝝁3)=97,16 \n \n𝐷2(𝐩2,𝝁1)=98,10  𝐷2(𝐩2,𝝁2)=93,56  𝐷2(𝐩2,𝝁3)=𝟑𝟕,𝟕𝟕 \n \n𝐩1 viene assegnato alla classe 1 mentre 𝐩2 viene assegnato alla classe 3.  ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#3": "Appr occi Non Parametrici e Stima della Densità\n!In Teoria della Probabilità, la distribuzione binomiale è una \ndistribuzione di probabilità discreta che descrive il numero di \nsuccessi in un processo di Bernoulli!Tale processo vale nel caso di esperimenti di prove ripetute (i.e., \nesperimenti in cui si vuole misurare quante volte si verifichi un \ncerto esito su tutte le prove effettuate)!E’ necessario che il risultato di una prova non influenzi le \nsuccessive, ossia che le singole prove siano fra loro indipendenti!La formula da utilizzare in questi casi è la Formula di Bernoulli : \nse l’evento da noi indagato ha una probabilità p di verificarsi per \nciascuna prova ed effettuiamo n prove indipendenti, la probabilità \nche l’evento si verifichi kvolte (con k ≤ n) è data da\nP(k successi su n prove)=n\nk⎛\n⎝⎜⎜⎞\n⎠⎟⎟pk⋅(1−p)n−k",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#30": "Esercizio 4 \n5) Un multiclassificatore, composto da 3 classificatori combinati a livello di decisione utilizzando Borda \ncount come tecnica di fusione, viene utilizzato per riconoscere pattern appartenenti a 4 classi. Nella tabella \nseguente sono riportati i ranking restituit i dai singoli classificatori ( 𝐶𝑖) dati in input 3 diversi pattern ( 𝒑𝑗). \nCompletare la tabella nell’ipotesi che alla prima classe siano assegnati 10 punti, alla seconda 7, alla terza 5 e \nalla quarta 2.  \n \n 𝐶1 𝐶2 𝐶3 \n 𝒑1 4 2 1 3 2 4 1 3 1 4 2 3 \n𝒑2 1 2 3 4 1 3 2 4 2 1 3 4 \n𝒑3 3 2 4 1 2 4 3 1 3 2 1 4 \n \n Punteggi Classi  Classe \nscelta  1 2 3 4 \n 𝒑1 20 22 6 24 4 \n𝒑2 27 22 17 6 1 \n𝒑3 9 24 25 14 3 \n \n \n6) Data un rete neurale MLP a 3 livelli  con bias  composta da : \n \n• 6 neuroni di Input  \n• 8 neuroni Intermedi  \n• 5 neuroni di Output  \n \nCalcolare, motivandone la risposta, il numero di pesi totale.  \n \nSvolgimento  \n \nNel caso di una rete  neurale  MLP il numero di pesi è pari al numero di connessioni  presenti.  Il numero di \nconnessioni (e quindi di pesi) presenti t ra due livelli consecutivi ( 𝑖 e 𝑖+1) si può calcolare come il prodotto  \ndel numero di neuroni  del livello 𝑖 per il numero di neuroni del livello 𝑖+1. Nel caso dell’utilizzo del bias, il \nnumero di neuroni di ogni livello  𝑖 dovrà essere incrementato di u no. \n \nPertanto il numero totale di pesi sarà pari a: (6+1)⋅8+ (8+1)⋅5=101. \n \n \n7)  Date due distribuzioni multinormali identificate dai seguenti parametri:  \n𝝁0=[10,90\n−0,43] \n𝚺0−1=[1,531,27\n1,271,61] \n|𝚺0|=1,170996  \n𝑃(𝑤0)=0,55 𝝁1=[2,87\n2,90] \n𝚺1−1=[0,41−0,14\n−0,140,35] \n|𝚺1|=8,005816  \n𝑃(𝑤1)=0,45 \nNell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[7,05\n0,96]: \nle densità di probabilità condizionali;  \nx le probabilità a posteriori;  \nx l’indice della  classe restituita in output.  \n \nSi ricorda che la densità di probabilità, nel caso della distribuzione multinormale è:  \n𝑝(𝒙)=1\n(2𝜋)𝑑\n2⋅|𝚺|1\n2⋅𝑒−1\n2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) Machine Learning                        Matricola: ___________________  \n17-Lug-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n  \n5) Un multiclassificatore, composto da 3 classificatori combinati a livello di decisione utilizzando Borda \ncount come tecnica di fusione, viene utilizzato per riconoscere pattern appartenenti a 4 classi. Nella tabella \nseguente sono riportati i ranking restituit i dai singoli classificatori ( 𝐶𝑖) dati in input 3 diversi pattern ( 𝒑𝑗). \nCompletare la tabella nell’ipotesi che alla prima classe siano assegnati 10 punti, alla seconda 7, alla terza 5 e \nalla quarta 2.  \n \n 𝐶1 𝐶2 𝐶3 \n 𝒑1 4 2 1 3 2 4 1 3 1 4 2 3 \n𝒑2 1 2 3 4 1 3 2 4 2 1 3 4 \n𝒑3 3 2 4 1 2 4 3 1 3 2 1 4 \n \n Punteggi Classi  Classe \nscelta  1 2 3 4 \n 𝒑1 20 22 6 24 4 \n𝒑2 27 22 17 6 1 \n𝒑3 9 24 25 14 3 \n \n \n6) Data un rete neurale MLP a 3 livelli  con bias  composta da : \n \n• 6 neuroni di Input  \n• 8 neuroni Intermedi  \n• 5 neuroni di Output  \n \nCalcolare, motivandone la risposta, il numero di pesi totale.  \n \nSvolgimento  \n \nNel caso di una rete  neurale  MLP il numero di pesi è pari al numero di connessioni  presenti.  Il numero di \nconnessioni (e quindi di pesi) presenti t ra due livelli consecutivi ( 𝑖 e 𝑖+1) si può calcolare come il prodotto  \ndel numero di neuroni  del livello 𝑖 per il numero di neuroni del livello 𝑖+1. Nel caso dell’utilizzo del bias, il \nnumero di neuroni di ogni livello  𝑖 dovrà essere incrementato di u no. \n \nPertanto il numero totale di pesi sarà pari a: (6+1)⋅8+ (8+1)⋅5=101. \n \n \n7)  Date due distribuzioni multinormali identificate dai seguenti parametri:  \n𝝁0=[10,90\n−0,43] \n𝚺0−1=[1,531,27\n1,271,61] \n|𝚺0|=1,170996  \n𝑃(𝑤0)=0,55 𝝁1=[2,87\n2,90] \n𝚺1−1=[0,41−0,14\n−0,140,35] \n|𝚺1|=8,005816  \n𝑃(𝑤1)=0,45 \nNell’ipotesi dell’impiego di un classificatore di Bayes multinormale, calcolare per il punto 𝒙=[7,05\n0,96]: \nle densità di probabilità condizionali;  \nx le probabilità a posteriori;  \nx l’indice della  classe restituita in output.  \n \nSi ricorda che la densità di probabilità, nel caso della distribuzione multinormale è:  \n𝑝(𝒙)=1\n(2𝜋)𝑑\n2⋅|𝚺|1\n2⋅𝑒−1\n2⋅(𝒙−𝝁)t⋅𝚺−1⋅(𝒙−𝝁) Machine Learning                        Matricola: ___________________  \n17-Lug-2017 ( 90 minuti )     Cognome: __________ Nome: ____________  \n \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#31": "Esercizio 4\nSvolgimento  \n \n𝒙−𝝁0=[7,05\n0,96]−[10,90\n−0,43]=[−3,85\n1,39] \n \n𝑝(𝒙|𝑤0)=1\n2𝜋⋅√1,170996⋅𝑒−1\n2⋅[−3,851,39]⋅[1,531,27\n1,271,61]⋅[−3,85\n1,39] \n \n[1,531,27\n1,271,61]⋅[−3,85\n1,39]=[1,53⋅(−3,85)+1,27⋅1,39\n1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252\n−2,6516] \n \n[−3,851,39]⋅[−4,1252\n−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  \n \n𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296\n2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) \n \n𝒙−𝝁1=[7,05\n0,96]−[2,87\n2,90]=[4,18\n−1,94] \n \n𝑝(𝒙|𝑤1)=1\n2𝜋⋅√8,005816⋅𝑒−1\n2⋅[4,18−1,94]⋅[0,41−0,14\n−0,140,35]⋅[4,18\n−1,94] \n \n[0,41−0,14\n−0,140,35]⋅[4,18\n−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)\n(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854\n−1,2642] \n \n[4,18−1,94]⋅[1.9854\n−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  \n \n𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152\n2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) \n \n𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) \n \n𝑝(𝑤0|𝒙)=0,000330⋅0,55\n0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) \n \n𝑝(𝑤1|𝒙)=0,000260⋅0,45\n0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) \n \nIndice della classe restituita: 0 \n \n \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#32": "Esercizio 4Svolgimento  \n \n𝒙−𝝁0=[7,05\n0,96]−[10,90\n−0,43]=[−3,85\n1,39] \n \n𝑝(𝒙|𝑤0)=1\n2𝜋⋅√1,170996⋅𝑒−1\n2⋅[−3,851,39]⋅[1,531,27\n1,271,61]⋅[−3,85\n1,39] \n \n[1,531,27\n1,271,61]⋅[−3,85\n1,39]=[1,53⋅(−3,85)+1,27⋅1,39\n1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252\n−2,6516] \n \n[−3,851,39]⋅[−4,1252\n−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  \n \n𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296\n2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) \n \n𝒙−𝝁1=[7,05\n0,96]−[2,87\n2,90]=[4,18\n−1,94] \n \n𝑝(𝒙|𝑤1)=1\n2𝜋⋅√8,005816⋅𝑒−1\n2⋅[4,18−1,94]⋅[0,41−0,14\n−0,140,35]⋅[4,18\n−1,94] \n \n[0,41−0,14\n−0,140,35]⋅[4,18\n−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)\n(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854\n−1,2642] \n \n[4,18−1,94]⋅[1.9854\n−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  \n \n𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152\n2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) \n \n𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) \n \n𝑝(𝑤0|𝒙)=0,000330⋅0,55\n0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) \n \n𝑝(𝑤1|𝒙)=0,000260⋅0,45\n0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) \n \nIndice della classe restituita: 0 \n \n \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#33": "Esercizio 4Svolgimento  \n \n𝒙−𝝁0=[7,05\n0,96]−[10,90\n−0,43]=[−3,85\n1,39] \n \n𝑝(𝒙|𝑤0)=1\n2𝜋⋅√1,170996⋅𝑒−1\n2⋅[−3,851,39]⋅[1,531,27\n1,271,61]⋅[−3,85\n1,39] \n \n[1,531,27\n1,271,61]⋅[−3,85\n1,39]=[1,53⋅(−3,85)+1,27⋅1,39\n1,27⋅(−3,85)+1,61⋅1,39]=[−4,1252\n−2,6516] \n \n[−3,851,39]⋅[−4,1252\n−2,6516]=(−3,85)⋅(−4,1252)+1,39⋅(−2,6516)=12,196296  \n \n𝑝(𝒙|𝑤0)=0,147076⋅𝑒−12,196296\n2=0,000330  (Densità di probabilità condizionale di 𝒙 data 𝑤0) \n \n𝒙−𝝁1=[7,05\n0,96]−[2,87\n2,90]=[4,18\n−1,94] \n \n𝑝(𝒙|𝑤1)=1\n2𝜋⋅√8,005816⋅𝑒−1\n2⋅[4,18−1,94]⋅[0,41−0,14\n−0,140,35]⋅[4,18\n−1,94] \n \n[0,41−0,14\n−0,140,35]⋅[4,18\n−1,94]=[0,41⋅4,18+(−0,14)⋅(−1,94)\n(−0,14)⋅4,18+0,35⋅(−1,94)]=[1.9854\n−1,2642] \n \n[4,18−1,94]⋅[1.9854\n−1,2642]=4,18⋅1.9854+(−1,94)⋅(−1,2642)=10,75152  \n \n𝑝(𝒙|𝑤1)=0,056249⋅𝑒−10,75152\n2=0,000260  (Densità di probabilità condizionale di 𝒙 data 𝑤1) \n \n𝑝(𝒙)=0,000330⋅0,55+0,000260⋅0,45=0,000299  (Densità di probabilità assoluta dato 𝒙) \n \n𝑝(𝑤0|𝒙)=0,000330⋅0,55\n0,000299=0,608 (Probabilità a posteriori di 𝑤0 dato 𝒙) \n \n𝑝(𝑤1|𝒙)=0,000260⋅0,45\n0,000299=0,392 (Probabilità a posteriori di 𝑤1 dato 𝒙) \n \nIndice della classe restituita: 0 \n \n \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#34": "Si supponga di partecipare a un gioco \na premi, in cui si può scegliere fra tre \nporte: dietro una di esse c’è \nun’automobile, dietro le altre, due \ncapre. \nSi sceglie una porta, diciamo la numero \n1. A quel punto, il conduttore del gioco \na premi, che sa cosa si nasconde \ndietro ciascuna porta, ne apre un’altra, \ndiciamo la 3, rivelando una capra. \nQuindi domanda: “vorresti scegliere la \nnumero 2 o conservare la tua scelta \niniziale?”\nTi conviene cambiare la tua scelta \noriginale?\nProblema",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#35": "Dal quiz televisivo americano Let’s Make a Deal , \ncondotto dal presentatore Maurice Halprin , noto\ncon lo pseudonimo di Monty Hall. \n4500 puntate dal 1963 al 1991.\nIl concorrente deve scegliere una delle tre\nporte chiuse cheha davanti a sé: dietro a due \ndi esse c’èuna capra , dietro l’altra c’èuna \nautomobile . \nOvviamente , né luiné ilpubblico sanno dietro\na quale porta sitrova l’auto .\nIl concorrente fa la suascelta .\nProblema di Monty Hall",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#36": "A questo punto, ilpresentatore apre\nuna delle altre due porte , rivelando\nuna capra .\nQuindi chiede al concorrente se vuole\nmantenere la porta scelta , o se vuole\ncambiarla .\nDomanda : al concorrente conviene\ncambiare ? \nLa risposta sembra ovvia : sono rimaste\ndue porte , e dietro una di esse c’è\nl’auto . Cambiare porta non dovrebbe\ninfluenzare le probabilità di vincita chea \nquesto punto èlogico ritenere pari a 1/2, \nchesidecida di cambiare o meno .Problema di Monty Hall",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#37": "Problema di Monty Hall",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#38": "Problema di Monty Hall",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#39": "Problema di Monty Hall",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#4": "Appr occi Non Parametrici e Stima della Densità\n!Esempi di casi di distribuzione binomiale sono i risultati di una \nserie di lanci di una stessa moneta o di una serie di estrazioni \nda un'urna (con reintroduzione o reimbussolamento), ognuna \ndelle quali può fornire due soli risultati : il successo con \nprobabilità pe il fallimento con probabilità q=1−p!Reimbussolamento: dovendo estrarre un certo numero di \ncarte/palline/numeri da un mazzo/urna/bussolo, ogni oggetto \nestratto è immesso nuovamente prima di estrarre \ncarte/palline/numeri successivi",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#40": "h\"ps ://www.youtube.com /watch?v =nYX8DMG8_ywProblema di Monty Hall",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#5": "Appr occi Non Parametrici e Stima della Densità\n21prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneApprocci non parametrici e\nStima della Densità\nNon vengono fatte ipotesi sulle distribuzioni deipattern eledensità\ndiprobabilità sono stimate direttamente daltraining set.\nIlproblema della stima accurata della densità èritenuto damolti un\nproblema piùcomplesso della classificazione .Pertanto perché\nrisolvere come sotto -problema unproblema che èpiùcomplesso\ndell’intero compito diclassificazione ?\nIngenerale lastima della densità èaffrontabile inspazi a\ndimensionalità ridotta (es.𝑑=3)ediventa critica alcrescere della\ndimensionalità (curse ofdimensionality ):ilvolume dello spazio\naumenta così tanto cheipattern diventato troppo sparsi .\nStima Densità\nLaprobabilità cheunpattern𝐱cadaall’interno diè:\n𝑃1=න\n𝑝𝐱′𝑑𝐱′\nDati𝑛pattern indipendenti, laprobabilità che𝑘diquesti cadano\nnella regioneècalcolabile attraverso ladistribuzione binomiale :\n𝑃𝑘=𝑛\n𝑘𝑃1𝑘1−𝑃1𝑛−𝑘\nilcuivalor medio è𝑘=𝑛𝑃1(equindi𝑃1=𝑘/𝑛)\nAssumendo che laregione (divolume𝑉)siapiccola eche\nquindi𝑝∙nonvarisignificativamente all’interno diessa :\n𝑃1=න\n𝑝𝐱′𝑑𝐱′≈𝑝𝐱∙𝑉\n𝑝𝐱=𝑃1\n𝑉=𝑘\n𝑛∙𝑉",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#6": "Parzen Window\n22prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneParzen Window\nLaregione ,denominata finestra (Window ),ècostituita daun\nipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:\n𝜑𝐮=ቐ1𝑢𝑗≤1\n2,𝑗=1…𝑑\n0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖\nDato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi\nvolume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono\nall’interno dell’iper-cubo èdato da:\n𝑘𝑛=෍\n𝑖=1𝑛\n𝜑𝐱𝑖−𝐱\nℎ𝑛\nsostituendo 𝑘𝑛(vedi lucido precedente) siottiene :\n𝑝𝑛𝐱=1\n𝑛∙𝑉𝑛෍\n𝑖=1𝑛\n𝜑𝐱𝑖−𝐱\nℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑\nOvviamente, specie nelcaso incuiilnumero dipattern non sia\nelevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun\nforte impatto sulrisultato, infatti :\nSe\nlafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,\nmolto attratta daicampioni estatisticamente instabile .\nSe\nlafinestra ègrande lastima èpiùstabile mapiuttosto vaga\nesfuocata .\nSidimostra che perottenere convergenza ,ladimensione della\nfinestra deve essere calcolata tenendo conto del numero di\ncampioni deltraining set:\n𝑉𝑛=𝑉1\n𝑛,dove𝑉1oℎ1èuniperparametro",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#7": "Parzen Window\n22prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneParzen Window\nLaregione ,denominata finestra (Window ),ècostituita daun\nipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:\n𝜑𝐮=ቐ1𝑢𝑗≤1\n2,𝑗=1…𝑑\n0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖\nDato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi\nvolume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono\nall’interno dell’iper-cubo èdato da:\n𝑘𝑛=෍\n𝑖=1𝑛\n𝜑𝐱𝑖−𝐱\nℎ𝑛\nsostituendo 𝑘𝑛(vedi lucido precedente) siottiene :\n𝑝𝑛𝐱=1\n𝑛∙𝑉𝑛෍\n𝑖=1𝑛\n𝜑𝐱𝑖−𝐱\nℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑\nOvviamente, specie nelcaso incuiilnumero dipattern non sia\nelevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun\nforte impatto sulrisultato, infatti :\nSe\nlafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,\nmolto attratta daicampioni estatisticamente instabile .\nSe\nlafinestra ègrande lastima èpiùstabile mapiuttosto vaga\nesfuocata .\nSidimostra che perottenere convergenza ,ladimensione della\nfinestra deve essere calcolata tenendo conto del numero di\ncampioni deltraining set:\n𝑉𝑛=𝑉1\n𝑛,dove𝑉1oℎ1èuniperparametro\n22prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneParzen Window\nLaregione ,denominata finestra (Window ),ècostituita daun\nipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:\n𝜑𝐮=ቐ1𝑢𝑗≤1\n2,𝑗=1…𝑑\n0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖\nDato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi\nvolume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono\nall’interno dell’iper-cubo èdato da:\n𝑘𝑛=෍\n𝑖=1𝑛\n𝜑𝐱𝑖−𝐱\nℎ𝑛\nsostituendo 𝑘𝑛(vedi lucido precedente) siottiene :\n𝑝𝑛𝐱=1\n𝑛∙𝑉𝑛෍\n𝑖=1𝑛\n𝜑𝐱𝑖−𝐱\nℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑\nOvviamente, specie nelcaso incuiilnumero dipattern non sia\nelevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun\nforte impatto sulrisultato, infatti :\nSe\nlafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,\nmolto attratta daicampioni estatisticamente instabile .\nSe\nlafinestra ègrande lastima èpiùstabile mapiuttosto vaga\nesfuocata .\nSidimostra che perottenere convergenza ,ladimensione della\nfinestra deve essere calcolata tenendo conto del numero di\ncampioni deltraining set:\n𝑉𝑛=𝑉1\n𝑛,dove𝑉1oℎ1èuniperparametro\n22prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneParzen Window\nLaregione ,denominata finestra (Window ),ècostituita daun\nipercubo 𝑑-dimensionale, definito dalla funzione 𝜑:\n𝜑𝐮=ቐ1𝑢𝑗≤1\n2,𝑗=1…𝑑\n0𝑎𝑙𝑡𝑟𝑖𝑚𝑒𝑛𝑡𝑖\nDato ungenerico ipercubo centrato in𝐱eavente latoℎ𝑛(equindi\nvolume𝑉𝑛=ℎ𝑛𝑑)ilnumero dipattern deltraining setchecadono\nall’interno dell’iper-cubo èdato da:\n𝑘𝑛=෍\n𝑖=1𝑛\n𝜑𝐱𝑖−𝐱\nℎ𝑛\nsostituendo 𝑘𝑛(vedi lucido precedente) siottiene :\n𝑝𝑛𝐱=1\n𝑛∙𝑉𝑛෍\n𝑖=1𝑛\n𝜑𝐱𝑖−𝐱\nℎ𝑛,dove𝑉𝑛=ℎ𝑛𝑑\nOvviamente, specie nelcaso incuiilnumero dipattern non sia\nelevato, ladimensione della finestra𝑉𝑛(equindi illatoℎ𝑛)haun\nforte impatto sulrisultato, infatti :\nSe\nlafinestra èpiccola ,lastima risulta piuttosto “rumorosa ”,\nmolto attratta daicampioni estatisticamente instabile .\nSe\nlafinestra ègrande lastima èpiùstabile mapiuttosto vaga\nesfuocata .\nSidimostra che perottenere convergenza ,ladimensione della\nfinestra deve essere calcolata tenendo conto del numero di\ncampioni deltraining set:\n𝑉𝑛=𝑉1\n𝑛,dove𝑉1oℎ1èuniperparametro",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#8": "Iperparametri\n14prof. Davide Maltoni –Università di Bologna\nML\nFondamentiIperparametri\nMolto\n algoritmi richiedono didefinire, primadell’apprendimento\nvero eproprio, ilvalore deicosiddetti iperparametri H.\nEsempi\n diiperparametri :\nIl\nnumero dineuroni inunareteneurale .\nIl\nnumero divicini kinunclassificatore k-NN.\nIl\ngrado diunpolinomio utilizzato inunaregressione .\nIl\ntipodilossfunction .\nSi\nprocede con unapproccio adue livelli nelquale perogni\nvalore «ragionevole » degli iperparametri si esegue\nl’apprendimento, ealtermine della procedura siscelgono gli\niperparametri chehanno fornito prestazioni migliori .\nMa\ncome sivalutano leprestazioni ,esuquali dati?",
    "data_test\\rootfolder\\università\\MachineLearning\\31-CB(3)-sbloccato.pdf#9": "Iperparametri\n!Ricordiamo che\n!Il Training Set è l’insieme di pattern su cui addestrare il \nsistema, trovando il valore ottimo per i parametri (e.g., i pesi \ndelle connessioni in una rete neurale)!Il Validation Set è l’insieme di pattern su cui tarare gli \niperparametri (ciclo esterno)!Il Test Set è l’insieme di pattern su cui valutare le prestazioni \nfinali del sistema\n!N.B. Sempre forte è la tentazione di tarare gli iperparametri \ndirettamente sul Test Set, ma questo dovrebbe essere evitato, \npena sovrastima delle prestazioni! ",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#0": "Machine Learning\nUniversità Roma Tre  \nDipartimento di Ingegneria \nAnno Accademico 2019 -2020\nBayes & Nearest Neighbor",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#1": "Classiﬁcatore Nearest Neighbor (NN)\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#10": "Da NN a k-NN\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#11": "Da NN a k-NN\n28prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDa NN a k-NN\nLa\nregola nearest neighbor produce unpartizionamento dello\ndello spazio, noto come tassellazione diVoronoi :\nOgni elemento 𝐱𝑖∈TSdetermina untassello, all’interno delquale i\npattern saranno assegnati allastessa classe di𝐱𝑖.\nLa\nregola diclassificazione nearest neighbor èpiuttosto radicale ;\ninfatti basta che unelemento deltraining setnon siamolto\n“affidabile” (outlier )affinché tuttiipattern nelle suevicinanze siano\ninseguito etichettati noncorrettamente .\nChe\n errore commette ilclassificatore NNsultraining set?\nUn\nmodo generalmente piùrobusto ,chepuòessere visto come\nestensione della regola nearest -neighbor (inquesto caso detta\n1-nearest neighbor )èilcosiddetto classificatore k-nearest\nneighbor (k-NN).\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#12": "k-Nearest Neighbor ( k-NN)\n29prof. Davide Maltoni –Università di Bologna\nML\nClassificazionek-Nearest -Neighbor (k-NN)\nLa\nregola k-Nearest Neighbor (k-NN)determina ikelementi più\nvicini alpattern𝐱daclassificare (kèuniperparametro );ogni\npattern traikvicini vota perlaclasse cuiesso stesso appartiene ;\nilpattern𝐱viene assegnato allaclasse chehaottenuto ilmaggior\nnumero divoti.\nPer\nTSinfiniti laregola diclassificazione k-NNsidimostra migliore\ndi1-NN, eall’aumentare dik,l’errore Pconverge all’errore\nBayesiano .\nNella\n pratica (TSlimitati), aumentare ksignifica estendere l’iper-\nsfera diricerca andando asondare laprobabilità aposteriori\nlontano dalpunto diinteresse ;ilvalore ottimale dik(solitamente\n<10)deve essere determinato suunvalidation setseparato .\nnella figura il classificatore 5-NN,\nassegna 𝐱alla classe “nera”\nin quanto quest’ultima ha ricevuto 3 \nvoti su 5.\nNel caso di 2 classi è bene \nscegliere k dispari per evitare \npareggi.",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#13": "k-Nearest Neighbor ( k-NN)4.5. THE NEAREST-NEIGHBOR RULE 27\nby examining the labels on the knearest neighbors and taking a vote (Fig. 4.15). We\nshall not go into a thorough analysis of the k-nearest-neighbor rule. However, by\nconsidering the two-class case with kodd (to avoid ties), we can gain some additional\ninsight into these procedures.\nx\nx1x2\nFigure 4.15: The k-nearest-neighbor query starts at the test point and grows a spher-\nical region until it encloses ktraining samples, and labels the test point by a majority\nvote of these samples. In this k= 5 case, the test point xwould be labelled the\ncategory of the black points.\nThe basic motivation for considering the k-nearest-neighbor rule rests on our ear-\nlier observation about matching probabilities with nature. We notice ﬁrst that if\nkis ﬁxed and the number nof samples is allowed to approach inﬁnity, then all of\ntheknearest neighbors will converge to x. Hence, as in the single-nearest-neighbor\ncases, the labels on each of the k-nearest-neighbors are random variables, which in-\ndependently assume the values ωiwith probabilities P(ωi|x),i=1,2. If P(ωm|x)\nis the larger a posteriori probability, then the Bayes decision rule always selects ωm.\nThe single-nearest-neighbor rule selects ωmwith probability P(ωm|x). The k-nearest-\nneighbor rule selects ωmif a majority of the knearest neighbors are labeled ωm, an\nevent of probability\nk/summationdisplay\ni=(k+1)/2/parenleftbiggk\ni/parenrightbigg\nP(ωm|x)i[1−P(ωm|x)]k−i. (54)\nIn general, the larger the value of k, the greater the probability that ωmwill be\nselected.\nWe could analyze the k-nearest-neighbor rule in much the same way that we\nanalyzed the single-nearest-neighbor rule. However, since the arguments become more\ninvolved and supply little additional insight, we shall content ourselves with stating\nthe results. It can be shown that if kis odd, the large-sample two-class error rate for\nthek-nearest-neighbor rule is bounded above by the function Ck(P∗), where Ck(P∗)\nis deﬁned to be the smallest concave function of P∗greater than\n(k−1)/2/summationdisplay\ni=0/parenleftbiggk\ni/parenrightbigg/bracketleftbig\n(P∗)i+1(1−P∗)k−i+(P∗)k−i(1−P∗)i+1/bracketrightbig\n. (55)",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#14": "k-Nearest Neighbor ( k-NN)\n29prof. Davide Maltoni –Università di Bologna\nML\nClassificazionek-Nearest -Neighbor (k-NN)\nLa\nregola k-Nearest Neighbor (k-NN)determina ikelementi più\nvicini alpattern𝐱daclassificare (kèuniperparametro );ogni\npattern traikvicini vota perlaclasse cuiesso stesso appartiene ;\nilpattern𝐱viene assegnato allaclasse chehaottenuto ilmaggior\nnumero divoti.\nPer\nTSinfiniti laregola diclassificazione k-NNsidimostra migliore\ndi1-NN, eall’aumentare dik,l’errore Pconverge all’errore\nBayesiano .\nNella\n pratica (TSlimitati), aumentare ksignifica estendere l’iper-\nsfera diricerca andando asondare laprobabilità aposteriori\nlontano dalpunto diinteresse ;ilvalore ottimale dik(solitamente\n<10)deve essere determinato suunvalidation setseparato .\nnella figura il classificatore 5-NN,\nassegna 𝐱alla classe “nera”\nin quanto quest’ultima ha ricevuto 3 \nvoti su 5.\nNel caso di 2 classi è bene \nscegliere k dispari per evitare \npareggi.",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#15": "k-Nearest Neighbor ( k-NN)28 CHAPTER 4. NONPARAMETRIC TECHNIQUES\nHere the summation over the ﬁrst bracketed term represents the probability of error\ndue to ipoints coming from the category having the minimum probability and k−i>i\npoints from the other category. The summation over the second term in the brackets\nis the probability that k−ipoints are from the minimum-probability category and\ni+1<k−ifrom the higher probability category. Both of these cases constitute\nerrors under the k-nearest-neighbor decision rule, and thus we must add them to ﬁnd\nthe full probability of error (Problem 18).\nFigure 4.16 shows the bounds on the k-nearest-neighbor error rates for several\nvalues of k. As kincreases, the upper bounds get progressively closer to the lower\nbound — the Bayes rate. In the limit as kgoes to inﬁnity, the two bounds meet and\nthek-nearest-neighbor rule becomes optimal.\n0 0.1 0.2 0.3 0.40.10.20.30.4\nBayes Rate\nP*P\n1\n3\n5\n9\n150.5\nFigure 4.16: The error-rate for the k-nearest-neighbor rule for a two-category problem\nis bounded by Ck(P∗) in Eq. 55. Each curve is labelled by k; when k=∞, the\nestimated probabilities match the true probabilities and thus the error rate is equal\nto the Bayes rate, i.e., P=P∗.\nAt the risk of sounding repetitive, we conclude by commenting once again on the\nﬁnite-sample situation encountered in practice. The k-nearest-neighbor rule can be\nviewed as another attempt to estimate the a posteriori probabilities P(ωi|x) from\nsamples. We want to use a large value of kto obtain a reliable estimate. On the\nother hand, we want all of the knearest neighbors x′to be very near xto be sure\nthatP(ωi|x′) is approximately the same as P(ωi|x). This forces us to choose a\ncompromise kthat is a small fraction of the number of samples. It is only in the limit\nasngoes to inﬁnity that we can be assured of the nearly optimal behavior of the\nk-nearest-neighbor rule.\n4.5.5 Computational Complexity of the k–Nearest-Neighbor\nRule\nThe computational complexity of the nearest-neighbor algorithm — both in space\n(storage of prototypes) and time (search) — has received a great deal of analy-\nsis. There are a number of elegant theorems from computational geometry on the\nconstruction of Voronoi tesselations and nearest-neighbor searches in one- and two-\ndimensional spaces. However, because the greatest use of nearest-neighbor techniques\nis for problems with many features, we concentrate on the more general d-dimensional\ncase.\nSuppose we have nlabelled training samples in ddimensions, and seek to ﬁnd\nthe closest to a test point x(k= 1). In the most naive approach we inspect each\nstored point in turn, calculate its Euclidean distance to x, retaining the identity only\nof the current closest one. Each distance calculation is O(d), and thus this search4.5. THE NEAREST-NEIGHBOR RULE 27\nby examining the labels on the knearest neighbors and taking a vote (Fig. 4.15). We\nshall not go into a thorough analysis of the k-nearest-neighbor rule. However, by\nconsidering the two-class case with kodd (to avoid ties), we can gain some additional\ninsight into these procedures.\nx\nx1x2\nFigure 4.15: The k-nearest-neighbor query starts at the test point and grows a spher-\nical region until it encloses ktraining samples, and labels the test point by a majority\nvote of these samples. In this k= 5 case, the test point xwould be labelled the\ncategory of the black points.\nThe basic motivation for considering the k-nearest-neighbor rule rests on our ear-\nlier observation about matching probabilities with nature. We notice ﬁrst that if\nkis ﬁxed and the number nof samples is allowed to approach inﬁnity, then all of\ntheknearest neighbors will converge to x. Hence, as in the single-nearest-neighbor\ncases, the labels on each of the k-nearest-neighbors are random variables, which in-\ndependently assume the values ωiwith probabilities P(ωi|x),i=1,2. If P(ωm|x)\nis the larger a posteriori probability, then the Bayes decision rule always selects ωm.\nThe single-nearest-neighbor rule selects ωmwith probability P(ωm|x). The k-nearest-\nneighbor rule selects ωmif a majority of the knearest neighbors are labeled ωm, an\nevent of probability\nk/summationdisplay\ni=(k+1)/2/parenleftbiggk\ni/parenrightbigg\nP(ωm|x)i[1−P(ωm|x)]k−i. (54)\nIn general, the larger the value of k, the greater the probability that ωmwill be\nselected.\nWe could analyze the k-nearest-neighbor rule in much the same way that we\nanalyzed the single-nearest-neighbor rule. However, since the arguments become more\ninvolved and supply little additional insight, we shall content ourselves with stating\nthe results. It can be shown that if kis odd, the large-sample two-class error rate for\nthek-nearest-neighbor rule is bounded above by the function Ck(P∗), where Ck(P∗)\nis deﬁned to be the smallest concave function of P∗greater than\n(k−1)/2/summationdisplay\ni=0/parenleftbiggk\ni/parenrightbigg/bracketleftbig\n(P∗)i+1(1−P∗)k−i+(P∗)k−i(1−P∗)i+1/bracketrightbig\n. (55)Inparticolare ,sipuò dimostrare (vedi Duda etal.,2000 )che Ck(P*) èdefinita come\nlapiùpiccola funzione concava diP*maggiore di",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#16": "Esempi k-NN\n30prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempi k-NN\nNell’esempio visto in precedenza, \n la regola k -NN con k=3 \nassegna il pattern 𝐱alla classe 𝑤2(femmine -rossi )\nL’animazione (scomposta nel lucido successivo) mostra il \npartizionamento dello spazio operato dalla regola k-NN sul \ntraining set con 5 classi visto in precedenza al variare di k\nPesoAltezza\n>@T168 ,57 x\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#17": "Esempi k-NN\n30prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempi k-NN\nNell’esempio visto in precedenza, \n la regola k -NN con k=3 \nassegna il pattern 𝐱alla classe 𝑤2(femmine -rossi )\nL’animazione (scomposta nel lucido successivo) mostra il \npartizionamento dello spazio operato dalla regola k-NN sul \ntraining set con 5 classi visto in precedenza al variare di k\nPesoAltezza\n>@T168 ,57 x\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#18": "Espansione Lucido Precedente (k=1,3)\n31prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEspansione dell’animazione\nlucido precedente (k=1,3,5,7,9,11)\nk=1 k=3\nk=5 k=7\nk=9 k=11",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#19": "Espansione Lucido Precedente (k=5,7)\n31prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEspansione dell’animazione\nlucido precedente (k=1,3,5,7,9,11)\nk=1 k=3\nk=5 k=7\nk=9 k=11",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#2": "Classiﬁcatore Nearest Neighbor (NN)\n26prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneClassificatore Nearest Neighbor (NN)\nData una metrica 𝑑𝑖𝑠𝑡(∙)nello spazio multidimensionale (es.\ndistanza euclidea )ilclassificarore nearest neighbor (letteralmente “il\npiùvicino traivicini”),classifica unpattern𝐱conlastessa classe\ndell’elemento 𝐱′adesso piùvicino neltraining setTS:\n𝑑𝑖𝑠𝑡𝐱,𝐱′=𝑚𝑖𝑛\n𝐱𝑖∈TS𝑑𝑖𝑠𝑡𝐱,𝐱𝑖\nInvece\n diderivare daidatiledistribuzioni condizionali delle classi\nperpoifaruso della regola diBayes perlaclassificazione,\nquesto classificatore cerca inmodo piuttosto pragmatico di\nmassimizzare direttamente laprobabilità aposteriori ;infatti se𝐱′\nèmolto vicino a𝐱èlecito supporre che:\n𝑃𝑤𝑖𝐱≈𝑃𝑤𝑖𝐱′\nIn\neffetti, sipuòdimostrare (solo però nelcaso diTSpopolato da\ninfiniti campioni) chelaprobabilità dierrore P(nella figura sotto)\ndella regola nearest neighbor nonèmaipeggiore deldoppio del\nminimo errore possibile P*(quello Bayesiano ).\nNella\n pratica ,questo non significa però chel’approccio\nBayesiano fornisca sempre risultati migliori dinearest neighbor ,\ninfatti selastima delle densità condizionali èpoco accurata i\nrisultati delclassificatore Bayesiano possono essere peggiori .\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#20": "Espansione Lucido Precedente (k=9,11)\n31prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEspansione dell’animazione\nlucido precedente (k=1,3,5,7,9,11)\nk=1 k=3\nk=5 k=7\nk=9 k=11",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#21": "Esempi Bayes\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\nIn figura un \nesempio con\ns=5 classi",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#22": "Bayes e Conﬁdenza di Classiﬁcazione\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\nIn figura un \nesempio con\ns=5 classi",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#23": "Bayes e Conﬁdenza di Classiﬁcazione\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#24": "k-NN e Conﬁdenza di Classiﬁcazione\n32prof. Davide Maltoni –Università di Bologna\nML\nClassificazionek-NN e Confidenza di Classificazione\nDaunclassificatore k-NNrisulta piuttosto semplice estrarre una\nconfidenza (probabilistica) circa laclassificazione eseguita ;siano\n𝑣1,𝑣2…𝑣𝑠,෍\n𝑖=1𝑠\n𝑣𝑖=𝑘\nivotiottenuti dalpattern𝐱,allora leconfidenze (vedi sfumature in\nfigura sotto )possono essere semplicemente ottenute dividendo\nper𝑘ivotiottenuti :\n𝑣1\n𝑘,𝑣2\n𝑘…𝑣𝑠\n𝑘\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#25": "k-NN e Confidenza di Classificazione\n32prof. Davide Maltoni –Università di Bologna\nML\nClassificazionek-NN e Confidenza di Classificazione\nDaunclassificatore k-NNrisulta piuttosto semplice estrarre una\nconfidenza (probabilistica) circa laclassificazione eseguita ;siano\n𝑣1,𝑣2…𝑣𝑠,෍\n𝑖=1𝑠\n𝑣𝑖=𝑘\nivotiottenuti dalpattern𝐱,allora leconfidenze (vedi sfumature in\nfigura sotto )possono essere semplicemente ottenute dividendo\nper𝑘ivotiottenuti :\n𝑣1\n𝑘,𝑣2\n𝑘…𝑣𝑠\n𝑘\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#26": "NN e Complessità Computazionale\n33prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneNN e complessità computazionale\nL’utilizzo diunclassificatore NNok-NNnelcaso ditraining setdi\nelevate dimensioni puòdiventare problematico :\nNecessario\n memorizzare tuttiipattern delTraining Set\nPer\nogni classificazione ènecessario calcolare ladistanza del\npattern daclassificare datutti ipattern deltraining sete\nordinare (parzialmente ledistanze) perottenere lepiùpiccole\nTecniche diediting/ condensing (lucido successivo) possono\nalleviare questo problema, maquando l’efficienza èimportante è\nconsigliabile indicizzare idati attraverso strutture spaziali (es.\nkd-tree)checonsentono diindividuare ivicini senza effettuare una\nscansione esaustiva .\nLalibreria FLANN (C++) consente dieffettuare ricerche nearest\nneighbor approssimate molto efficientemente .\nhttp://www .cs.ubc.ca/research/flann/",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#27": "NN e Complessità Computazionale\n33prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneNN e complessità computazionale\nL’utilizzo diunclassificatore NNok-NNnelcaso ditraining setdi\nelevate dimensioni puòdiventare problematico :\nNecessario\n memorizzare tuttiipattern delTraining Set\nPer\nogni classificazione ènecessario calcolare ladistanza del\npattern daclassificare datutti ipattern deltraining sete\nordinare (parzialmente ledistanze) perottenere lepiùpiccole\nTecniche diediting/ condensing (lucido successivo) possono\nalleviare questo problema, maquando l’efficienza èimportante è\nconsigliabile indicizzare idati attraverso strutture spaziali (es.\nkd-tree)checonsentono diindividuare ivicini senza effettuare una\nscansione esaustiva .\nLalibreria FLANN (C++) consente dieffettuare ricerche nearest\nneighbor approssimate molto efficientemente .\nhttp://www .cs.ubc.ca/research/flann/\nhttps ://github.com /mariusmuja /flann",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#28": "NN e Complessità ComputazionaleFAST APPROXIMATE NEAREST NEIGHBORS\nWITH AUTOMATIC ALGORITHM CONFIGURATION\nMarius Muja, David G. Lowe\nComputer Science Department, University of British Columbia, Vancouver, B.C., Canada\nmariusm@cs.ubc.ca, lowe@cs.ubc.ca\nKeywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.\nAbstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-\ning in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional\nproblems that are faster than linear search. Approximate algorithms are known to provide large speedups with\nonly minor loss in accuracy, but many such algorithms have been published with only minimal guidance on\nselecting an algorithm and its parameters for any given problem. In this paper, we describe a system that\nanswers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system\nwill take any given dataset and desired degree of precision and use these to automatically determine the best\nalgorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical\nk-means trees, which we have found to provide the best known performance on many datasets. After testing a\nrange of alternatives, we have found that multiple randomized k-d trees provide the best performance for other\ndatasets. We are releasing public domain code that implements these approaches. This library provides about\none order of magnitude improvement in query time over the best previously available software and provides\nfully automated parameter selection.\n1 INTRODUCTION\nThe most computationally expensive part of many\ncomputer vision algorithms consists of searching for\nthe closest matches to high-dimensional vectors. Ex-\namples of such problems include ﬁnding the best\nmatches for local image features in large datasets\n(Lowe, 2004; Philbin et al., 2007), clustering local\nfeatures into visual words using the k-means or sim-\nilar algorithms (Sivic and Zisserman, 2003), or per-\nforming normalized cross-correlation to compare im-\nage patches in large datasets (Torralba et al., 2008).\nThe nearest neighbor search problem is also of major\nimportance in many other applications, including ma-\nchine learning, document retrieval, data compression,\nbioinformatics, and data analysis.\nWe can deﬁne the nearest neighbor search prob-\nlem as follows: given a set of points P={p1,..., pn}\nin a vector space X, these points must be preprocessed\nin such a way that given a new query point q∈X,\nﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that\nXis an Euclidean vector space, which is appropriate\nfor most problems in computer vision. We will de-\nscribe potential extensions of our approach to general\nmetric spaces, although this would come at some cost\nin efﬁciency.\nFor high-dimensional spaces, there are often no\nknown algorithms for nearest neighbor search that\nare more efﬁcient than simple linear search. As lin-\near search is too costly for many applications, this\nhas generated an interest in algorithms that perform\napproximate nearest neighbor search, in which non-\noptimal neighbors are sometimes returned. Such ap-\nproximate algorithms can be orders of magnitude\nfaster than exact search, while still providing near-\noptimal accuracy.\nThere have been hundreds of papers published on\nalgorithms for approximate nearest neighbor search,\nbut there has been little systematic comparison to\nguide the choice among algorithms and set their inter-\nnal parameters. One reason for this is that the relativeFAST APPROXIMATE NEAREST NEIGHBORS\nWITH AUTOMATIC ALGORITHM CONFIGURATION\nMarius Muja, David G. Lowe\nComputer Science Department, University of British Columbia, Vancouver, B.C., Canada\nmariusm@cs.ubc.ca, lowe@cs.ubc.ca\nKeywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.\nAbstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-\ning in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional\nproblems that are faster than linear search. Approximate algorithms are known to provide large speedups with\nonly minor loss in accuracy, but many such algorithms have been published with only minimal guidance on\nselecting an algorithm and its parameters for any given problem. In this paper, we describe a system that\nanswers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system\nwill take any given dataset and desired degree of precision and use these to automatically determine the best\nalgorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical\nk-means trees, which we have found to provide the best known performance on many datasets. After testing a\nrange of alternatives, we have found that multiple randomized k-d trees provide the best performance for other\ndatasets. We are releasing public domain code that implements these approaches. This library provides about\none order of magnitude improvement in query time over the best previously available software and provides\nfully automated parameter selection.\n1 INTRODUCTION\nThe most computationally expensive part of many\ncomputer vision algorithms consists of searching for\nthe closest matches to high-dimensional vectors. Ex-\namples of such problems include ﬁnding the best\nmatches for local image features in large datasets\n(Lowe, 2004; Philbin et al., 2007), clustering local\nfeatures into visual words using the k-means or sim-\nilar algorithms (Sivic and Zisserman, 2003), or per-\nforming normalized cross-correlation to compare im-\nage patches in large datasets (Torralba et al., 2008).\nThe nearest neighbor search problem is also of major\nimportance in many other applications, including ma-\nchine learning, document retrieval, data compression,\nbioinformatics, and data analysis.\nWe can deﬁne the nearest neighbor search prob-\nlem as follows: given a set of points P={p1,..., pn}\nin a vector space X, these points must be preprocessed\nin such a way that given a new query point q∈X,\nﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that\nXis an Euclidean vector space, which is appropriate\nfor most problems in computer vision. We will de-\nscribe potential extensions of our approach to general\nmetric spaces, although this would come at some cost\nin efﬁciency.\nFor high-dimensional spaces, there are often no\nknown algorithms for nearest neighbor search that\nare more efﬁcient than simple linear search. As lin-\near search is too costly for many applications, this\nhas generated an interest in algorithms that perform\napproximate nearest neighbor search, in which non-\noptimal neighbors are sometimes returned. Such ap-\nproximate algorithms can be orders of magnitude\nfaster than exact search, while still providing near-\noptimal accuracy.\nThere have been hundreds of papers published on\nalgorithms for approximate nearest neighbor search,\nbut there has been little systematic comparison to\nguide the choice among algorithms and set their inter-\nnal parameters. One reason for this is that the relativeFAST APPROXIMATE NEAREST NEIGHBORS\nWITH AUTOMATIC ALGORITHM CONFIGURATION\nMarius Muja, David G. Lowe\nComputer Science Department, University of British Columbia, Vancouver, B.C., Canada\nmariusm@cs.ubc.ca, lowe@cs.ubc.ca\nKeywords: nearest-neighbors search, randomized kd-trees, hierarchical k-means tree, clustering.\nAbstract: For many computer vision problems, the most time consuming component consists of nearest neighbor match-\ning in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional\nproblems that are faster than linear search. Approximate algorithms are known to provide large speedups with\nonly minor loss in accuracy, but many such algorithms have been published with only minimal guidance on\nselecting an algorithm and its parameters for any given problem. In this paper, we describe a system that\nanswers the question, “What is the fastest approximate nearest-neighbor algorithm for my data?” Our system\nwill take any given dataset and desired degree of precision and use these to automatically determine the best\nalgorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical\nk-means trees, which we have found to provide the best known performance on many datasets. After testing a\nrange of alternatives, we have found that multiple randomized k-d trees provide the best performance for other\ndatasets. We are releasing public domain code that implements these approaches. This library provides about\none order of magnitude improvement in query time over the best previously available software and provides\nfully automated parameter selection.\n1 INTRODUCTION\nThe most computationally expensive part of many\ncomputer vision algorithms consists of searching for\nthe closest matches to high-dimensional vectors. Ex-\namples of such problems include ﬁnding the best\nmatches for local image features in large datasets\n(Lowe, 2004; Philbin et al., 2007), clustering local\nfeatures into visual words using the k-means or sim-\nilar algorithms (Sivic and Zisserman, 2003), or per-\nforming normalized cross-correlation to compare im-\nage patches in large datasets (Torralba et al., 2008).\nThe nearest neighbor search problem is also of major\nimportance in many other applications, including ma-\nchine learning, document retrieval, data compression,\nbioinformatics, and data analysis.\nWe can deﬁne the nearest neighbor search prob-\nlem as follows: given a set of points P={p1,..., pn}\nin a vector space X, these points must be preprocessed\nin such a way that given a new query point q∈X,\nﬁnding the points in Pthat are nearest to qcan be per-formed efﬁciently. In this paper, we will assume that\nXis an Euclidean vector space, which is appropriate\nfor most problems in computer vision. We will de-\nscribe potential extensions of our approach to general\nmetric spaces, although this would come at some cost\nin efﬁciency.\nFor high-dimensional spaces, there are often no\nknown algorithms for nearest neighbor search that\nare more efﬁcient than simple linear search. As lin-\near search is too costly for many applications, this\nhas generated an interest in algorithms that perform\napproximate nearest neighbor search, in which non-\noptimal neighbors are sometimes returned. Such ap-\nproximate algorithms can be orders of magnitude\nfaster than exact search, while still providing near-\noptimal accuracy.\nThere have been hundreds of papers published on\nalgorithms for approximate nearest neighbor search,\nbut there has been little systematic comparison to\nguide the choice among algorithms and set their inter-\nnal parameters. One reason for this is that the relative",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#29": "NN e Prototipi di Classi\n34prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneNN e Prototipi di Classi\nTalvolta nella classificazione nearest neighbor invece dimantenere\ntuttiipattern delTSecalcolare ladistanza daciascuno diessi, si\npreferisce selezionare/derivare daessi uno (opiù) prototipi per\nciascuna classe eutilizzare questi ultimi perlaclassificazione come\nsefossero isolielementi diTS:queste tecniche prendono ilnome di:\nediting\n :quando sicancellano solo pattern daltraining set,senza\nderivare nuovi pattern\ncondensing\n :seiprototipi non appartenevano alTSesono stati\nderivati\nCiòcomporta solitamente iseguenti vantaggi :\nnon\nènecessario calcolare unelevato numero didistanze .\niprototipi sono spesso piùaffidabili erobusti disingoli pattern (si\nriduce ilrischio diaffidarsi adoutlier ).\nUnsingolo prototipo diclasse può essere derivato come vettore\nmedio deivettori diquella classe nelTS.Processi divector\nquantization oclustering consentono diottenere piùprototipi perogni\nclasse .sebbene il pattern di \nTS più vicino a 𝐱sia \n“blu”, 𝐱viene \nclassificato come \nrosso, in quanto il \nprototipo più vicino è \nquello rosso.x",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#3": "Classiﬁcatore di Bayes\n3prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneClassificatore di Bayes\nDato unpattern𝐱daclassificare inunadelle𝑠classi𝑤1,𝑤2…𝑤𝑠di\ncuisono note:\nle\nprobabilità apriori𝑃𝑤1,𝑃𝑤2…𝑃𝑤𝑠\nledensità diprobabilità condizionali 𝑝𝐱𝑤1,𝑝𝐱𝑤2…𝑝𝐱𝑤𝑠\nlaregola diclassificazione diBayes assegna 𝐱allaclasse𝑏percui\nèmassima laprobabilità aposteriori :\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑃𝑤𝑖𝐱\nMassimizzare laprobabilità aposteriori significa massimizzare la\ndensità diprobabilità condizionale tenendo comunque conto della\nprobabilità apriori delle classi .\nLa\nregola sidimostra ottima inquanto minimizza l’errore di\nclassificazione .Adesempio nelcaso di2classi e𝑑=1:\n𝑃𝑒𝑟𝑟𝑜𝑟=න\n1𝑝𝑥𝑤2𝑃𝑤2𝑑𝑥+න\n2𝑝𝑥𝑤1𝑃𝑤1𝑑𝑥\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#30": "NN e Prototipi di Classi\n34prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneNN e Prototipi di Classi\nTalvolta nella classificazione nearest neighbor invece dimantenere\ntuttiipattern delTSecalcolare ladistanza daciascuno diessi, si\npreferisce selezionare/derivare daessi uno (opiù) prototipi per\nciascuna classe eutilizzare questi ultimi perlaclassificazione come\nsefossero isolielementi diTS:queste tecniche prendono ilnome di:\nediting\n :quando sicancellano solo pattern daltraining set,senza\nderivare nuovi pattern\ncondensing\n :seiprototipi nonappartenevano alTSesono stati\nderivati\nCiòcomporta solitamente iseguenti vantaggi :\nnon\nènecessario calcolare unelevato numero didistanze .\niprototipi sono spesso piùaffidabili erobusti disingoli pattern (si\nriduce ilrischio diaffidarsi adoutlier ).\nUnsingolo prototipo diclasse può essere derivato come vettore\nmedio deivettori diquella classe nelTS.Processi divector\nquantization oclustering consentono diottenere piùprototipi perogni\nclasse .sebbene il pattern di \nTS più vicino a 𝐱sia \n“blu”, 𝐱viene \nclassificato come \nrosso, in quanto il \nprototipo più vicino è \nquello rosso.x",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#31": "NN e Prototipi di Classi\n34prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneNN e Prototipi di Classi\nTalvolta nella classificazione nearest neighbor invece dimantenere\ntuttiipattern delTSecalcolare ladistanza daciascuno diessi, si\npreferisce selezionare/derivare daessi uno (opiù) prototipi per\nciascuna classe eutilizzare questi ultimi perlaclassificazione come\nsefossero isolielementi diTS:queste tecniche prendono ilnome di:\nediting\n :quando sicancellano solo pattern daltraining set,senza\nderivare nuovi pattern\ncondensing\n :seiprototipi nonappartenevano alTSesono stati\nderivati\nCiòcomporta solitamente iseguenti vantaggi :\nnon\nènecessario calcolare unelevato numero didistanze .\niprototipi sono spesso piùaffidabili erobusti disingoli pattern (si\nriduce ilrischio diaffidarsi adoutlier ).\nUnsingolo prototipo diclasse può essere derivato come vettore\nmedio deivettori diquella classe nelTS.Processi divector\nquantization oclustering consentono diottenere piùprototipi perogni\nclasse .sebbene il pattern di \nTS più vicino a 𝐱sia \n“blu”, 𝐱viene \nclassificato come \nrosso, in quanto il \nprototipo più vicino è \nquello rosso.x",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#32": "NN e Metriche\n35prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneNN e Metriche\nIl\ncomportamento della regola k-NNèstrettamente legato alla\nmetrica (funzione distanza )adottata .\nLa\ndistanza euclidea ,cherappresenta ilcaso L2nella definizione\ndimetriche diMinkowski ,èsicuramente lametrica piùspesso\nutilizzata .\n𝐿𝑘𝐚,𝐛=෍\n𝑖=1𝑑\n𝑎𝑖−𝑏𝑖𝑘1/𝑘\nNella\n pratica ,prima diadottare semplicemente ladistanza\neuclidea èbene valutare lospazio divariazione delle componenti\n(ofeature )elapresenza dieventuali forti correlazioni trale\nstesse .\nSupponiamo\n adesempio divoler classificare lepersone sulla\nbasedell’altezza edella lunghezza delpiede .Ogni pattern𝐱\n(bidimensionale) risulta costituito dadue feature (𝑥1=altezza,\n𝑥2=lunghezza delpiede) .\nLospazio divariazione dell’altezza (210-140 =70cm) risulta\nmaggiore diquello della lunghezza delpiede (40-20=20cm).\nPertanto selasimilarità trapattern venisse misurata consemplice\ndistanza euclidea lacomponente altezza“peserebbe ”piùdella\ncomponente lunghezza delpiede .𝑥2140 cm 210 cm𝑥1\n20 cm40 cm",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#33": "NN e Metriche\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#34": "Normalizzazione\n36prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneNormalizzazione\nPerevitare iproblemi legati adiversi spazi divariazioni delle feature ,\nparticolarmente fastidiosi peralcune tecniche (es.retineurali), si\nconsiglia dinormalizzare ipattern .\nLenormalizzazioni piùcomuni sono :\nMin\n-Max scaling :per ogni feature 𝑖−𝑒𝑠𝑖𝑚𝑎 sicalcolano il\nmassimo 𝑚𝑎𝑥𝑖eilminimo𝑚𝑖𝑛𝑖esiapplica una trasformazione\nlineare (scaling )che«tipicamente» mappa𝑚𝑖𝑛𝑖a0e𝑚𝑎𝑥𝑖a1.\n𝑥′=𝑥−𝑚𝑖𝑛𝑖/𝑚𝑎𝑥𝑖−𝑚𝑖𝑛𝑖\nStandardization\n :perogni feature𝑖−𝑒𝑠𝑖𝑚𝑎 sicalcola lamedia\n𝑚𝑒𝑎𝑛𝑖eladeviazione standard 𝑠𝑡𝑑𝑑𝑒𝑣 𝑖esitrasformano ivalori\ncome :\n𝑥′=𝑥−𝑚𝑒𝑎𝑛𝑖/𝑠𝑡𝑑𝑑𝑒𝑣 𝑖\nDopo latrasformazione tutte lefeature hanno (sul training set)\nmedia 0edeviazione standard 1.\nAttenzione :iparametri della normalizzazione (es.minimi, massimi) si\ncalcolano sulsolo training setelatrasformazione siapplica siaatutti\nidati(training, validation ,test).\nLesemplici tecniche sopra descritte operano sulle singole feature\nindipendentemente .Una tecnica dinormalizzazione efficace (mapiù\ncostosa) che opera simultaneamente sututte lefeature tenendo\nconto della lorocorrelazione èlaWhitening transform .",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#35": "Normalizzazione\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#36": "Whitening Transform\n37prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneWhitening transform\nUn’efficace normalizzazione rispetto agli spazi divariazione, in\ngrado anche ditener conto delle correlazioni trafeature èpossibile :\npre\n-normalizzando lospazio delle feature attraverso\nWhitening transform (che vedremo meglio inseguito)\nutilizzando\n come metrica ladistanza diMahalanobis .\nLedue alternative sono equivalenti .Nelprimo casol’ellissoide\ncorrispondente allospazio delle feature viene“sfericizzato ”apriori\neviene inseguito usata ladistanza euclidea ;nelsecondo la\ndistanza diMahalanobis normalizza ogni componente sulla base\ndella matrice dicovarianza 6.\nDanon sottovalutare l’importanza della correlazione trafeatures\ncome aspetto negativo perlaclassificazione .Infatti,l’utilizzo di\nfeature correlate riduce (anche drasticamente) ilpotere\ndiscriminante .Nelcaso ideale tutte lefeature sono staticamente\nindipendenti (ellissoide assiparalleli aquelli cartesiani) .\nDue feature altamente discriminanti seprese individualmente, matraloro\nfortemente correlate, sono nelcomplesso meno discriminanti diuna terza\nfeature leggermente piùdidiscriminante diognuna delle precedenti .\nLadistanza diMahalanobis (olasfericizzazione dello spazio) tiene\nconto delle correlazioni epesa maggiormente feature non\ncorrelate .𝑥1𝑥2\ndistribuzione\noriginaledopo Whitening\ntransform",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#37": "Distanza Mahalanobis\n11prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDistanza Mahalanobis\nLa\ndistanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :\n𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍\ndefinisce ibordi adensità costante inuna distribuzione\nmultinormale .Tale distanza viene spesso utilizzata in\nsostituzione della distanza euclidea ,essendo ingrado di\n“pesare”lediverse componenti tenendo conto deirelativi spazi\ndivariazione edella lorocorrelazione .\n𝑟=1\n𝑟=2\n𝑟=3\n𝑟=4\n𝑥1𝑥2\n11prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneDistanza Mahalanobis\nLa\ndistanza diMahalanobis 𝑟tra𝐱e𝛍,definitadall’equazione :\n𝑟2=𝐱−𝛍𝑡Σ−1𝐱−𝛍\ndefinisce ibordi adensità costante inuna distribuzione\nmultinormale .Tale distanza viene spesso utilizzata in\nsostituzione della distanza euclidea ,essendo ingrado di\n“pesare”lediverse componenti tenendo conto deirelativi spazi\ndivariazione edella lorocorrelazione .\n𝑟=1\n𝑟=2\n𝑟=3\n𝑟=4\n𝑥1𝑥2",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#38": "Whitening Transform\n37prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneWhitening transform\nUn’efficace normalizzazione rispetto agli spazi divariazione, in\ngrado anche ditener conto delle correlazioni trafeature èpossibile :\npre\n-normalizzando lospazio delle feature attraverso\nWhitening transform (che vedremo meglio inseguito)\nutilizzando\n come metrica ladistanza diMahalanobis .\nLedue alternative sono equivalenti .Nelprimo casol’ellissoide\ncorrispondente allospazio delle feature viene“sfericizzato ”apriori\neviene inseguito usata ladistanza euclidea ;nelsecondo la\ndistanza diMahalanobis normalizza ogni componente sulla base\ndella matrice dicovarianza 6.\nDanon sottovalutare l’importanza della correlazione trafeatures\ncome aspetto negativo perlaclassificazione .Infatti,l’utilizzo di\nfeature correlate riduce (anche drasticamente) ilpotere\ndiscriminante .Nelcaso ideale tutte lefeature sono staticamente\nindipendenti (ellissoide assiparalleli aquelli cartesiani) .\nDue feature altamente discriminanti seprese individualmente, ma traloro\nfortemente correlate, sono nelcomplesso meno discriminanti diuna terza\nfeature leggermente piùdidiscriminante diognuna delle precedenti .\nLadistanza diMahalanobis (olasfericizzazione dello spazio) tiene\nconto delle correlazioni epesa maggiormente feature non\ncorrelate .𝑥1𝑥2\ndistribuzione\noriginaledopo Whitening\ntransform",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#39": "10prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneRappresentazione grafica\nNormale Multivariata\nPer\n𝑑=2laforma della distribuzione èquella diun’ellisse .\n𝛍\n=𝜇1,𝜇2controlla laposizione delcentro .\n𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .\n𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi\ncartesiani .\n•se=0(matrice dicovarianza diagonale ),ladistribuzione\nmultinormale èdefinita come prodotto di𝑑normali\nmonodimensionali .Intalcaso gliassidell’ellisse sono\nparalleli agliassicartesiani (es.Naive Bayes Classifier ).\n•Se >0(come nel caso della figura )𝑥1e𝑥2sono\npositivamente correlate (quando aumenta 𝑥1aumenta\nanche𝑥2).\n•Se<0𝑥1e𝑥2sono negativamente correlate (quando\naumenta 𝑥1cala𝑥2).\nGli\nassidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi \nindividuano \nluoghi di punti a \ndensità costante\n𝑥1𝑥2Distribuzione Normale Multivariata (Multinormale)",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#4": "Classiﬁcatore Nearest Neighbor (NN)\nQuando laprobabilità aposteriori diuna classe èvicina a1,la\nprobabilità dierrore Bayesiano P*èpiccola ,così come la\nprobabilità dierrore Pdella regola nearest neighbor .Quando\nciascuna classe èquasi ugualmente probabile ,siaBayes cheNN\nhanno untasso dierrore ~(1-1/c),con cnumero diclassi .Nel\nmezzo, iltasso dierrore NNèlimitato daltasso dierrore diBayes :\n!∗≤!≤!∗2−%\n%−1!∗(Eq.52)",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#40": "10prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneRappresentazione grafica\nNormale Multivariata\nPer\n𝑑=2laforma della distribuzione èquella diun’ellisse .\n𝛍\n=𝜇1,𝜇2controlla laposizione delcentro .\n𝜎11e𝜎22determinano l’allungamento suidueassidell’ellisse .\n𝜎12=𝜎21controlla larotazione dell’ellisse rispetto agli assi\ncartesiani .\n•se=0(matrice dicovarianza diagonale ),ladistribuzione\nmultinormale èdefinita come prodotto di𝑑normali\nmonodimensionali .Intalcaso gliassidell’ellisse sono\nparalleli agliassicartesiani (es.Naive Bayes Classifier ).\n•Se >0(come nel caso della figura )𝑥1e𝑥2sono\npositivamente correlate (quando aumenta 𝑥1aumenta\nanche𝑥2).\n•Se<0𝑥1e𝑥2sono negativamente correlate (quando\naumenta 𝑥1cala𝑥2).\nGli\nassidell’ellisse sono paralleli agliautovettori diΣ.Le diverse ellissi \nindividuano \nluoghi di punti a \ndensità costante\n𝑥1𝑥2\nDistribuzione Normale Multivariata (Multinormale)\nN.B. Per quanto l’assunzione chele variabili siano statisticamente indipendenti\n(!12=0) non siavera in generale , iClassificatori Naive Bayes sidimostrano lavorare\nbene sumolti dataset. Per tale motivo , taliclassificatori sono fraipiùpopolari",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#41": "Whitening Transform",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#42": "Metric Learning\n38prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneMetric Learning\nUnapproccio piùgenerale allascelta della metrica dautilizzare in\nunadeterminata applicazione, consiste nellearning supervisionato\ndella metrica stessa daidatideltraining set.\nObiettivo èdeterminare unatrasformazione degli input che:\n«avvicini »pattern della stessa classe\n«allontani »pattern diclassi diverse\nLadistanza euclidea nella spazio originale è:\n𝑑𝑖𝑠𝑡𝑎,𝑏=𝐚−𝐛𝑡𝐚−𝐛=𝐚−𝐛2\nUntipico approccio dimetric learning lineare determina (con\ntraining supervisionato) una matrice 𝐆che trasforma gliinput, e\ncontinuare adapplicare ladistanza euclidea agliinput trasformati\n𝑑𝑖𝑠𝑡𝑎,𝑏=𝐆𝐚−𝐆𝐛2\nVedremo una possibile soluzione diquesto problema nell’ambito\ndella riduzione didimensionalità con LDA (Linear Discriminant\nAnalysys ).\nSono anche possibili approcci nonlineari :\n𝑑𝑖𝑠𝑡𝑎,𝑏=𝐆𝜙𝐚−𝐆𝜙𝐛2\ndove𝜙èunafunzione nonlineare .",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#43": "Metric Learning\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#44": "Similarità /Distanza Coseno\n39prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneSimilarità Coseno e Distanza Coseno\nUna similarità/distanza piuttosto utilizzata inapplicazioni di\ninformation retrieval ,data mining etext mining èla\nsimilarità/distanza coseno .\nGeometricamente, dati due vettori𝐚e𝐛lasimilarità coseno\ncorrisponde alcosenodell’angolo tradiessi:\n𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛=𝐚𝑡∙𝐛\n𝐚∙𝐛\nènoto infatti cheilprodotto scalare traduevettori è:\n𝐚𝑡∙𝐛=𝐚∙𝐛∙𝑐𝑜𝑠𝜃\nDue vettori identici hanno similarità 1eduevettori opposti -1.\nLadistanza coseno èsemplicemente :\n𝐶𝑜𝑠𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=1−𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛\nEsempio Confronto ditesti:Untesto può essere codificato daun\nvettore numerico dove ogni dimensione contiene ilnumero di\noccorrenze diuna certa parola rispetto aundato dizionario .La\nsimilarità dicontenuto tradue testi non dipende dal numero\nassoluto diparole madalla frequenza relativa diciascuna diesse .\nLadistanza coseno «sconta» lalunghezza deivettori .\nLadistanza coseno non èuna metrica (es.non rispetta la\ndiseguaglianza triangolare ).Sesièinteressati aunametrica sipuò\npassare alladistanza angolare :\n𝐴𝑛𝑔𝑢𝑙𝑎𝑟𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=𝑐𝑜𝑠−1𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛\n𝜋",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#45": "Similarità /Distanza Coseno\n39prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneSimilarità Coseno e Distanza Coseno\nUna similarità/distanza piuttosto utilizzata inapplicazioni di\ninformation retrieval ,data mining etext mining èla\nsimilarità/distanza coseno .\nGeometricamente, dati due vettori𝐚e𝐛lasimilarità coseno\ncorrisponde alcosenodell’angolo tradiessi:\n𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛=𝐚𝑡∙𝐛\n𝐚∙𝐛\nènoto infatti cheilprodotto scalare traduevettori è:\n𝐚𝑡∙𝐛=𝐚∙𝐛∙𝑐𝑜𝑠𝜃\nDue vettori identici hanno similarità 1eduevettori opposti -1.\nLadistanza coseno èsemplicemente :\n𝐶𝑜𝑠𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=1−𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛\nEsempio Confronto ditesti:Untesto può essere codificato daun\nvettore numerico dove ogni dimensione contiene ilnumero di\noccorrenze diuna certa parola rispetto aundato dizionario .La\nsimilarità dicontenuto tradue testi non dipende dal numero\nassoluto diparole madalla frequenza relativa diciascuna diesse .\nLadistanza coseno «sconta» lalunghezza deivettori .\nLadistanza coseno non èuna metrica (es.non rispetta la\ndiseguaglianza triangolare ).Sesièinteressati aunametrica sipuò\npassare alladistanza angolare :\n𝐴𝑛𝑔𝑢𝑙𝑎𝑟𝐷𝑖𝑠𝑡𝑎𝑛𝑐𝑒 𝐚,𝐛=𝑐𝑜𝑠−1𝐶𝑜𝑠𝑆𝑖𝑚𝑖𝑙𝑎𝑟𝑖𝑡𝑦 𝐚,𝐛\n𝜋",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#46": "Riferimenti\n!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern \nApproach (3 ed.) , Pearson, 2009.\n!K. Fukunaga, Statistical Pattern Recognition , Academic Press, \n1990.\n!D. Maltoni , Machine Learning , Università di Bologna, 2017.\n!C.M. Bishop, Pattern Recognition and Machine Learning , \nSpringer, 2006.\n!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The \nMIT Press, 2012.\n!R.O. Duda , P.E. Hart, and D.G. Stork. 2000. Pattern Classification \n(2nd Edition). Wiley -Interscience , New York, NY, USA. ",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#5": "Esempi NN\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#6": "18prof. Davide Maltoni –Università di Bologna\nML\nClassificazione…continua\nSupponendo di non avere altre informazioni, si possono stimare le \nprobabilità a priori come: 𝑃𝑤1=8/18, 𝑃𝑤2=10/18\n\u000b\f\n\u000b\f\u000b\f\u000b\f0.003321exp\nπ21|11\n1 1 2/1\n12/ 1  »¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010μxμx xt\ndwp\n\u000b\f\n\u000b\f\u000b\f\u000b\f 0045.021exp\nπ21|21\n2 2 2/1\n22/2  »¼º\n«¬ª\u0010¦\u0010\u0010\n¦ \u0010μxμx xt\ndw p\nPesoAltezza\n>@T168 ,57 x\n\u000b\f\u000b\f\u000b\f 0040.0 w w|is\n1ii   ¦\n P p p x x\n\u000b\f\u000b\f\u000b\f\n\u000b\f36.0w w||w1 1\n1 # xxxpP pP\n\u000b\f\u000b\f\u000b\f\n\u000b\f64.0w w||w2 2\n2 # xxxpP pPEsempi Bayes",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#7": "Esempi NN\n27prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneEsempi NN\nNell’esempio visto in precedenza, \n la regola NN assegna il \npattern 𝐱alla classe 𝑤1(maschi -blu)\nLa figura seguente mostra il partizionamento dello spazio \noperato dalla regola NN su un training set con 5 classi:\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#8": "Esempi Bayes\n19prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneBayes e confidenza di classificazione\nUngrande vantaggio delclassificatore diBayes ,rispetto adaltri\nclassificatori, èlegato alfatto cheesso produce unvalore dioutput\nprobabilistico (unvero eproprio valore diprobabilità tra0e1,con\nsomma 1sulle diverse classi )che può essere utilizzato come\nconfidenza (visualizzata nella figura come sfumatura colore ):\nInfatti, unclassificatore puòassegnare unpattern𝐱aunaclasse\n𝑤𝑖condiversi livelli dicertezza (oconfidenza) chepossono essere\nimpiegati per:\nscartare pattern in applicazioni open\n -setcon soglia\ncostruire \n un multi -classificatore\nSe non si è interessati alla confidenza, nella formula di Bayes non \nè necessario dividere per 𝑝𝐱il numeratore, e la regola di Bayes è \nsemplicemente:\n𝑏=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑖=1..𝑠𝑝𝐱𝑤𝑖∙𝑃𝑤𝑖\n",
    "data_test\\rootfolder\\università\\MachineLearning\\32-CBNN-sbloccato.pdf#9": "Da NN a k-NN\n",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Classiﬁcatore Bayesiano (Ex 13)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#1": "Sommario\n...",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#10": "Naive Bayes classiﬁer: step 2\nPer ogni dataset ricaviamo 2 statistiche: media e deviazione standard. \nLa media può essere ricavata così: \n μ\n = sum(x)/n * count(x) \n    \ndove x è la lista dei valori (o colonna) sui cui stiamo stimando la media.  \n# Calculate the mean of a list of numbers\ndef mean\n (\nnumbers\n)\n:\nreturn \nsum\n(\nnumbers\n)\n/\nfloat\n(\nlen\n(\nnumbers\n))\nPer la deviazione standard \n σ\n si ha: \n sqrt( \nΣ\ni\n(x\ni\n – \nμ\n(x))\n2\n / N-1)  \nfrom math import \n sqrt\n \n# Calculate the standard deviation of a list of numbers\ndef stdev\n (\nnumbers\n)\n:\navg\n = \nmean\n(\nnumbers\n)\nvariance\n  = \nsum\n([(\nx\n-\navg\n)\n**\n2 \nfor \nx \nin \nnumbers\n])\n / \nfloat\n(\nlen\n(\nnumbers\n)\n-\n1\n)\nreturn \nsqrt\n(\nvariance\n )\nMedia e deviazione standard devono essere calcolate per ogni feature e \nconsiderando tutte le istanze.\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#11": "Naive Bayes classiﬁer: step 2\nMedia e deviazione standard devono essere calcolate per ogni feature e considerando \ntutte le istanze. \nLa funzione \n zip(*...)\n  separa le colonne del dataset e restituisce una tupla per ogni \ncolonna contenente i relativi valori delle features. \n def summarize_dataset\n (\ndataset\n)\n:\nsummaries\n =\n[(\nmean\n(\ncolumn\n),\nstdev\n(\ncolumn\n),\nlen\n(\ncolumn\n)) \nfor \ncolumn \nin \nzip\n(\n*\ndataset\n)]\ndel\n(\nsummaries\n [\n-\n1\n])\nreturn \nsummaries\nAd esempio: \ndataset\n = \n[[\n3.393533211\n ,\n2.331273381\n ,\n0\n],\n[\n3.110073483\n ,\n1.781539638\n ,\n0\n],\n[\n1.343808831\n ,\n3.368360954\n ,\n0\n],\n[\n3.582294042\n ,\n4.67917911\n ,\n0\n],\n[\n2.280362439\n ,\n2.866990263\n ,\n0\n],\n[\n7.423436942\n ,\n4.696522875\n ,\n1\n],\n[\n5.745051997\n ,\n3.533989803\n ,\n1\n],\n[\n9.172168622\n ,\n2.511101045\n ,\n1\n],\n[\n7.792783481\n ,\n3.424088941\n ,\n1\n],\n[\n7.939820817\n ,\n0.791637231\n ,\n1\n]]\nsummary\n = \nsummarize_dataset\n (\ndataset\n)\nprint\n(\nsummary\n)\n> [(5.178333386499999, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#12": "Naive Bayes classiﬁer: step 3\nVogliamo ricavare le statistiche per ogni classe (o label). Sfruttiamo la funzione \nseparate_by_class()\n  deﬁnita in precedenza:  \ndef summarize_by_class\n (\ndataset\n)\n:\nseparated\n  = \nseparate_by_class\n (\ndataset\n)\nsummaries\n  = \ndict\n()\nfor \nclass_value\n , \nrows \nin \nseparated\n .\nitems\n()\n:\nsummaries\n [\nclass_value\n ]\n = \nsummarize_dataset\n (\nrows\n)\nreturn \nsummaries\nAd esempio:  \ndataset\n = \n[[\n3.393533211\n ,\n2.331273381\n ,\n0\n],\n[\n3.110073483\n ,\n1.781539638\n ,\n0\n],\n[\n1.343808831\n ,\n3.368360954\n ,\n0\n],\n[\n3.582294042\n ,\n4.67917911\n ,\n0\n],\n[\n2.280362439\n ,\n2.866990263\n ,\n0\n],\n[\n7.423436942\n ,\n4.696522875\n ,\n1\n],\n[\n5.745051997\n ,\n3.533989803\n ,\n1\n],\n[\n9.172168622\n ,\n2.511101045\n ,\n1\n],\n[\n7.792783481\n ,\n3.424088941\n ,\n1\n],\n[\n7.939820817\n ,\n0.791637231\n ,\n1\n]]\nseparated\n  = \nseparate_by_class\n (\ndataset\n)\nfor \nlabel \nin \nseparated\n :\nprint\n(\nlabel\n)\nfor \nrow \nin \nseparated\n [\nlabel\n]\n:\nprint\n(\nrow\n)\n13\n>>>\n0\n(2.7420144012, 0.9265683289298018, 5)\n(3.0054686692, 1.1073295894898725, 5)\n1\n(7.6146523718, 1.2344321550313704, 5)\n(2.9914679790000003, 1.4541931384601618, 5)",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#13": "Naive Bayes classiﬁer: step 4\nAssumiamo che la probabilità che un certo valore \n x\n osservato sia funzione \nda una distribuzione gaussiana, descritta interamente dai due valori: media \ne deviazione standard.  \nLa funzione di densità di probabilità sarà così ricavata (vedi lezione; la y \ncorrisponde alla media): \nf(x) = (1 / sqrt(2 * PI) * Σ) * exp(-((x-\n μ\n)^2 / (2 * Σ^2)))\nDove \n Σ\n è la matrice di covarianza (con d =1 coincide con la varianza). \nEsercizio\n : deﬁnire la funzione \n calculate_probability(x, mean, stdev) \n per il \ncalcolo della densità di probabilità.\n14\n",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#14": "Naive Bayes classiﬁer: step 4\nEsercizio\n : deﬁnire la funzione calculate_probability(x, mean, stdev) per il \ncalcolo della densità di probabilità. \nfrom math import sqrt\nfrom math import pi\nfrom math import \n exp\ndef calculate_probability\n (\nx\n, \nmean\n, \nstdev\n)\n:\nexponent\n  = \nexp\n(\n-\n((\nx\n-\nmean\n)\n**\n2\n / \n(\n2\n * \nstdev*\n*\n2 \n)))\nreturn \n(\n1\n / \n(\nsqrt\n(\n2\n * \npi\n)\n * \nstdev\n))\n * \nexponent\nprint\n(\ncalculate_probability\n (\n1.0\n, \n1.0\n, \n1.0\n))\nprint\n(\ncalculate_probability\n (\n2.0\n, \n1.0\n, \n1.0\n))\nprint\n(\ncalculate_probability\n (\n0.0\n, \n1.0\n, \n1.0\n))\n> \n0.3989422804014327\n> \n0.24197072451914337\n> \n0.24197072451914337\nNotare come per x=1, e media e varianza pari a 1, l'apice della campana \nassume valore 0.39. Per x=2 e x=0, e medesime statistiche, il valore è 0.24.\n15",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#15": "Naive Bayes classiﬁer: step 5\nOra impieghiamo le statistiche ricavate dal training data per nuovi dati. La \nstima delle probabilità viene stimata per ogni classe. \nP(class|data) = P(X|class) * P(class) \nAttenzione: Avendo eliminato la frazione, il risultato non è strettamente \nuna probabilità.  \nVogliamo massimizzare tale valore, ovvero prendere la classe con valore di \nprobabilità massimo. \nL'approccio naive implica l'indipendenza, es: \nP(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#16": "Naive Bayes classiﬁer: step 5\nEsercizio\n : deﬁnire \n calculate_class_probabilities()\n  che prende in input le \nstatistiche restituite da \n summarize_by_class()\n  e valuta la probabilità per una \ncerta istanza data sempre in input. \nEsempio: \n# Test calculating class probabilities\ndataset\n = \n[[\n3.393533211\n ,\n2.331273381\n ,\n0\n],\n[\n3.110073483\n ,\n1.781539638\n ,\n0\n],\n[\n1.343808831\n ,\n3.368360954\n ,\n0\n],\n[\n3.582294042\n ,\n4.67917911\n ,\n0\n],\n[\n2.280362439\n ,\n2.866990263\n ,\n0\n],\n[\n7.423436942\n ,\n4.696522875\n ,\n1\n],\n[\n5.745051997\n ,\n3.533989803\n ,\n1\n],\n[\n9.172168622\n ,\n2.511101045\n ,\n1\n],\n[\n7.792783481\n ,\n3.424088941\n ,\n1\n],\n[\n7.939820817\n ,\n0.791637231\n ,\n1\n]]\nsummaries\n  = \nsummarize_by_class\n (\ndataset\n)\nprobabilities\n  = \ncalculate_class_probabilities\n (\nsummaries\n , \ndataset\n[\n0\n])\nprint\n(\nprobabilities\n )\n> {0: 0.05032427673372075, 1: 0.00011557718379945765}\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#17": "Naive Bayes classiﬁer: step 5\nEsercizio\n : deﬁnire \n calculate_class_probabilities()\n  che prende in input le \nstatistiche restituite da \n summarize_by_class()\n  e valuta la probabilità per una \ncerta istanza data sempre in input. \nCalcola il numero totale di istanze a partire dalle statistiche passate \ncome parametro. \nValuta il valore P(class) come frazione tra il numero di istanze per una \nclasse e il numero di istanze nel dataset \nStima la probabilità per ogni valore in input impiegando la funzione \ndensità di probabilità, e le statistiche per ogni colonna associata ad una \ncerta classe. Le probabilità saranno moltiplicate se associate alla stessa \nclasse. \nIl processo sarà ripetuto per ogni classe nel dataset. \nRestituire un dizionario classe->probabilità\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#18": "Naive Bayes classiﬁer: step 5\nEsercizio\n : deﬁnire \n calculate_class_probabilities()\n  che prende in input le \nstatistiche restituite da \n summarize_by_class()\n  e valuta la probabilità per una \ncerta istanza data sempre in input. \ndef calculate_class_probabilities\n (\nsummaries\n , \nrow\n)\n:\n \n# numero totale di istanze di training\n \ntotal_rows\n  = \nsum\n([\nsummaries\n [\nlabel\n][\n0\n][\n2\n] \nfor \nlabel \nin \nsummaries\n ])\n \n# output\nprobabilities\n  = \ndict\n()\n \n# per ogni chiave (classe) e valore (istanze di quella classe)\nfor \nclass_value\n , \nclass_summaries \n in \nsummaries\n .\nitems\n()\n:\n   \n# probabilità calcolata in base alle frequenze\nprobabilities\n [\nclass_value\n ]\n = \nsummaries\n [\nclass_value\n ][\n0\n][\n2\n]\n/\nfloat\n(\ntotal_rows\n )\n   \n# per ogni istanza in summaries associata ad una classe\nfor \ni \nin \nrange\n(\nlen\n(\nclass_summaries\n ))\n:\n      \n# ricava le statistiche di quella classe\nmean\n, \nstdev\n, \ncount\n = \nclass_summaries\n [\ni\n]\n      \n# aggiorna la probabilità per quella classe\nprobabilities\n [\nclass_value\n ]\n *= \ncalculate_probability\n (\nrow\n[\ni\n], \nmean\n, \nstdev\n)\nreturn \nprobabilities\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#19": "Naive Bayes classiﬁer: esercitazione\nConsiderare il dataset Kaggle Adult income dataset:  \nhttps://www.kaggle.com/datasets/wenruliu/adult-income-dataset  \nhttp://www.cs.toronto.edu/~delve/data/adult/adultDetail.html   \nContiene 16 colonne: \nTarget ﬁled: Income  \n-- The income is divide into two classes: <=50K and >50K   \nNumber of attributes: 14  \n-- These are the demographics and other features to describe a person \nAnalizza il dataset passo passo seguendo le considerazioni su: \nhttps://www.kaggle.com/code/prashant111/naive-bayes-classiﬁer-in-python/notebook  \nApplica l'algoritmo Naive Bayes classiﬁer per i suddetto dataset.  \nNota\n : alcuni attributi potrebbero dover essere normalizzati oppure convertiti in valori \nnumerici.\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#2": "Scikit-learn: Classiﬁcatori Naive Bayes\nUn approccio di classiﬁcazione molto veloce nell'addestramento, che non \nrichiede che il training set sia caricato interamente in memoria, anche se a \nvolte mostrano performance peggiori rispetto agli approcci lineare (es. \nLogisticRegression e LinearSVC). \nNaive\n  perché basato sull'assunzione che le feature siano indipendenti dal \npunto di vista statistico, spesso inesatta. \nEs. un problema cardiovascolare può dipendere dal colesterolo, peso, livelli di \ndiabete, etc; se presenti contemporaneamente possono aumentarne il rischio, ma \nl'approccio naive le valuta singolarmente. \nSi ricavano i parametri del modello analizzando le features singolarmente, e \ncollezionando statistiche per ogni feature per ogni classe. \nRicavare la classe più verosimile (con più alta probabilità \n a posteriori\n ) si \nottiene mediante il \n Teorema di Bayes\n . \nL'approccio naive (indipendenza tra features) ci porta a non interpretare la probabilità \nin output poiché risulta essere una approssimazione troppo grossolana rispetto a \nquella reale. \n3",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#20": "Naive Bayes classiﬁer: esercitazione\nAlcune funzioni di supporto: \n# Load a CSV file\ndef \nload_csv\n (\nfilename\n ):\n  dataset = \n list\n()\n  \nwith \nopen\n(filename, \n 'r'\n) \nas \nfile\n:\n    csv_reader = reader(\n file\n)\n    \nfor\n row \nin\n csv_reader:\n      \nif \nnot\n row:\n        \n continue\n      dataset.append(row)\n  \nreturn\n dataset\n# Convert string column to float\ndef \nstr_column_to_float\n (\ndataset\n, \ncolumn\n):\n  \nfor\n row \nin\n dataset:\n    row[column] = \n float\n(row[column].strip())\n# Convert string column to integer\ndef \nstr_column_to_int\n (\ndataset\n, \ncolumn\n):\n  class_values = [row[column] \n for\n row \nin\n dataset]\n  unique = \n set\n(class_values)\n  lookup = \n dict\n()\n  \nfor\n i, value \n in \nenumerate\n (unique):\n    lookup[value] = i\n  \nfor\n row \nin\n dataset:\n    row[column] = lookup[row[column]]\n  \nreturn\n lookup\n21",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#21": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017 \nTutorial \n https://machinelearningmastery.com/naive-bayes-classiﬁer-scratch-\npython/  \nDataset: \nhttps://www.kaggle.com/datasets/wenruliu/adult-income-dataset  \nhttp://www.cs.toronto.edu/~delve/data/adult/adultDetail.html  \nTesti di Riferimento\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#3": "Classiﬁcatori Naive Bayes: pregi e difetti\nSemplice implementazione (basata sulle occorrenze) \nPuò funzionare anche su dataset piccoli \nÈ veloce e richiede poca memoria \nGestiste il caso di valori mancanti nei dati  \nPoco sensibile a dati rumorosi \nL'assunzione dell'indipendenza statistica è raramente soddisfatta; il modello non \nconsidera le dipendenze tra features \nI dati nel continuo devono essere spesso rielaborati (es. binning) \nNon raggiunge prestazioni ottimali rispetto ad altri approcci \nNon supporta l'\n online learning\n : occorre riaddestrare il modello in presenza di \nnuovi dati. \nNon funziona correttamente se i dati nel test set non sono presenti nel training.\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#4": "Scikit-learn: Classiﬁcatori Naive Bayes\nCi sono vari classiﬁcatori implementati in Scikit-learn: \nGaussianNB: adatto a dati nel continuo \nCategoricalNB: features discrete distribuite su categorie predeﬁnite \nBernoulliNB: assume dati binari \nMultinomialNB: assume feature che accumulano valori (es. frequenza) \nComplementNB: variazione del Multinomial per correggere alcune \nassunzioni sui dati. \nBernoulliNB e MultinomialNB sono spesso usati per dati testuali. \nPer dataset di training molto grandi e sparsi si può usare il parametro \n partial_ﬁt\n  che \nriduce la richiesta di memoria. \nÈ una valida alternativa a \n logistic regression\n  e \ndecision trees\n .\n5",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#5": "Scikit-learn: BernoulliNB\nConteggia quante volte una feature non è pari 0 per ogni classe. \nAd esempi, 4 istanze con 4 feature binarie ciascuna. La 1a e 3a istanza \nhanno classe '0', mentre la 2a e 4a hanno classe '1'. \nX \n= \nnp\n.\narray\n([[\n0\n, \n1\n, \n0\n, \n1\n],\n[\n1\n, \n0\n, \n1\n, \n1\n],\n[\n0\n, \n0\n, \n0\n, \n1\n],\n[\n1\n, \n0\n, \n1\n, \n0\n]])\ny \n= \nnp\n.\narray\n([\n0\n, \n1\n, \n0\n, \n1\n])\nEffettuando il conteggio per entrambe le classi si ha: \ncounts \n= \n{}\nfor \nlabel \nin \nnp\n.\nunique\n(\ny\n):\n# iterate over each class\n# count (sum) entries of 1 per feature\ncounts\n[\nlabel\n] \n= \nX\n[\ny \n== \nlabel\n]\n.\nsum\n(\naxis\n=\n0\n)\nprint\n(\n\"Feature counts:\\n{}\"\n .\nformat\n(\ncounts\n))\nFeature counts:\n{0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}\n6",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#6": "Scikit-learn: MultinomialNB e GaussianNB\n ,\nMultinomialNB\n  tiene conto del valor medio per ogni feature per ogni \nclasse. \n GaussianNB\n  ricava valor medio e varianza. \nLa predizione su una istanza è ricavata valutando tutte le classi e \nscegliendo quella ottimale. \nMultinomialNB e BernoulliNB hanno un singolo parametro \n alpha\n , che \ndetermina la complessità del modello. Ai dati sono aggiunti \n alpha\n  istanze \nvirtuali che hanno valori positivi per tutte le features. Questo genera uno \n\"smoothing\" sulle statistiche calcolate.  \nValori elevati di \n alpha\n  creano smoothing elevati e modelli meno \ncomplessi.  \nGaussianNB\n  è più adatto a dataset con molte features. \n MultinomialNB\n  è \nmigliore rispetto a \n BernoulliNB\n  con dataset con un numero elevato di \nfeatures diverse da 0 (es. grandi documenti testuali).\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#7": "Naive Bayes classiﬁer da zero\nProviamo a fare l'implementazione del classiﬁcatore \nStep 1: Separate By Class.  \nStep 2: Summarize Dataset.  \nStep 3: Summarize Data By Class.  \nStep 4: Gaussian Probability Density Function.  \nStep 5: Class Probabilities \nImmaginiamo di impiegare il dataset \n Iris\n: \nlunghezza e larghezza sepalo (reali) \nlunghezza e larghezza petalo (reali) \nclasse di appartenenza = {Iris-setosa, Iris-versicolor, Iris-virginica}\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#8": "Naive Bayes classiﬁer: step 1\nCalcoliamo la probabilità di appartenenza di una istanza ad una certa \nclasse. \nSepariamo i dati in ingresso in base alla classe di appartenenza.  \n# Split the dataset by class values\n# Restituisce un dizionario classe -> lista di istanze\n# Funziona per ogni dataset il cui ultimo valore è la classe di appartenenza\ndef separate_by_class\n (\ndataset\n)\n:\nseparated\n  = \ndict\n()\nfor \ni \nin \nrange\n(\nlen\n(\ndataset\n))\n:\nvector\n = \ndataset\n[\ni\n]\nclass_value\n  = \nvector\n[\n-\n1\n]   # ultimo valore\nif \n(\nclass_value \n not \nin \nseparated\n )\n:\nseparated\n [\nclass_value\n ]\n = \nlist\n()\nseparated\n [\nclass_value\n ].\nappend\n(\nvector\n) \nreturn \nseparated\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\33-Ex_13 Esercitazione su Classificatore Bayesiano-sbloccato.pdf#9": "Naive Bayes classiﬁer: step 1\n# Iris dataset\ndataset\n = \n[[\n3.393533211\n ,\n2.331273381\n ,\n0\n],\n[\n3.110073483\n ,\n1.781539638\n ,\n0\n],\n[\n1.343808831\n ,\n3.368360954\n ,\n0\n],\n[\n3.582294042\n ,\n4.67917911\n ,\n0\n],\n[\n2.280362439\n ,\n2.866990263\n ,\n0\n],\n[\n7.423436942\n ,\n4.696522875\n ,\n1\n],\n[\n5.745051997\n ,\n3.533989803\n ,\n1\n],\n[\n9.172168622\n ,\n2.511101045\n ,\n1\n],\n[\n7.792783481\n ,\n3.424088941\n ,\n1\n],\n[\n7.939820817\n ,\n0.791637231\n ,\n1\n]]\nseparated\n  = \nseparate_by_class\n (\ndataset\n)\nfor \nlabel \nin \nseparated\n :\nprint\n(\nlabel\n)\nfor \nrow \nin \nseparated\n [\nlabel\n]\n:\nprint\n(\nrow\n)\n0\n[3.393533211, 2.331273381, 0]\n[3.110073483, 1.781539638, 0]\n[1.343808831, 3.368360954, 0]\n[3.582294042, 4.67917911, 0]\n[2.280362439, 2.866990263, 0]\n1\n[7.423436942, 4.696522875, 1]\n[5.745051997, 3.533989803, 1]\n[9.172168622, 2.511101045, 1]\n[7.792783481, 3.424088941, 1]\n[7.939820817, 0.791637231, 1]\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#0": "Machine Learning\nUniversità Roma Tre  \nDipartimento di Ingegneria \nAnno Accademico 2021 -2022\nSupport Vector Machine (SVM)",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#1": "Sommario\n!SVM Lineari: Pattern Linearmente Separabili e Non\n!SVM Non Lineari\n!SVM Multiclasse",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#10": "SVM50 CHAPTER 5. LINEAR DISCRIMINANT FUNCTIONS\ntransformation ϕ() that well separates the data — so the expected number of support\nvectors is small — then Eq. 107 shows that the expected error rate will be lower.\ny1y2\nR1\nR2\noptimal hyperplanemaximummargin b\nmaximummargin b\nFigure 5.19: Training a Support Vector Machine consists of ﬁnding the optimal hy-\nperplane, i.e., the one with the maximum distance from the nearest training patterns.\nThe support vectors are those (nearest) patterns, a distance bfrom the hyperplane.\nThe three support vectors are shown in solid dots.\n5.11.1 SVM training\nWe now turn to the problem of training an SVM. The ﬁrst step is, of course, to choose\nthe nonlinear ϕ-functions that map the input to a higher dimensional space. Often\nthis choice will be informed by the designer’s knowledge of the problem domain. In\nthe absense of such information, one might choose to use polynomials, Gaussians or\nyet other basis functions. The dimensionality of the mapped space can be arbitrarily\nhigh (though in practice it may be limited by computational resources).\nWe begin by recasting the problem of minimizing the magnitude of the weight\nvector constrained by the separation into an unconstrained problem by the method\nof Lagrange undetermined multipliers. Thus from Eq. 106 and our goal of minimizing\n||a||, we construct the functional\nL(a,α)=1\n2||a||2−n/summationdisplay\nk=1αk[zkatyk−1]. (108)\nand seek to minimize L() with respect to the weight vector a, and maximize it with\nrespect to the undetermined multipliers αk≥0. The last term in Eq. 108 expresses\nthe goal of classifying the points correctly. It can be shown using the so-called Kuhn-\nTucker construction (Problem 30) (also associated with Karush whose 1939 thesis\naddressed the same problem) that this optimization can be reformulated as maximiz-\ning\nL(α)=n/summationdisplay\nk=1αi−1\n2n/summationdisplay\nk,jαkαjzkzjyt\njyk, (109)\nsubject to the constraintsVedi Duda et al., Pattern Classification , 2000, pg. 262",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#11": "Sommario\n!SVM Lineari: Pattern Linearmente Separabili e Non\n!SVM Non Lineari\n!SVM Multiclasse",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#12": "SVM Lineari: Pattern Separabili\n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  ℜd: spazio vettoriale di d\ndimensioni ( d=3 in figura)\nxi: vettore di d componenti \nrelativo al pattern i-esimo \ndel TS\nyi: etichetta relativa al \npattern i-esimo del TS\nw: vettore che indica la \ndirezione ortogonale a tutti \ni vettori dell’iperpiano H\nb : coefficiente del termine \nnoto che compare nell’eq. \ndel iperpiano H",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#13": "Qualche Richiamo\n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \n!Iperpiano : sottospazio inferiore di una dimensione allo spazio in cui è \ndefinito (e.g., nello spazio 3D gli iperpiani sono i piani)\n!Equazione cartesiana di un piano:\nIl luogo delle soluzioni (x,y,z) che verificano l’equazione è il luogo dei \npunti P = (x,y,z) che appartengono al piano\n!L’equazione del piano specifica due elementi\n!la terna (w1,w2,w3) dei coefficienti detti parametri direttori del piano\nche individua la direzione ortogonale a tutti i vettori del piano\n!il coefficiente del termine noto b\n!In sintesi, per individuare univocamente un piano nello spazio è \nsufficiente disporre della direzione ortogonale al piano we del \ncoefficiente bw1x+w2y+w3z+b=0,     con w1,w2,w3, b ∈ ℜ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#14": "Qualche Richiamo\n!Sia      uno spazio vettoriale di dimensione n sul campo    . \nIl prodotto scalare fra due vettori di      è un’operazione che \ngeneralmente si indica con il simbolo “ •” ed è definita come segue:\novvero associa ad una coppia di vettori x=(x 1,x2,...,x n)e y=(y 1,y2,...,y n) \nun numero reale così definito \nx∙y = <x,y> = x1y1+x 2y2,..., +x nyn\n!Alle volte il prodotto scalare è definito anche come\nx∙y = = < x,y> = xty\ndove xtyè il prodotto riga per colonna tra il vettore trasposto xte il \nvettore y\n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \nℜn\nℜn\n•: ℜn×ℜn→ℜℜ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#15": "Qualche Richiamo\n!La norma di un vettore                                    è un’applicazione che \nad un vettore associa un numero reale\nEssa è pari alla radice quadrata della somma del quadrato delle \ncomponenti del vettore o, equivalentemente, alla radice quadrata del \nprodotto scalare del vettore con se stesso\n!Fra le proprietà di cui gode la norma vi è quella di omogeneità : x=x1,x2,...,xn ( )∈ ℜn\n•: ℜn→ℜ\nx=x12+x22+...+xn2=x•x\nper ogni x∈ ℜn e per ogni λ∈ ℜ si ha\nλx=λx\n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#16": "Qualche Richiamo\n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \n!Dato un piano P di equazione\nla sua distanza dall’origine degli assi è pari a\n!\n\"!\"+\"\"\"+\"#\"=!\n%\n!Si può dimostrare che la distanza !di un punto \"da un piano P è pari a\n&=%'(+!\n\"!\"+\"\"\"+\"#\"=%'(+!\n%=)(+)\n%\nmentre se il punto \"appartiene al piano, cioè se \"∈P, allora la \ndistanza !é per definizione zero w1x+w2y+w3z+b=0,     con w1,w2,w3, b ∈ ℜ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#17": "SVM Lineari: Pattern Separabili\n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \nIn altri termini, D(x) è la funzione distanza dall’iperpiano, cioè indica \nquanto il pattern xè distante dalla superficie decisionale ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#18": "SVM Lineari: Pattern Separabili\n182 4. LINEAR MODELS FOR CLASSIFICATION\nFigure 4.1 Illustration of the geometry of a\nlinear discriminant function in two dimensions.\nThe decision surface, shown in red, is perpen-\ndicular to w, and its displacement from the\norigin is controlled by the bias parameter w0.\nAlso, the signed orthogonal distance of a gen-\neral point xfrom the decision surface is given\nbyy(x)/∥w∥.x2\nx1wx\ny(x)\n∥w∥\nx⊥\n−w0\n∥w∥y=0\ny<0y>0\nR2R1\nan arbitrary point xand let x⊥be its orthogonal projection onto the decision surface,\nso that\nx=x⊥+rw\n∥w∥. (4.6)\nMultiplying both sides of this result by wTand adding w0, and making use of y(x)=\nwTx+w0andy(x⊥)=wTx⊥+w0=0, we have\nr=y(x)\n∥w∥. (4.7)\nThis result is illustrated in Figure 4.1.\nAs with the linear regression models in Chapter 3, it is sometimes convenient\nto use a more compact notation in which we introduce an additional dummy ‘input’\nvalue x0=1and then deﬁne /tildewidew=(w0,w)and/tildewidex=(x0,x)so that\ny(x)=/tildewidewT/tildewidex. (4.8)\nIn this case, the decision surfaces are D-dimensional hyperplanes passing through\nthe origin of the D+1-dimensional expanded input space.\n4.1.2 Multiple classes\nNow consider the extension of linear discriminants to K> 2classes. We might\nbe tempted be to build a K-class discriminant by combining a number of two-class\ndiscriminant functions. However, this leads to some serious difﬁculties (Duda and\nHart, 1973) as we now show.\nConsider the use of K−1classiﬁers each of which solves a two-class problem of\nseparating points in a particular class Ckfrom points not in that class. This is known\nas a one-versus-the-rest classiﬁer. The left-hand example in Figure 4.2 shows an4.1. Discriminant Functions 181\n(McCullagh and Nelder, 1989). Note, however, that in contrast to the models used\nfor regression, they are no longer linear in the parameters due to the presence of the\nnonlinear function f(·). This will lead to more complex analytical and computa-\ntional properties than for linear regression models. Nevertheless, these models are\nstill relatively simple compared to the more general nonlinear models that will be\nstudied in subsequent chapters.\nThe algorithms discussed in this chapter will be equally applicable if we ﬁrst\nmake a ﬁxed nonlinear transformation of the input variables using a vector of basis\nfunctions φ(x)as we did for regression models in Chapter 3. We begin by consider-\ning classiﬁcation directly in the original input space x, while in Section 4.3 we shall\nﬁnd it convenient to switch to a notation involving basis functions for consistency\nwith later chapters.\n4.1. Discriminant Functions\nA discriminant is a function that takes an input vector xand assigns it to one of K\nclasses, denoted Ck. In this chapter, we shall restrict attention to linear discriminants ,\nnamely those for which the decision surfaces are hyperplanes. To simplify the dis-\ncussion, we consider ﬁrst the case of two classes and then investigate the extension\ntoK>2classes.\n4.1.1 Two classes\nThe simplest representation of a linear discriminant function is obtained by tak-\ning a linear function of the input vector so that\ny(x)=wTx+w0 (4.4)\nwhere wis called a weight vector , andw0is abias (not to be confused with bias in\nthe statistical sense). The negative of the bias is sometimes called a threshold .A n\ninput vector xis assigned to class C1ify(x)/greaterorequalslant0and to class C2otherwise. The cor-\nresponding decision boundary is therefore deﬁned by the relation y(x)=0 , which\ncorresponds to a (D−1)-dimensional hyperplane within the D-dimensional input\nspace. Consider two points xAandxBboth of which lie on the decision surface.\nBecause y(xA)=y(xB)=0 ,w eh a v e wT(xA−xB)=0 and hence the vector wis\northogonal to every vector lying within the decision surface, and so wdetermines the\norientation of the decision surface. Similarly, if xis a point on the decision surface,\ntheny(x)=0 , and so the normal distance from the origin to the decision surface is\ngiven by\nwTx\n∥w∥=−w0\n∥w∥. (4.5)\nWe therefore see that the bias parameter w0determines the location of the decision\nsurface. These properties are illustrated for the case of D=2in Figure 4.1.\nFurthermore, we note that the value of y(x)gives a signed measure of the per-\npendicular distance rof the point xfrom the decision surface. To see this, consider\nVedi Bishop, Pattern Recognition and Machine Learning , 2006, pg. 182In questo caso la notazione è \ny(x) = wTx + w0  = D(x) = w · x + b\ncioè\nwTx =w · x = <w,x>\nw0 = b",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#19": "SVM Lineari: Pattern Separabili\n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \n4 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili  \nDate  due classi  di pattern  (linearmente  separabili ), e un training  set \nTS contenente  𝑛 campioni  𝐱1,𝑦1 …𝐱𝑛,𝑦𝑛 , dove  𝐱𝑖∈𝑑 sono  i \npattern  multidimensionali  e 𝑦𝑖∈+1,−1 le etichette  delle  due classi,  \nesistono  diversi  iperpiani  in grado  di eseguire  la separazione  voluta . \nUn generico  iperpiano  è definito  dai parametri  (𝐰,𝑏): \n \n \n \n \n \n \n \n \n \n \nLa distanza  di un vettore  𝐱 dall’iperpiano  vale pertanto : 𝑟=𝐷𝐱\n𝐰 \nGli iperpiani  (𝐰,𝑏) che separano  i pattern  del TS, con distanza  \nminima  1/𝐰 su ogni lato, soddisfano,  per 𝑖=1…𝑛, le equazioni : \n𝐰∙𝐱𝒊+𝑏≥+1     𝑠𝑒    𝑦𝑖=+1 \n𝐰∙𝐱𝒊+𝑏≤−1     𝑠𝑒    𝑦𝑖=−1 \no in modo  più compatto : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1     𝑝𝑒𝑟  𝑖=1…𝑛 \n \n \n \n \nIperpiano  \n𝐷𝐱=𝐰∙𝐱+𝑏 \n𝐰: vettore normale all’iperpiano  \n𝑏/𝐰: distanza dall’origine  \n𝐷𝐱=0: luogo dei vettori sul piano  \n𝐱=𝐱𝑝+𝑟𝐰\n𝐰,𝐷𝐱𝑝=𝟎 \n \n \n𝐷𝐱=𝐰∙𝐱+𝑏=𝑟∙𝐰 \n \nper semplicità \nomettiamo il trasposto \nnel prodotto scalare  \n5 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (2)  \nLa minima  distanza  tra l’iperpiano  di separazione  e un pattern  del \ntraining  set è detta  margine  (W). \n \n \n \n \n \n \n \n \nLa distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 \ndall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i \npunti  sull’iperpiano  𝐷𝐱=−1. \nPertanto  il margine  è  W= 2/𝐰.  \nL’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di \nseparazione  dei pattern  e massimizza  il margine  W (o \nalternativamente  minimizza  il suo inverso) : \nMinimizza : 𝐰2/2 \nVincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 \nI pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in \nfigura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi \npiù complessi,  definiscono  completamente  la soluzione  del \nproblema,  che può essere  espressa  come  funzione  di solo tali \npattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal \nnumero  𝑛 di elementi  in TS.    \n 𝐷𝐱=+1 1/𝐰 \n𝐷𝐱=0 \n𝐷𝐱=−1 𝐷𝐱>+1 \n𝐷𝐱<−1 1/𝐰 Vincoli da soddisfare",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#2": "Dilemma\nReti Neurali a un solo strato :\nPro: algoritmo di apprendimento semplice ed efficiente\nCons : potere espressivo limitato (i.e., possono apprendere solo \n“confini” decisionali lineari nello spazio di input)\nReti Neurali multistrato :\nPro: potere espressivo elevato (i.e., possono rappresentare funzioni        \ngeneriche non lineari)\nCons : algoritmo di apprendimento complicato (a causa della \nabbondanza di minimi locali e dell’alto numero di dimensioni  \ndello spazio dei pesi)\n?:\nPro: potere espressivo elevato\nPro: algoritmo di apprendimento efficiente",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#20": "SVM Lineari: Pattern Separabili\n5prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneSVM lineari: Pattern Separabili (2)\nLaminima distanza tral’iperpiano diseparazione eunpattern del\ntraining setèdetta margine (W).\nLadistanza dei punti che giacciono sull’iperpiano 𝐷𝐱=+1\ndall’iperpiano diseparazione (𝐷𝐱=0)è1/𝐰;lostesso vale peri\npuntisull’iperpiano 𝐷𝐱=−1.\nPertanto ilmargine èW=2/𝐰.\nL’iperpiano ottimo secondo SVM èquello soddisfa ivincoli di\nseparazione dei pattern emassimizza ilmargine W(o\nalternativamente minimizza ilsuoinverso) :\nMinimizza :𝐰2/2\nVincoli :𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0𝑝𝑒𝑟𝑖=1…𝑛\nIpattern deltraining setchegiacciono sulmargine (cerchi pieni in\nfigura) sono detti support vector .Talipattern, checostituiscono icasi\npiù complessi, definiscono completamente lasoluzione del\nproblema, che può essere espressa come funzione disolo tali\npattern ,indipendentemente dalla dimensionalità dello spazio𝑑edal\nnumero𝑛dielementi inTS.𝐷𝐱=+11/𝐰\n𝐷𝐱=0\n𝐷𝐱=−1𝐷𝐱>+1\n𝐷𝐱<−11/𝐰Laminima distanza trapattern del training set didue classi\ndifferenti piùvicini all’iperpiano diseparazione èdetta margine (-).",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#21": "SVM Lineari: Pattern Separabili\n5 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (2)  \nLa minima  distanza  tra l’iperpiano  di separazione  e un pattern  del \ntraining  set è detta  margine  (W). \n \n \n \n \n \n \n \n \nLa distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 \ndall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i \npunti  sull’iperpiano  𝐷𝐱=−1. \nPertanto  il margine  è  W= 2/𝐰.  \nL’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di \nseparazione  dei pattern  e massimizza  il margine  W (o \nalternativamente  minimizza  il suo inverso) : \nMinimizza : 𝐰2/2 \nVincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 \nI pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in \nfigura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi \npiù complessi,  definiscono  completamente  la soluzione  del \nproblema,  che può essere  espressa  come  funzione  di solo tali \npattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal \nnumero  𝑛 di elementi  in TS.    \n 𝐷𝐱=+1 1/𝐰 \n𝐷𝐱=0 \n𝐷𝐱=−1 𝐷𝐱>+1 \n𝐷𝐱<−1 1/𝐰 \n",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#22": "SVM Lineari: Pattern Separabili\n6 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (3)  \nIl problema  di ottimizzazione  precedente , può essere  risolto  \npassando  innanzitutto  a una formulazione  Lagrangiana  e \nsuccessivamente  a una formulazione  duale .  \nLa formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  \n𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  \nil vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : \n𝑄𝐰,𝑏,𝛂=1\n2𝐰∙𝐰− 𝛼𝑖𝑛\n𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 \nda minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. \n \nUtilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  \npuò essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in \nfunzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  \nfunzione  obiettivo  rispetto  ai soli 𝛼𝑖: \n𝑄𝛂= 𝛼𝑖\n𝑖=1…𝑛−1\n2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗\n𝑖,𝑗=1…𝑛 \n \ncon vincoli     𝑦𝑖𝛼𝑖=0\n𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  \n \nPer approfondimenti  e derivazione  delle  equazioni : \nS. Gunn,  Support  Vector  Machines  for Classification  and Regression  \nC. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  \n \n \n5 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (2)  \nLa minima  distanza  tra l’iperpiano  di separazione  e un pattern  del \ntraining  set è detta  margine  (W). \n \n \n \n \n \n \n \n \nLa distanza  dei punti  che giacciono  sull’iperpiano  𝐷𝐱=+1 \ndall’iperpiano  di separazione  (𝐷𝐱=0) è 1/𝐰; lo stesso  vale per i \npunti  sull’iperpiano  𝐷𝐱=−1. \nPertanto  il margine  è  W= 2/𝐰.  \nL’iperpiano  ottimo  secondo  SVM  è quello  soddisfa  i vincoli  di \nseparazione  dei pattern  e massimizza  il margine  W (o \nalternativamente  minimizza  il suo inverso) : \nMinimizza : 𝐰2/2 \nVincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏−1≥0     𝑝𝑒𝑟  𝑖=1…𝑛 \nI pattern  del training  set che giacciono  sul margine  (cerchi  pieni  in \nfigura)  sono  detti support  vector . Tali pattern,  che costituiscono  i casi \npiù complessi,  definiscono  completamente  la soluzione  del \nproblema,  che può essere  espressa  come  funzione  di solo tali \npattern , indipendentemente  dalla  dimensionalità  dello  spazio  𝑑 e dal \nnumero  𝑛 di elementi  in TS.    \n 𝐷𝐱=+1 1/𝐰 \n𝐷𝐱=0 \n𝐷𝐱=−1 𝐷𝐱>+1 \n𝐷𝐱<−1 1/𝐰 Funzione \nObiettivo",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#23": "6 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (3)  \nIl problema  di ottimizzazione  precedente , può essere  risolto  \npassando  innanzitutto  a una formulazione  Lagrangiana  e \nsuccessivamente  a una formulazione  duale .  \nLa formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  \n𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  \nil vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : \n𝑄𝐰,𝑏,𝛂=1\n2𝐰∙𝐰− 𝛼𝑖𝑛\n𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 \nda minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. \n \nUtilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  \npuò essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in \nfunzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  \nfunzione  obiettivo  rispetto  ai soli 𝛼𝑖: \n𝑄𝛂= 𝛼𝑖\n𝑖=1…𝑛−1\n2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗\n𝑖,𝑗=1…𝑛 \n \ncon vincoli     𝑦𝑖𝛼𝑖=0\n𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  \n \nPer approfondimenti  e derivazione  delle  equazioni : \nS. Gunn,  Support  Vector  Machines  for Classification  and Regression  \nC. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  \n \n SVM Lineari: Pattern Separabili\nVincoliFunzione \nObiettivo",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#24": "SVM Lineari: Pattern Separabili\n6 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (3)  \nIl problema  di ottimizzazione  precedente , può essere  risolto  \npassando  innanzitutto  a una formulazione  Lagrangiana  e \nsuccessivamente  a una formulazione  duale .  \nLa formulazione  Lagrangiana  prevede  di introdurre  un moltiplicatore  \n𝛼𝑖 (𝛼𝑖 ≥0) per ogni vincolo  nella  forma  𝑒𝑞𝑢𝑎𝑧𝑖𝑜𝑛𝑒  ≥0 e di sottrarre  \nil vincolo  moltiplicato  per 𝛼𝑖 dalla  funzione  obiettivo : \n𝑄𝐰,𝑏,𝛂=1\n2𝐰∙𝐰− 𝛼𝑖𝑛\n𝑖=1𝑦𝑖𝐰∙𝐱𝒊+𝑏−1 \nda minimizzare  rispetto  a 𝐰 e 𝑏 e massimizzare  rispetto  a 𝛼𝑖 ≥0. \n \nUtilizzando  le condizioni  di Karush -Kuhn -Tucker  (KKT), il problema  \npuò essere  posto  in forma  duale  esprimendo  i parametri  𝐰 e 𝑏 in \nfunzione  dei moltiplicatori  𝛼𝑖, e risolto  massimizzando  la nuova  \nfunzione  obiettivo  rispetto  ai soli 𝛼𝑖: \n𝑄𝛂= 𝛼𝑖\n𝑖=1…𝑛−1\n2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗\n𝑖,𝑗=1…𝑛 \n \ncon vincoli     𝑦𝑖𝛼𝑖=0\n𝑖=1…𝑛      e      𝛼𝑖≥0   𝑝𝑒𝑟 𝑖=1…𝑛  \n \nPer approfondimenti  e derivazione  delle  equazioni : \nS. Gunn,  Support  Vector  Machines  for Classification  and Regression  \nC. Burges , A Tutorial  on Support  Vector  Machines  for Pattern  Recognition  \n \n \nprodotto scalare fra \ncoppie di vettori del TS \nVincoliFunzione \nObiettivo",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#25": "SVM Lineari: Pattern Separabili\n7 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (4)  \nIl problema  di ottimizzazione  precedente  può essere  risolto  \nattraverso  un algoritmo  di programmazione  quadratica  (disponibile  in \nlibrerie  numeriche) . \nLa soluzione  consiste  nel derivare  i valori  ottimi  𝛼1∗,𝛼2∗…𝛼𝑛∗ \nLe condizioni  KKT assicurano  che 𝛼𝑖∗=0 per tutti i vettori  che non \nsono  support  vector . \nL’iperpiano  ottimo  è dunque  parametrizzato  da:  \n     𝐰∗= 𝛼𝑖∗\n𝑖=1…𝑛𝑦𝑖 𝐱𝑖 \ne   𝑏∗=𝑦𝑠− 𝛼𝑖∗\n𝑖=1…𝑛𝑦𝑖𝐱𝑖∙𝐱𝑠 \ndove  (𝐱𝑠, 𝑦𝑠) è uno dei support  vector .  \n \nLa funzione  distanza  dall’iperpiano  è: \n𝐷𝐱=𝐰∗∙𝐱+𝑏∗= 𝛼𝑖∗\n𝑖=1…𝑛𝑦𝑖𝐱∙𝐱𝑖+𝑏∗ \n \nSi noti che: \nIl segno  della  funzione  𝐷𝐱 consente  di classificare  un generico  \npattern  𝐱.  \nLe sommatorie  sono  riducibili  ai soli support  vector . \nNel caso  lineare  non è necessario,  dopo  aver calcolato  𝐰∗ e   𝑏∗, \nconservare/memorizzare  i support  vectors .   \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#26": "SVM Lineari: Pattern Separabili\n7 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (4)  \nIl problema  di ottimizzazione  precedente  può essere  risolto  \nattraverso  un algoritmo  di programmazione  quadratica  (disponibile  in \nlibrerie  numeriche) . \nLa soluzione  consiste  nel derivare  i valori  ottimi  𝛼1∗,𝛼2∗…𝛼𝑛∗ \nLe condizioni  KKT assicurano  che 𝛼𝑖∗=0 per tutti i vettori  che non \nsono  support  vector . \nL’iperpiano  ottimo  è dunque  parametrizzato  da:  \n     𝐰∗= 𝛼𝑖∗\n𝑖=1…𝑛𝑦𝑖 𝐱𝑖 \ne   𝑏∗=𝑦𝑠− 𝛼𝑖∗\n𝑖=1…𝑛𝑦𝑖𝐱𝑖∙𝐱𝑠 \ndove  (𝐱𝑠, 𝑦𝑠) è uno dei support  vector .  \n \nLa funzione  distanza  dall’iperpiano  è: \n𝐷𝐱=𝐰∗∙𝐱+𝑏∗= 𝛼𝑖∗\n𝑖=1…𝑛𝑦𝑖𝐱∙𝐱𝑖+𝑏∗ \n \nSi noti che: \nIl segno  della  funzione  𝐷𝐱 consente  di classificare  un generico  \npattern  𝐱.  \nLe sommatorie  sono  riducibili  ai soli support  vector . \nNel caso  lineare  non è necessario,  dopo  aver calcolato  𝐰∗ e   𝑏∗, \nconservare/memorizzare  i support  vectors .   \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#27": "SVM Lineari: Pattern Separabili\n8 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (4)  \nVantaggi  dell’approccio  SVM :  \nDefinizione  della  soluzione  sulla base  di un numero  ridotto  di \nsupport  vector  (solitamente  pochi) . \nIl numero  di support  vector  𝑛𝑠𝑣 indica  la complessità  del problema  \ne può essere  dimostrato  che l’errore  medio  (sui possibili  training  \nset) è limitato  da 𝑛𝑠𝑣/𝑛. \nSVM  «scala » molto  bene  rispetto  alla dimensionalità  𝑑 dello  \nspazio  delle  feature  (grazie  ai prodotti  scalari) . La complessità  \ncomputazionale  nel training  è quadratica  rispetto  al numero  𝑛 di \npattern  in TS. In pratica  il problema  può essere  risolto  per 𝑑=107 \ne per 𝑛 fino a 104. \n \n \nEsempio :  \ni support vectors \n(cerchiati ) \ndefiniscono  la \nsoluzione . ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#28": "SVM Lineari: Pattern Separabili\n8 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern Separabili (4)  \nVantaggi  dell’approccio  SVM :  \nDefinizione  della  soluzione  sulla base  di un numero  ridotto  di \nsupport  vector  (solitamente  pochi) . \nIl numero  di support  vector  𝑛𝑠𝑣 indica  la complessità  del problema  \ne può essere  dimostrato  che l’errore  medio  (sui possibili  training  \nset) è limitato  da 𝑛𝑠𝑣/𝑛. \nSVM  «scala » molto  bene  rispetto  alla dimensionalità  𝑑 dello  \nspazio  delle  feature  (grazie  ai prodotti  scalari) . La complessità  \ncomputazionale  nel training  è quadratica  rispetto  al numero  𝑛 di \npattern  in TS. In pratica  il problema  può essere  risolto  per 𝑑=107 \ne per 𝑛 fino a 104. \n \n \nEsempio :  \ni support vectors \n(cerchiati ) \ndefiniscono  la \nsoluzione . ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#29": "SVM Lineari: Pattern Non Separabili\n9 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern non Separabili  \nIn questo  caso  non tutti i pattern  possono  essere  separati  da un \niperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far \nsì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il \nconfine  della  classe . \nA tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si \nmodificano  i vincoli  di separazione : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 \nPer ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal \nmargine . Per i pattern  separabili  del TS le corrispondenti  variabili  di \nslack  assumeranno  valore  0. \n \n \n \n \n \n \n \nL’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il \nmargine , ma allo stesso  tempo  minimizzare  il numero  di elementi  \nnon correttamente  classificati . La funzione  obiettivo,  e di \nconseguenza  il problema  di ottimizzazione  vengono  così modificati : \nMinimizza : 𝐰2\n2+𝐶  ξ𝑖 𝑖=1…𝑛 \nVincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  \nclassificati: [ > 0 \n9 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern non Separabili  \nIn questo  caso  non tutti i pattern  possono  essere  separati  da un \niperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far \nsì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il \nconfine  della  classe . \nA tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si \nmodificano  i vincoli  di separazione : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 \nPer ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal \nmargine . Per i pattern  separabili  del TS le corrispondenti  variabili  di \nslack  assumeranno  valore  0. \n \n \n \n \n \n \n \nL’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il \nmargine , ma allo stesso  tempo  minimizzare  il numero  di elementi  \nnon correttamente  classificati . La funzione  obiettivo,  e di \nconseguenza  il problema  di ottimizzazione  vengono  così modificati : \nMinimizza : 𝐰2\n2+𝐶  ξ𝑖 𝑖=1…𝑛 \nVincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  \nclassificati: [ > 0 \nVi saranno quindi tante\nvariabili di slack (scarto)\nquanti sono ipattern del\nTraning Set(TS) .\nTali variabili saranno, però,\ndiverse dazero (>0)solo per\nipattern non separabili, cioè\nclassificati erroneamente",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#3": "Support Vector Machine (SVM)\nLeMacchine aVettori diSupporto oMacchine Kernel (Support Vector Machine,\nSVM) costituiscono uninsieme dimetodi diapprendimento supervisionato .\nPossono essere utilizzate siaperfare Classificazione ,siaperfare Regressione .\nInunbreve lasso temporale dalla loro prima implementazione hanno trovato\napplicazione inunnutrito numero dibranche scientifiche come Fisica, Biologia,\nChimica :\n!Preparazione difarmaci\n!Ricerca direlazioni quantitative sulle proprietà distrutture\n!Chemiometria\n!Sensoristica\n!Ingegneria chimica\n!Computer vision (e.g.,face detection erecognition inimmagini evideo)\n!...",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#30": "SVM Lineari: Pattern Non Separabili\n9 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern non Separabili  \nIn questo  caso  non tutti i pattern  possono  essere  separati  da un \niperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far \nsì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il \nconfine  della  classe . \nA tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si \nmodificano  i vincoli  di separazione : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 \nPer ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal \nmargine . Per i pattern  separabili  del TS le corrispondenti  variabili  di \nslack  assumeranno  valore  0. \n \n \n \n \n \n \n \nL’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il \nmargine , ma allo stesso  tempo  minimizzare  il numero  di elementi  \nnon correttamente  classificati . La funzione  obiettivo,  e di \nconseguenza  il problema  di ottimizzazione  vengono  così modificati : \nMinimizza : 𝐰2\n2+𝐶  ξ𝑖 𝑖=1…𝑛 \nVincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  \nclassificati: [ > 0 \n9 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern non Separabili  \nIn questo  caso  non tutti i pattern  possono  essere  separati  da un \niperpiano,  ed è necessario  rilassare  i vincoli  di separazione , per far \nsì che alcuni  pattern  (il minor  numero  possibile)  possano  valicare  il \nconfine  della  classe . \nA tal fine si introducono  𝑛 variabili  di slack  positive  ξ𝑖,𝑖=1…𝑛 e si \nmodificano  i vincoli  di separazione : \n𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 \nPer ogni pattern  𝐱𝑖 del TS, la variabile  ξ𝑖 codifica  la deviazione  dal \nmargine . Per i pattern  separabili  del TS le corrispondenti  variabili  di \nslack  assumeranno  valore  0. \n \n \n \n \n \n \n \nL’iperpiano  ottimo  deve  in questo  caso  ancora  massimizzare  il \nmargine , ma allo stesso  tempo  minimizzare  il numero  di elementi  \nnon correttamente  classificati . La funzione  obiettivo,  e di \nconseguenza  il problema  di ottimizzazione  vengono  così modificati : \nMinimizza : 𝐰2\n2+𝐶  ξ𝑖 𝑖=1…𝑛 \nVincoli :  𝑦𝑖𝐰∙𝐱𝒊+𝑏≥1−ξ𝑖      𝑝𝑒𝑟  𝑖=1…𝑛 Pattern erroneamente  \nclassificati: [ > 0 ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#31": "SVM Lineari: Pattern Non Separabili\n10 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern non Separabili (2)  \nIl coefficiente  𝐶 nel problema  di ottimizzazione  precedente,  indica  \nl’importanza  relativa  degli  errori  di classificazione  rispetto  \nall’ampiezza  del margine . Si tratta  di uno dei pochi  iperparametri  che \nl’utente  deve  scegliere  per il tuning  di SVM . \nPassando  attraverso  forma  lagrangiana/duale  otteniamo  un risultato  \nuguale  al caso  linearmente  separabile,  tranne  che per l’introduzione  \ndel limite  superiore  (𝐶) per i valori  dei moltiplicatori  𝛼𝑖 : \n𝑄𝛂= 𝛼𝑖\n𝑖=1…𝑛−1\n2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗\n𝑖,𝑗=1…𝑛 \n \ncon vincoli     𝑦𝑖𝛼𝑖=0\n𝑖=1…𝑛      e      0≤𝛼𝑖≤𝐶   𝑝𝑒𝑟 𝑖=1…𝑛  \nIl metodo  di soluzione  (i.e. Progr . Quadratica)  e il modo  di derivare  \nl’iperpiano  dagli  𝛼𝑖 sono  gli stessi  del caso  linearmente  separabile . \nEsempi : \n𝐶=200 \n1 solo errore, margine minore  𝐶=10 \n2 errori, margine maggiore  -Se C ---> ∞  : non ammettiamo violazioni del margine (hard -margin SVM)\n-Se C è finito : ammettiamo violazioni del margine e pattern misclassificati \n(soft-margin SVM)VincoliFunzione \nObiettivo",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#32": "SVM Lineari: Pattern Non Separabili\n10 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM lineari: Pattern non Separabili (2)  \nIl coefficiente  𝐶 nel problema  di ottimizzazione  precedente,  indica  \nl’importanza  relativa  degli  errori  di classificazione  rispetto  \nall’ampiezza  del margine . Si tratta  di uno dei pochi  iperparametri  che \nl’utente  deve  scegliere  per il tuning  di SVM . \nPassando  attraverso  forma  lagrangiana/duale  otteniamo  un risultato  \nuguale  al caso  linearmente  separabile,  tranne  che per l’introduzione  \ndel limite  superiore  (𝐶) per i valori  dei moltiplicatori  𝛼𝑖 : \n𝑄𝛂= 𝛼𝑖\n𝑖=1…𝑛−1\n2 𝛼𝑖𝛼𝑗𝑦𝑖𝑦𝑗𝐱𝑖∙𝐱𝑗\n𝑖,𝑗=1…𝑛 \n \ncon vincoli     𝑦𝑖𝛼𝑖=0\n𝑖=1…𝑛      e      0≤𝛼𝑖≤𝐶   𝑝𝑒𝑟 𝑖=1…𝑛  \nIl metodo  di soluzione  (i.e. Progr . Quadratica)  e il modo  di derivare  \nl’iperpiano  dagli  𝛼𝑖 sono  gli stessi  del caso  linearmente  separabile . \nEsempi : \n𝐶=200 \n1 solo errore, margine minore  𝐶=10 \n2 errori, margine maggiore  \nAll’aumentare del valore di C\n!diminuisce il numero di support vector (i.e., complessità del problema)\n!diminuisce il numero di errori sul Traning Set\n!diminuisce il margine di separazione (i.e., capacità di generalizzazione)",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#4": "SVM\n!In1936 ,R.A.Fisher suggested the first algorithm forPattern Recognition\n(Fisher 1936 ).\n!Aronszajn (1950 )introduced the“Theory ofReproducing Kernels” .\n!In1957 Frank Rosenblatt invented alinear classifier called the perceptron (the\nsimplest kind offeedforward neural network) .\n!Vapnik and Lerner (1963 )introduced the Generalized Portrait algorithm (the\nalgorithm implemented by support vector machines isanonlinear\ngeneralization oftheGeneralized Portrait algorithm) .\n!Aizerman, Braverman and Rozonoer (1964 )introduced the geometrical\ninterpretation ofthekernels asinner products inafeature space .\n!Vapnik and Chervonenkis (1964 )further developed the Generalized\nPortrait algorithm .\n!...\n!SVMs close totheir current form were first introduced with apaper attheCOLT\n1992 conference (Boser, Guyon and Vapnik 1992 ).\n!In1995 thesoft margin classifier was introduced byCortes and Vapnik (1995 );\ninthe same year the algorithm was extended tothe case ofregression by\nVapnik (1995 )inThe Nature ofStatistical Learning Theory .\nfonte: https://www.svms.org/history.html",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#5": "SVM! SVMs (Vapnik, 1990’s) choose the linear separator with the \nlargest margin  \n• Good according to intuition, theory, practice  \n• SVM became famous when, using images as input, it gave \naccuracy comparable to neural-network with hand-designed \nfeatures in a handwriting recognition task Support Vector Machine (SVM) \nV. Vapnik Robust to \noutliers! \nA. Chervonenkis    XXV «                         »   * 1 \n1964 \n    5 1 9 . 9 5 \n                             \n .  .       ,  .  .             \n(      ) \n                                  ,                          -\n                    .                -                              \n                          .                                         -\n                                                                \n                           . \n1.          \n  1 9 5 7  .                                                     -\n                                   ,                            -\n      . \n                                              ,                \n                                                                     \n               ,        ,   -       ,                                -\n  ,     -       ,                                                    -\n     . \n  \n      \n   . 1 \n  1 9 5 7  .                                                  .   -\n                                  ,                                  \n                   .     -                                    . 1. \n                        ,                                        , \n                                  -        . \n   ,                                                ,        -\n        ,                                                        . \n               ,                                      ,             -\n    ,          % ,...,  ,                             ,              , \n                   .                                                \n        .                                                        \n[1].          [ 1]                                           ,           \n                                                     .               , \n                                                                     \n                                 ,                                  \n         .              ,                    U                      \n                   \n£*= ejx     §2   . . .   cnfn, \n112 \n                        \n1.              .  . ,              .  .                                     -\n             .                          ,  . X X I V ,   6, 1 9 6 3 . \n2. X        .  ,              .  ,              .  .                - 1 ,     \n                            .                        ,   4.    -          . \n     . , 1 9 6 2 . \n3.            .  .                                                      . \n .         ,        .            .    . ,  . 2,   2, 1 9 6 2 . \n4.                .    .                                                    -\n            .                        ,   4.    -          .      . , 1 9 6 2 . \n5.            .                                               .          -\n              ,   4.    -          .      . , 1 9 6 2 . \nON A P E R C E P T R O N C L A S S \nV. N . V A P N I K , A . Y A . C H E R V O N E N K I S \nA c l a s s of p e r c e p t r o n s d i f f e r i n g f r o m p e r c e p t r o n s in e x i s t e n c e w i t h t h e l e a r n i n g m e t -\nhod is c o n s i d e r e d . S u c h a p e r c e p t r o n is d e s c r i b e d , i t s b l o c k - s c h e m e a n d t h e l e a r n i n g m e t -\nhod s a r e p r o p o s e d . T h e a l g o r i t h m s f o r v a r i o u s c l a s s e s of p e r c e p t r o n s a r e c o m p a r e d w i t h \nthe t h e o r y of p a t t e r n r e c o g n i t i o n w i t h t h e h e l p of a g e n e r a l i z e d p o r t r a i t . Journal of Machine Learning Research 16 (2015) 2067-2080 Published 9/15\nAlexey Chervonenkis’s Bibliography\nAlex Gammerman alex@cs.rhul.ac.uk\nVladimir Vovk v.vovk@rhul.ac.uk\nComputer Learning Research Centre, Department of Computer Science\nRoyal Holloway, University of London\nThis bibliography does not contain Alexey’s patents (he has at least two), technical reports,\nunpublished manuscripts, and collections edited by him. \"NA\" indicates that a journal paper\nwas not assigned to a volume; e.g., it is common for Russian journals (such as Проблемы\nуправления and, in some years, Автоматика и телемеханика ) not to have volumes, and\nalso to have pages numbered separately inside each issue. All papers published by Alexey\nbefore 2001 (and afterwards in the case of papers whose original language was Russian) have\nauthor lists ordered according to the Cyrillic alphabetic order; for other papers the order\nmay reﬂect the authors’ contributions (people who contributed most tend to be listed ﬁrst)\nand administrative positions (bosses tend to be listed last).\nThe bibliography is given by the year of the original publication (which may be di ﬀerent\nfrom the year of the English translation, always given ﬁrst when available).\n1964\n[1] Vladimir N. Vapnik and Alexey Ya. Chervonenkis. On a class of perceptrons. Au-\ntomation and Remote Control ,2 5 ( 1 ) : 1 0 3 – 1 0 9 ,1 9 6 4 . R u s s i a no r i g i n a l : В.Н.Вапник ,\nА.Я.Червоненкис .Об одном классе персептронов .Автоматика и телемеханика ,\n25(1):112–120, 1964; with English summary entitled “On a perceptron class”. The orig-\ninal article submitted on 21 February 1963.\n[2] Vladimir N. Vapnik and Alexey Ya. Chervonenkis. On a class of pattern-recognition\nlearning algorithms. Automation and Remote Control ,2 5 ( 6 ) : 8 3 8 – 8 4 5 ,1 9 6 4 . R u s s i a n\noriginal: В.Н.Вапник ,А.Я.Червоненкис .Об одном классе алгоритмов обучения\nраспознаванию образов .Автоматика и телемеханика , 25(6):937–945, 1964; with\nEnglish summary entitled “A class of algorithms for pattern recognition learning”. The\nsubmission date is not given.\n[3] Vladimir N. Vapnik, Lyudmila M. Dronfort, and Alexey Ya. Chervonenkis. Some ques-\ntions of the self-organization of recognizing systems (in Russian). In Theory and Appli-\ncation of Automatic Systems (Russian), pages 172–177. Nauka, Moscow, 1964. In the\noriginal language: В.Н.Вапник ,Л.М.(Людмила Михайловна )Дронфорт ,А.Я.\nЧервоненкис .Некоторые вопросы самоорганизации распознающих устройств .\nТеория и применение автоматических систем ,сс.1 7 2 – 1 7 7 . Наука ,Москва ,1 9 6 4 .\nc\u00002015 Alex Gammerman and Vladimir Vovk.",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#6": "SVM\n2 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  Support Vector  Machines  (SVM)  \nLa teoria  che governa  i meccanismi  di funzionamento  di SVM  è stata  \nintrodotta  da Vapnik  a partire  dal 1965  (statistical  learning  theory ), e \nperfezionata  più recentemente  (1995 ) dallo  stesso  Vapnik  e altri. \nSVM  è uno degli  strumenti  più utilizzati  per la classificazione  di \npattern . \nInvece  di stimare  le densità  di probabilità  delle  classi,  Vapnik  \nsuggerisce  di risolvere  direttamente  il problema  di interesse  (che \nconsidera  più semplice),  ovvero  determinare  le superfici  decisionali  \ntra le classi  (classification  boundaries ). \n \nandiamo per gradi …  \nSVM  nasce  come  classificatore  binario  (2 classi),  estendibile  a più \nclassi . Affrontiamo  la trattazione  per gradi : \nSVM  lineare  (i.e., la superficie  di separazione  è un iperpiano ) e \npattern  del training  set linearmente  separabili  (i.e., esiste  per \nipotesi  almeno  un iperpiano  in grado  di separarli) . \nSVM  lineare  e pattern  non linearmente  separabili . Ci saranno  \ninevitabilmente  errori  di classificazione  nel training  set non \nesistendo  alcun  iperpiano  in grado  di separare  i pattern . \nSVM  non lineare  (i.e., superficie  di separazione  complessa ) \nsenza  ipotesi  sulla separabilità  dei pattern . \nEstensione  multiclasse . \n 1.  Use optimization to find solution (i.e. a hyperplane) \nwith few errors \n2.  Seek large margin separator to improve \ngeneralization \n3.  Use kernel trick to make large feature \nspaces computationally efficient Support vector machines: 3 key ideas ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#7": "SVM\nLe SVM si fondano su tre idee chiave\n!L’adozione di tecniche di ottimizzazione matematica per \nindividuare soluzioni (i.e., iperpiani) con un basso tasso di errori\n!La ricerca di un separatore con margine largo per migliorare la \ngeneralizzazione \n!L’impiego dello stratagemma del kernel (kernel trick) per rendere \ncomputazionalemente efficienti ampi spazi di feature1.  Use optimization to find solution (i.e. a hyperplane) \nwith few errors \n2.  Seek large margin separator to improve \ngeneralization \n3.  Use kernel trick to make large feature \nspaces computationally efficient Support vector machines: 3 key ideas ",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#8": "SVM\n2 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  Support Vector  Machines  (SVM)  \nLa teoria  che governa  i meccanismi  di funzionamento  di SVM  è stata  \nintrodotta  da Vapnik  a partire  dal 1965  (statistical  learning  theory ), e \nperfezionata  più recentemente  (1995 ) dallo  stesso  Vapnik  e altri. \nSVM  è uno degli  strumenti  più utilizzati  per la classificazione  di \npattern . \nInvece  di stimare  le densità  di probabilità  delle  classi,  Vapnik  \nsuggerisce  di risolvere  direttamente  il problema  di interesse  (che \nconsidera  più semplice),  ovvero  determinare  le superfici  decisionali  \ntra le classi  (classification  boundaries ). \n \nandiamo per gradi …  \nSVM  nasce  come  classificatore  binario  (2 classi),  estendibile  a più \nclassi . Affrontiamo  la trattazione  per gradi : \nSVM  lineare  (i.e., la superficie  di separazione  è un iperpiano ) e \npattern  del training  set linearmente  separabili  (i.e., esiste  per \nipotesi  almeno  un iperpiano  in grado  di separarli) . \nSVM  lineare  e pattern  non linearmente  separabili . Ci saranno  \ninevitabilmente  errori  di classificazione  nel training  set non \nesistendo  alcun  iperpiano  in grado  di separare  i pattern . \nSVM  non lineare  (i.e., superficie  di separazione  complessa ) \nsenza  ipotesi  sulla separabilità  dei pattern . \nEstensione  multiclasse . \n Iperpiano: sottospazio di dimensione inferiore di uno (n-1) rispetto allo spazio in \ncui è contenuto (n) (e.g., se lo spazio ha dimensione 3, i suoi iperpiani sono i piani)",
    "data_test\\rootfolder\\università\\MachineLearning\\34-SVM(1)-sbloccato.pdf#9": "3 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM: l’idea  \nDate  due classi  di pattern  multidimensionali  linearmente  separabili,  \ntra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in \ngrado  di separare  le classi  con il maggior  margine  possibile . \nIl margine  è la distanza  minima  di punti  delle  due classi  nel training  \nset dall’iperpiano  individuato . Definizione  formale  in seguito . \n \n \n \n \n \n \n \n \n \n \n \nLa massimizzazione  del margine  è legata  alla generalizzazione . Se i \npattern  del training  set sono  classificati  con ampio  margine  si può \n«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  \nsiano  gestiti  correttamente .  \n3 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM: l’idea  \nDate  due classi  di pattern  multidimensionali  linearmente  separabili,  \ntra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in \ngrado  di separare  le classi  con il maggior  margine  possibile . \nIl margine  è la distanza  minima  di punti  delle  due classi  nel training  \nset dall’iperpiano  individuato . Definizione  formale  in seguito . \n \n \n \n \n \n \n \n \n \n \n \nLa massimizzazione  del margine  è legata  alla generalizzazione . Se i \npattern  del training  set sono  classificati  con ampio  margine  si può \n«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  \nsiano  gestiti  correttamente .  \n3 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM: l’idea  \nDate  due classi  di pattern  multidimensionali  linearmente  separabili,  \ntra tutti i possibili  iperpiani  di separazione,  SVM  determina  quello  in \ngrado  di separare  le classi  con il maggior  margine  possibile . \nIl margine  è la distanza  minima  di punti  delle  due classi  nel training  \nset dall’iperpiano  individuato . Definizione  formale  in seguito . \n \n \n \n \n \n \n \n \n \n \n \nLa massimizzazione  del margine  è legata  alla generalizzazione . Se i \npattern  del training  set sono  classificati  con ampio  margine  si può \n«sperare»  che anche  pattern  del test set vicini  al confine  tra le classi  \nsiano  gestiti  correttamente .  \nSVM",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#0": "Sommario\n!SVM Lineari: Pattern Linearmente Separabili e Non\n!SVM Non Lineari\n!SVM Multiclasse",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#1": "SVM Non Lineari\n11 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM Non lineari  \nSVM  prevede  un’importante  estensione  della  teoria  inizialmente  \nsviluppata  per iperpiani,  al caso  (non lineare ) di separazione  dei \npattern  con superfici  anche  molto  complesse . Tutto  ciò avviene  in \nmodo  molto  semplice :    \nViene  definito  un mapping  Φ non lineare  dei pattern  dallo  spazio  \ndi partenza  𝑑 verso  uno spazio  𝑚 a più alta dimensionalità  \n(𝑚>𝑑): \nΦ:𝑑→𝑚,Φ𝐱=𝑔1𝐱,𝑔2𝐱,…𝑔𝑚𝐱 \nNello  spazio  𝑚, dove  maggiori  sono  i gradi  di libertà , i pattern  \nΦ𝐱1,Φ𝐱2,…Φ𝐱𝑛 possono  essere  più facilmente  separati  da \nun iperpiano  utilizzando  la teoria  nota. Ciò equivale  a separare  i \npattern  𝐱1,𝐱2,…𝐱𝑛 in 𝑑 con superfici  arbitrariamente  complesse .  \nAnalizzando  la formulazione  del problema  lagrangiano -duale , si nota \nche i vettori  del training  set appaiono  solo in forma  di prodotti  scalari  \ntra coppie  di vettori . Questa  proprietà  (fondamentale ) permette  di \nevitare  la manipolazione  di vettori  nello  spazio  𝑚 (𝑚 può facilmente  \nraggiungere  dimensione  108 e anche  assumere  valore  infinito) . \nInfatti,  per opportuni  mapping  Φ è possibile  ricondurre  il prodotto  \nscalare  di due pattern  mappati  nello  spazio  𝑚 a una funzione  𝐾 \n(detta  Kernel ) dei due pattern  originali  nello  spazio  𝑑.  \nΦ𝐱∙Φ𝐱′=𝐾𝐱,𝐱′ \nCiò consente  di risolvere  il problema  di ottimizzazione  senza  \nparticolari  complicazioni  rispetto  al caso  lineare . Una volta  \ndeterminati  gli𝛼𝑖∗, la superficie  di separazione  (regola  di \nclassificazione)  è esprimibile  come :  \n𝐷𝐱= 𝛼𝑖∗\n𝑖=1…𝑛𝑦𝑖 𝐾𝐱,𝐱𝑖+𝑏∗ \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#10": "SVM Non Lineari: Kernel Function\n12 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM Non lineari: Kernel  functions  \nPolinomio  di grado   𝑞 (iperparametro ): \n Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le \npossibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  \ncomponenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: \nΦ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  \n e quindi  𝑚=9.  \n Si dimostra  che: \n𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 \nRadial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): \n \n𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2\n2𝜎2 \n2-layer  Neural  Network  (meno  utilizzato) : \n \n𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 \n \n𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : \nuna possibile  scelta  è: 𝜈=1,𝑎=1 \nIl numero  di hidden  units  e i pesi sono  determinati  \nautomaticamente  da SVM  \n \n \n \n \n \n \n \n \n Si può vedere che il kernel RBF (o gaussiano) equivale a eseguire \nil prodotto interno dei dati di input mappati in un feature space a \ndimensione infinita ",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#11": "SVM Non Lineari: Kernel Function\n12 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM Non lineari: Kernel  functions  \nPolinomio  di grado   𝑞 (iperparametro ): \n Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le \npossibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  \ncomponenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: \nΦ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  \n e quindi  𝑚=9.  \n Si dimostra  che: \n𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 \nRadial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): \n \n𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2\n2𝜎2 \n2-layer  Neural  Network  (meno  utilizzato) : \n \n𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 \n \n𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : \nuna possibile  scelta  è: 𝜈=1,𝑎=1 \nIl numero  di hidden  units  e i pesi sono  determinati  \nautomaticamente  da SVM  \n \n \n \n \n \n \n \n \n Il kernel 2-layer Neural Network è anche detto kernel Sigmoid",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#12": "SVM Non Lineari: Kernel Function\n!Inoltre spesso viene chiamato kernel lineare il kernel\nche equivale a utilizzare una funzione di mapping φtale \nche φ(x)=x, cioè a nonutilizzare un kernelK(x,x')=(x⋅x')",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#13": "SVM Non Lineari: Esempi\n13 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM Non lineari: Esempi  \nPolinomio 𝑞 = 2 Polinomio 𝑞 = 10 \nRBF V = 1 RBF V = 0.2  All’aumentare del valore dell’iperparametro q (grado del polinomio)\n!aumenta il numero di support vector (i.e., complessità del problema)\n!diminuisce il numero di errori sul Traning Set (da 1 a 0)\n!diminuisce il margine di separazione (i.e., capacità di generalizzazione)",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#14": "SVM Non Lineari: Esempi\n13 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM Non lineari: Esempi  \nPolinomio 𝑞 = 2 Polinomio 𝑞 = 10 \nRBF V = 1 RBF V = 0.2  \nAl diminuire del valore dell’iperparametro !(deviazione standard)\n!aumenta il numero di support vector (i.e., complessità del problema)\n!diminuisce il numero di errori sul Traning Set (da 1 a 0)\n!diminuisce il margine di separazione (i.e., capacità di generalizzazione)",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#15": "Sommario\n!SVM Lineari: Pattern Linearmente Separabili e Non\n!SVM Non Lineari\n!SVM Multiclasse",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#16": "SVM: Multiclasse\n14 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM: estensione multiclasse  \nSVM  è in grado  di determinare  la superficie  di separazione  tra 2 \nclassi  di pattern ; come  gestire  allora  i problemi  con più di 2 classi  ? \nSi tratta  di un problema  ancora  aperto  anche  se esistono  diverse  \nsoluzioni ; le più utilizzate  sono : \n \nOne-Against -One: che studieremo  in seguito  nell’ambito  dei multi -\nclassificatori . \n \nOne-Against -All: \nDate  𝑠 classi , 𝑤1,𝑤2…𝑤𝑠 \nPer ogni classe  𝑤𝑘, si determina  con SVM  la superficie  di \nseparazione  tra i pattern  di 𝑤𝑘 (etichettati  +1) da una parte,  e i \npattern  di tutte le rimanenti  classi  𝑤ℎ,ℎ≠𝑘 (etichettati  -1) \ndall’altra,  ottenendo  la funzione  𝐷𝑘𝐱 che indica  quanto  𝐱 è \ndistante  dalla  superficie  decisionale  in direzione  di 𝑤𝑘. \nMaggiore  è 𝐷𝑘𝐱 più confidenti  siamo  dell’appartenenza  di 𝐱 a \n𝑤𝑘.  \nAl termine  del training,  si assegna  il pattern  𝐱 alla classe  𝑘∗ per \ncui è massima  la distanza  dalla  superficie  decisionale :  \n𝑘∗=𝑎𝑟𝑔 𝑚𝑎𝑥\n𝑘𝐷𝑘𝐱 \nNota : È necessario  eseguire  𝑠 training  SVM   \n \n \n !One-Against -One\n!One-Against -All",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#17": "One-Against -One\nE’ingenere piùaccurato diOne-Against -All(vedi dopo), anche se\nmeno efficiente inquanto richiede l’addestramento diunnumero\nmaggiore diclassificatori\n24 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  One-Against -One \nL’approccio  One-Against -One, consente  di risolvere  un problema  di \nclassificazione  multi -classe , attraverso  classificatori  binari . \nÈ l’approccio  adottato  dalla  libreria  LIBSVM  (usata  in BioLab ). \nSe 𝑠 sono  le classi  del problema,  si addestrano  \n𝑠×𝑠−1/2 classificatori  binari : tutte le possibili  coppie , \nindipendentemente  dall’ordine . \nDurante  la classificazione,  il pattern  𝐱 viene  classificato  da ogni \nclassificatore  binario,  che assegna  un voto alla classe  (tra le due) \npiù probabile .  \nAl termine  il pattern  𝐱 è assegnato  alla classe  che ha ricevuto  più \nvoti (majority  vote rule).  \n \nÈ in genere  più accurato  di One-Against -All (discusso  in precedenza  \nper SVM),  anche  se meno  efficiente  in quanto  richiede  \nl’addestramento  di un numero  maggiore  di classificatori . \n \n (Numero di combinazioni di classe k=2)",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#18": "14prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneSVM: estensione multiclasse\nSVM èingrado dideterminare lasuperficie diseparazione tra2\nclassi dipattern ;come gestire allora iproblemi conpiùdi2classi ?\nSitratta diunproblema ancora aperto anche seesistono diverse\nsoluzioni ;lepiùutilizzate sono :\nOne\n-Against -One:chestudieremo inseguitonell’ambito deimulti -\nclassificatori .\nOne\n-Against -All:\nDate\n𝑠classi ,𝑤1,𝑤2…𝑤𝑠\nPer\n ogni classe𝑤𝑘,sidetermina con SVM lasuperficie di\nseparazione traipattern di𝑤𝑘(etichettati +1)daunaparte, ei\npattern ditutte lerimanenti classi𝑤ℎ,ℎ≠𝑘(etichettati -1)\ndall’altra, ottenendo lafunzione 𝐷𝑘𝐱cheindica quanto𝐱è\ndistante dalla superficie decisionale indirezione di𝑤𝑘.\nMaggiore è𝐷𝑘𝐱piùconfidenti siamodell’appartenenza di𝐱a\n𝑤𝑘.\nAl\ntermine deltraining, siassegna ilpattern𝐱allaclasse𝑘∗per\ncuièmassima ladistanza dalla superficie decisionale :\n𝑘∗=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑘𝐷𝑘𝐱\nNota :Ènecessario eseguire 𝑠training SVMSVM: Multiclasse\n(con x pattern da classificare \ne k=1, 2 ... s)  \n14prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneSVM: estensione multiclasse\nSVM èingrado dideterminare lasuperficie diseparazione tra2\nclassi dipattern ;come gestire allora iproblemi conpiùdi2classi ?\nSitratta diunproblema ancora aperto anche seesistono diverse\nsoluzioni ;lepiùutilizzate sono :\nOne\n-Against -One:chestudieremo inseguitonell’ambito deimulti -\nclassificatori .\nOne\n-Against -All:\nDate\n𝑠classi ,𝑤1,𝑤2…𝑤𝑠\nPer\nogni classe𝑤𝑘,sidetermina con SVM lasuperficie di\nseparazione traipattern di𝑤𝑘(etichettati +1)daunaparte, ei\npattern ditutte lerimanenti classi𝑤ℎ,ℎ≠𝑘(etichettati -1)\ndall’altra, ottenendo lafunzione 𝐷𝑘𝐱cheindica quanto𝐱è\ndistante dalla superficie decisionale indirezione di𝑤𝑘.\nMaggiore è𝐷𝑘𝐱piùconfidenti siamodell’appartenenza di𝐱a\n𝑤𝑘.\nAl\ntermine deltraining, siassegna ilpattern𝐱allaclasse𝑘∗per\ncuièmassima ladistanza dalla superficie decisionale :\n𝑘∗=𝑎𝑟𝑔𝑚𝑎𝑥\n𝑘𝐷𝑘𝐱\nNota :Ènecessario eseguire 𝑠training SVM",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#19": "SVM: Implementazione\n15 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM: implementazione  \n \nIl training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di \nrisolvere  un problema  di programmazione  quadratica .  \nAlcune  implementazioni  sono  disponibili  on-line. Ad esempio : \nLIBSVM  (wrapped  da BioLab ) \nhttp://www .csie.ntu.edu.tw/~cjlin/libsvm  \nAttenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  \ndiverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). \nIn particolare  si fa uso del generico  parametro  gamma  (𝛾) per \nregolare  la complessità  della  superficie  decisionale . \nAumentando  γ la superficie  può assumere  forme  più \ncomplesse . \nN.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. \nInserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e \nCoef 0) \nPer la classificazione  multiclasse  utilizza  internamente  One-\nAgainst -One [2] (accurato  ma inefficiente  per molte  classi ). \n[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  \nClassification,  disponibile  sul sito web di LIBSVM  \n[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . \nACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, \n2011 , disponibile  sul sito web di LIBSVM  \n \nLIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / \nStessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  \ndimensionalità  ed elevato  numero  di pattern . \nSVM -light - http://svmlight .joachims .org \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#2": "Kernel Trick\nSVM Classification\nOvviamente le SVM possono essere\nusate per separare classi che non\npotrebbero essere separate con un\nclassificatore lineare, altrimenti la loro\napplicazione a casi di reale interesse\nnon sarebbe possibile. In questi casi le\ncoordinate degli oggetti sono mappate\nin uno spazio detto “feature space”\nutilizzando funzioni non lineare,\nchiamate “feature function” ϕ.Ilfeature\n chiamate “feature function” ϕ.Ilfeature\nspace è uno spazio fortemente\nmultidimensionale in cui le due classi\npossono essere separate con un\nclassificatore lineare.\nQuindi lo spazio iniziale viene rimappato\nnel nuovo spazio, a questo punto viene\nidentificato il classificatore che poi viene\nriportato nello spazio iniziale, come\nillustrato in figura.Fonte: Stefano Cavuoti\nSVM Classification\nLa funzione ϕcombina quindi lo spazio iniziale (le \ncaratteristiche originali degli oggetti) nello spaz io \ndelle features che potrebbe in linea di principio \navere anche dimensione infinita. A causa del fatto \nche questo spazio ha molte dimensioni non \nsarebbe pratico utilizzare una funzione generica \nper trovare l’iperpiano di separazione, quindi \nvengono usate delle funzioni dette “kernel” e si \nidentifica la funzione ϕtramite una combinazione \ndi funzioni di kernel.\nFonte: http://www.ivanciuc.org/\ndi funzioni di kernel.\nL’implementazione più famosa delle SVM (libSVM) \nusa quattro possibili kernel:\nFonte: http://www.imtech.res.in/raghava/rbpred/svm. jpg\nKernel trick–(1)\n•Possiamo trasformare i dati nell' input space in un nuovo \nspazio, detto feature space , a più alta dimensionalità\n•I vettori che prima non erano linearmente separabili hanno più \nprobabilità di esserlo in uno spazio a più dimensioni\n25\nIdea:trasformare idati nell’Input Space inunnuovo spazio, detto\nFeature Space ,apiùaltadimensionalità .\nIpattern che prima non erano linearmente separabili nello spazio di\npartenza hanno piùprobabilità diesserlo inuno spazio apiùdimensioni,\nessendo ilnumero digradi dilibertà piùelevato .",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#20": "SVM: Implementazione\n15 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM: implementazione  \n \nIl training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di \nrisolvere  un problema  di programmazione  quadratica .  \nAlcune  implementazioni  sono  disponibili  on-line. Ad esempio : \nLIBSVM  (wrapped  da BioLab ) \nhttp://www .csie.ntu.edu.tw/~cjlin/libsvm  \nAttenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  \ndiverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). \nIn particolare  si fa uso del generico  parametro  gamma  (𝛾) per \nregolare  la complessità  della  superficie  decisionale . \nAumentando  γ la superficie  può assumere  forme  più \ncomplesse . \nN.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. \nInserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e \nCoef 0) \nPer la classificazione  multiclasse  utilizza  internamente  One-\nAgainst -One [2] (accurato  ma inefficiente  per molte  classi ). \n[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  \nClassification,  disponibile  sul sito web di LIBSVM  \n[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . \nACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, \n2011 , disponibile  sul sito web di LIBSVM  \n \nLIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / \nStessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  \ndimensionalità  ed elevato  numero  di pattern . \nSVM -light - http://svmlight .joachims .org \n \n \n 15 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM: implementazione  \n \nIl training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di \nrisolvere  un problema  di programmazione  quadratica .  \nAlcune  implementazioni  sono  disponibili  on-line. Ad esempio : \nLIBSVM  (wrapped  da BioLab ) \nhttp://www .csie.ntu.edu.tw/~cjlin/libsvm  \nAttenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  \ndiverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). \nIn particolare  si fa uso del generico  parametro  gamma  (𝛾) per \nregolare  la complessità  della  superficie  decisionale . \nAumentando  γ la superficie  può assumere  forme  più \ncomplesse . \nN.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. \nInserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e \nCoef 0) \nPer la classificazione  multiclasse  utilizza  internamente  One-\nAgainst -One [2] (accurato  ma inefficiente  per molte  classi ). \n[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  \nClassification,  disponibile  sul sito web di LIBSVM  \n[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . \nACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, \n2011 , disponibile  sul sito web di LIBSVM  \n \nLIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / \nStessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  \ndimensionalità  ed elevato  numero  di pattern . \nSVM -light - http://svmlight .joachims .org \n \n \n15 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM: implementazione  \n \nIl training  di SVM,  richiede  algoritmi  numerici  non banali  in grado  di \nrisolvere  un problema  di programmazione  quadratica .  \nAlcune  implementazioni  sono  disponibili  on-line. Ad esempio : \nLIBSVM   \nhttp://www .csie.ntu.edu.tw/~cjlin/libsvm  \nAttenzione  i Kernel  (RBF,  ecc.) sono  parametrizzati  in modo  \ndiverso  da quello  comune  (vedi  file Readme .txt di LibSvm  e [1]). \nIn particolare  si fa uso del generico  parametro  gamma  (𝛾) per \nregolare  la complessità  della  superficie  decisionale . \nAumentando  γ la superficie  può assumere  forme  più \ncomplesse . \nN.B. Con kernel  RBF γ opera  in modo  inverso  rispetto  a 𝜎. \nInserito  γ anche  nel kernel  polinomiale  (oltre  al grado  polinomio  e \nCoef 0) \nPer la classificazione  multiclasse  utilizza  internamente  One-\nAgainst -One [2] (accurato  ma inefficiente  per molte  classi ). \n[1] C.W. Hsu, C.C. Chang,  and C.J. Lin, A Practical  Guide  to Support  Vector  \nClassification,  disponibile  sul sito web di LIBSVM  \n[2] C.C. Chang  and C.J. Lin. LIBSVM : a library  for support  vector  machines . \nACM  Transactions  on Intelligent  Systems  and Technology,  2:27:1--27:27, \n2011 , disponibile  sul sito web di LIBSVM  \n \nLIBLINEAR  - https ://www .csie.ntu.edu.tw/~cjlin/liblinear / \nStessi  autori  di LIBSVM,  consigliata  nel caso  lineare  per elevata  \ndimensionalità  ed elevato  numero  di pattern . \nSVM -light - http://svmlight .joachims .org \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#21": "SVM: Implementazione\n27LIBSVM :AL i b r a r yf o rS u p p o r tV e c t o rM a c h i n e s\nCHIH-CHUNG CHANG and CHIH-JEN LIN ,N a t i o n a lT a i w a nU n i v e r s i t y\nLIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package\nsince the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained\nwide popularity in machine learning and many other areas. In this article, we present all implementation\ndetails of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass\nclassiﬁcation probability estimates and parameter selection are discussed in detail.\nCategories and Subject Descriptors: I.5.2 [ Pattern Recognition ]: Design Methodology— Classiﬁer design\nand evaluation ;G . 1 . 6[ Numerical Analysis ]: Optimization— Quadratic programming methods\nGeneral Terms: Algorithms, Performance, Experimentation\nAdditional Key Words and Phrases: Classiﬁcation LIBSVM optimization regression support vector machines\nSVM\nACM Reference Format:\nChang, C.-C. and Lin, C.-J. 2011. LIBSVM : A library for support vector machines. ACM Trans. Intell. Syst.\nTechnol. 2, 3, Article 27 (April 2011), 27 pages.\nDOI=10.1145/1961189.1961199 http://doi.acm.org/10.1145/1961189.1961199\n1. INTRODUCTION\nSupport Vector Machines (SVMs) are a popular machine learning method for clas-\nsiﬁcation, regression, and other learning tasks. Since the year 2000, we have been\ndeveloping the package LIBSVM as a library for support vector machines.1LIBSVM is\ncurrently one of the most widely used SVM software. In this article,2we present all\nimplementation details of LIBSVM .H o w e v e r ,t h i sa r t i c l ed o e sn o ti n t e n dt ot e a c ht h e\npractical use of LIBSVM . For instructions of using LIBSVM ,s e et h e README ﬁle included\nin the package, the LIBSVM FAQ ,3and the practical guide by Hsu et al. [2003].\nLIBSVM supports the following learning tasks.\n(1) SVC: support vector classiﬁcation (twoclass and multiclass);\n(2) SVR: support vector regression.\n(3) One-class SVM.\n1The Web address of the package is at http://www.csie.ntu.edu.tw/ ∼cjlin/libsvm.\n2This LIBSVM implementation document was created in 2001 and has been maintained at\nhttp://www.csie.ntu.edu.tw/ ∼cjlin/papers/libsvm.pdf.\n3LIBSVM FAQ :h t t p : / / w w w . c s i e . n t u . e d u . t w / ∼cjlin/libsvm/faq.html.\nThis work was supported in part by the National Science Council of Taiwan via the grants NSC 89-2213-E-\n002-013 and NSC 89-2213-E-002-106.\nAuthors’ addresses: C.-C. Chang and C.-J. Lin (corresponding author), Department of Computer Science,\nNational Taiwan University, Taipei 106, Taiwan; email: cjlin@csie.ntu.edu.tw.\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted\nwithout fee provided that copies are not made or distributed for proﬁt or commercial advantage and that\ncopies show this notice on the ﬁrst page or initial screen of a display along with the full citation. Copyrights for\ncomponents of this work owned by others than ACM must be honored. Abstracting with credit is permitted.\nTo copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this\nwork in other works requires prior speciﬁc permission and/or a fee. Permissions may be requested from\nPublications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1( 2 1 2 )\n869-0481, or permissions@acm.org.\nc⃝2011 ACM 2157-6904/2011/04-ART27 $10.00\nDOI 10.1145/1961189.1961199 http://doi.acm.org/10.1145/1961189.1961199\nACM Transactions on Intelligent Systems and Technology, Vol. 2, No. 3, Article 27, Publication date: April 2011.\n15prof. Davide Maltoni –Università di Bologna\nML\nClassificazioneSVM: implementazione\nIltraining diSVM, richiede algoritmi numerici nonbanali ingrado di\nrisolvere unproblema diprogrammazione quadratica .Alcune\nimplementazioni sono disponibili on-line:\nLIBSVM\n -http://www .csie.ntu.edu.tw/~cjlin/libsvm\nAttenzione\n iKernel (RBF, ecc.)sono parametrizzati inmodo\ndiverso daquello comune (vedi Readme .txtdiLibSvm e[1]).In\nparticolare sifausodelparametro gamma (𝛾)perregolare la\ncomplessità della superficie decisionale .Aumentando γla\nsuperficie puòassumere forme piùcomplesse .\nN.B.Con kernel RBFγopera inmodo inverso rispetto a𝜎.\nInserito\nγanche nelkernel polinomiale (oltre algrado polinomio e\nCoef 0)\nPer\n laclassificazione multiclasse utilizza internamente One-\nAgainst -One [2](accurato mainefficiente permolte classi ).\nWrapped\n daScikit -Learn→sklearn .svm.SVC\n[1]C.W.Hsu, C.C.Chang, andC.J.Lin,APractical Guide toSupport Vector\nClassification, disponibile sulsitoweb diLIBSVM\n[2]C.C.Chang andC.J.Lin.LIBSVM :alibrary forsupport vector machines .\nACM Transactions onIntelligent Systems andTechnology, 2:27:1--27:27,\n2011 ,disponibile sulsitoweb diLIBSVM\nLIBLINEAR\n -https ://www .csie.ntu.edu.tw/~cjlin/liblinear /\nStessi\n autori diLIBSVM, consigliata nelcaso lineare perelevata\ndimensionalità edelevato numero dipattern .\nWrapped\n daScikit -Learn→sklearn .svm.LinearSVC\nSVM\n -light -http://svmlight .joachims .org",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#22": "Esempi LIBSVM\n16 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  Esempi LibSvm  (1) \n«maschi -femmine»  \n \nLineare , 𝐶=10 Lineare , 𝐶=500 \nPolinomio  𝑞=3,𝐶=10 Polinomio  𝑞=3,𝐶=500 \nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezzaSVM Lineare",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#23": "Esempi LIBSVM\n16 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  Esempi LibSvm  (1) \n«maschi -femmine»  \n \nLineare , 𝐶=10 Lineare , 𝐶=500 \nPolinomio  𝑞=3,𝐶=10 Polinomio  𝑞=3,𝐶=500 \nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nSVM Non Lineare (Kernel Polinomiale)",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#24": "Esempi LIBSVM\n17 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  RBF, γ=5,𝐶=10 RBF,γ=5,𝐶=500 \nRBF,γ=10,𝐶=10 RBF,γ=10,𝐶=500 \nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezzaEsempi LibSvm  (2) \n«maschi -femmine»  \n \nSVM Non Lineare (Kernel RBF)",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#25": "Esempi LIBSVM\n17 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  RBF, γ=5,𝐶=10 RBF,γ=5,𝐶=500 \nRBF,γ=10,𝐶=10 RBF,γ=10,𝐶=500 \nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezza\nPesoAltezzaEsempi LibSvm  (2) \n«maschi -femmine»  \n \nSVM Non Lineare (Kernel RBF)",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#26": "Esempi LIBSVM\n18 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  Lineare , 𝐶=100 \nPolinomio  𝑞=7,𝐶=100 RBF,γ=5,𝐶=100 Polinomio  𝑞=2,𝐶=100 \nEsempi LibSvm  (3) \nmulticlasse  \n \nSVM Lineare e Non Lineare (Kernel Polinomiale)\nCaso Multiclasse",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#27": "Esempi LIBSVM\n18 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  Lineare , 𝐶=100 \nPolinomio  𝑞=7,𝐶=100 RBF,γ=5,𝐶=100 Polinomio  𝑞=2,𝐶=100 \nEsempi LibSvm  (3) \nmulticlasse  \n \nSVM Non Lineare (Kernel Polinomiale e Kernel RBF)\nCaso Multiclasse",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#28": "Esempi LIBSVM\nUna semplicissima applicazione sviluppata\ndaicreatori della libreria LIBSVM che ne\nillustra ilfunzionamento èdisponibile allink\nseguente :\nhttps://www.csie.ntu.edu.tw/~cjlin/libsvm/\nInparticolare, cliccando col mouse si\ntracciano dei punti sullo schermo,\npremendo suChange sicambia laclasse (il\ncolore deipunti relativi) ;infine, premendo\nsuRun, una semplice SVM attribuisce al\npiano l’appartenenza alle varie classi\nmostrandole colorate inmaniera diversa .\nLIBSVM is an integrated software for support vector classification, (C -SVC, nu -SVC), \nregression (epsilon -SVR, nu -SVR) and distribution estimation (one -class SVM). \nIt supports multi -class classification. ",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#29": "Esempi LIBSVM\nThis isasimple graphical interface which\nshows how SVM separate data inaplane .\nYou canclick inthewindow todraw data\npoints .Use \"change\" button tochoose\nclass 1,2or3(i.e.,uptothree classes are\nsupported), \"load\" button toload data from\nafile,\"save\" button tosave data toafile,\n\"run\" button toobtain anSVM model, and\n\"clear\" button toclear thewindow .Youcan\nenter options inthebottom ofthewindow,\nthesyntax ofoptions isthesame as`svm -\ntrain' .Note that\"load\" and\"save\" consider\ndata inthe classification but not the\nregression case .Each data point hasone\nlabel (the color) which must be1,2,or3\nand two attributes (x-axis and y-axis\nvalues) in[0,1].Type `make' inrespective\ndirectories tobuild them ...",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#3": "!Dato un insieme              , una funzione                           è un kernel se \nrisulta che  \ndove                     e   è uno spazio di Hilbert\n!Lo Spazio di Hilbert è uno spazio vettoriale che generalizza la nozione \ndi Spazio Euclideo\n!φ è la funzione di mapping dall’Input Space al Feature Space\n!Si può dimostrare che una funzione                           è un kernel se, e \nsolo se, comunque si scelgano r elementi x1, x 2, ..., x r∈X, la matrice \nK=[k(x i,xj)]i,j=1,...,r è simmetrica e semidefinita positiva\n!Ogni matrice simmetrica semidefinita positiva ha tutti gli autovalori non \nnegativik(x,y)=φ(x),φ(y)   ∀x,y∈XX⊂ ℜ k:X×X→ℜ\nϕ:X→ΗΗ\nk:X×X→ℜKernel",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#30": "Esempi LIBSVM",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#31": "Esempi LIBSVM\nQ:What isthedifference between\nnu-SVC and C-SVC? Basically they\narethesame thing butwith different\nparameters .The range ofCisfrom\nzero toinfinity but nu isalways\nbetween [0,1].Anice property ofnuis\nthatitisrelated totheratio ofsupport\nvectors and theratio ofthetraining\nerror.\nAdditionally one-class SVM type is\nsupported fordistribution estimation .\nThe one-class SVM type gives the\npossibility tolearn from justone class\nofexamples and later ontest ifnew\nexamples match theknown ones .",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#32": "SVM in pratica\n19 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM in pratica  \nLineare  o Non-lineare?   \nse la dimensionalità  𝑑 dello  spazio  è molto  elevata  (es. 5000  \nfeature ) si utilizza  generalmente  SVM  lineare . Infatti  in uno \nspazio  così grande  i pattern  sono  tipicamente  molto  sparsi  e \nanche  «semplici»  iperpiani  sono  in grado  di separare  le \nclassi  efficacemente . Il solo iperparametro  da tarare  è 𝐶.  \nper bassa  dimensionalità  (es. 20 feature ) la scelta  primaria  è \nSVM  non lineare  con kernel  RBF. Gli iperparametri  da tarare  \nsono  𝐶 e V (o γ se si utilizza  LIBSVM ). \nPer media  dimensionalità  (es. 200 features ) in genere  si \nprovano  entrambe  le tipologie  (i.e., anche  questa  scelta  \ndiventa  un iperparametro ). \nCome  sempre  gli iperparametri  si tarano  su un validation  set \nseparato,  oppure  attraverso  cross -validation  sul training  set. \n \nCome  gestire  il caso  multi -classe?   \nTipicamente  ci si affida  alla soluzione  disponibile  nella  libreria  \nutilizzata  (One-Agaist -One per LIBSVM ). \nSe però il numero  di classi  è molto  elevato,  il costo  può \ndiventare  inaccettabile  per certe  applicazioni . In questo  caso  \nOne-Against -All diventa  la scelta  obbligata .  \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#33": "SVM in pratica\n",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#34": "SVM in sintesi\n!Vantaggi\n!Si basa su una teoria ben fondata\n!Presenta eccellenti proprietà di generalizzazione\n!La funzione obiettivo non presenta minimi locali\n!Può essere impiegata per individuare funzioni discriminanti non lineari\n!La complessità del classificatore è caratterizzata dal numero di su pport \nvector piuttosto che dalla dimensionalità dello spazio trasformato\n!Svantaggi\n!Tende ad essere più lenta rispetto ad altri metodi\n!La programmazione quadratica è computazionalmente onerosa ",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#35": "!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern Approach (4 ed.) , \nPearson, 2020.\n!C. Burges, A Tutorial on Support Vector Machines for Pattern Recognition , \n1998.\n!S. Gunn, Support Vector Machines for Classification and Regression , 1998.\n!D. Maltoni, Machine Learning , Università di Bologna, 2017.\n!C.W. Hsu, C.C. Chang, and C.J. Lin, A Practical Guide to Support Vector \nClassification , Last updated: May 19, 2016.\n!C.C. Chang and C.J. Lin, LIBSVM: A Library for Support Vector Machines , ACM \nTransactions on Intelligent Systems and Technology, 2:27:1 —27:27, 2011.\n!G. Raiconi, Support Vector Machines: Concetti ed Esempi , Università di \nSalerno 2016.\n!R.O. Duda, P.E. Hart, and D.G. Stork. 2000. Pattern Classification (2nd \nEdition). Wiley -Interscience, New York, NY, USA. \n!C.M. Bishop, Pattern Recognition and Machine Learning, Springer, 2006.Riferimenti",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#4": "Kernel\n!Uno spazio di Hilbert     è uno spazio vettoriale Hreale o \ncomplesso sul quale è definito un prodotto interno tale che, detta d \nla distanza indotta da       su H, lo spazio metrico ( H, d) sia completo\n!Uno spazio metrico è un insieme di elementi, detti punti , nel quale è \ndefinita una distanza , detta anche metrica (lo spazio metrico più \ncomune è lo spazio euclideo di dimensione 1, 2 o 3)\n!Uno spazio metrico completo è uno spazio metrico in cui tutte le \nsuccessioni di Cauchy sono convergenti ad un elemento dello spazio\n!Una successione di Cauchy è una successione tale che, comunque si \nfissi una distanza arbitrariamente piccola ε> 0, da un certo punto in poi \ntutti gli elementi della successione hanno distanza reciproca inferiore \nad ε=(H,⋅,⋅) Η\n⋅,⋅\n⋅,⋅",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#5": "SVM Non Lineari\n11 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM Non lineari  \nSVM  prevede  un’importante  estensione  della  teoria  inizialmente  \nsviluppata  per iperpiani,  al caso  (non lineare ) di separazione  dei \npattern  con superfici  anche  molto  complesse . Tutto  ciò avviene  in \nmodo  molto  semplice :    \nViene  definito  un mapping  Φ non lineare  dei pattern  dallo  spazio  \ndi partenza  𝑑 verso  uno spazio  𝑚 a più alta dimensionalità  \n(𝑚>𝑑): \nΦ:𝑑→𝑚,Φ𝐱=𝑔1𝐱,𝑔2𝐱,…𝑔𝑚𝐱 \nNello  spazio  𝑚, dove  maggiori  sono  i gradi  di libertà , i pattern  \nΦ𝐱1,Φ𝐱2,…Φ𝐱𝑛 possono  essere  più facilmente  separati  da \nun iperpiano  utilizzando  la teoria  nota. Ciò equivale  a separare  i \npattern  𝐱1,𝐱2,…𝐱𝑛 in 𝑑 con superfici  arbitrariamente  complesse .  \nAnalizzando  la formulazione  del problema  lagrangiano -duale , si nota \nche i vettori  del training  set appaiono  solo in forma  di prodotti  scalari  \ntra coppie  di vettori . Questa  proprietà  (fondamentale ) permette  di \nevitare  la manipolazione  di vettori  nello  spazio  𝑚 (𝑚 può facilmente  \nraggiungere  dimensione  108 e anche  assumere  valore  infinito) . \nInfatti,  per opportuni  mapping  Φ è possibile  ricondurre  il prodotto  \nscalare  di due pattern  mappati  nello  spazio  𝑚 a una funzione  𝐾 \n(detta  Kernel ) dei due pattern  originali  nello  spazio  𝑑.  \nΦ𝐱∙Φ𝐱′=𝐾𝐱,𝐱′ \nCiò consente  di risolvere  il problema  di ottimizzazione  senza  \nparticolari  complicazioni  rispetto  al caso  lineare . Una volta  \ndeterminati  gli𝛼𝑖∗, la superficie  di separazione  (regola  di \nclassificazione)  è esprimibile  come :  \n𝐷𝐱= 𝛼𝑖∗\n𝑖=1…𝑛𝑦𝑖 𝐾𝐱,𝐱𝑖+𝑏∗ \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#6": "SVM Non Lineari\n!In altri termini, possiamo calcolare w*, b*e funzione di \ndecisione in maniera analoga a quanto visto in precedenza\n!Utilizzando il kernel evitiamo l’operazione costosa di \ntrasformazione e prodotto interno nello spazio trasformato, \nessendo il kernel una funzione dei pattern originali definiti \nnell’Input Space ℜd\n!Possiamo inoltre effettuare trasformazioni in spazi a \ndimensione infinita\n!In sintesi, le proprietà del prodotto scalare consentono di \nesprimere il prodotto scalare dei pattern immagine (\"(x) ∈ℜm) \ncorrispondenti ai pattern in input (x ∈ℜd) semplicemente come \nfunzioni kernel dei pattern in input (x ∈ℜd)",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#7": "Kernel Trick\n!Pattern linearmente non separabili possono diventare \nlinearmente separabili se trasformati, o mappati, in uno spazio \ndimensionale superiore\n!Il calcolo della matematica vettoriale (cioè i prodotti scalari) in \nuno spazio dimensionale assai elevato è costoso dal punto di \nvista computazionale\n!Il trucco del kernel consente di calcolare in modo efficiente \nprodotti scalari di dimensioni molto elevate\n!Esso consente di mappare in pattern in input in modo implicito \nin uno spazio dimensionale più elevato (possibilmente infinito) \ncon un overhead computazionale ridotto\n!“In modo implicito”, in quanto i vettori a dimensionalità \nsuperiore non sono mai effettivamente costruiti",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#8": "Kernel Function: Esempio\n!Supponiamo di avere i seguenti due vettori bidimensionali \n\"=$!,$\"e &='!,'\"\n!La funzione seguente ((*)mappa vettori bidimensionali in vettori \ntridimensionali\n!Il modo standard per calcolare\nè prima mappare i pattern in input nello spazio delle feature e poi \neseguire il prodotto scalare nello spazio a dimensione più elevata\n!Tuttavia, il prodotto scalare può essere effettuato interamente nello \nspazio originale a due dimensioni(,=-!\"\n2-!-\"\n-\"\"\n(\"*(&\n(\"*(&=$!\"'!\"+2$!$\"'!'\"+$\"\"'\"\"=\"*&\"",
    "data_test\\rootfolder\\università\\MachineLearning\\35-SVM(2)-sbloccato.pdf#9": "SVM Non Lineari: Kernel Function\n12 prof. Davide Maltoni  – Università di Bologna  \nML \nClassificazione  SVM Non lineari: Kernel  functions  \nPolinomio  di grado   𝑞 (iperparametro ): \n Le componenti  𝑔𝑖𝐱,𝑖=1..𝑚 sono  ottenute  come  tutte le \npossibili  combinazioni  di elevamento  a potenze  d 𝑞 delle  \ncomponenti  di 𝐱. Ad esempio  per 𝑑=2,𝑞=2: \nΦ𝐱=Φ𝑥1,𝑥2=1,𝑥1,𝑥2,𝑥1𝑥2,𝑥12,𝑥22,𝑥12𝑥2,𝑥1𝑥22,𝑥12𝑥22  \n e quindi  𝑚=9.  \n Si dimostra  che: \n𝐾𝐱,𝐱′=𝐱∙𝐱′+1𝑞 \nRadial  Basis  Function  (RBF) di ampiezza  𝜎 (iperparametro ): \n \n𝐾𝐱,𝐱′= 𝑒− 𝐱−𝐱′2\n2𝜎2 \n2-layer  Neural  Network  (meno  utilizzato) : \n \n𝐾𝐱,𝐱′=𝑡𝑎𝑛ℎ𝜈𝐱∙𝐱′+𝑎 \n \n𝜈 ed 𝑎 (iperparametri ) devono  essere  scelti  opportunamente : \nuna possibile  scelta  è: 𝜈=1,𝑎=1 \nIl numero  di hidden  units  e i pesi sono  determinati  \nautomaticamente  da SVM  \n \n \n \n \n \n \n \n \n ",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#0": "MATLAB (MATrix LABoratory)\n!Per installare il sofftware, accedere all’Area Sistemi Informativi di Roma Tre \ndisponibile al seguente indirizzo: http://asi.uniroma3.it/ ---> cliccare su ‘servizi \nagli studenti’ ---> scorrere fino in fondo e cliccare su ‘MathWorks’\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#1": "MATLAB\nManualetto di Matlabr\nL. Scuderi\n1 Comandi d’avvio\nPer avviare Matlab in ambiente Windows ` e su éciente selezionare con il mouse l’icona corrispon-\ndente. In ambiente MsDos o in ambiente Unix basta digitare matlab e premere il tasto di invio (o\nenter, return, ...). Il simbolo >>che compare, ` e il prompt di Matlab . Per eseguire un comando\ndigitato occorre premere il tasto di invio. Per terminare la sessione di lavoro occorre digitare il\ncomando exit oppure quit .\nTabella 1. Alcuni comandi per gestire una sessione di lavoro.\nComando Signiﬁcato\nhelp per visualizzare tutti gli argomenti presenti\nhelp arg per visualizzare informazioni su arg\ndoc arg per visualizzare dettagliate informazioni su arg\nclc per cancellare il contenuto della ﬁnestra di lavoro\n; per non visualizzare il risultato di un’istruzione\n... per continuare a scrivere un’istruzione nella riga successiva\nwho per visualizzare le variabili poste in memoria\nwhos per visualizzare informazioni sulle variabili poste in memoria\nclear per cancellare tutte le variabili dalla memoria\nclear var1 var2 per cancellare le variabili var1 evar2 dalla memoria\n2 Le variabili in Matlab\nI nomi delle variabili possono essere lunghi al massimo 32 caratteri. I caratteri utilizzabili sono\nle lettere (maiuscole e minuscole), i numeri e il carattere “ _” (underscore). Un nome di variabile\ndeve cominciare con un carattere alfabetico (a-z, A-Z). Matlab distingue tra lettere maiuscole\ne minuscole (ad esempio i nomi a1edA1rappresentano variabili diverse). La variabile si crea\nautomaticamente nel momento in cui si assegna ad essa un valore o il risultato di un’espressione.\nL’assegnazione avviene mediante il simbolo =secondo la seguente sintassi\n>> nome_variabile=espressione\nSe la variabile che si vuole creare ` e di tipo stringa occorre racchiudere espressione tra una\ncoppia di apici. Nella tabella 2 abbiamo riportato alcune variabili scalari predeﬁnite.\nMatlab lavora con sedici cifre signiﬁcative. Tuttavia, in output una variabile intera viene\nvisualizzata generalmente in un formato privo di punto decimale, mentre una variabile reale (non\nintera) viene visualizzata solo con quattro cifre decimali. Se si vuole modiﬁcare il formato di output\nsi pu` o utilizzare uno dei comandi della tabella 3. Per visualizzare tutte le sedici cifre impiegate da\nMatlab ` e necessario attivare il comando format long e .\nNella tabella 4 abbiamo riportato le principali operazioni eseguibili sulle variabili scalari. Oltre\nalle operazioni di base, in Matlab sono presenti anche le funzioni predeﬁnite riportate nella tabella\n5.\nGli elementi di un vettore vanno digitati tra parentesi quadre; gli elementi di un vettore riga\nvanno separati con uno spazio oppure una virgola, quelli di un vettore colonna con un punto e virgola\n1!Per avviare Matlab in ambiente Windows o Mac è sufficiente selezionare con \nil mouse l’icona corrispondente!In ambiente MsDos o in ambiente Unix basta digitare matlab e premere il \ntasto Invio (o Enter, Return, ... )!Il simbolo >> che compare nella Command Window è il prompt di Matlab!Per eseguire un comando digitato occorre premere il tasto Invio!Per terminare la sessione di lavoro occorre digitare il comando exit o quit!Seguono alcuni comandi per gestire una sessione di lavoro",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#10": "Esempi in MATLAB\n!Overfitting con SVM Non Lineare (Kernel Gaussiano)\nσ=1/15, C=106Esempi in MATLAB –(7)\n49\n•Vediamo invece un esempio di overfitting utilizzando il kernel\ngaussiano con 𝜎=1/15e 𝐶=106:\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#11": "Esempi in MATLAB\n% … caricamento dei dati come nel caso precedente …%\nload fisheriris; % carica le osservazioni in ‘meas’ e le label in ‘species’\nX=meas(:,3:4); % estrae lunghezza e larghezza dei petali\ny = ~strcmp(species,'virginica'); % label 0 se Iris viginica, 1 se altre specie\n% … caricamento dei dati come nel caso precedente …%\nSVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6,'KernelFunction' ,'gaussian' ,'KernelScale' ,\n1/15);\n% … disegno dello scatter plot come nel caso precedente …%\nfigure\ngscatter(X(:,1),X(:,2),y); % scatter plot dei vettori di training\nhold on\nsv = SVMModel.SupportVectors;\nplot(sv(:,1),sv(:,2),'ko','MarkerSize',10) % cerchia i vettori di supporto\nlegend('Iris virginica','Altre specie','Support vectors','Location','southeast')\naxis manual\n% … disegno dello scatter plot come nel caso precedente …%\nd=0.02; % intervallo utilizzato per generare la griglia di punti\n[x1Grid,x2Grid]=meshgrid(min(X(:,1)):d:max(X(:,1)),min(X(:,2)):d:max(X(:,2))); % \ngenerazione della griglia\nxGrid=[x1Grid(:),x2Grid(:)];\n[~,scores1]=predict(SVMModel,xGrid); % valutiamo l’output del modello nei punti \ndella griglia\ncontour(x1Grid,x2Grid,reshape(scores1(:,2),size(x1Grid)),[0 0],'k'); % plot del \nconfine di decisione",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#12": "Esempi in MATLAB\nσ=1/15, C=106\n% … caricamento dei dati come nel caso precedente …%\nSVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6, 'KernelFunction' ,'gaussian' ,'KernelScale' ,1/15);\n% … disegno dello scatter plot come nel caso precedente …%!Overfitting con SVM Non Lineare (Kernel Gaussiano)",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#13": "Esempi in MATLAB\nσ=1/15, C=106\n% … caricamento dei dati come nel caso precedente …%\nSVMModel=fitcsvm(X,y, 'BoxConstraint' ,1e6, 'KernelFunction' ,'gaussian' ,'KernelScale' ,1/15);\n% … disegno dello scatter plot come nel caso precedente …%\nC σ!Overfitting con SVM Non Lineare (Kernel Gaussiano)",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#14": "Esempi in MATLAB\nσ=1/15, C=106Esempi in MATLAB –(8)\n50\n𝐶=106,𝜎=1/15\n!Overfitting con SVM Non Lineare (Kernel Gaussiano)",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#15": "Esempi in MATLAB\n!Esempio di SVM Non Lineare (Kernel Gaussiano)\nσ=5, C=100\n% … caricamento dei dati come nel caso precedente …%\nSVMModel=fitcsvm(X,y, 'BoxConstraint' ,100, 'KernelFunction' ,'gaussian' ,'KernelScale’ ,5);\n% … disegno dello scatter plot come nel caso precedente …%",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#16": "Esempi in MATLAB\nσ=5, C=100\n% … caricamento dei dati come nel caso precedente …%\nSVMModel=fitcsvm(X,y, 'BoxConstraint' ,100, 'KernelFunction' ,'gaussian' ,'KernelScale’ ,5);\n% … disegno dello scatter plot come nel caso precedente …%\nC σ!Esempio di SVM Non Lineare (Kernel Gaussiano)",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#17": "Esempi in MATLAB\nσ=5, C=100\nEsempi in MATLAB –(8)\n51\n𝐶=100,𝜎=5!Esempio di SVM Non Lineare (Kernel Gaussiano)",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#18": "Classification Learner\nThe Classification Learner app lets you train models toclassify data using supervised\nmachine learning .\nUsing Classification Learner, you can perform common machine learning tasks such\nasinteractively exploring your data, selecting features, specifying validation schemes,\ntraining models, and assessing results .Choose from several classification types\nincluding decision trees ,support vector machines (SVM) ,and k-nearest neighbors ,\nand select from ensemble methods such asbagging, boosting, and random subspace .\nClassification Learner helps you choose thebest model foryour data byletting you\nperform model assessment and model comparisons using confusion matrices and\nROC curves .Export classification models tothe MATLAB workspace togenerate\npredictions onnew data, orgenerate MATLAB code tointegrate models into\napplications such ascomputer vision, signal processing, and data analytics .",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#19": "Classification Learner\nMatrice diConfusione (oTabella diErrata Classificazione) :rappresentazione\ndell'accuratezza diclassificazione statistica .\nOgni colonna della matrice rappresenta ivalori predetti, mentre ogni riga\nrappresenta ivalori reali (i.e.,l'elemento sulla riga iesulla colonna jèilnumero di\ncasi incui ilclassificatore haclassificato laclasse \"vera\" icome classe j).\nAttraverso questa matrice èosservabile seviè\"confusione\" nella classificazione di\ndiverse classi .\nCurve ROC (Receiver Operating Characteristic) :schemi grafici perunclassificatore\nbinario .\nLungo idue assi sipossono rappresentare lasensibilità e(1-specificità), come True\nPositive Rate (vero positivo) eFalse Positive Rate (falso positivo) .Inaltri termini, si\nstudiano irapporti fraveri allarmi (hitrate) efalsi allarmi alvariare diuna soglia .",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#2": "Esempi in MATLAB\n!Dataset multivariato Iris (Fisher's 1936 iris data)\n!50 esemplari di Iris Setosa , 50 di Iris Versicolor , 50 di Iris Virginica\n!4 feature: lunghezza e larghezza del sepalo, lunghezza e larghezza \ndel petalo\n!Sepalo: in botanica, ciascuno degli elementi, simili a foglioline verdi, \nche formano il calice del fiore\n!Utilizzeremo solo lunghezza e larghezza del sepalo (per poter \nvisualizzare i dati)\n!Funzione fitcsvm di MATLAB (metodo di ottimizzazione adottato: \nSequential Minimal Optimization (SMO))\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#20": "Classification Learner\n-Avviare Matlab\n-Scaricare il file ClassificationLearner_Example_Datasets.mat\n-Doppio clic sul file ClassificationLearner_Example_Datasets.mat\n-Selezionare i dati che si desidera importare \n[e.g., FisherIris (Numero di feature (predittori): 4, Numero di pattern (osservazioni): 150, Numero di \nclassi: 3); tabella di 150 righe (osservazioni) e 5 colonne (4 valori delle feature + classe)]\n-Digitare Finish per importarli nel Workspace di Matlab\n-Avviare l’app Classification Learner (vedi scheda APPS o digitare al prompt il \ncomando classificationLearner )",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#21": "Classification Learner\n-New Session —> From Workspace\n-Selezionare le feature e l’eventuale metodo di validazione\n-Start Session\n-Selezionare uno o più algoritmi di classificazione dalla barra superiore (per \nselezionare i parametri vedi Advanced)\n-Train e buon divertimento!\n-per ulteriori dettagli: https://it.mathworks.com/help/stats/classificationlearner -app.html",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#22": "CL Features\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#23": "CL Features\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#24": "CL Features\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#25": "CL Features\n-Linear SVM\n-Fine Gaussian SVM (Kernel Scale=0.35)\n-Medium Gaussian SVM (Kernel Scale=1.4)\n-Coarse Gaussian SVM (Kernel Scale=5.7)\n-Quadratic SVM (Kernel Polinomiale con grado=2)\n-Cubic SVM (Kernel Polinomiale con grado=3)\n-Kernel scale parameter, specified as the comma -separated pair consisting of 'KernelScale' and 'auto' or a positive \nscalar. The software divides all elements of the predictor matrix X by the value of KernelScale. Then, the software \napplies the appropriate kernel norm to compute the Gram matrix.\n-per ulteriori dettagli digitare al prompt il comando doc fitcsvm",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#26": "CL Features\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#27": "CL Features\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#28": "Altri Dataset\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#29": "Altri Dataset",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#3": "Dataset Fisher Iris\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#30": "Altri Dataset",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#31": "Altri Dataset",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#32": "Altri Dataset",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#33": "Classification Learner\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#34": "Classification Learner\n“Plotting the fisheriris data, you can see that sepal length\nand sepal width separate one ofthe classes well\n(setosa) .You need toplot other predictors (features) to\nsee ifyou can separate theother two classes .”",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#35": "Classification Learner\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#36": "Classification Learner\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#37": "Classification Learner\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#38": "Classification Learner\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#39": "Classification Learner\n“Plotting thefisheriris data, you can seethat petal length and petal\nwidth arethefeatures that separate theclasses best.”",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#4": "Esempi in MATLAB\nfitcsvm trains or cross -validates a support vector machine (SVM) model for \ntwo-class (binary) classification on a low -dimensional or moderate -\ndimensional predictor data set. fitcsvm supports mapping the predictor data \nusing kernel functions, and supports sequential minimal optimization (SMO), \niterative single data algorithm (ISDA), or L1 soft -margin minimization via \nquadratic programming for objective -function minimization. Matlab Help\nThe support vectors are observations that occur on or beyond their estimated \nclass boundaries. \nYou can adjust the boundaries (and, therefore, the number of support \nvectors) by setting a box constraint during training using the 'BoxConstraint'\nname -value ( C) pair argument.",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#40": "L'errore di classificazione è uguale, ma i classificatori sono molto diversi fra loro!Vera Assegnata\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n2 1\n2 1\n2 1Vera Assegna ta\n1 1\n1 2\n1 2\n1 1\n1 1\n1 1\n1 1\n2 2\n2 2\n2 1Classificatore 1  \n(assegn aun \noggetto sempre \nalla prima classe )\nErrore: 3/10 = 0.3 \n(30%)Classificatore 2Valutazione Prestazioni\nErrore: 3/10 = 0.3\n(30%)Il sempice errore di classificazione (i.e., numero di errori / numero totale di classificazioni) \nnon sempre ci permette di capire o confrontare completamente due classificatori.\nEsempio:",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#41": "Vera Assegna ta\n1 1\n1 2\n1 2\n1 1\n1 1\n1 1\n1 1\n2 2\n2 2\n2 1Elementi della classe 1 classificati  \ncome appartenenti alla classe 1\nElementi della classe 1classificati \ncome appartenenti alla classe 2\nElementi della classe 2 classificati  \ncome appartenenti alla classe 2Matrice di Confusione\nElementi della classe 2classificati  \ncome appartenenti alla classe 15 2\n1 2EsempioMatrice Mche ci dice come un classificatore opera rispetto alle diverse classi \nm(i,j) = numero di elementi della classe iclassificati come elementi della classe j\nIn altri termini, indice di riga i:valore reale , indice di colonna j:valore predetto",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#42": "Matrice di Confusione\nL'errore di classificazione può essere calcolato facilmente dalla matrice di \nconfusione\nLa somma di tutti gli elementi non appartenenti alla diagonale principale\nO, meglio, può essere calcolato come “1 -Accuracy”\nAccuracy: somma elementi diagonale principale / numero elementi totali",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#43": "Nel caso di problema a due classi la matrice di \nconfusione  assume una forma particolare (2 classi, \npositivi vs negativi)\nTrue  \nPositive  \n(TP)False  \nNegative  \n(FN)\nFalse  \nPositive  \n(FP)True  \nNegative  \n(TN)ESEMPIO: classificazione tra malati (positivi) e sani(negativi)\nCLASSIFICAZIONE CORRETTA:\nVeri positivi: pazienti malati classificati come malati\nVeri negativi: pazienti sani classificati come sani\nCLASSIFICAZIONE ERRATA:\nFalsi positivi: pazienti sani classificati come malati\nFalsi negativi: pazienti malati classificati come saniMatrice di Confusione",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#44": "Dalla matrice di confusione possono essere calcolati diversi indici\nIndice Formula Intuizione\nAccuracy Percentuale di classificazioni corrette\nPrecision Percentuale di classificazioni positive che  \nsono corrette\nRecall (Sensitivity) Percentuale di elementi positivi del tes tset \nche sono stati classificati come positivi\nSpecificity Percentuale di elementi negativi del test set \nche sono stati classificati come negativi\nPrecision: se dico “positivo”, è corretto ?\nRecall: riesco a trovare tuttii positivi del testing set?Matrice di Confusione\nTN\nTN+FPTP\nTP+FNTP+TN\nTP+FP+TN+FN\nTP\nTP+FP",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#45": "Matrice di Confusione\nVera Assegnata\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n2 1\n2 1\n2 1Vera Assegnata\n1 1\n1 2\n1 2\n1 1\n1 1\n1 1\n1 1\n2 2\n2 2\n2 1Matrice diconfusione\nAccuracy: 7/10 (0.7)\nPrecision: 7/10 (0.7)\nRecall: 7/7 (1)\nSpecificity: 0/3 (0)TP:7 FN:0\nFP:3 TN:0Indice Formula\nAccuracy\nPrecision\nRecall (Sensitivity)\nSpecificity\nMatrice diconfusione\nAccuracy: 7/10 (0.7)\nPrecision: 5/6 (0.83)\nRecall: 5/7 (0.71)\nSpecificity: 2/3 (0.66)TP:5 FN:2\nFP:1 TN:2TP+TN\nTP+FP+TN+FN\nTP\nTP+FP\nTP\nTP+FN\nTN\nTN+FP",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#46": "blu50 10\n20 20Supponiamo diaver addestrato unmodello utilizzando 100\nesempi ditraining .Diquesti 100,60sono diclasse “rosso” e\n40sono diclasse “blu”.\nIlmodello haeffettuato leseguenti classificazioni :\nEtichette predette\nrosso blu\nrosso\nEtichette\nrealiMatrice di Confusione",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#47": "rosso\nblu50 10\n20 20Etichette predette\nrosso blu\nNB: la somma è sempre  \n100 (pari al numero di  \npattern ditraining)Etichetta reale Etichetta predetta Tipo predizione\nrosso rosso True positive (TP) (50)\nrosso blu False negative (FN) (10)\nblu blu True negative (TN) (20)\nblu rosso False positive (FP) (20)\nMatrice di confusioneEtichette\nrealiMatrice di Confusione",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#48": "rosso\nbluTP FN\nFP TNEtichette predette\nrosso blu\nNB: la somma è sempre  \n100 (pari al numero di  \npattern ditraining)Etichetta reale Etichetta predetta Tipo predizione\nrosso rosso True positive (TP) (50)\nrosso blu False negative (FN) (10)\nblu blu True negative (TN) (20)\nblu rosso False positive (FP) (20)\nMatrice di confusioneEtichette\nrealiMatrice di Confusione",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#49": "Precision: =50 / (50+20) =0.7142\nTP +FPEtichetta reale Etichetta predetta Tipo predizione\nrosso rosso True positive (TP) (50)\nrosso blu False negative (FN) (10)\nblu blu True negative (TN) (20)\nblu rosso False positive (FP) (20)\nMisure di performance :\nPrecision: \"Quanti dei pattern che ho predetto di tipo rosso sono\ndavvero pattern di classe rosso ?\"\nTPMatrice di Confusione",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#5": "Esempi in MATLAB\nload fisheriris; % carica le osservazioni in ‘meas’ e le label in ‘species’\nX=meas(:,3:4); % estrae lunghezza e larghezza dei sepali\ny = ~strcmp(species, 'setosa' ); % label 0 se Iris setosa, 1 se altre specie\nSVMModel=fitcsvm(X,y, 'BoxConstraint' ,+Inf); % C=+Inf —> hard-margin linear SVM\nfigure\ngscatter(X(:,1),X(:,2),y); % scatter plot dei vettori di training\nhold on\nsv = SVMModel.SupportVectors;\nplot(sv(:,1),sv(:,2), 'ko','MarkerSize' ,10) % cerchia i vettori di supporto\nlegend('Iris setosa' ,'Altre specie' ,'Support vectors' ,'Location' ,'southeast' )\naxis manual\nx1 = linspace( -5,5);\nf=@(x)(-SVMModel.Bias -SVMModel.Beta(1)*x)/SVMModel.Beta(2); % iperpiano di \nseparazione\nplot(x1,f(x1))\nf1=@(x)( -SVMModel.Bias+1 -SVMModel.Beta(1)*x)/SVMModel.Beta(2); % margine \npositivo\nplot(x1,f1(x1))\nf2=@(x)( -SVMModel.Bias -1-SVMModel.Beta(1)*x)/SVMModel.Beta(2); % margine \nnegativo\nplot(x1,f2(x1))",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#50": "Recall \n(Sensi tivity) :\nTP\nSensitivity: =50 / (50+10) =0.8333Etichetta reale Etichetta predetta Tipo predizione\nrosso rosso True positive (TP) (50)\nrosso blu False negative (FN) (10)\nblu blu True negative (TN) (20)\nblu rosso False positive (FP) (20)\nMisure di performance :\nTP + FN\nsomma dei positivi nel training setMatrice di Confusione\n“Dei pattern che dovrei predire come rosso (positivo) \nquanti ne ho predetti di classe rosso (positivo)?”",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#51": "Specificity: = 20 / (20+20) =0.5Etichetta reale Etichetta predetta Tipo predizione\nrosso rosso True positive (TP) (50)\nrosso blu False negative (FN) (10)\nblu blu True negative (TN) (20)\nblu rosso False positive (FP) (20)\nMisure di performance :\nSpecifici ty:Matrice di Confusione\nTN“Dei pattern che dovrei predire come blu(negativo) \nquanti ne ho predetti di classe blu(negativo)?”\nTN+FP\nsomma dei negativi nel training set",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#52": "Lacurva ROC (Receiver Operating Characteristic) èuna\ntecnica statistica attualmente utilizzata inuna grande varietà di\ncampi scientifici .\nQuesta tecnica trae origine nell'ambito della teoria della\nrilevazione delsegnale .Sitratta diunametodologia cheèstata\nadottata per laprima volta daalcuni ingegneri, durante la\nseconda guerra mondiale, perl'analisi delle immagini radar elo\nstudio delrapporto segnale/disturbo .\nE'possibile usare lacurva ROC anche pervalutare leprestazioni\ndiunmodello diclassificazione .Curva ROC",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#53": "Sistema molto utilizzato per valutare un classificatore binario\nbasato susoglia\nLegenda: \nPositivo = Disease (Malati) \nNegativo = Normal (Sani)\nClassificazione:\nNegativo < !\nPositivo > !\nVariando il valore di soglia \n!(cut-off)si ottengono \ndiversi valori di TP, TN, FP,\nFN\nEsempio: con ilvalore  di !\nin figura i Falsi Positivi \nsono azeroCurva ROC\n!",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#54": "La curva ROC mette in relazione la specificity (recall) \nconla sensitivity al variare della soglia\nFissata una soglia, quanti sono i veri positivi rispetto ai falsipositivi? \nCome si calcola:\nSi fa variare la soglia calcolando i  \ncorrispondenti veri positivi e falsi  \npositivi, che rappresentano un  \npunto della curva\nIl valore minimo/massimo della  \nsoglia è quello per cui sono tutti  \nfalsi positivi o tutti veri positiviCurva ROC",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#55": "Fissatauna sogliat,\nperi tutti gliesempi  \nquali il\n(classificatore)modello\ngenera\nunoscore >tvengono  \npredetti positivi.\nQuesto cipermette di\nquantificare, per ogni\nscelta del valore di\nsoglia ,TP,TN, FPe\nFN.\nTP\nFPCurva ROC\nTN\nFN",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#56": "Fissato unvalore dit\npossiamo calcolare, ad\nesempio :\nTP=0.5  \nFN=0.5  \nFP=0.12  \nFN=0.88\nPossiamo  \nidentificare un  \npunto sulla curva  \n(associato al  \nvalore di tscelto)Curva ROC",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#57": "Possiamo calcolare TP  \ne FP per una serie di  \nvalori  di t (es. 0.1,0.2,\n0.3, 0.4, 0.5, 0.6, …,\n1.0). In questo modo  \notteniamo diversi punti  \nche compongono la  \ncurva ROC.\nCurva ROC\nIl valore degli score \ngenerati dal \nclassificatore può \nvariare tra 0 e 1.",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#58": "A seconda di come si vuole operare si sceglie lasoglia\nEsempio 1 (curva) : Sensitivity al 95%, si \nottiene un corrispondente valore di Specificity\n(70%)\nEsempio 2 (segmento tratteggiato) : \nSensitivity = 100-Specificity, si chiama \nEqual Error Rate\nCurva ROC",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#59": "Ciò che èimportante\nperò non èlacurva di\npersé,mal’area sotto\nla curva . Questa\nquantità èindicata con\niltermine Area Under\ntheROC Curve (AUC )\nCurva ROC",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#6": "Esempi in MATLAB Esempi in MATLAB –(3)\n45\n𝐶=+∞C=+∞\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#60": "AUC = 1:\nIl classificatore è  \nperfetto\nAUC = 0.5 :\nIl classificatore è\ntotalmente casuale\n(lancio diunamoneta)\nCurva ROC",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#61": "Rispetto a TP e FP :\nTP:0, FP:0\nPredice sempre «negativo»\nTP:1, FP:1\nPredice sempre «positivo»\nTP:1, FP:0\nClassificatore ideale\nCurva ROC",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#62": "Si possono confrontare curve ROC calcolando l'area\nsotto la curva (AUC –Area Under theCurve)\nUn AUC più grande \nimplica unclassificatore\nmigliore\nCurva ROC",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#63": "A B CA migliore di B migliore di C (C=lancio moneta)Curva ROC",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#64": "Join the protest!!!\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#7": "Esempi in MATLAB\nC=+∞Esempi in MATLAB –(4)\n46\n𝐶=+∞\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#8": "Esempi in MATLAB\nC=1Esempi in MATLAB –(5)\n47\n𝐶=1\n",
    "data_test\\rootfolder\\università\\MachineLearning\\36-SVM(3)-sbloccato.pdf#9": "Esempi in MATLAB\nC=10−6Esempi in MATLAB –(6)\n48\n𝐶=10−6\n",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: SVM (Ex 14)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#1": "Sommario\nScikit-learn e SVM \nSVM e Iris dataset \nUse case: Stock forecasting \nUse case: Sentiment Analysis",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#10": "Esercitazione: stock forecasting\nfrom\n sklearn.svm \n import\n SVC\nfrom\n sklearn.metrics \n import\n accuracy_score\n  \nimport\n pandas \n as\n pd\nimport\n numpy \nas\n np\n  \nimport\n matplotlib.pyplot \n as\n plt\nplt.style.use(\n 'seaborn-darkgrid'\n )\n  \nimport\n warnings\nwarnings.filterwarnings(\n \"ignore\"\n )\ndf = pd.read_csv(\n 'RELIANCE.csv'\n )\nd\nf.index = pd.to_datetime(df[\n 'Date'\n])\ndf = df.drop([\n 'Date'\n], axis=\n 'columns'\n )\n... (completa)\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#11": "Esercitazione: stock forecasting\nfrom\n sklearn.svm \n import\n SVC\nfrom\n sklearn.metrics \n import\n accuracy_score\n  \nimport\n pandas \n as\n pd\nimport\n numpy \nas\n np\n  \nimport\n matplotlib.pyplot \n as\n plt\nplt.style.use(\n 'seaborn-darkgrid'\n )\n  \nimport\n warnings\nwarnings.filterwarnings(\n \"ignore\"\n )\ndf = pd.read_csv(\n 'RELIANCE.csv'\n )\nd\nf.index = pd.to_datetime(df[\n 'Date'\n])\ndf = df.drop([\n 'Date'\n], axis=\n 'columns'\n )\ndf[\n'Open-Close'\n ] = df.Open - df.Close\ndf[\n'High-Low'\n ] = df.High - df.Low\n  \n# per ora uso solo 2 valori\nX = df[[\n 'Open-Close'\n , \n'High-Low'\n ]]\ny = np.where(df[\n 'Close'\n].shift(\n -1\n) > df[\n'Close'\n], \n1\n, \n0\n)\n>> [1 1 1 ... 1 0 0]\n... (segue)\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#12": "Esercitazione: stock forecasting\nsplit_percentage = \n 0.8\nsplit = \n int\n(split_percentage*\n len\n(df))\n  \n# Train data set\nX_train = X[:split]\ny_train = y[:split]\n  \n# Test data set\nX_test = X[split:]\ny_test = y[split:]\ncls = SVC().fit(X_train, y_train)\ndf[\n'Predicted_Signal'\n ] = cls.predict(X)\ndf[\n'Return'\n ] = df.Close.pct_change()\ndf[\n'Strategy_Return'\n ] = df.Return *df.Predicted_Signal.shift(\n 1\n)\ndf[\n'Cum_Ret'\n ] = df[\n'Return'\n ].cumsum()\ndf[\n'Cum_Strategy'\n ] = df[\n'Strategy_Return'\n ].cumsum()\nimport\n matplotlib.pyplot \n as\n plt\n%matplotlib \n inline\n  \nplt.plot(df[\n 'Cum_Ret'\n ],color=\n 'red'\n)\nplt.plot(df[\n 'Cum_Strategy'\n ],color=\n 'blue'\n)\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#13": "Esercitazione: stock forecasting\n14\n",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#14": "Esercitazione: stock forecasting\nL'algoritmo genera un ritorno del 18.87% in un 1 anno, rispetto al 5.97% \ndel titolo azionario. \nLa funzione accuracy_score() restituisce una accuracy del 62.07% sul train \nset e 50.67 sul test set. \nEsercizi: (1) crea il target value a distanza di più giorni dall'istanza \ncorrente; (2) usa gli ultimi 15 valori Close come istanza di input per predire \nil successivo; (3) impiega altri kernel (es. rbf).\n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#15": "Esercitazione: Sentiment Analysis\nTecnica molto popolare per classiﬁcare brani di testo, micropost o frasi in \nlinguaggio naturale in base al sentimento (es. positivo, negativo, neutro). \nSupponiamo di impiegare le review di ﬁlm, es: \nhttp://www.cs.cornell.edu/people/pabo/movie-review-data/  \nMovie-review data for use in sentiment-analysis experiments. Available are collections of \nmovie-review documents labeled with respect to their overall \n sentiment polarity\n  (positive \nor negative) or \n subjective rating\n  (e.g., \"two and a half stars\") and sentences labeled with \nrespect to their \n subjectivity status\n  (subjective or objective) or \n polarity \nimport pandas as pd  \ntrainData = pd.read_csv(\"\n https://raw.githubusercontent.com/Vasistareddy/\nsentiment_analysis/master/data/train.csv\n \") \ntestData = pd.read_csv(\"\n https://raw.githubusercontent.com/Vasistareddy/\nsentiment_analysis/master/data/test.csv\n \") \ntrainData.sample(frac=1).head(5) # shuffle the df and pick first 5  \n      \nContent                                             \n Label \n56\n    jarvis cocker of pulp once said that he wrote ...   pos  \n1467\n  david spade has a snide , sarcastic sense of h...   neg  \n392\n   upon arriving at the theater during the openin...   pos  \n104\n   every once in a while , a film sneaks up on me...   pos  \n1035\n  susan granger's review of \" american outlaws \"...   neg\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#16": "Esercitazione: Sentiment Analysis\nPer impiegare il testo come input agli algoritmi di ML spesso si effettua una \npipeline di processamento per trasformare parole o frasi in vettori numerici. \nPer dettagli: \n https://medium.com/@vasista/preparing-the-text-data-with-\nscikit-learn-b31a3df567e\n   e  \nhttps://scikit-learn.org/stable/modules/\ngenerated/sklearn.feature_extraction.text.TﬁdfVectorizer.html   \nfrom sklearn.feature_extraction.text import TfidfVectorizer  \n# ignora i termini che compaiono in meno di 5 documenti \n# e i termini che compaiono in > 80% dei documenti; \n# abilita l'inverse document frequency per pesare i termini \nvectorizer = TfidfVectorizer(min_df = 5,  \n                             max_df = 0.8,  \n                             sublinear_tf = True,  \n                             use_idf = True)  \ntrain_vectors = vectorizer.fit_transform(trainData['Content'])  \ntest_vectors = vectorizer.transform(testData['Content']) \nEsercizio\n : completa il codice impiegando SVM lineare e valutane \nl'accuratezza. Testa la predizione su review di Amazon.\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#17": "Esercitazione: Sentiment Analysis\nfrom sklearn import svm \nfrom sklearn.metrics import classification_report \nclassifier_linear = svm.SVC(kernel='linear') \nclassifier_linear.fit(train_vectors, trainData['Label']) \nprediction_linear = classifier_linear.predict(test_vectors) \ntime_linear_train = t1-t0 \ntime_linear_predict = t2-t1 \nreport = classification_report(testData['Label'], prediction_linear, \noutput_dict=True) \nprint('positive: ', report['pos']) \nprint('negative: ', report['neg']) \npositive:  {'precision': 0.9191919191919192, 'recall': 0.91, 'f1-score': \n0.9145728643216081, 'support': 100} \nnegative:  {'precision': 0.9108910891089109, 'recall': 0.92, 'f1-score': \n0.9154228855721394, 'support': 100} \nreview = \"\"\"Very good picture and sound, very glad I chose this unit\"\"\" \nreview_vector = vectorizer.transform([review]) # vectorizing \nprint(classifier_linear.predict(review_vector))  \n18",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#18": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and TensorFlow: \nConcepts, Tools, and Techniques to Build Intelligent Systems\n . O'Reilly Media \n2017 \nhttps://www.kaggle.com/code/parulpandey/getting-started-with-time-series-\nusing-pandas/notebook   \nhttps://medium.com/@vasista/preparing-the-text-data-with-scikit-learn-\nb31a3df567e    \nhttps://scikit-learn.org/stable/modules/generated/\nsklearn.feature_extraction.text.TﬁdfVectorizer.html  \nTutorial: \n https://www.geeksforgeeks.org/predicting-stock-price-direction-using-\nsupport-vector-machines/?ref=rp  \nTutorial: \n https://medium.com/@vasista/sentiment-analysis-using-\nsvm-338d418e3ff1\nTesti di Riferimento\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#2": "Support Vector Machines\nL'algoritmo SVM è impiegato in ambito di classiﬁcazione e regressione. \nHa molti vantaggi tra cui: \nEfﬁcace in spazi con molte dimensioni (cioè features) \nPuò trattare casi in cui le dimensioni sono maggiori delle istanze \nÈ efﬁciente in termini di spazio di memoria richiesto \nAttenzione: \nSe le dimensioni sono molto maggiori delle istanze, la scelta della \nfunzione kernel e la regolarizzazione sono fondamentali. \nSVM non restituisce direttamente probabilità.\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#3": "Scikit-learn: Support Vector Machines\nI dati in input supportati in scikit-learn sono sia \n dense\n  (es. \nnumpy.ndarray\n , \nnumpy.asarray\n ) sia sparsi (qualsiasi \n scipy.sparse\n ) \n>>> \nfrom \nsklearn \nimport\n svm \n>>> \nX \n=\n [[\n0\n, \n0\n], [\n1\n, \n1\n]] \n>>> \ny \n=\n [\n0\n, \n1\n] \n>>> \nclf \n=\n svm\n.\nSVC() \n>>> \nclf\n.\nfit(X, y) \nSVC() \n>>> \nclf\n.\npredict([[\n 2.\n, \n2.\n]]) \narray([1]) \n>>> \n# support vectors  \n>>> \nclf\n.\nsupport_vectors_ \narray([[0., 0.],  \n       [1., 1.]])  \n>>> \n# indici dei support vectors  \n>>> \nclf\n.\nsupport_ \narray([0, 1]...)  \n>>> \n# numero dei support vectors per ogni classe  \n>>> \nclf\n.\nn_support_ \narray([1, 1]...)\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#4": "Scikit-learn: Support Vector Machines\nEsempio IRIS dataset: \n# carico il dataset IRIS\niris \n=\n load_iris()\n# uso solo le prime due features\nX \n=\n iris.data[:, :\n 2\n]\nY \n=\n iris.target\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\nscaler = StandardScaler()\nX_train_std = scaler.fit_transform(X_train)\nX_test_std = scaler.transform(X_test)\n# equivale a SVC(kernel\n =\n\"linear\"\n )\nsvm \n=\n LinearSVC()\nsvm.fit(X_train_std, Y_train)\n \nprint\n(\n\"Accuracy Train Set:\"\n , svm.score(X_train_std, Y_train))\nprint\n(\n\"Accuracy Test Set:\"\n , svm.score(X_test_std, Y_test))\n>> Accuracy Train Set: 0.8285714285714286\n>> \nAccuracy Test Set: 0.6888888888888889\nCosa possiamo dire?\n5",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#5": "Scikit-learn: Support Vector Machines\n>> Accuracy Train Set: 0.8285714285714286\n>> \nAccuracy Test Set: 0.6888888888888889\nCosa possiamo dire? \nIl modello soffre di overﬁtting. \nEsercizio: prova ad impiegare tutte le features del dataset.\n6\n",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#6": "Scikit-learn: Support Vector Machines\nEsercizio: prova ad impiegare tutte le features del dataset. \n>> Accuracy Train Set: 0.9428571428571428\n>> \nAccuracy Test Set: 0.9555555555555556\nEsercizio: cambia il parametro \n kernel\n  di SVC() e testa le altre funzioni oltre \nalla \n linear\n  cioè \n rbf\n, \nsigmoid\n  e \npoly\n impiegando sempre 2 features.\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#7": "Scikit-learn: Support Vector Machines\nEsercizio: prova ad impiegare tutte le features del dataset. \n>> Accuracy Train Set: 0.9428571428571428\n>> \nAccuracy Test Set: 0.9555555555555556\nEsercizio: cambia il parametro \n kernel\n  di SVC() e testa le altre funzioni oltre \nalla \n linear\n  cioè \n rbf\n, \nsigmoid\n  e \npoly\n impiegando sempre 2 features. \n8\nAccuracy Train Set: 0.81\nAccuracy Test Set: 0.78Accuracy Train Set: 0.72\nAccuracy Test Set: 0.8Accuracy Train Set: 0.76\nAccuracy Test Set: 0.67",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#8": "Stock forecasting\nAlcuni servizi web rendono disponibili gli andamenti di titoli azionari via \nAPIs, es: \nOpen: Starting price at which a stock is traded in a day. \nClose: Closing price. \nHigh: The highest price of equity symbol in a day. \nLow: The lowest price of the share in a day \nVWAP: Volume weighted average price \nVolume: Total volume of stocks traded on a particular day.  \nI dati possono essere interpretati come \n time series\n , cioè sequenze di valori \nordinati temporalmente. \nPer approfondimenti:  \nhttps://www.kaggle.com/code/parulpandey/getting-started-with-time-series-using-pandas/notebook  \nIl task della stock price forecasting è predire il valore futuro (es. intraday, \ngiornalieri, mensile, etc). di un titolo in base ai valori passati.\n9",
    "data_test\\rootfolder\\università\\MachineLearning\\37-Ex_14 Esercitazione SVM-sbloccato.pdf#9": "Esercitazione: stock forecasting\nAl seguente indirizzo trovi i dati storici del titolo RELIANCE: \nhttps://storage.googleapis.com/kaggle-forum-message-attachments/894813/16059/RELIANCE.csv \nPossiamo impiegare l'istanza attuale come input e tentare di fare predizione \nsul comprare (+1) oppure no (0). \nIn ambito azionario è utile deﬁnire nuove features che combinano quelle \nattuali, es. Open-Close o High-Low: \ndf[\n'Open-Close'\n ] = df.Open - df.Close\nLa variabile target puoi essere approssimare nel seguente modo: \ny = np.where(df[\n 'Close'\n].shift(\n -1\n) > df[\n'Close'\n], \n1\n, \n0\n)\nIl ritorno cumulato può essere ottenuto nel seguente modo: \ndf[\n'Return'\n ] = df.Close.pct_change() \n # variazione percentuale rispetto al prec\ndf[\n'Strategy_Return'\n ] = df.Return * df.Predicted_Signal.shift(\n 1\n)\ndf[\n'Cum_Ret'\n ] = df[\n'Return'\n ].cumsum()\ndf[\n'Cum_Strategy'\n ] = df[\n'Strategy_Return'\n ].cumsum()\nEsercizio\n : impiega l'algoritmo SVM per la predizione e valuta l'accuratezza.\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#0": "Machine Learning\nUniversità Roma Tre  \nDipartimento di Ingegneria \nAnno Accademico 2021 -2022\nRiduzione di Dimensionalità",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#1": "Sommario\n!Introduzione\n!Definizioni\n!Le Principali Tecniche\n!PCA vs LDA\n!Principal Component Analysis (PCA)\n!Linear Discriminant Analysis (LDA)\n!t-SNE",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#10": "PCA: Retro -Proiezione\n6prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA: proiezione e retroproiezione\nProiezione\n (o):una volta determinato lospazio PCA, la\nproiezione diunpattern sutale spazio èsemplicemente la\nproiezione geometrica diunvettoresull’iperpiano chedefinisce\nlospazio .Inrealtà lavera proiezione geometrica èunvettore\nchehalastessa dimensionalità delvettore originale mentre in\nquesto contesto indichiamo con proiezione ilvettore (ridotto)\nnello spazio PCA.Matematicamente questa operazione è\neseguita come prodotto della matrice diproiezione trasposta\nperilpattern alquale èpreventivamente sottratta lamedia .\n𝑃𝐶𝐴:𝑑→𝑘\n𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱\nRetro\n -proiezione (m):Dato unvettore nello spazio PCA, lasua\nretro-proiezione verso lospazio originale siottiene moltiplicando\nilvettore perlamatrice diproiezione esommando ilvettore\nmedio .Questa trasformazione non sposta spazialmente il\nvettore, che giace ancora sullo spazio PCA,maopera un\ncambiamento dicoordinate che nepermette lacodifica in\ntermini delle𝑑componenti dello spazio originale .\n𝑃𝐶𝐴:𝑘→𝑑\n𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱\n𝑑=3,𝑘=2\n𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘\n6prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA: proiezione e retroproiezione\nProiezione\n (o):una volta determinato lospazio PCA, la\nproiezione diunpattern sutale spazio èsemplicemente la\nproiezione geometrica diunvettoresull’iperpiano chedefinisce\nlospazio .Inrealtà lavera proiezione geometrica èunvettore\nchehalastessa dimensionalità delvettore originale mentre in\nquesto contesto indichiamo con proiezione ilvettore (ridotto)\nnello spazio PCA.Matematicamente questa operazione è\neseguita come prodotto della matrice diproiezione trasposta\nperilpattern alquale èpreventivamente sottratta lamedia .\n𝑃𝐶𝐴:𝑑→𝑘\n𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱\nRetro\n -proiezione (m):Dato unvettore nello spazio PCA, lasua\nretro-proiezione verso lospazio originale siottiene moltiplicando\nilvettore perlamatrice diproiezione esommando ilvettore\nmedio .Questa trasformazione non sposta spazialmente il\nvettore, che giace ancora sullo spazio PCA,maopera un\ncambiamento dicoordinate che nepermette lacodifica in\ntermini delle𝑑componenti dello spazio originale .\n𝑃𝐶𝐴:𝑘→𝑑\n𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱\n𝑑=3,𝑘=2\n𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#11": "PCA: Esempio Riduzione 2 --->1\n7prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA: esempio riduzione 2 o1\nL’\nellisse rappresenta la distribuzione dei pattern nel training set .\n𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.\nGli \nautovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo \ngli assi 𝝋1e 𝝋2.\n𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.\nSe \n𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′\n(retroproiezione di 𝐲) senza perdite significative di informazione. \nSi \npuò dimostrare che tra tutte le riduzioni di dimensionalità\nlineari PCA è quella che preserva al massimo l’informazione dei \nvettori originali.0\nSpazio iniziale\n(𝑑=2)Spazio KL\n(𝑘=1)\n𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘\n𝜆2\n𝜆1𝑥2\n𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1\n𝐲=𝑦1,𝐲∈1\nത𝐱=𝑥1,𝑥2𝑡,𝐱∈2\n𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2\n7prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA: esempio riduzione 2 o1\nL’\nellisse rappresenta la distribuzione dei pattern nel training set .\n𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.\nGli \nautovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo \ngli assi 𝝋1e 𝝋2.\n𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.\nSe \n𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′\n(retroproiezione di 𝐲) senza perdite significative di informazione. \nSi \npuò dimostrare che tra tutte le riduzioni di dimensionalità\nlineari PCA è quella che preserva al massimo l’informazione dei \nvettori originali.0\nSpazio iniziale\n(𝑑=2)Spazio KL\n(𝑘=1)\n𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘\n𝜆2\n𝜆1𝑥2\n𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1\n𝐲=𝑦1,𝐲∈1\nത𝐱=𝑥1,𝑥2𝑡,𝐱∈2\n𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#12": "PCA: Esempio Riduzione 2 --->1\n7prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA: esempio riduzione 2 o1\nL’\nellisse rappresenta la distribuzione dei pattern nel training set .\n𝝋1e 𝝋2sono gli autovettori della matrice di covarianza.\nGli \nautovalori 𝜆1e 𝜆2sono le varianze della distribuzione lungo \ngli assi 𝝋1e 𝝋2.\n𝑦1e 𝑦2sono le proiezioni di 𝐱sugli assi 𝝋1e 𝝋2.\nSe \n𝜆2è piccolo, 𝐱può essere approssimato con 𝐱′\n(retroproiezione di 𝐲) senza perdite significative di informazione. \nSi \npuò dimostrare che tra tutte le riduzioni di dimensionalità\nlineari PCA è quella che preserva al massimo l’informazione dei \nvettori originali.0\nSpazio iniziale\n(𝑑=2)Spazio KL\n(𝑘=1)\n𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘\n𝜆2\n𝜆1𝑥2\n𝑥1 𝑥1𝑥2ത𝐱𝑦2𝑦1𝐱Φ1=𝝋1,Φ1∈2×1\n𝐲=𝑦1,𝐲∈1\nത𝐱=𝑥1,𝑥2𝑡,𝐱∈2\n𝐱=𝑥1,𝑥2𝑡,𝐱∈2Φ=𝝋1,𝝋2,Φ∈2×2𝝋1𝝋2",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#13": "PCA: Scelta di k\n8prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA: scelta di 𝑘\nTalvolta\n lascelta di𝑘èobbligata :adesempio per la\nvisualizzazione 2Do3Ddeidati.\nQuando\n invecel’obiettivo èquello discartare informazione\ninutile edati correlati mantenendo gran parte delcontenuto\ninformativo sipuòscegliere 𝑘nelmodo seguente :\nFissata\n una percentuale 𝑡delcontenuto informativo chesi\nvuole preservare (es.𝑡=95%)sisceglie ilminimo valore di\n𝑘percuilasomma deipiùgrandi𝑘autovalori ,rispetto alla\nsomma dituttigliautovalori ,èmaggiore ouguale a𝑡.\nConsiderando\n gliautovalori ordinati inordine decrescente :\n𝑘=𝑎𝑟𝑔𝑚𝑖𝑛\n𝑧σ𝑖=1…𝑧𝜆𝑖\nσ𝑖=1…𝑑𝜆𝑖≥𝑡\nInfatti, ricordando che gliautovalori denotano lavarianza\nlungo idiversi assi, ilrapporto nella formula indica lavarianza\n«conservata» rispetto allavarianza totale .",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#14": "PCA: Codifica di Immagini\n9prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA: codifica di un’immagine\n𝐱∈16500\n𝐲∈15\n𝐱′∈16500Immagine\noriginaleRicostruzione\n(retroproiezione)\nproiezione retro-proiezioneiprimi 8 autovettori o componenti principali\n(denominati eigenfaces nell’applicazione al riconoscimento volto )\n𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ15𝐱′=𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ15\n-2532 2193 -2179 2099 491\n427 -324 961 35 -40\n-149 -624 317 -158 -142",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#15": "Calcolo PCA in Pratica\n10prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàCalcolo PCA in pratica\nPer𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di\ncovarianza puòessere molto grande .\nper\n𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !\nse\n𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi\n𝑘autovettori) attraverso decomposizione SVD della matrice\nrettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare\nperlamatrice dicovarianza (vedi [1]).\n𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱\ndecomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛\nortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .\n𝚺=1\n𝑛𝐗𝐗𝑡=1\n𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1\n𝑛𝐔𝚪2𝐔𝑡\nAutovettori eautovalori di𝚺possono dunque essere ottenuti\ndalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti\nelementi diagonali di𝚪alquadrato (valori singolari alquadrato\ndi𝐗).\n[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component \nAnalysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione\nformato trasposto rispetto a \n𝐗usata in regressione.\nOgni pattern una colonna.\ndecomposizione \nspettrale della \nmatrice quadrata 𝚺\n10prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàCalcolo PCA in pratica\nPer𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di\ncovarianza puòessere molto grande .\nper\n𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !\nse\n𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi\n𝑘autovettori) attraverso decomposizione SVD della matrice\nrettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare\nperlamatrice dicovarianza (vedi [1]).\n𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱\ndecomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛\nortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .\n𝚺=1\n𝑛𝐗𝐗𝑡=1\n𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1\n𝑛𝐔𝚪2𝐔𝑡\nAutovettori eautovalori di𝚺possono dunque essere ottenuti\ndalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti\nelementi diagonali di𝚪alquadrato (valori singolari alquadrato\ndi𝐗).\n[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component \nAnalysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione\nformato trasposto rispetto a \n𝐗usata in regressione.\nOgni pattern una colonna.\ndecomposizione \nspettrale della \nmatrice quadrata 𝚺",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#16": "Singular Value Decomposition (SVD)\n!LaDecomposizione aiValori Singolari (Singular Value\nDecomposition, SVD) èuna importante fattorizzazione per\nmatrici avalori reali ocomplessi chesiavvale diautovalori\neautovettori\n!Ogni matrice M∈!m×npuò essere fattorizzata in \nM=U\"V*\ndove\n!Uèuna matrice m×munitaria (cioè UUt=Im)\n!#èuna matrice m×ndiagonale rettangolare con soli elementi\nreali non negativi\n!V*èlatrasposta coniugata diuna matrice n×nunitaria V",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#17": "Singular Value Decomposition (SVD)\n!Glielementi della diagonale di\"sono detti valori singolari diM\n!Lemcolonne diUsono dette vettori singolari sinistri diM\n!Lencolonne diVsono dette vettori singolari destri diM\n!Vale quanto segue\n!Ivettori singolari sinistri diMsono gliautovettori diM∙M*\n!Ivettori singolari destri diMsono gliautovettori diM*∙M\n!Ivalori singolari diMsono leradici quadrate degli autovalori non\nnulli diM∙M* eM*∙M",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#18": "Calcolo PCA in Pratica\n10prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàCalcolo PCA in pratica\nPer𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di\ncovarianza puòessere molto grande .\nper\n𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !\nse\n𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi\n𝑘autovettori) attraverso decomposizione SVD della matrice\nrettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare\nperlamatrice dicovarianza (vedi [1]).\n𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱\ndecomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛\nortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .\n𝚺=1\n𝑛𝐗𝐗𝑡=1\n𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1\n𝑛𝐔𝚪2𝐔𝑡\nAutovettori eautovalori di𝚺possono dunque essere ottenuti\ndalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti\nelementi diagonali di𝚪alquadrato (valori singolari alquadrato\ndi𝐗).\n[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component \nAnalysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione\nformato trasposto rispetto a \n𝐗usata in regressione.\nOgni pattern una colonna.\ndecomposizione \nspettrale della \nmatrice quadrata 𝚺\n10prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàCalcolo PCA in pratica\nPer𝑑elevato (tipico nelcaso diimmagini, audio, ecc.)lamatrice di\ncovarianza puòessere molto grande .\nper\n𝑑=16500 ,𝚺∈16500×16500,oltre 272milioni divalori !\nse\n𝑛≪𝑑,èconveniente calcolare lamatrice diproiezione (primi\n𝑘autovettori) attraverso decomposizione SVD della matrice\nrettangolare deipattern centralizzati 𝐗∈𝑑×𝑛senza passare\nperlamatrice dicovarianza (vedi [1]).\n𝐗=𝐱1−ത𝐱𝐱2−ത𝐱⋯𝐱𝑛−ത𝐱\ndecomposizone SVD per𝑑>𝑛:𝐗=𝐔𝚪𝐕𝑡,con𝐔∈𝑑×𝑛\nortonormale, con𝐕∈𝑛×𝑛ortonormale, 𝚪∈𝑛×𝑛diagonale .\n𝚺=1\n𝑛𝐗𝐗𝑡=1\n𝑛𝐔𝚪𝐕𝑡𝐕𝚪𝐔𝑡=1\n𝑛𝐔𝚪2𝐔𝑡\nAutovettori eautovalori di𝚺possono dunque essere ottenuti\ndalle colonne di𝐔(vettori singolari sinistri di𝐗)ecorrispondenti\nelementi diagonali di𝚪alquadrato (valori singolari alquadrato\ndi𝐗).\n[1] R. Madsen, L. Hansen, O. Winther, “Singular Value Decomposition and Principal Component \nAnalysis”, http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/4000/pdf/imm4000.pdfAttenzione\nformato trasposto rispetto a \n𝐗usata in regressione.\nOgni pattern una colonna.\ndecomposizione \nspettrale della \nmatrice quadrata 𝚺\n",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#19": "PCA Whitening\n11prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA Whitening\nÈunatecnica dipre-normalizzazione deidati, che:\nRimuove\n lecorrelazioni traledimensioni, ruotando lanuvola di\npunti per allineare gliassi divariazione principale deidati\n(autovettori )agliassicartesiani .\nSfericizza\n l’ellissoide, uniformando levarianze (denotate dagli\nautovalori )a1lungo tuttigliassi\nDopo aver proiettato ipattern sullo spazio PCA (definito daiprimi𝑘\nautovettori )èsufficiente dividere ogni dimensione perlaradice\nquadrata dell’autovalore corrispondente (deviazione standard) .\nLamatrice dicovarianza deidati normalizzati èl’identità .𝝋1\n𝝋2 𝝋1𝝋2\n𝝋1𝝋2\n𝝋1𝝋2Ricordiamo, infatti, che gliautovettori della matrice dicovarianza !\nsono paralleli agli assi dell’ellisse che rappresenta ladistribuzione dei\npattern delTraning Set(TS)",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#2": "Definizioni\n2prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàDefinizioni\nObiettivo dei metodi per lariduzione didimensionalità\n(dimensionality reduction )èquello dieseguire unmapping dallo\nspazio iniziale𝑑aunospazio didimensione inferiore 𝑘,𝑘<𝑑.\nPuò essere vista come unaforma dicompressione (con perdita di\ninformazione) .Obiettivo èscartare leinformazioni non rilevanti o\nmeno rilevanti perilproblema diinteresse :\nallevia\n iproblemi collegati allacurse ofdimensionality :operare\ninspazi adelevata dimensionalità ,acausa delfatto che i\npattern sono molto sparsi, richiede ingenti moli didati per\nl’addestramento .\noperare\n inspazi adimensionalità inferiore rende piùsemplice\naddestrare algoritmi dimachine learning .Scartando dati\nridondanti (informazioni correlate) erumorosi talvolta si\nmigliorano anche leprestazioni .\nAttenzione :riduzione didimensionalità non significa mantenere\nalcune «dimensioni» ecancellarne altre, ma «combinare »le\ndimensioni inmodo opportuno .",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#20": "PCA Whitening\n11prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA Whitening\nÈunatecnica dipre-normalizzazione deidati, che:\nRimuove\n lecorrelazioni traledimensioni, ruotando lanuvola di\npunti per allineare gliassi divariazione principale deidati\n(autovettori )agliassicartesiani .\nSfericizza\n l’ellissoide, uniformando levarianze (denotate dagli\nautovalori )a1lungo tuttigliassi\nDopo aver proiettato ipattern sullo spazio PCA (definito daiprimi𝑘\nautovettori )èsufficiente dividere ogni dimensione perlaradice\nquadrata dell’autovalore corrispondente (deviazione standard) .\nLamatrice dicovarianza deidati normalizzati èl’identità .𝝋1\n𝝋2 𝝋1𝝋2\n𝝋1𝝋2\n𝝋1𝝋2",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#21": "Linear Discriminant Analysis (LDA)\n12prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàLinear Discriminant Analysis (LDA)\nRiduzione didimensionalità lineare esupervisionata ilcui\nobiettivo èmassimizzare laseparazione traleclassi (che nelTS\nsono etichettate ).L’esempio seguente mostra chealfinedella\ndiscriminazione lasoluzione ottimale può essere anche molto\ndiversa dalla soluzione PCA.\nPer\n formulare ilcriterio diottimizzazione dimassima\nseparazione traleclassi sono definite leseguenti matrici di\nscattering (initaliano“sparpagliamento” ):\nwithin\n -class𝐒𝑤:indica come ivettori sono scattered rispetto\nalcentro delle classi (ciascuno rispetto allapropria classe) .\nbetween\n -class𝐒𝑏:indica come icentri delle classi sono\nscattered rispetto alcentro generale della distribuzione\n(ovvero quanto leclassi sono scattered ).\nUna matrice discatter sicalcola come unamatrice dicovarianza\nsenza normalizzare perilnumero dipatternaltezzapesoPCA\nLDAuomini\ndonne",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#22": "Linear Discriminant Analysis (LDA)\n12prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàLinear Discriminant Analysis (LDA)\nRiduzione didimensionalità lineare esupervisionata ilcui\nobiettivo èmassimizzare laseparazione traleclassi (che nelTS\nsono etichettate ).L’esempio seguente mostra chealfinedella\ndiscriminazione lasoluzione ottimale può essere anche molto\ndiversa dalla soluzione PCA.\nPer\n formulare ilcriterio diottimizzazione dimassima\nseparazione traleclassi sono definite leseguenti matrici di\nscattering (initaliano“sparpagliamento” ):\nwithin\n -class𝐒𝑤:indica come ivettori sono scattered rispetto\nalcentro delle classi (ciascuno rispetto allapropria classe) .\nbetween\n -class𝐒𝑏:indica come icentri delle classi sono\nscattered rispetto alcentro generale della distribuzione\n(ovvero quanto leclassi sono scattered ).\nUna matrice discatter sicalcola come unamatrice dicovarianza\nsenza normalizzare perilnumero dipatternaltezzapesoPCA\nLDAuomini\ndonne",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#23": "Calcolo LDA\n",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#24": "Richiami\n!Latraccia diuna matrice èdefinita solo per lematrici\nquadrate edèlasomma degli elementi presenti sulla\ndiagonale principale .\n!Traccia eautovalori diuna matrice :latraccia diuna\nmatrice èuguale allasomma deisuoi autovalori moltiplicati\nperlerispettive molteplicità algebriche ,cioè seλ1,λ2,...,λp\nsono gliautovalori distinti diuna matrice Adiordine n,\ndette m1,m2,...,mplerispettive molteplicità algebriche, se\nm1+m2+...+mp=n,allora\ntr(A) =m1λ1+m2λ2+...+mpλp",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#25": "Richiami\n!SiaAuna matrice quadrata diordine nesiaλ0unsuo\nautovalore .Sidice molteplicità algebrica dell’autovalore λ0,\nesiindica conma(λ0),ilnumero cheesprime quante volte\nl’autovalore λ0annulla ilpolinomio caratteristico .\n!Ricordiamo che ilpolinomio caratteristico associato auna\nmatrice quadrata Aèildeterminante della matrice A-λIn,\ndove Aèlamatrice inesame, λèun’incognita eInèla\nmatrice identità dello stesso ordine di A.\nInformule :\npA(λ):=det(A-λIn)",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#26": "Calcolo LDA\n13prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàCalcolo LDA\nDato untraining setTScontenente 𝑛pattern 𝐱1,𝑦1…𝐱𝑛,𝑦𝑛,\ndove𝐱𝑖∈𝑑sono ipattern multidimensionali e𝑦𝑖∈[1…𝑠]le\netichette delle𝑠classi .Siano𝑛𝑖eഥ𝐱𝑖ilnumero dipattern eilvettore\nmedio della classe i-esima .Allora lematrici discattering sono\ndefinite come :\nwithin\n -class :\n𝐒𝑤=෍\n𝑖=1…𝑠𝐒𝑖,𝐒𝑖=෍\n𝐱𝑗|𝑦𝑗=𝑖𝐱𝑗−ഥ𝐱𝑖𝐱𝑗−ഥ𝐱𝑖𝑡\nbetween\n -class :\n𝐒𝑏=෍\n𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖−𝐱0ഥ𝐱𝑖−𝐱0𝑡,𝐱0=1\n𝑛෍\n𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖\nTra idiversi criteri diottimizzazione possibili quello più\nfrequentemente utilizzato èlamassimizzazione della quantità :\n𝐽1=𝑡𝑟𝐒𝑤−1𝐒𝑏=෍\n𝑖=1…𝑑𝜆𝑖\ndove𝑡𝑟èlatraccia (somma degli autovalori )della matrice .Il\ncriterio èintuitivo inquanto cerca dimassimizzare loscattering tra\nleclassi (𝐒𝑏)minimizzando alcontempo (matrice inversa 𝐒𝑤−1)\nquelloall’interno diogni classe .\nSidimostra che perlamassimizzazione di𝐽1lospazio LDA è\ndefinito (analogia con PCA)dagli autovettori relativi aiprimi𝑘(𝑘<\n𝑛,𝑘<𝑠,𝑘<𝑑)autovalori della matrice𝐒𝑤−1𝐒𝑏.𝑝𝑎𝑡𝑡𝑒𝑟𝑛𝑑𝑒𝑙𝑙𝑎𝑐𝑙𝑎𝑠𝑠𝑒𝑖−𝑒𝑠𝑖𝑚𝑎\n𝑚𝑒𝑑𝑖𝑎𝑔𝑙𝑜𝑏𝑎𝑙𝑒\nvaloremassimo di𝑘=𝑠−1\n13prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàCalcolo LDA\nDato untraining setTScontenente 𝑛pattern 𝐱1,𝑦1…𝐱𝑛,𝑦𝑛,\ndove𝐱𝑖∈𝑑sono ipattern multidimensionali e𝑦𝑖∈[1…𝑠]le\netichette delle𝑠classi .Siano𝑛𝑖eഥ𝐱𝑖ilnumero dipattern eilvettore\nmedio della classe i-esima .Allora lematrici discattering sono\ndefinite come :\nwithin\n -class :\n𝐒𝑤=෍\n𝑖=1…𝑠𝐒𝑖,𝐒𝑖=෍\n𝐱𝑗|𝑦𝑗=𝑖𝐱𝑗−ഥ𝐱𝑖𝐱𝑗−ഥ𝐱𝑖𝑡\nbetween\n -class :\n𝐒𝑏=෍\n𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖−𝐱0ഥ𝐱𝑖−𝐱0𝑡,𝐱0=1\n𝑛෍\n𝑖=1…𝑠𝑛𝑖∙ഥ𝐱𝑖\nTra idiversi criteri diottimizzazione possibili quello più\nfrequentemente utilizzato èlamassimizzazione della quantità :\n𝐽1=𝑡𝑟𝐒𝑤−1𝐒𝑏=෍\n𝑖=1…𝑑𝜆𝑖\ndove𝑡𝑟èlatraccia (somma degli autovalori )della matrice .Il\ncriterio èintuitivo inquanto cerca dimassimizzare loscattering tra\nleclassi (𝐒𝑏)minimizzando alcontempo (matrice inversa𝐒𝑤−1)\nquelloall’interno diogni classe .\nSidimostra che perlamassimizzazione di𝐽1lospazio LDA è\ndefinito (analogia con PCA)dagli autovettori relativi aiprimi𝑘(𝑘<\n𝑛,𝑘<𝑠,𝑘<𝑑)autovalori della matrice𝐒𝑤−1𝐒𝑏.𝑝𝑎𝑡𝑡𝑒𝑟𝑛𝑑𝑒𝑙𝑙𝑎𝑐𝑙𝑎𝑠𝑠𝑒𝑖−𝑒𝑠𝑖𝑚𝑎\n𝑚𝑒𝑑𝑖𝑎𝑔𝑙𝑜𝑏𝑎𝑙𝑒\nvaloremassimo di𝑘=𝑠−1",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#27": "t-distributed Stochastic Neighbor Embedding (t -SNE)\n14prof. Davide Maltoni –Università di Bologna\nML\nRiduzione Dimensionalitàt-distributed Stochastic Neighbor \nEmbedding (t-SNE)\nÈunatecnica nonlineare (nonsupervisionata )perlariduzione\ndidimensionalità introdotta nel2008 daVan derMaaten e\nHinton [1].\nRappresenta\n lostatodell’arte perlavisualizzazione 2Do3Ddi\ndati multidimensionali .Implementazione disponibile inmolti\nlinguaggi in[2].\nAnche\n PCA (con𝑘=2o𝑘=3)può essere utilizzata atale\nscopo, madaticondistribuzioni spiccatamente nonmultinormali\nnon possono essere efficacemente «ridotti» attraverso un\nmapping lineare .\nEsempio\n :visualizzazione 2DdiMNIST (digit scritti amano) .\n[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-\nSNE.Journal ofMachine Learning Research ,2008 .\n[2]https ://lvdmaaten .github .io/tsne/\n14prof. Davide Maltoni –Università di Bologna\nML\nRiduzione Dimensionalitàt-distributed Stochastic Neighbor \nEmbedding (t-SNE)\nÈunatecnica nonlineare (nonsupervisionata )perlariduzione\ndidimensionalità introdotta nel2008 daVan derMaaten e\nHinton [1].\nRappresenta\n lostatodell’arte perlavisualizzazione 2Do3Ddi\ndati multidimensionali .Implementazione disponibile inmolti\nlinguaggi in[2].\nAnche\n PCA (con𝑘=2o𝑘=3)può essere utilizzata atale\nscopo, madaticondistribuzioni spiccatamente nonmultinormali\nnon possono essere efficacemente «ridotti» attraverso un\nmapping lineare .\nEsempio\n :visualizzazione 2DdiMNIST (digit scritti amano) .\n[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-\nSNE.Journal ofMachine Learning Research ,2008 .\n[2]https ://lvdmaaten .github .io/tsne/\n14prof. Davide Maltoni –Università di Bologna\nML\nRiduzione Dimensionalitàt-distributed Stochastic Neighbor \nEmbedding (t-SNE)\nÈunatecnica nonlineare (nonsupervisionata )perlariduzione\ndidimensionalità introdotta nel2008 daVan derMaaten e\nHinton [1].\nRappresenta\n lostatodell’arte perlavisualizzazione 2Do3Ddi\ndati multidimensionali .Implementazione disponibile inmolti\nlinguaggi in[2].\nAnche\n PCA (con𝑘=2o𝑘=3)può essere utilizzata atale\nscopo, madaticondistribuzioni spiccatamente nonmultinormali\nnon possono essere efficacemente «ridotti» attraverso un\nmapping lineare .\nEsempio\n :visualizzazione 2DdiMNIST (digit scritti amano) .\n[1]L.J.P.vanderMaaten andG.E.Hinton .Visualizing High-Dimensional Data Using t-\nSNE.Journal ofMachine Learning Research ,2008 .\n[2]https ://lvdmaaten .github .io/tsne/\n",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#28": "14prof. Davide Maltoni –Università di Bologna\nML\nRiduzione Dimensionalitàt-distributed Stochastic Neighbor \nEmbedding (t-SNE)\nÈunatecnica nonlineare (nonsupervisionata )perlariduzione\ndidimensionalità introdotta nel2008 daVan derMaaten e\nHinton [1].\nRappresenta\n lostatodell’arte perlavisualizzazione 2Do3Ddi\ndati multidimensionali .Implementazione disponibile inmolti\nlinguaggi in[2].\nAnche\n PCA (con𝑘=2o𝑘=3)può essere utilizzata atale\nscopo, madaticondistribuzioni spiccatamente nonmultinormali\nnon possono essere efficacemente «ridotti» attraverso un\nmapping lineare .\nEsempio\n :visualizzazione 2DdiMNIST (digit scritti amano) .\n[1]L.J.P.vanderMaaten and G.E.Hinton .Visualizing High-Dimensional Data Using t-\nSNE.Journal ofMachine Learning Research ,2008 .\n[2]https ://lvdmaaten .github .io/tsne/\nt-SNE: Esempio",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#29": "t-SNE in Scikit -Learn\nPer maggiori dettagli vedi documentazione online della libreria\nopen source scikit -learn :sklearn .manifold .TSNE!Esempio :visualizzazione 2Ddiundataset contenente immagini\n(non controllate) di1000 Cani +1000 Gatti, utilizzando come\nfeature diinput leHOG (Histogram ofOriented Gradients)\ninvece deipixel .\n15prof. Davide Maltoni –Università di Bologna\nML\nRiduzione Dimensionalitàt-SNE in sklearn\nEsempio\n :visualizzazione 2Ddiundataset contente immagini\n(non controllate) di1000 Cani +1000 Gatti, utilizzando come\nfeature diinput leHOG (Histogram ofOriented Gradients )\ninvece deipixel.\nVedi\n https ://distill .pub/2016 /misread -tsne/perconsigli sucome\ntarare iparametri (es.perplexity )ditsne.\nI due cluster sono \nmolto sovrapposti. I \nclassificatori \ntradizionali (es. SVM) \nraggiungono il 70% \ncirca, sfruttando la \nmaggiore densità dei \npatter verdi (gatti) in \nuna certa regione.",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#3": "Le Principali Tecniche\n3prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàLe principali tecniche\nLepiùnote tecniche diriduzione didimensionalità (che vedremo)\nsono :\nPrincipal\n Component Analysis (PCA):trasformazione non-\nsupervisionata nota anche come Karhunen Loeve (KL)\ntransform .Esegue unmapping lineare conl’obiettivo di\npreservare almassimo l’informazione deipattern .\nLinear\n Discriminant Analysis (LDA):ilmapping èancora lineare ,\nmainquesto caso èsupervisionato .Mentre PCA privilegia le\ndimensioni cherappresentano almeglio ipattern, LDA privilegia\nledimensioni chediscriminano almeglio ipattern delTS.\nt-distributed Stochastic Neighbor Embedding (t-SNE):\ntrasformazione non lineare e non supervisionata ,\nspecificatamente ideata per ridurre dimensionalità a2o3\ndimensioni onde poter visualizzare datimultidimensionali .\nAltre tecniche diinteresse :\nIndependent\n Component Analysis (ICA):trasformazione lineare\norientata aproiettare ipattern suuna base dicomponenti\n(statisticamente indipendenti ).\nKernel\n PCA:simile aPCA mapiùpotente perché ilmapping è\nnon-lineare .Utilizza un«trucco» simile aquello chepermette di\npassare daSVM lineare aSVM nonlineare .\nLocal\n Linear Embedding (LLE):trasformazione non-lineare che\ninvece dicalcolare unmapping «globale», considera relazioni\ntragruppi dipattern vicini .",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#30": "15prof. Davide Maltoni –Università di Bologna\nML\nRiduzione Dimensionalitàt-SNE in sklearn\nEsempio\n :visualizzazione 2Ddiundataset contente immagini\n(non controllate) di1000 Cani +1000 Gatti, utilizzando come\nfeature diinput leHOG (Histogram ofOriented Gradients )\ninvece deipixel.\nVedi\n https ://distill .pub/2016 /misread -tsne/perconsigli sucome\ntarare iparametri (es.perplexity )ditsne.\nI due cluster sono \nmolto sovrapposti. I \nclassificatori \ntradizionali (es. SVM) \nraggiungono il 70% \ncirca, sfruttando la \nmaggiore densità dei \npatter verdi (gatti) in \nuna certa regione.\n15prof. Davide Maltoni –Università di Bologna\nML\nRiduzione Dimensionalitàt-SNE in sklearn\nEsempio\n :visualizzazione 2Ddiundataset contente immagini\n(non controllate) di1000 Cani +1000 Gatti, utilizzando come\nfeature diinput leHOG (Histogram ofOriented Gradients )\ninvece deipixel.\nVedi\n https ://distill .pub/2016 /misread -tsne/perconsigli sucome\ntarare iparametri (es.perplexity )ditsne.\nI due cluster sono \nmolto sovrapposti. I \nclassificatori \ntradizionali (es. SVM) \nraggiungono il 70% \ncirca, sfruttando la \nmaggiore densità dei \npatter verdi (gatti) in \nuna certa regione.I due cluster appaiono molto \nsovrapposti. \nI classificatori tradizionali \n(e.g., SVM) raggiungono una \naccuratezza di circa il 70%, \nsfruttando la maggiore \ndensità dei pattern verdi \n(gatti) in una certa regione.t-SNE in Scikit -Learn",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#31": "!Matlab Toolbox for Dimensionality Reduction:\nhttps://lvdmaaten.github.io/drtoolbox/\nt-SNE in Matlab",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#32": "Riferimenti\n!S.J. Russell & P. Norvig, Artificial Intelligence: A Modern \nApproach (4 ed.) , Pearson, 2020.\n!K. Fukunaga, Statistical Pattern Recognition , Academic Press, \n1990.\n!D. Maltoni , Machine Learning , Università di Bologna, 2017.\n!C.M. Bishop, Pattern Recognition and Machine Learning , \nSpringer, 2006.\n!K.P. Murphy, Machine Learning: A Probabilistic Perspective , The \nMIT Press, 2012.\n!R.O. Duda , P.E. Hart, and D.G. Stork. 2000. Pattern Classification \n(2nd Edition). Wiley -Interscience , New York, NY, USA. ",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#4": "Le Principali Tecniche\n3prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàLe principali tecniche\nLepiùnote tecniche diriduzione didimensionalità (che vedremo)\nsono :\nPrincipal\n Component Analysis (PCA):trasformazione non-\nsupervisionata nota anche come Karhunen Loeve (KL)\ntransform .Esegue unmapping lineare conl’obiettivo di\npreservare almassimo l’informazione deipattern .\nLinear\n Discriminant Analysis (LDA):ilmapping èancora lineare ,\nmainquesto caso èsupervisionato .Mentre PCA privilegia le\ndimensioni cherappresentano almeglio ipattern, LDA privilegia\nledimensioni chediscriminano almeglio ipattern delTS.\nt-distributed Stochastic Neighbor Embedding (t-SNE):\ntrasformazione non lineare e non supervisionata ,\nspecificatamente ideata per ridurre dimensionalità a2o3\ndimensioni onde poter visualizzare datimultidimensionali .\nAltre tecniche diinteresse :\nIndependent\n Component Analysis (ICA):trasformazione lineare\norientata aproiettare ipattern suuna base dicomponenti\n(statisticamente indipendenti ).\nKernel\n PCA:simile aPCA mapiùpotente perché ilmapping è\nnon-lineare .Utilizza un«trucco» simile aquello chepermette di\npassare daSVM lineare aSVM nonlineare .\nLocal\n Linear Embedding (LLE):trasformazione non-lineare che\ninvece dicalcolare unmapping «globale», considera relazioni\ntragruppi dipattern vicini .",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#5": "Esempio PCA vs LDA\n4prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàEsempio PCA vs LDA\nInfigura dueesempi diriduzione didimensionalità da𝑑=2a𝑘=\n1dimensione :\nIl\nsegmento nero cheidentifica lasoluzione PCA èl’iperpiano\nsulquale proiettando ipattern (indipendentemente dalla loro\nclasse) conserviamo almassimo l’informazione .\nIl\nsegmento verde cheidentifica lasoluzione LDA èl’iperpiano\nsulquale proiettando ipattern siamo ingrado didistinguere al\nmeglio ledueclassi (pattern rossi contro blu).\nEntrambi sono mapping lineari2→1malasoluzione (retta) è\nprofondamente diversa .\n4prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàEsempio PCA vs LDA\nInfigura dueesempi diriduzione didimensionalità da𝑑=2a𝑘=\n1dimensione :\nIl\nsegmento nero cheidentifica lasoluzione PCA èl’iperpiano\nsulquale proiettando ipattern (indipendentemente dalla loro\nclasse) conserviamo almassimo l’informazione .\nIl\nsegmento verde cheidentifica lasoluzione LDA èl’iperpiano\nsulquale proiettando ipattern siamo ingrado didistinguere al\nmeglio ledueclassi (pattern rossi contro blu).\nEntrambi sono mapping lineari2→1malasoluzione (retta) è\nprofondamente diversa .\n",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#6": "Principal Component Analysis (PCA)\n5prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPrincipal Component Analysis \n(PCA)\nDato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :\nത𝐱=1\n𝑛෍\n𝑖=1…𝑛𝐱𝑖\n𝚺=1\n𝑛−1෍\n𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡\nilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑\n(definizioni simili aquelle usate per ilclassificatore diBayes\nparametrico con multinormali .Ladivisione per𝑛−1invece di\n𝑛dovuta acorrezione diBessel percaso unbiased ).\nallora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale\n(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di\nproiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli\nautovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :\nΦ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑\n𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑\n𝝋𝒊𝟏indica la direzione di \nmaggior varianza nel \ntraining set TS𝝋𝒊𝟏\n𝝋𝒊𝟐\nI primi 𝑘autovettori sono \ndetti componenti principali",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#7": "Principal Component Analysis (PCA)\n5prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPrincipal Component Analysis \n(PCA)\nDato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :\nത𝐱=1\n𝑛෍\n𝑖=1…𝑛𝐱𝑖\n𝚺=1\n𝑛−1෍\n𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡\nilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑\n(definizioni simili aquelle usate per ilclassificatore diBayes\nparametrico con multinormali .Ladivisione per𝑛−1invece di\n𝑛dovuta acorrezione diBessel percaso unbiased ).\nallora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale\n(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di\nproiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli\nautovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :\nΦ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑\n𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑\n𝝋𝒊𝟏indica la direzione di \nmaggior varianza nel \ntraining set TS𝝋𝒊𝟏\n𝝋𝒊𝟐\nI primi 𝑘autovettori sono \ndetti componenti principali",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#8": "Principal Component Analysis (PCA)\n!Riassumendo\n!Dagli npattern delTraining Set (TS) sicalcolano vettore medio e\nmatrice dicovarianza !\n!Dalla matrice dicovarianza sicalcolano idautovalori eautovettori\n!Dei dautovalori siconsiderano solo ikautovalori con valore\nmaggiore (inordine decrescente)\n!Lamatrice diproiezione \"ksarà unmatrice (d×k)lecuikcolonne\nsono costituite dagli autovettori relativi aikautovalori calcolati\ncome sopra\n!Gli autovettori !idella matrice di \ncovarianza \"sono paralleli agli \nassi dell’ ellisse che rappresenta \nladistribuzione dei pattern nel TS\n!Gli autovalori #isono le varianze \nlungo gli assi !i\n5prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPrincipal Component Analysis \n(PCA)\nDato untraining set𝑇𝑆=𝐱𝑖∈𝑑,𝑖=1…𝑛,siano :\nത𝐱=1\n𝑛෍\n𝑖=1…𝑛𝐱𝑖\n𝚺=1\n𝑛−1෍\n𝑖=1…𝑛𝐱𝑖−ത𝐱𝐱𝑖−ത𝐱𝑡\nilvettore medio∈𝑑elamatrice dicovarianza ∈𝑑×𝑑\n(definizioni simili aquelle usate per ilclassificatore diBayes\nparametrico con multinormali .Ladivisione per𝑛−1invece di\n𝑛dovuta acorrezione diBessel percaso unbiased ).\nallora perundato𝑘(𝑘<𝑑,𝑘<𝑛,𝑘>0),lospazio𝑘dimensionale\n(𝑆ത𝐱,Φ𝑘)èunivocamente definito dalvettore medio edalla matrice di\nproiezione Φ𝑘∈𝑑×𝑘lecui colonne sono costituite dagli\nautovettori di𝚺corrispondenti ai𝑘piùgrandi autovalori :\nΦ𝑘=𝝋𝑖1,𝝋𝑖2…𝝋𝑖𝑘con  𝜆𝑖1≥𝜆𝑖2≥⋯𝜆𝑖𝑘≥⋯𝜆𝑖𝑑\n𝝋𝑖𝑟autovettore di 𝚺corrispondente all’ autovalore 𝜆𝑖𝑟, 𝑟=1…𝑑\n𝝋𝒊𝟏indica la direzione di \nmaggior varianza nel \ntraining set TS𝝋𝒊𝟏\n𝝋𝒊𝟐\nI primi 𝑘autovettori sono \ndetti componenti principali",
    "data_test\\rootfolder\\università\\MachineLearning\\38-RD-sbloccato.pdf#9": "PCA: Proiezione\n6prof. Davide Maltoni –Università di Bologna\nML\nRiduzione DimensionalitàPCA: proiezione e retroproiezione\nProiezione\n (o):una volta determinato lospazio PCA, la\nproiezione diunpattern sutale spazio èsemplicemente la\nproiezione geometrica diunvettoresull’iperpiano chedefinisce\nlospazio .Inrealtà lavera proiezione geometrica èunvettore\nchehalastessa dimensionalità delvettore originale mentre in\nquesto contesto indichiamo con proiezione ilvettore (ridotto)\nnello spazio PCA.Matematicamente questa operazione è\neseguita come prodotto della matrice diproiezione trasposta\nperilpattern alquale èpreventivamente sottratta lamedia .\n𝑃𝐶𝐴:𝑑→𝑘\n𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘=Φ𝑘𝑡𝐱−ത𝐱\nRetro\n -proiezione (m):Dato unvettore nello spazio PCA, lasua\nretro-proiezione verso lospazio originale siottiene moltiplicando\nilvettore perlamatrice diproiezione esommando ilvettore\nmedio .Questa trasformazione non sposta spazialmente il\nvettore, che giace ancora sullo spazio PCA,maopera un\ncambiamento dicoordinate che nepermette lacodifica in\ntermini delle𝑑componenti dello spazio originale .\n𝑃𝐶𝐴:𝑘→𝑑\n𝑃𝐶𝐴𝐲,𝑆ത𝐱,Φ𝑘=Φ𝑘𝐲+ത𝐱𝐱\n𝑑=3,𝑘=2\n𝑆ത𝐱,Φ𝑘𝐲=𝑃𝐶𝐴𝐱,𝑆ത𝐱,Φ𝑘",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Riduzione dimensionalità (Ex 15)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#1": "Sommario\nRichiami riduzione dimensionalità, projection, mainfold learning \nPCA in Python \nScikit-learn e PCA \nPCA e compressione \nRandomized PCA \nKernel PCA \nLocally Linear Embedding LLE \nEsercitazione",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#10": "PCA: Step by step in Python\nUna volta ottenute le componenti, deﬁniamo il nuovo iperspazio con \n d \ndimensioni. Prendiamo le prime d colonne di \n V\n e proiettiamo le istanze nel \nnuovo spazio: \nX\nd-proj\n = X W\n d \nIn Python: \nW2 \n= \nVt\n.\nT\n[:, :\n2\n]\nX2D \n= \nX_centered\n .\ndot\n(\nW2\n)\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#11": "Scikit-learn e PCA\nScikit-learn implementa la PCA nel seguente modo: \nfrom \nsklearn.decomposition \n import \nPCA\npca \n= \nPCA\n(\nn_components \n = \n2\n)\nX2D \n= \npca\n.\nfit_transform\n (\nX\n)\nLa variabile components_ contiene i vettori. Per accedere al primo vettore:  \npca.components_.T[:,0] \nOgni componente è associata alla relativa varianza che si può analizzare \ncon la variabile \n explained_variance_ratio_\n . Considerando l'esempio \nprecedente si ottiene: \n>>> \npca\n.\nexplained_variance_ratio_\narray([0.84248607, 0.14631839])\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#12": "Scikit-learn e PCA\nLa scelta del numero di dimensioni dipende dalla varianza: si tende a \nscegliere il numero che garantisce sempre elevata varianza (es. 95%). \nEccezione se vogliamo fare un diagramma dei campioni, in tal caso ci \noccorrono 2 o 3 dimensioni. \nIl seguente codice ricava il numero di dimensioni che preservano il 95% \ndella varianza sul training set: \npca \n= \nPCA\n()\npca\n.\nfit\n(\nX_train\n)\ncumsum \n= \nnp\n.\ncumsum\n(\npca\n.\nexplained_variance_ratio_\n )\nd \n= \nnp\n.\nargmax\n(\ncumsum \n>= \n0.95\n) \n+ \n1\nUn modo alternativo per speciﬁcare la varianza: \npca \n= \nPCA\n(\nn_components\n =\n0.95\n)\nX_reduced \n = \npca\n.\nfit_transform\n (\nX_train\n)\n(continua)\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#13": "Scikit-learn e PCA\nUlteriore metodo per ﬁssare d è fare un graﬁco del cumsum della varianza. \nIl \ngomito\n  della curva è dove la varianza interrompe la crescita veloce.  \nNell'esempio una dimensionalità inferiore a 100 è un valore ideale:\n14\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#14": "PCA e compressione\nUna volta ottenuto il dataset proiettato sulle componenti, la dimensione del \ndataset si riduce sensibilmente. \nLa funzione \n inverse_transform\n () di PCA permette di ricostruire una \napprosimazione del dataset con le dimensioni originali a partire dalle \nistanze nello spazio ridotto. \nX\nrecovered\n  = X\n d-proj\n W\nd\nT \nEsercizio\n : (1) impiega il dataset MNIST (cifre, 784 dimensioni) e applica la \nPCA riducendo le dimensioni a 154, e valuta le dimensioni del nuovo \ndataset. (2) visualizza le cifre ricostruite con \n inverse_transform(). \nSuggerimento per visualizzare le cifre\n : \nimport\n matplotlib.pyplot \n as\n plt\nplt.imshow(X_train[\n 0\n].reshape((\n 28\n, \n28\n)), cmap=\n 'gray'\n)\nplt.show()\n15",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#15": "PCA e compressione\nEsercizio\n : (1) impiega il dataset MNIST (cifre, 784 dimensioni) e applica la \nPCA riducendo le dimensioni a 154, e valuta le dimensioni del nuovo \ndataset \nfrom\n sklearn.decomposition \n import\n PCA\nfrom\n sklearn \n import\n datasets\nfrom\n sklearn.model_selection \n import\n train_test_split\nfrom\n sklearn.datasets \n import\n fetch_openml\nfrom\n sklearn.preprocessing \n import\n StandardScaler\nmnist = fetch_openml(\n 'mnist_784'\n )\nX_train, X_test, y_train, y_test  = train_test_split\n        (mnist.data, mnist.target, test_size=\n 1\n/\n7.0\n, random_state=\n 0\n)\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\npca = PCA(n_components = \n 154\n)\nX_reduced = pca.fit_transform(X_train)\nX_recovered = pca.inverse_transform(X_reduced)\n(continua)\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#16": "PCA e compressione\noriginal_len = X_train.flatten().size\nprint\n(original_len)\nred_len = X_reduced.flatten().size\nprint\n(red_len)\nrec_len = X_recovered.flatten().size\nprint\n(rec_len)\npct = (red_len - original_len) * \n 100\n / original_len\nprint\n (pct)\n47040000\n9240000\n47040000\n-80.35714285714286 \nDataset ridotto al 20% della dimensione originale! \n17",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#17": "PCA e compressione\nEsercizio\n : ... (2) visualizza le cifre ricostruite con \n inverse_transform().  \nimport\n matplotlib.pyplot \n as\n plt\nplt.imshow(X_train[\n 0\n].reshape((\n 28\n, \n28\n)), cmap=\n 'gray'\n)\nplt.show()\nplt.imshow(X_recovered[\n 0\n].reshape((\n 28\n, \n28\n)), cmap=\n 'gray'\n)\nplt.show()\n18\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#18": "Scikit-learn: Randomized PCA\nImpiegando il parametro \n svd_solver\n =\n\"randomized\", impieghiamo \nl'algoritmo Randomized PCA che riduce notevolmente il tempo di \nesecuzione essendo d << n: \nO(\nm × n\n2\n) + O(\n n\n3\n)  --->   O(\n m × d\n2\n) + O(\n d\n3\n) \nPer default sciki-learn usa il solver \n auto\n, che impiega la versione \nrandomized se \n m\n o \nn\n sono maggiori di 500 e d è minore del 80% rispetto a \nm\n o \nn\n.  \nPer forzare l'impiego della versione esatta, impiegare l'opzione \n full\n. \n19",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#19": "Scikit-learn: Incremental PCA\nL'algoritmo PCA richieda che l'intero dataset sia presente in memoria. \nL'algoritmo Incremental PCA accetta il dataset suddiviso in mini-batch, e \npuò essere impiegato \n online\n . \nfrom \nsklearn.decomposition \n import \nIncrementalPCA\nn_batches \n = \n100\ninc_pca \n = \nIncrementalPCA\n (\nn_components\n =\n154\n)\nfor \nX_batch \n in \nnp\n.\narray_split\n (\nX_train\n, \nn_batches\n ):\n    \ninc_pca\n.\npartial_fit\n (\nX_batch\n)\nX_reduced \n = \ninc_pca\n.\ntransform\n (\nX_train\n)\nCon la classe memmap di NumPy possiamo leggere gli array \nincrementalmente da ﬁle binary: \nX_mm \n= \nnp\n.\nmemmap\n(\nfilename\n , \ndtype\n=\n\"float32\"\n , \nmode\n=\n\"readonly\"\n , \nshape\n=\n(\nm\n, \nn\n))\nbatch_size \n = \nm \n// \nn_batches\ninc_pca \n = \nIncrementalPCA\n (\nn_components\n =\n154\n, \nbatch_size\n =\nbatch_size\n )\ninc_pca\n.\nfit\n(\nX_mm\n)\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#2": "Richiami: riduzione di dimensionalità\nIn casi reali i dati da analizzare possono essere sempliﬁcati riducendo il \nnumero di features. L'obiettivo è velocizzare il processo di training senza \ninﬂuire troppo sulle performance, e ridurre l'eventuale rumore, es: \nNel MNIST dataset i pixel nei bordi sono sempre bianchi, possiamo \npensare di rimuoverli \nSpesso i pixel neri sono correlati, cioè appaiono vicini. È possibile \nfonderli facendone una media.  \nSe creassimo a caso immagini, in rarissimi casi potrebbero assomigliare \nalle cifre nel dataset. Perciò i gradi di libertà disponibili nella creazione \ndi istanze sono notevolmente ridotti rispetto a quelli potenziali in uno \nspazio con le medesime dimensioni. \nInoltre la riduzione di dimensionalità permette di creare graﬁci nel caso in \ncui le dimensioni siano 2 o 3.\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#20": "Scikit-learn: Kernel PCA (kPCA)\nIn modo simile ai kernel del SVM è possibile fare proiezioni non lineari \ncomplesse per la riduzione di dimensionalità. \nSimilmente al SVM, ha il vantaggio di mantenere cluster di istanze dopo la \nproiezione, oppure operare \n unrolling\n  di forme complesse. \nIn scikit-learn impiegando il kernel rbf si ha: \nfrom \nsklearn.decomposition \n import \nKernelPCA\nrbf_pca \n = \nKernelPCA\n (\nn_components \n = \n2\n, \nkernel\n=\n\"rbf\"\n, \ngamma\n=\n0.04\n)\nX_reduced \n = \nrbf_pca\n.\nfit_transform\n (\nX\n)\nDi seguito alcuni esempi di proiezioni a 2 dimensioni con vari kernel:\n21\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#21": "Scikit-learn: Kernel PCA (kPCA)\nLa scelta del kernel dipende dal task. Se il task è supervisionato, si può fare \nuna semplice grid search sui kernel e i relativi iperparametri per ottenere \nperformance migliori. \nNel seguente codice si impiega una pipeline per il task di regressione: \nfrom \nsklearn.model_selection \n import \nGridSearchCV\nfrom \nsklearn.linear_model \n import \nLogisticRegression\nfrom \nsklearn.pipeline \n import \nPipeline\nclf \n= \nPipeline\n ([\n(\n\"kpca\"\n, \nKernelPCA\n (\nn_components\n =\n2\n)),\n(\n\"log_reg\"\n , \nLogisticRegression\n ())\n])\nparam_grid \n = \n[{\n\"kpca__gamma\"\n : \nnp\n.\nlinspace\n (\n0.03\n, \n0.05\n, \n10\n),\n\"kpca__kernel\"\n : [\n\"rbf\"\n, \n\"sigmoid\"\n ]\n}]\ngrid_search \n = \nGridSearchCV\n (\nclf\n, \nparam_grid\n , \ncv\n=\n3\n)\ngrid_search\n .\nfit\n(\nX\n, \ny\n)\n>>> \nprint\n(\ngrid_search\n .\nbest_params_\n )\n{'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#22": "Scikit-learn: Kernel PCA (kPCA)\nSe il task è unsupervised, è possibile comunque fare un tuning dei \nparametri?\n23",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#23": "Scikit-learn: Kernel PCA (kPCA)\nSe il task è unsupervised, è possibile comunque fare un tuning dei \nparametri? \nSe ricostruiamo i dati originali con le componenti PCA possiamo valutare \nle performance con una misura di discostamento (es. distanza quadratica). \nAttenzione\n : l'impiego dei kernel implica che la ricostruzione generi un \nfeature space inﬁnito-dimensionale. Perciò non è possibile confrontare \ndirettamente le istanze con lo spazio originale. Con la tecnica \nrecontruction pre-image è possibile trovare il punto nello spazio originale \nche è vicino alla istanza \n ricostruita\n .\n24\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#24": "Scikit-learn: Kernel PCA (kPCA)\nIl parametro ﬁt_inverse_transform=True adotta questa strategia: \nrbf_pca \n = \nKernelPCA\n (\nn_components \n = \n2\n, \nkernel\n=\n\"rbf\"\n, \ngamma\n=\n0.0433\n,\n              \n fit_inverse_transform\n =\nTrue\n)\nX_reduced \n = \nrbf_pca\n.\nfit_transform\n (\nX\n)\nX_preimage \n = \nrbf_pca\n.\ninverse_transform\n (\nX_reduced\n )\n>>> \nfrom \nsklearn.metrics \n import \nmean_squared_error\n>>> \nmean_squared_error\n (\nX\n, \nX_preimage\n )\n32.786308795766132\n25",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#25": "Scikit-learn: Locally Linear Embedding (LLE)\nÈ una ulteriore tecnica non lineare, ma non si basa sulle proiezioni. \nIn sintesi, nella prima fase analizza le similarità tra una istanza e le istanze \nvicine (neighbors), e successivamente crea un iperspazio con meno \ndimensioni che mantiene queste tali relazioni.  \nÈ un approccio ideale per fare unrolling e in presenza di poco rumore. \nfrom \nsklearn.manifold \n import \nLocallyLinearEmbedding\nlle \n= \nLocallyLinearEmbedding\n (\nn_components\n =\n2\n, \nn_neighbors\n =\n10\n)\nX_reduced \n = \nlle\n.\nfit_transform\n (\nX\n)\nLo spazio risultate è correttamente dispiegato, anche se le distanze relative \nnon sono mantenute coerenti.\n26\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#26": "Esercitazione\nCarica il dataset MNIST e suddividilo in 60K training e 10K test set. \nAddestra un classiﬁcatore Random Forest, calcola il tempo di training e le \nperformance. \nApplica PCA con una \n explained variance ratio\n  del 95%. \nAddestra un nuovo classiﬁcatore Random Forest, calcola il tempo di \ntraining e le performance, e confronta i valori con i valori precedenti.\n27",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#27": "Esercitazione\nfrom\n sklearn.datasets \n import\n fetch_openml\nmnist = fetch_openml(\n 'mnist_784'\n )\nX_train = mnist[\n 'data'\n][:\n60000\n]\ny_train = mnist[\n 'target'\n ][:\n60000\n]\nX_test = mnist[\n 'data'\n][\n60000\n:]\ny_test = mnist[\n 'target'\n ][\n60000\n:]\nfrom\n sklearn.ensemble \n import\n RandomForestClassifier\nrnd_clf = RandomForestClassifier(n_estimators=\n 100\n, random_state=\n 42\n)\nimport\n time\nt0 = time.time()\nrnd_clf.fit(X_train, y_train)\nt1 = time.time()\nprint\n(\n\"Training took {:.2f}s\"\n .\nformat\n(t1 - t0))\n28",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#28": "Esercitazione\nfrom\n sklearn.metrics \n import\n accuracy_score\ny_pred = rnd_clf.predict(X_test)\naccuracy_score(y_test, y_pred)\nfrom\n sklearn.decomposition \n import\n PCA\npca = PCA(n_components=\n 0.95\n)\nX_train_reduced = pca.fit_transform(X_train)\nrnd_clf2 = RandomForestClassifier(n_estimators=\n 100\n, random_state=\n 42\n)\nt0 = time.time()\nrnd_clf2.fit(X_train_reduced, y_train)\nt1 = time.time()\nprint\n(\n\"Training took {:.2f}s\"\n .\nformat\n(t1 - t0))\nX_test_reduced = pca.transform(X_test)\ny_pred = rnd_clf2.predict(X_test_reduced)\naccuracy_score(y_test, y_pred)\n29",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#29": "Esercitazione\nfrom\n sklearn.linear_model \n import\n LogisticRegression\nlog_clf = LogisticRegression(multi_class=\n \"multinomial\"\n , solver=\n \"lbfgs\"\n, \nrandom_state=\n 42\n)\nt0 = time.time()\nlog_clf.fit(X_train, y_train)\nt1 = time.time()\nprint\n(\n\"Training took {:.2f}s\"\n .\nformat\n(t1 - t0))\ny_pred = log_clf.predict(X_test)\nprint(\naccuracy_score(y_test, y_pred))\nlog_clf2 = LogisticRegression(multi_class=\n \"multinomial\"\n , solver=\n \"lbfgs\"\n, \nrandom_state=\n 42\n)\nt0 = time.time()\nlog_clf2.fit(X_train_reduced, y_train)\nt1 = time.time()\nprint\n(\n\"Training took {:.2f}s\"\n .\nformat\n(t1 - t0))\ny_pred = log_clf2.predict(X_test_reduced)\nprint(\naccuracy_score(y_test, y_pred))\n30",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#3": "Osservazione\nPresi 2 punti a caso in un quadrato di dimensioni 1x1, la distanza media è \n0.52. In un cubo 3d è 0.66. In un ipercubo di 1M dimensioni è 408,25. \nIn dataset con alta dimensionalità il rischio di data sparity è elevato. \nUna nuova istanza è molto probabile che sia lontana dalle altre già \nincontrate in precedenza; probabile overﬁtting durante il test. \nSe incrementiamo le istanze nel training set riduciamo il problema, ma il \ntempo di addestramento si allungano, e a volte non è possibile \ncollezionare nuove istanze. \nIl numero di istanze da includere cresce esponenzialmente col numero \ndi dimensioni del dataset.\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#30": "Esercitazione\n>>>\nTraining took 57.60s\nTraining took 124.90s\n0.9255\nTraining took 55.04s\nTraining took 15.68s\n0.9201\n31",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#31": "Andreas C. Müller, Sarah Guido. \n Introduction to Machine Learning with \nPython: A Guide for Data Scientists\n . O'Reilly Media 2016  \nAurélien Géron. \n Hands-On Machine Learning with Scikit-Learn and \nTensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n . \nO'Reilly Media 2017\nTesti di Riferimento\n32",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#4": "Projection\nSpesso le features sono correlate tra loro, oppure assumono spesso valori in \npiccoli intervalli. \nNell'esempio seguente si può notare come molti punti sono vicini ad un \npiano (2d). Se proiettiamo questi punti sul piano (sottospazio) otteniamo un \ndataset di dimensioni ridotte, con 2 nuove features, cioè le coordinate nel \npiano.\n5\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#5": "Projection\nIn altri casi la proiezione è difﬁcile o impossibile. \nNel dataset toy Swiss roll, semplici piani non permettono di mantenere la \ncoerenza spaziale originale delle istanze. Solo \"dispiegando il rotolo\" di \npunti è possibile avere un piano coerente.\n6\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#6": "Manifold learning\nNell'esempio precedente, il \n roll\n è una struttura che assomiglia a un piano \n2d (d=2) che è disposta (rotolata) in uno spazio 3d (n=3 con n>d). \nManifold assumption\n : l'ipotesi che molti dataset reali possono essere \nrappresentati in spazi con dimensioni ridotte. Inoltre suppone che nello \nspazio ridotto sia più facile risolvere problemi di classiﬁcazione, \nregressione, etc.  \nQuest'ultima assunzione non è sempre vera, es:\n7\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#7": "Richiami: PCA\nPer proiettare i dati in uno iperspazio con meno dimensioni, occorre prima \ndeﬁnirlo. Nell'esempio, il piano con linea continua mantiene la varianza \nmassima, mentre i 2 piani tratteggiati hanno varianze più basse. \nQuale piano sceglieresti?\n8\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#8": "Richiami: PCA\nPer proiettare i dati in uno iperspazio con meno dimensioni, occorre prima \ndeﬁnirlo. Nell'esempio, il piano con linea continua mantiene la varianza \nmassima, mentre i 2 piani tratteggiati hanno varianze più basse. \nIl piano con massima varianza potenzialmente riduce la perdita di \ninformazione durante la proiezione. \nPCA mira a identiﬁcare tali assi.\n9\n",
    "data_test\\rootfolder\\università\\MachineLearning\\39-Ex_15 Riduzione dimensionalita-sbloccato.pdf#9": "PCA: Step by step in Python\nAttenzione\n : se perturbiamo leggermente il training set, i \n principal \ncomponent \n (gli assi) possono cambiare, ad esempio invertendo la \ndirezione, anche se il piano deﬁnito da essi rimane generalmente lo stesso. \nPer trovare le compomenti si impiega la Singular Value Decomposition \n(SVD) che permette di ottenere la seguente decomposizione: \nX = U \n Σ\n V\nT \ndove le colonne di V rappresentano le componenti che stiamo cercando. \nIn Python possiamo ottenerle nel seguente modo: \nX_centered \n = \nX \n- \nX\n.\nmean\n(\naxis\n=\n0\n)\nU\n, \ns\n, \nVt \n= \nnp\n.\nlinalg\n.\nsvd\n(\nX_centered\n )\nc1 \n= \nVt\n.\nT\n[:, \n0\n]\nc2 \n= \nVt\n.\nT\n[:, \n1\n]\nAttenzione\n : è sempre consigliabile centrare i dati nell'origine impiegando \nlo \nStandardScaler\n ().\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nRegressione:  \nValutazione delle prestazioni\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#1": "Sommario\nIntroduzione alla Valutazione delle Prestazioni nella \nRegression \nLoss Function e le tre misure di Loss: \n•\n Training Error, Generalization Error, Test Error \nOverﬁtting \nLe tre fonti di errore: Noise, Bias, Variance\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#10": "Training Error vs.  \nComplessità del Modello\n \n11E’ interessante vedere come può variare tale errore in base \nalla complessità del modello.  \ncaso di modello costante:  \ny\nArea xPrezzo\nComplessità del modelloErrore ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#11": "Training Error vs.  \nComplessità del Modello\n \n12caso di modello lineare:  \ny\nArea xPrezzo\nComplessità del modelloErrore ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#12": "Training Error vs.  \nComplessità del Modello\n \n13\ncaso di modello quadratico:  \nComplessità del modelloErrore \ny\nArea xPrezzo\n",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#13": "Training Error vs.  \nComplessità del Modello\n \n14\ncaso di modello polinomiale:  \nComplessità del modelloErrore \ny\nArea xPrezzo\n",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#14": "Training Error vs.  \nComplessità del Modello\n \n15L’andamento dell’errore ha dunque in genere la seguente \nforma: \nComplessità del modelloErrore ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#15": "Training Error vs.  \nComplessità del Modello\n \n16Il training error non è una buona misura della predictive \nperformance: \nEsso è eccessivamente ottimistico, proprio perché il vettore \nŵ è calcolato afﬁnché il modello si adatti ai dati di training. y\nArea xPrezzo\nxt\n",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#16": "Generalization Error\n \n17Sarebbe interessante conoscere il “loss” prendendo in \nconsiderazione tutte le possibili coppie ( x, y), ossia, per il \nnostro esempio degli appartamenti, tutte le possibili case della \nzona presa in considerazione, calcolando la media della \nfunzione loss su tali appartamenti. \nIn genere però nel nostro data set abbiamo soltanto un \nnumero limitato di osservazioni ( x, y). ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#17": "Generalization Error\n \n18Per effettuare una stima di tale costo dovremmo cercare di \npesare le varie coppie ( x, y) in base alla probabilità che hanno \ndi essere presenti nella zona d’interesse.  \nE’ dunque utile prendere in considerazione la distribuzione \ndegli appartamenti in base al valore della loro area:\nArea",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#18": "Generalization Error\n \n19Potremmo inoltre considerare la distribuzione delle case in \nbase al loro prezzo, a parità di area:\nPrezzo",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#19": "Generalization Error\n \n20Formalmente, possiamo deﬁnire il Generalization (o True) \nError come segue:\nGeneralization Error = Ex,y[L(y,f ˆw(x))]\nossia come l’average value della funzione Loss, calcolato su \ntutte le possibili coppie ( x, y) pesate in base alla loro \nprobabilità di comparire nella zona.",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#2": "La valutazione delle prestazioni è di importanza cruciale \nper poter apprezzare il metodo che stiamo utilizzando per \nle nostre previsioni. \nEssa ci aiuta nella scelta tra modelli di diversa complessità \na nostra disposizione. \nA tal ﬁne occorre deﬁnire una metrica che ci consenta di \nvalutare quanto perdiamo (loss) quando facciamo una \ncerta previsione. \n \n3\nIntroduzione alla  \nValutazione delle Prestazioni",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#20": "Generalization Error\n \n21Vediamo ora di intuire come tale errore possa variare in base \nalla complessità del modello. \nPer far questo ci avvarremo della rappresentazione che segue, \ndove la regione in blu rappresenta, con le diverse gradazioni \nnei vari punti, la distribuzione di probabilità di avere una casa \nnel nostro data set (la parte bianca rappresenta le più alte \nprobabilità):\ny\nArea xPrezzo",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#21": "Generalization Error\n \n22Per valutare l’errore consideriamo come la “ﬁtted function” f \n(in verde nella ﬁgura precedente e in quelle successive), che \nsi adatta alle osservazioni del training set, possa predire i \nvalori delle case non presenti nel training set, pesate dalle \nloro probabilità. \nOssia dobbiamo vedere quanto la f sia “vicina” all’area in \nbianco della distribuzione rappresentata in ﬁgura. \nNei lucidi che seguono cercheremo di intuire l’andamento del \nGeneralization Error a fronte di diverse complessità del \nmodello (costante, lineare, quadratico, ecc.).",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#22": "Generalization Error vs.  \nComplessità del Modello\n \n23caso di modello costante: \nPrezzo\nAreaErrore \nComplessità del modello",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#23": "Generalization Error vs.  \nComplessità del Modello\n \n24caso di modello lineare: \nAreaPrezzoErrore \nComplessità del modello",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#24": "Generalization Error vs.  \nComplessità del Modello\n \n25caso di modello quadratico: \nAreaPrezzoErrore \nComplessità del modello",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#25": "Generalization Error vs.  \nComplessità del Modello\n \n26caso di modello polinomiale: \nAreaPrezzoErrore \nComplessità del modello",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#26": "Generalization Error vs.  \nComplessità del Modello\n \n27caso di modello “High level”: \nAreaPrezzoErrore \nComplessità del modello",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#27": "Generalization Error vs.  \nComplessità del Modello\n \n28L’andamento dell’errore è dunque in genere il seguente: \nComplessità del ModelloErrore",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#28": "Generalization Error\n \n29Ricordiamoci però che, a differenza di ciò che accade per \nil training error, NON è possibile calcolare il \nGeneralization Error. \nPer calcolarlo, dovremmo conoscere la “true distribution” \ndelle probabilità vista prima, cosa che non sappiamo fare. ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#29": "Test Error\nDeﬁnito come average loss sui punti dell’insieme di test:\n \n30\nTest Error =1\nNtest·X\ni2testL[yi,fˆw(xi)]\nAreaPrezzo",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#3": "Loss Function\n \n4Possiamo indicare una funzione di Loss come segue:\ndove y è l’actual value, mentre la funzione f ci fornisce il \nvalore previsto ŷ.  \nTale funzione L rappresenta il costo che abbiamo se usiamo \nla f con il vettore dei pesi ŵ a fronte dell’input x.L[y, f ˆw(x)]",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#30": "Andamento degli errori  vs.  \nComplessità del Modello\n \n31Training Error: \nTraining Error\nComplessità del modelloErrore ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#31": "Andamento degli errori vs.  \nComplessità del Modello\n \n32Generalization Error: \nGeneralization Error\nTraining Error\nComplessità del modelloErrore ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#32": "Andamento degli errori vs.  \nComplessità del Modello\n \n33Test Error: approssima il Generalization Error \nGeneralization Error\nTraining ErrorTest Error\nComplessità del modelloErrore ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#33": "Overﬁtting\n \n34Dato un modello con parametri ŵ, si ha overﬁtting se esiste un \nmodello con i parametri stimati w’ tale che: \n 1. training error( ŵ) < training error(w’) \n 2. true error( ŵ) > true error(w’) \nGeneralization (true) Error\nTraining ErrorTest Error\nŵw’\nComplessità del modelloErrore ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#34": "Training/Test Split\nUn importante problema da considerare ai ﬁni \ndell’addestramento e della valutazione di un modello è la \nsuddivisione delle osservazioni disponibili tra training set \ne test set:\n \n35\nTraining Set Test Set",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#35": "Training/Test Split\nSe per il training set abbiamo poche osservazioni \nrischiamo di non stimare in modo adeguato il modello, \ncosa che potrebbe comportare previsioni imprecise da \nparte dello stesso.\n \n36\nTraining Set Test Set\nTroppo pochi ➝ ŵ non stimato adeguatamente  ",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#36": "Training/Test Split\nD’altro canto, se abbiamo poche osservazioni per il test \nset rischiamo di non avere una rappresentazione adeguata \ndei dati che stiamo analizzando (e.g., tutte le case in \nvendita) \n \n37\nTraining Set Test Set\nTroppo pochi ➝ true error non stimato  \n                       adeguatamente dal test error",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#37": "Training/Test Split\nPurtroppo non esiste una formula che ci dica come \nsuddividere esattamente i dati in training set e test set. \nUna regola pratica da poter seguire consiste nell’usare un \nnumero sufﬁciente di punti per il test set per consentire \nuna ragionevole approssimazione del true error: \n \n38\nTraining Set Test Set\nSe ciò lascia troppi pochi punti per il training set,  ci \npossiamo avvalere di altri metodi che vedremo \nsuccessivamente (\n cross validation\n ).",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#38": "Le tre sorgenti di errore\nNoise \nBias  \nVariance\n \n39Test SetE’ estremamente utile analizzare le diverse cause che possono \nportare ad un errore nelle previsioni. Esse sono le seguenti:\nCominciamo a vedere in modo intuitivo di cosa si tratta.",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#39": "Noise\nCome sappiamo, in genere i dati sono intrinsecamente \n“rumorosi”. \nNel nostro caso, possiamo ipotizzare che esista una “true \nfunction” che lega \n x\n a y. Essa però non è una descrizione \nperfetta di tale legame. Ci sono infatti altri fattori che \nmagari non abbiamo tenuto in conto (altri attributi, ecc.)\n \n40\nTutto ciò comporta un “rumore” intrinseco, che possiamo \nrappresentare con il termine \n ε\n, che ha media uguale a zero.y\nArea xPrezzo\n",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#4": "Esempi di Loss Function\n \n5La funzione di Loss può essere ad esempio deﬁnita come \nErrore Assoluto (Absolute Error):\noppure come Errore Quadratico (Squared Error):L[y, f ˆw(x)] = |y\u0000fˆw(x)|\nL[y, f ˆw(x)] = [ y\u0000fˆw(x)]2\nTali esempi di funzione assumono che il “loss” per \nunderpredicting sia uguale a quello di overpredicting.",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#40": "Noise\nTale rumore comporta in genere uno scostamento (spread) \nrispetto alla funzione vera. \nPossiamo dunque prendere in considerazione la varianza \ndi tale variabile:\n \n41varianza di ε\nIl rumore in questione è chiamato “\n irreducible error\n ”.y\nArea xPrezzo\n",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#41": "Bias\nIl rumore prima descritto non lo possiamo controllare. \nPossiamo però controllare il bias e la variance. \nPer deﬁnire il bias, consideriamo ad es. un modello \ncostante addestrato con diversi training set:\n \n42y\nArea xPrezzo\ny\nArea xPrezzo\n",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#42": "Bias\nConsideriamo adesso la funzione media (quella tratteggiata) \ndelle varie funzioni f stimate:\n \n43y\nArea xPrezzo\ny\nArea xPrezzo\nf¯w(xt),Etrain [fˆw(xt)]",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#43": "Bias\nIl bias è deﬁnito come la differenza tra la funzione media \ne la true function:\n \n44\nE’ in sostanza una valutazione di quanto il mio modello si \nadatti alla true function.\nlow complexity → high biasy\nArea xPrezzo\nbias( fˆw(xt)) = fw(true) (xt)\u0000f¯w(xt)",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#44": "Variance\nPer introdurre il concetto di varianza nella regression, \ndobbiamo considerare quanto le varie funzioni f stimate \ndifferiscono dalla funzione media. Vediamo ad esempio il \ncaso di modello costante: \n \n45Non abbiamo una variazione elevata  \nper le diverse funzioni stimate.\nlow complexity → low variancey\nArea xPrezzo\ny\nArea xPrezzo\ny\nArea xPrezzo\nvar(fˆw(xt)) =Etrain [(fˆw(xt)\u0000f¯w(xt))2]",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#45": "Variance\nPer un modello polinomiale di grado elevato le cose \nvanno in modo diverso:\n \n46\nPrezzo\nPrezzo\nArea Area",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#46": "Variance\nSe consideriamo le funzioni f stimate per i possibili \ntraining set:\n \n47\nQuesta volta la variazione è elevata.\nhigh complexity → high varianceArea AreaPrezzo\nPrezzo\nvar(fˆw(xt)) =Etrain [(fˆw(xt)\u0000f¯w(xt))2]",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#47": "Bias per  \nhigh-complexity models\nIl bias per modelli “high order” è invece in genere basso:\n \n48high complexity → low biasy\nArea xPrezzo\nf¯w(xt),Etrain [fˆw(xt)]\nbias( fˆw(xt)) = fw(true) (xt)\u0000f¯w(xt)",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#48": " \n49\nBias-Variance Tradeoff\nbias variance\nComplessità del Modello\nsweet spotMSE = bias + variance2",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#49": " \n50\nBias-Variance Tradeoff\ngoal in ML →  trovare il cosiddetto “sweet spot”\npurtroppo non possiamo calcolare bias e variance!\nPer calcolarle dovremmo avere a disposizione la true \nfunction e tutti i possibili training set. \nVedremo in seguito come poter operare in pratica per \nottimizzare il tradeoff.",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#5": "Valutare la funzione Loss \n \n6Ai ﬁni della valutazione del “loss” occorre deﬁnire i \nseguenti tipi di errore: \n• Training Error \n• Generalization Error (True Error) \n• Test Error",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#50": " \n51\nErrori vs. numerosità dei dati \n(con un modello di ﬁssata complessità)\nbias + noise\n#data points nel training settrue errorErrore\ntraining error",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#51": " \n52Andamento del True Error:\nSe abbiamo pochi punti nel training set l’errore è alto, perché la \nfunzione f (ﬁtted function) non stima bene la “true relationship” \ntra \nx\n e y. \nAumentando i punti l’errore diminuisce. \nAl limite, esso tende ad un valore uguale a: bias + noise. Questo \nperché, anche se avessimo tutte le osservazioni possibili, il \nmodello potrebbe non essere sufﬁcientemente ﬂessibile per \ncatturare perfettamente la “true relationship” (questa è la nostra \ndeﬁnizione di bias). \nA ciò si aggiunge il noise che, come sappiamo, non possiamo \ncontrollare. \nErrori vs. numerosità dei dati \n(con un modello di ﬁssata complessità)",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#52": " \n53Andamento del Training Error:\nSe abbiamo pochi punti nel training set l’errore è basso, \nperché la funzione f (ﬁtted function) può approssimare più \nfacilmente la “true relationship” tra \n x\n e y. \nAumentando i punti l’errore aumenta. \nAl limite, anch’esso tende ad un valore uguale a: bias + noise. \nQuesto perché, se avessimo tutte le osservazioni possibili, \nl’errore calcolato sarebbe proprio il true error che, come \nabbiamo visto, tende al valore bias + noise. \nErrori vs. numerosità dei dati \n(con un modello di ﬁssata complessità)",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#53": "Workﬂow per Regression  \n(e per il ML in generale)\nI due task importanti che dobbiamo attuare nella \nregression sono: \n1.\n Scelta del modello di regressione (\n model selection\n ) \n2.\n Valutazione del modello (\n model assessment\n )\n \n54",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#54": "Workﬂow per Regression (e ML)\n1.\n Model selection \nSpesso dobbiamo scegliere dei parametri di tuning \n λ \nche controllano la complessità del modello (e.g., grado \ndel polinomio) \n2.\n Model assessment \nUna volta scelto il modello, dobbiamo effettuare la \nvalutazione del Generalization Error.\n \n55",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#55": "Workﬂow per Regression (e ML)\n1.\n Model selection \nPer ogni modello di complessità \n λ\n: \n• \nstima dei parametri \n ŵ\nλ\n sui training data \n•\n valutazione delle prestazioni sui test data \n•\nscelta del parametro \n λ\n (\nλ\n*) che comporta il più basso test error  \n2.\n Model assessment \nConsiderare il test error calcolato su \n ŵ\nλ\n*\n (ﬁtted model per la \ncomplessità scelta \n λ\n*) per approssimare il Generalization \nError.\n \n56Un approccio ingenuo  al problema potrebbe essere il seguente:",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#56": "Workﬂow per Regression (e ML)\n \n57Attenzione! \nSi è veriﬁcato un Peaking!!!\n•E’ accaduto che l’ipotesi (i.e., la funzione stimata) è stata \nselezionata  in base alle sue prestazioni sull’insieme di test . \n•L’informazione che avrebbe dovuto rimanere conﬁnata in \ntale insieme si è, per così dire, “inﬁltrata” nell’algoritmo di \napprendimento.",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#57": "Una soluzione è quella di considerare non solo due data \nset, ossia il training set e il test set: \n \n58\nTraining \nSetTest \nSet\nma considerarne tre (a patto di avere dati sufﬁcienti): \nTraining \nSetTest \nSet\nValidation\n Set\nWorkﬂow per Regression (e ML)",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#58": "Workﬂow per Regression (e ML)\n1.\n Model selection \nPer ogni modello di complessità \n λ\n: \n•\n stima dei parametri \n ŵ\nλ \nsul training set \n•\n valutazione delle prestazioni sul validation set \n•\nscelta del parametro \n λ\n (\nλ\n*) che comporta il più basso errore sul \nvalidation set \n2.\n Model assessment \nCalcolo del test error (usando dunque il test set) con \n ŵ\nλ\n*\n per \napprossimare il Generalization Error.\n \n59L’approccio in questo caso è il seguente:",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#59": "Tipici split \n \n60Non c’è una regola generale per suddividere le \nosservazioni disponibili tra i tre data set. \nTipici split sono i seguenti:\nTraining \nSetTest \nSet\nValidation\n Set\n80%      10 %   10%\n50%      25%   25%",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#6": "Training Error\n \n7Consideriamo ancora l’esempio relativo ai prezzi degli \nappartamenti. Supponiamo di avere a disposizione le \nosservazioni come rappresentate in ﬁgura:\ny\nAreaxPrezzo\n",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#60": "Riferimenti\n \n61\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , Apogeo, 2008. \nMachine Learning: Regression\n , University of Washington - Coursera, 2015. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. \nMurphy, K.P. \n Machine Learning - A Probabilistic Approach\n , The MIT Press, 2012.",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#7": "Training Error\n \n8y\nAreaxPrezzo\nCome sappiamo, dobbiamo decidere il modello da \nutilizzare (lineare, quadratico, ecc.) e scegliere un \nsottoinsieme delle osservazioni per effettuare la fase di \ntraining del modello:",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#8": "Training Error\n \n9y\nAreaxPrezzo\nPossiamo ad esempio scegliere un modello quadratico e \ncalcolare i pesi w tali da minimizzare la funzione RSS:",
    "data_test\\rootfolder\\università\\MachineLearning\\4-Regression-Valutazione-sbloccato.pdf#9": "Calcolo del Training Error\n \n10Una volta stimati i parametri del modello, possiamo \nvalutare il training error di tale modello stimato come \nsegue: \n1. Deﬁnizione di una Loss Function (absolute error, squared \nerror, ecc.) \n2. Calcolo del Training Error come “average loss”, deﬁnito \nsugli N punti di training: \nTraining Error =1\nN·NX\ni=1L[yi,fˆw(xi)]",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#0": "Machine Learning\nUniversità Roma Tre  \nDipartimento di Ingegneria \nAnno Accademico 2021 -2022\nReinforcement Learning",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#1": "Acknowledgements, sources and links\nOrganization, content and images of the slides are extracted from  the \nfollowing sources:\n•Reinforcement Learning: An Introduction . Richard S. Sutton  \nand Andrew G. Barto, second edition, 2018.\n•Implementation of Reinforcement Learning algorithms, from \nSutton -Barto’s book . Denny Britz, GitHub project, 2016.\n•Tutorial: Introduction to Reinforcement Learning with \nFunction Approximation . Richard S. Sutton, 2016.\n•UCL Course, Reinforcement Learning, videos and slides .  \nDavid Silver, 2015.\n•UCL course, Advanced Deep Learning & Reinforcement \nLearning, videos and slides . DeepMind, 2018.",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#10": "First actor: the agent\nA never -ending loop\n•...we(the agent) receive Rtand observe Ot...\n•...wechoose the action At∼π(·,f(Ot,Rt,At−1,Ot−1,Rt−1,...))...\n•...and because ofour action At, the environment send usareward\n•Rt+1 and a new state , that we observe as Ot+1. ..",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#11": "First actor: the agent\nA never -ending loop\n•...we(the agent) receive Rtand observe Ot...\n•...wechoose the action At∼π(·,f(history ))...\n•...and because ofour action At, the environment send usareward\n•Rt+1 and a new state , that we observe as Ot+1. ..",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#12": "Not alone! Second actor: the environment\nAgent, step t\n•Receives observation Ot\n•Receives scalar reward Rt \n•Computes his own state !!\"\n•Executes action At.\nEnvironment, step t\n•Receives action At \n•Computes his own state !!#$%\n•Emits observation Ot+1\n•Emits scalar reward Rt+1",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#13": "1What is Reinforcement Learning?\nThe RL setup: problem and actors\n 2\n3 What do we know? State and observability\n4What can we do? Policy and value -andmodel?\n5The never -ending control loop: prediction =improvement",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#14": "History , agent state , environment state\nNotation\n•History : the sequence of observations, actions, rewards up \nto  time step t:\nHt:=O1,R1,A1,...,At−1,Ot,Rt\n•The agent selects actions, and the environment answers with\nobservations andrewards\n•State : the information used (by the agent and the  \nenvironment) to determine what happens next\n•State is naturally a sequence St\n•Agent state is a function of history: St := f (Ht)\n•Environment state \"!\"is different from agent state \"!#",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#15": "Markov state\nUncertainty\nSince we have no control of environment, everything is a random  \nvariable\nDefinition\nA sequence of states (random variables) is Markov if and only if\nPr(St+1|St)=Pr(St+1|S1,...,St)\n•The future is independent of the past given the present:\nSt  →Ht+1:+ ∞\n•Once the state is known, the history may be thrown away: the  \nstate is a sufficient statistic of the future\nExercise\nIs the environment state \"!\"Markov? Is the history HtMarkov?",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#16": "Fully observable environments\n•Agent observes environment\nstate: Ot = !!\"=!!%\n•Agent state andenvironment  \nstate coincides!\nAnever -ending loop\n•...we(the agent) receive Rt\nand observe St...\n•...and thus wedecide todo  \naction At∼π(·,St)...\n•...andenvironment answers  \nAt with a new reward, state  \npair Rt+1,St+1...",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#17": "Example: themaze\nExercise\nDiscuss this example in terms of the language you have  \nlearned up tonow.",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#18": "1What is Reinforcement Learning?\nThe RL setup: problem and actors\n 2\n3 What do we know? State and observability\n4 What can we do? Policy and value -and model?\n5 The never -ending control loop: prediction =improvement",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#19": "Strategy Policy\nArrows represent the policy π: which action to take from  \nevery state.Example: a policy for themaze\n",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#2": "1What is Reinforcement Learning?\nThe RL setup: problem and actors\n 2\n3What do we know? State and observability\n4What can we do? Policy and value -andmodel?\n5The never -ending control loop: prediction =improvement",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#20": "Example: values for the policy of the maze\n•Let πbe the optimal policy\n•Value vπ (s) for every state s\nExercise\nChoose a state s and compute vπ (s) by yourself. If sj denote s\nthe successor state of s, can the value vπ (sj) help with this  \ncomputation?",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#21": "1What is Reinforcement Learning?\nThe RL setup: problem and actors\n 2\n3What do we know? State and observability\n4What can we do? Policy and value -and model?\n5 The never -ending control loop: prediction =improvement",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#22": "Prediction , improvement and control\nThe prediction problem inRL\nForecast the future: can you say from each state how much will be  \nyour return? It depends on the policy!\nThe improvement problem inRL\nChange the future: can you find a different policy that will give  \nyou a better return?\nThe control problem inRL\nChange the future: can you find the best policy atall?\nExercise\nState formally the prediction, the improvement and the control  \nproblem.",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#23": "Gridworld example: prediction\nExercise\nCompute the value function for the uniform random policy.",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#24": "Gridworld example: improvement\nExercise\nFind an improvement of the uniform policy.",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#25": "Gridworld example: optimal control\nExercise\nCompute the optimal value function over all possible policies.  \nGiven the optimal value v∗as above, find the optimal policy.  Is \nthe optimal policy unique?",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#26": "Wrapping up\nLearning goals\n•Understand the RL problem, and how RL differs from  \nsupervised learning\n•Understand reward, return and how they are used to \nmake  decisions\n•Understand actions, states and rewards in term \nof  agent/environment interactions\n•Understand the optimal control problem",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#27": "Wrapping up\nWhat we (hopefully) have learnt\n•Reinforcement Learning (RL) is concerned with goal -directed  \nlearning and decision -making. In RL an agent learns from  \nexperiences it gains by interacting with the environment. In  \nsupervised learning we cannot affect theenvironment\n•In RL rewards are often delayed in time and the agent tries to  \nmaximize the cumulative sum of rewards, called return .Return \nis a long -term goal. For example, one may need to  make \nseemingly suboptimal moves to reach a winning position in a \ngame\n•An agent interacts with the environment via actions. The  \nenvironment answers with states and rewards ... and so on in \na  loop, that can finish after a certain number of steps or go \non  forever\n•Optimal control can be achieved by a prediction -improvement  \nloop",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#28": "Exercises\n•Can every decision task be represented as an optimization  \nproblem with respect to a suitable reward?\n•Is the reward an intrinsic datum of the decision task?\n•Make an example where the greedy policy isoptimal.\n•Make an example of a decision task with non-Markov  \nenvironment state.\n•Make an example of a decision task with non-Markov agent  \nstate.",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#29": "Exercises\nThe generic definition of policy is a time -dependant stochastic  \nfunction of the history: πt (At|Ht ) = Pr(At |Ht ). Give a definition  of the \npolicy in the following cases, and find a corresponding task.\n•Fully observable environment, stochastic and non-stationary  \npolicy.\n•Partially observable environment, stochastic and stationary  \npolicy.\n•Fully observable environment, deterministic and stationary  \npolicy.",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#3": "1What is Reinforcement Learning?\nThe RL setup: problem and actors\n 2\n3What do we know? State and observability\n4What can we do? Policy and value -andmodel?\n5The never -ending control loop: prediction =improvement",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#4": "The RLproblem\nImportant points\n•Trying to reach a goal\n•Interactions: active decision -making agent vs environment\n•Uncertainty about theenvironment\n•Effects of actions cannot be fully predicted: \nadaptation required ( learning )\nThe RL reward hypothesis\nAll goals can be described by the maximization of some expected  \ncumulative reward\n•Is it true? Interesting analysis at  \nhttp://incompleteideas.net/rlai.cs.ualberta.ca/ \nRLAI/rewardhypothesis.html\n•Related with the expected utility hypothesis from von  \nNeumann -Morgenstern utility theory",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#5": "The RLproblem\nRL main task\nDecision problem: we would like to choose actions that maximize  \nthe return , i.e. the total future reward\nSequential decision making\nActions may have long term consequences\nUncertainty\nThe best we can aim for is maximizing the value , i.e.the\nexpected total future reward\nExercise\nFind an example of a deterministic task, that is, a task where  your \nactions gives a fixed outcome (that you may or may not know  in \nadvance)",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#6": "The RLproblem\nTo be greedy can bewrong\n•A financial investment (may take months to mature)\n•Refuelling a helicopter (might prevent a crash in \nseveral  hours)\n•Blocking opponent moves (might help winning chances \nmany moves from now)\nExercise\nDiscuss the difference between return and value",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#7": "The RLproblem\nExamples of reward\n•Games: RT := −1, 0, +1 (win, draw, lose). More generally,\n•RT can be the final score\n•Games: RT := 0, +1 (win, lose). In this case, the value is the  \nprobability of winning. Why?\n•Atari games: Rt is the immediate score increment at step t\n•Walking robot: Rt := +1 for every step he doesn’t fall\nhttps://www.youtube.com/watch?v=gn4nRCC9TwQ .\n•Financial investment: Rt is the money increment in the last  \ntime step in portfolio\n•Maze and Gridworld: +100 for reaching the exit, 0 otherwise.  \nWrong. Why?",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#8": "The RLproblem\nExamples of reward\n•Games: RT := −1, 0, +1 (win, draw, lose). More generally,\n•RT can be the final score\n•Games: RT := 0, +1 (win, lose). In this case, the value is the  \nprobability of winning. Why?\n•Atari games: Rt is the immediate score increment at step t\n•Walking robot: Rt := +1 for every step he doesn’t fall\nhttps://www.youtube.com/watch?v=gn4nRCC9TwQ .\n•Financial investment: Rt is the money increment in the last  \ntime step in portfolio\n•Maze and Gridworld: +100 for reaching the exit, 0 otherwise.  \nWrong. Why?\n•Maze and Gridworld: −1 for every move. Correct. Why?",
    "data_test\\rootfolder\\università\\MachineLearning\\40-RL(1)-sbloccato.pdf#9": "Examples\nGames\nTD-Gammon, 1995, ACM Communications .  \nAtari’s family (video ).\n•49 out of 57: DQN, 25 Feb 2015, Nature .\n•52 out of 57: R2D2, Sep 2018, ICLR 2019 .\n•51 out of 57: MuZero, Nov 2019, arXiv .\n•57 out of 57: Agent57, Mar 2020, arXiv .\nAlphaGo’s family (video ).\n•AlphaGo, 27 Jan 2016, Nature .\n•AlphaGo Zero, Oct 2017, Nature . \n•AlphaZero, Dec 2018, Science .\n•MuZero, Nov 2019, arXiv .\nStarCraft II (video ).AlphaStar, Nov 2019, Nature .\nProtein folding\nHow a protein’s amino acid sequence dictates its three -dimensional  \nstructure? AlphaFold :Oct 2019, PROTEINS ;Jan 2020, Nature .",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#0": "1Distribution model\n2Decisions andreturn\n3Value functions\n4 Bellman equationsMDP: Markov Decision Processes\n",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#1": "Basic block: state , action , model ,reward\nuintermediate\nor initial state\n vintermediate\nor final state\nw\nr =+3\np(v,+3|u,a)=0.7\nr =−1\np(w,−1|u,a)=0.3intermediate\nor final stateaction a",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#10": "1Distribution model\n2Decisions andreturn\n3Value functions\n4 Bellman equations",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#11": "The D in MDP: decisions\nWhere are thedecisions?\n•In any state s, the agent must choose between available  \nactions a\n•When choosing a from s, the environment answers s’ \nwith probability #!!!\". Environment decision.\n•The agent behaviour is given by probabilities π(a|s): ”how  \nlikely I’m going to choose a from s?”.  Agent decision.\nDefinition\nA policy π is a probability distribution over actions given states:\nπ(a|s) := Pr(At = a|St =s)",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#12": "Example: uniform stochastic policy\nA\n1\nB\n1\n0.5\n0.5\n0.8,+10\n 0.2,+3\n0.1,+2\n 0.9,−30.5\n0.5\n0.1,+39\n0.9,+42\n0.1,−2\n0.9,+3\n2 2\nWhat can wedo?\nAt every step, we choose the action according to the probability.",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#13": "Example: deterministic policy\nA\n1\n2B\n1\n2\n0.8,+10\n 0.2,+3\n0.1,+2\n 0.9,−3\n0.1,+39\n0.9,+42\n0.9,+3\n0.1,−2\nWhat can wedo?\nAt every step, we choose the given action.",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#14": "Tabular representation\nS and Aarefinite\nA policy can be represented by a table: every line in the table  \ncorresponds to a state.\nStochastic policy\nA[0.5,0.5]\nB[0.5,0.5]\nDeterministic policy\nA2\nB1",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#15": "The return : towards the goal\nDefinition\n•Total return ofanepisode ending attime T:thevalue ofthe  \nrandom variable Gt:=Rt+1+Rt+2+···+RTfortheepisode\n•If the MDP is continuing, we need a discount factor :\nWhy?\n•Transforming theterminal state inabsorbing with reward 0,we  \ncan use a unified notation for episodic and continuing MDP:\n•In episodic tasks we can use γ = 1, in continuing tasks we  \nmust use γ <1!!≔#!\"#+%#!\"$+%$#!\"%+…=(\n&'(\")\n%&#!\"&\"#\n!!≔#!\"#+%#!\"$+%$#!\"%+…=(\n&'(\")\n%&#!\"&\"#",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#16": "The return : towards the goal\nWhy the discount\n•The discount factor measures how much do we care about \nrewards far in thefuture\n•A reward r after k + 1 time -steps is worth “only” γkr : wesay\nmyopic evaluation if γ ∼0, far-sighted evaluation if γ ∼1\n•Convenience: avoids infinite returns in cyclic MDP\n•We shouldn’t trust our model too much: uncertainty about  \nthe future may not be fully represented\n•If the reward is financial, immediate rewards may earn more  \ninterest than delayed rewards\n•Animal and human behaviour shows preference for immediate  \nreward",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#17": "1Distribution model\n2Decisions andreturn\n3Value functions\n4 Bellman equations",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#18": "How much are states and actions worth?\nRemark\nThe total return Gt at time t is a random variable:\nThus, it makes sense to compute its expected value.\nDefinition :state -value function\nThe state -value function vπ(s)foraMDP isthe return wecan\nexpect toaccumulate starting from state s,following thepolicy π:\nvπ(s):=\"π[Gt|St=s]\nExercise\nIs the above definition/notation correct?!!≔#!\"#+%#!\"$+%$#!\"%+%%#!\"*+…=(\n&'(\")\n%&#!\"&\"#",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#19": "How much are states and actions worth?\nTotal return\nState -value function\nvπ(s)=\"π[Gt|St=s]\nDefinition: action -value function\nThe action -value function qπ (s,a) for a MDP is the return we can \nexpect to accumulate starting from a state s, choosing action a, \nand then following the policy π:\nqπ(s,a):=Eπ[Gt|St=s,At=a]!!≔#!\"#+%#!\"$+%$#!\"%+%%#!\"*+…=(\n&'(\")\n%&#!\"&\"#",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#2": "Basic block: state , action , model ,reward\nu\nv\nwa\nr = +3, p =0.7\nr=−1,p=0.3",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#20": "Example\nExercise\nCompute qπ(A,1),qπ(A,2),qπ(B,1) and qπ(B,2) forthe uniform policy π.",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#3": "Markov Decision Process: MDP\nMarkov decision process data\n•Asetofstates S,asetofactions Aandasetofrewards R\n•For each state s ∈S and action a∈A, a probability  \ndistribution p(·,·|s,a)over S×R\n•A discount factor γ ∈[0,1]\nDistribution model\nThe probability distribution p is called distribution model , or  \nsimply model, of the MDP\nFocus on finite MDP\nFrom now on, assume that S, Aand Rarefinite",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#4": "MDP: meaning of the model\nMarkov decision process data\n•Asetofstates S,asetofactions Aandasetofrewards R\n•For each state s ∈S and action a∈A, a probability  \ndistribution p(·,·|s,a)over S×R\n•A discount factor γ ∈[0,1]\nFrom distribution model to random variables St andRt\nThe probability distribution p of the MDP gives the next state and  \nreward:\nPr(St=s',Rt=r|St−1=s,At−1=a):=p(s',r|s,a)",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#5": "MDP: meaning of the model\nExercises\n•Explain what St,At and Rtare\n•Given p, give a formula for Pr(St = s'|St−1 = s, At−1 = a)\n•Given p, give a formula for \"[Rt|St−1 = s, At−1 =a]\n•Given p, give a formula for \"[Rt|St−1 = s, At−1 = a,St = s']",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#6": "The M in MDP: Markov property\nTabular representation: transitions\nAn action a ∈Agives a transition probability from a state s toa\nstate s' :\nThus, we have a transition matrix Pa for each action a, and a  \ncorresponding underlying Markov stochastic process.\nTabular representation: rewards\nAn action a ∈A gives an average reward for any state s:\nThus, we have an average reward vector Ra for any action a.!!!!\"≔#$#|$,'==!)*$=$#|*$%&=$,+$%&='\n,!\"=-,$|*$%&=$,+$%&='",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#7": "Example\nu\n1\n2v\n1\n2\n0.8,+10\n 0.2,+3\n0.1,+2\n 0.9,−3\n0.1,+39\n0.9,+42\n0.9,+3\n0.1,−2",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#8": "Example\nu1\n2v1\n0.8,+10 0.2,+3\n0.1,+2 0.9,−30.1,+39\n0.9,+42\n0.9,+30.1,−2\n2\n= distribution model",
    "data_test\\rootfolder\\università\\MachineLearning\\41-RL(2)-sbloccato.pdf#9": "Episodic MDP\n•If there is a special terminal  \nstate reachable from every  \nstate, the MDP is episodic\n•Otherwise, the MDP is\ncontinuing\n•Episode : any sample\nS0,A0,R1,S1,...terminating  \nin the final state\nExercise\n•Write an episode, and compute its probability \nof  happening. Hint: tricky question.",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Reinforcement Learning (Ex 16)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#1": "Sommario\nRichiami RL e Q-learning \nEsempio taxi  \nAmbiente OpenAI Gym \nApproccio non RL \nApproccio Q-Learning \nApproccio Epsilon-Greedy Q-Learning \nValutazione e iperparametri",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#10": "OpenAI Gym\nSono delle API in Python che permettono di sperimentare approcci RL. \nhttps://www.gymlibrary.ml  \nLa libreria include già l'ambiente Taxi già costruito. \n!\npip install cmake \n 'gym[atari]'\n  scipy\nimport\n gym\n# carichiamo l'environment taxi\nenv = gym.make(\n \"Taxi-v3\"\n ).env\nenv.render()\n>>\n+---------+\n|R: | : :\n G\n|\n| : | : : |\n| : : : : |\n| | : | \n: |\n|\nY\n| : |B: |\n+---------+\n11",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#11": "OpenAI Gym\n...\nenv.reset() \n # reset environment to a new, random state\nenv.render()\nprint\n(\n\"Action Space {}\"\n .\nformat\n(env.action_space))\nprint\n(\n\"State Space {}\"\n .\nformat\n(env.observation_space))\n>>\n+---------+\n|R: | : :\n G\n|\n| : | : : |\n| : : \n: : |\n| | : | : |\n|Y| : |\n B\n: |\n+---------+\n>> Action Space Discrete(6)\n>> State Space Discrete(500)\n...\n12",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#12": "OpenAI Gym\nLe azioni sono codiﬁcate con interi:  \n0 = south, 1 = north, 2 = east, 3 = west, 4 = pickup, 5 = dropoff \nstate, reward, done, info \n =\n env.step(\n 0\n) # azione: verso south\nenv.render()\n+---------+\n|R: | : :\n G\n|\n| : | : : |\n| : : : : |\n| | : \n| : |\n|Y| : |\n B\n: |\n+---------+\nstate, reward, done, info \n =\n env.step(\n 0\n) # azione: verso south\nenv.render()\n+---------+\n|R: | : :\n G\n|\n| : | : : |\n| : : : : |\n| | : | : |\n|Y| : \n|\nB\n: |\n+---------+\n13",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#13": "OpenAI Gym\nSono delle API in Python che permettono di sperimentare approcci RL. \n# parametri (taxi row, taxi column, passenger index, destination index) \nstate = env.encode(\n 3\n, \n1\n, \n2\n, \n0\n)\nprint\n(\n\"State:\"\n , state)\nenv.s = state\nenv.render()\n>> State: 328\n+---------+\n|\nR\n: | : :G|\n| : | : : |\n| : : : : |\n| | \n: | : |\n|\nY\n| : |B: |\n+---------+\n14",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#14": "OpenAI Gym\nPossiamo rappresentare un certo stato dell'environment esplicitamente. \nAllo stato sarà associato un id numerico (328). \nstate \n=\n env.\nencode\n(\n3\n, \n1\n, \n2\n, \n0\n)  \n# (taxi row, taxi column, passenger index, destination index)\nprint\n(\n\"State:\"\n , state)\nenv.\ns \n=\n state\nenv.\nrender\n()\nState: 328\n+---------+\n|\nR\n: | : :G|\n| : : : : |\n| : : : : |\n| | \n: | : |\n|\nY\n| : |B: |\n+---------+\n15",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#15": "OpenAI Gym\nLa reward table rappresenta coppie stati x azioni. \nAd esempio, per lo stato 328 otteniamo il seguente dizionario: \nenv.P[\n328\n]\n>>\n{0: [(1.0, 428, -1, False)],\n 1: [(1.0, 228, -1, False)],\n 2: [(1.0, 348, -1, False)],\n 3: [(1.0, 328, -1, False)],\n 4: [(1.0, 328, -10, False)],\n 5: [(1.0, 328, -10, False)]}\nDove il dizionario ha la struttura:  \n{action: [(probability \n sempre_1\n , next-state, reward, done)]}.\n16",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#16": "Esercizio Taxi: senza RL\nSupponi che l'agente abbia accesso unicamente la \n reward table\n  P per \ndecidere quale azioni compiere. Perciò non apprende dall'esperienza \nacquista nel passato. \nCrea un loop che prosegua ﬁnché il cliente non sia arrivato a destinazione. \nSuggerimento: la funzione \n env.action_space\n .\nsample\n ()\n restituisce una \nazione in modo casuale.\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#17": "Esercizio Taxi: senza RL\nenv.\ns \n= \n328  \n# stato iniziale\nepochs \n= \n0\npenalties, reward \n = \n0\n, \n0\nframes \n=\n [] \n# per animazione\ndone \n= \nFalse\nwhile \nnot\n done:\n    action \n =\n env.\naction_space\n .\nsample\n()\n    state, reward, done, info \n =\n env.\nstep\n(action)\n    \nif\n reward \n == \n-\n10\n:\n        penalties \n += \n1\n    \n    frames.\n append\n({\n        \n 'frame'\n: env.\nrender\n(mode\n=\n'ansi'\n),\n        \n 'state'\n: state,\n        \n 'action'\n : action,\n        \n 'reward'\n : reward\n        }\n    )\n    epochs \n += \n1\n    \nprint\n(\n\"Timesteps taken: {}\"\n .\nformat\n(epochs))\nprint\n(\n\"Penalties incurred: {}\"\n .\nformat\n(penalties))\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#18": "Esercizio Taxi: senza RL\nPer l'animazione: \nfrom\n IPython.\n display \nimport\n clear_output\nfrom\n time \nimport\n sleep\ndef\n print_frames(frames):\n    \nfor\n i, frame \n in \nenumerate\n (frames):\n        clear_output(wait\n =\nTrue\n)\n        \n print\n(frame[\n'frame'\n].\ngetvalue\n ())\n        \n print\n(\nf\"Timestep: \n {i \n+ \n1\n}\n\"\n)\n        \n print\n(\nf\"State: \n {frame[\n'state'\n]}\n\"\n)\n        \n print\n(\nf\"Action: \n {frame[\n'action'\n ]}\n\"\n)\n        \n print\n(\nf\"Reward: \n {frame[\n'reward'\n ]}\n\"\n)\n        sleep(\n .1\n)\n        \nprint_frames(frames)\nL'algoritmo può impiegare molti step (oltre 1000) incorrendo in molte \npenalty (oltre 300).\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#19": "Esercizio: Q-learning in Python\nEsercizio\n : modiﬁca il codice precedente implementando l'algoritmo  \nQ-learning. \n20",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#2": "Richiami: Reinforcement Learning\nNell'ambito del Reinforcement Learning (RL), la \n policy\n  è la strategia per \nscegliere una azione nello stato corrente che determini la massima \nricompensa (\n reward)\n . \nIl \nQ-learning\n  è un algoritmo che mira a determinare col tempo la migliore \nazione (\n best action\n ), dato lo stato corrente (\n current state), \n in base alla stima \ndi \nreward\n  attesa. \nMisura la bontà di una combinazione stato-azione in termini di \n reward\n . \nImpiega una \n Q-table\n  aggiornata dopo ogni episodio, dove la riga \ncorrisponde allo stato e la colonna all'azione. Il Q-value dentro la tabella \nindicano quanto una azione è stata buona (alto reward) in passato. \nÈ un algoritmo model-free, poiché l'agente non conosce il valore di una \nazione prima di effettuarla.  \nNon segue un approccio greedy poiché scegliere sempre l'azione con \nreward immediato massimo potrebbe determinare sequenze di azioni non \nottime.\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#20": "Esercizio: Q-learning in Python\nEsercizio\n : modiﬁca il codice precedente implementando l'algoritmo  \nQ-learning. \n%%time   # stampa il tempo trascorso al termine dell'esecuzione\nimport\n numpy \nas\n np\nimport\n random\nfrom\n IPython.display \n import\n clear_output\n# iperparametri\nalpha = \n 0.1\ngamma = \n 0.6\n# per il report\nall_epochs = []\nall_penalties = []\nq_table = np.zeros([env.observation_space.n, env.action_space.n])\n...\n21",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#21": "Esercizio: Q-learning in Python\n...\nfor\n i \nin \nrange\n(\n1\n, \n100001\n):\n    state = env.reset()\n    epochs, penalties, reward, = \n 0\n, \n0\n, \n0\n    done = \n False\n    \n    \nwhile \nnot\n done:\n        action = np.argmax(q_table[state])\n        next_state, reward, done, info = env.step(action) \n        \n        old_value = q_table[state, action]\n        next_max = np.\n max\n(q_table[next_state])\n        \n # eq Bellman \n        new_value = (\n 1\n - alpha) * old_value + alpha * \n                    (reward + gamma * next_max)\n        q_table[state, action] = new_value\n...\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#22": "Esercizio: Q-learning in Python\n...\n        \n if\n reward == \n -10\n:\n            penalties += \n 1\n        state = next_state\n        epochs += \n 1\n        \n    \nif\n i % \n100\n == \n0\n:\n        clear_output(wait=\n True\n)\n        \n print\n(\nf\n\"Episode: \n {i}\n\"\n)\nprint\n(\n\"Training finished.\\n\"\n )\n>> Episode: 100000\n>> Training finished.\n>> CPU times: user 1min 25s, sys: 15 s, total: 1min 40s\n>> Wall time: 1min 29s\nq_table[\n 328\n] # l'azione migliore è north -2.27\n>> array([-2.31436727, -2.27325184, -2.31164458, -2.3090025 , \n          -2.8816    , -2.8816    ])\n23",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#23": "Esercizio: Q-learning in Python\nEsercizio\n : valuta nuovamente l'algoritmo con le best action ricavate dalla \nQ-table. \n24",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#24": "Esercizio: Q-learning in Python\nValutazione dell'algoritmo con le best action ricavate dalla Q-table: \ntotal_epochs, total_penalties \n = \n0\n, \n0\nepisodes \n = \n100\nfor\n _ \nin \nrange\n(episodes):\n    state \n =\n env.\nreset\n()\n    epochs, penalties, reward \n = \n0\n, \n0\n, \n0\n    \n    done \n = \nFalse\n    \nwhile \nnot\n done:\n        \n action \n=\n np.\nargmax\n(q_table[state])\n        state, reward, done, info \n =\n env.\nstep\n(action)\n        \n if\n reward \n == \n-\n10\n:\n            penalties \n += \n1\n        epochs \n += \n1\n    total_penalties \n +=\n penalties\n    total_epochs \n +=\n epochs\nprint\n(\nf\"Results after \n {episodes}\n  episodes:\"\n )\nprint\n(\nf\"Average timesteps per episode: \n {total_epochs  \n/ \nepisodes}\n \"\n)\nprint\n(\nf\"Average penalties per episode: \n {total_penalties  \n/ \nepisodes}\n \"\n)\n>> Results after 100 episodes:\n>> Average timesteps per episode: 13.01     \n>> Average penalties per episode: 0.0       <-- nessuna penalty con 100 clienti \n25",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#25": "Epsilon-Greedy Q-learning\nCon l'approccio Epsilon-greedy Q-learning introduciamo il bilanciamento \ntra \nexploration\n  e \nexploitation\n .  \nNei modelli model-free è fondamentale esplorare l'ambiente per ottenere \ninformazioni su cui basare le successive decisioni informate. \nNella versione Espilon-greedy, con probabilità epsilon l'agente sceglie una \nazione in modo casuale (esplorazione) e segue l'azioni valutata migliore \nnell'altro caso (1-epsilon).  \nEsercizio\n : modiﬁca il codice introducendo questa versione.\n26\n",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#26": "Epsilon-Greedy Q-learning\nEsercizio\n : modiﬁca il codice introducendo questa versione. \n... \n# iperparametri\nalpha = \n 0.1\ngamma = \n 0.6\nepsilon = \n 0.1\n...\nwhile \nnot\n done:\n        \n if\n random.uniform(\n 0\n, \n1\n) < epsilon:\n            action = env.action_space.sample() \n # Explore action space\n        \n else\n:\n            action = np.argmax(q_table[state]) \n # Exploit learned values\n...\n>> Results after 100 episodes:\n>> Average timesteps per episode: 12.81     <-- invece di 13.01 \n>> Average penalties per episode: 0.0       <-- nessuna penalty con 100 clienti \n27",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#27": "Valutazione approccio RL\nAlcune metriche da considerare nella valutazione sono: \nNumero medio di \n penalità\n  per episodio (ideale --> 0) \nNumero medio di \n timesteps\n  per percorso  \nValore medio di \n reward\n  per mossa\n28\n",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#28": "Iperparametri\nAlpha\n : da decrementare con l'incremento dell'esperienza acquisita \nGamma\n : se ci avviciniamo all'obiettivo dobbiamo ridurre l'importanza \ndella reward a lungo termine \nEpsilon\n : con l'accumularsi dei tentativi, epsilon deve ridursi. \nEsercizio: applica un approccio \n grid search\n  per ricavare una \napprossimazione degli iperparametri nello scenario del taxi che guida da \nsolo.\n29",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#29": "OpenAI Gym \n https://www.gymlibrary.ml\nTesti di Riferimento\n30",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#3": "Richiami: Reinforcement Learning\nStep #1: inizializzo la Q-table con valori pari a 0, ogni azioni e \nequiprobabile. \nStep #2: scegli l'azione in modo random, o sfrutta l'eventuale informazione \nche hai al principio \nStep #3: esegui l'azioni e colleziona il reward \nStep #4: aggiorna la Q-table di conseguenza \n4\n",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#4": "Richiami: Reinforcement Learning\nL'equazione di \n Bellman\n  aggiorna i Q-values determinando il valore \nmassimo di \n reward\n  atteso per ogni stato nella Q-table.  \nIl primo termine \n Q()\n indica il valore dell'azione corrente nello stato \ncorrente. Il secondo combina il reward corrente e il valore discount dello \nstato futuro caratterizzato da reward massima.  \nIl \ndiscount factor lambda\n  [0,1] permette di ridurre il reward col tempo e \nindica quanta importanza assegnamo ai futuri reward: valori vicini allo 0 \nindicano che l'agente si limita a valutare i reward immediati, vicini al 1 \npermettono di valutare l'effetto a lungo termine dei reward. \nIl valore \n alpha\n  (learning rate (0,1]) determina l'importanza che assegniamo \nai valori futuri rispetto a quelli attuali.\n5\n",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#5": "Esempio: taxi che guida da solo\nDeﬁniamo un ambiente (environment) sempliﬁcato dove un taxi deve \nprendere un cliente in una certa locazione e lasciarlo in un'altra. \nVogliamo altresì: \nLasciare il cliente nel luogo giusto \nMinimizzare il tempo per il trasporto \nSeguire le regole della strada \nDobbiamo deﬁnire: rewards, states, actions. \nQuali puoi ipotizzare?\n6",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#6": "Taxi che guida da solo: reward\nPer i reward possiamo ipotizzare: \nAlto reward se il cliente viene lasciato correttamente. \nPenalizzazione se il cliente viene lasciato nella location sbagliata. \nPer ogni istante di tempo trascorso, una piccola penalità.\n7",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#7": "Taxi che guida da solo: state space\nLo state space corrisponde a tutte le possibili situazioni in cui un taxi si può \ntrovare. Ogni stato deve contenere abbastanza informazioni per permettere \nall'agente di decidere una azione. \nSupponiamo il taxi sia l'unico veicolo. \nSuddividiamo l'ambiente in una griglia 5x5  \nPosizione corrente (3,1) \n4 location per il pick up e drop off: R,G,Y,B;  \ncioè [(0,0), (0,4), (4,0), (4,3)] \nIl cliente è in Y e vuole andare in R. \nUno stato aggiuntivo che rappresenta  \nil cliente all'interno del taxi. \nQuanti sono il numero dei possibili stati?\n8\n",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#8": "Taxi che guida da solo: state space\nLo state space corrisponde a tutte le possibili situazioni in cui un taxi si può \ntrovare. Ogni stato deve contenere abbastanza informazioni per permettere \nall'agente di decidere una azione. \nSupponiamo il taxi sia l'unico veicolo. \nSuddividiamo l'ambiente in una griglia 5x5  \nPosizione corrente (3,1) \n4 location per il pick up e drop off: R,G,Y,B;  \ncioè [(0,0), (0,4), (4,0), (4,3)] \nIl cliente è in Y e vuole andare in R. \nUno stato aggiuntivo che rappresenta  \nil cliente all'interno del taxi. \nPossibili stati: 5 x 5 x 5 x 4 = 500\n9\n",
    "data_test\\rootfolder\\università\\MachineLearning\\42-Ex_16 Esercitazione RL 1-sbloccato.pdf#9": "Taxi che guida da solo: action space\nL'agente può in ogni stato fare una delle seguenti azioni: \nmuoversi a nord \nmuoversi a su \nmuoversi a est \nmuoversi a ovest \nprendere il cliente \nlasciare il cliente \nSe l'agente non può fare una certa azione in uno stato (es. presenza di un \nmuro) possiamo assegnare una penalità di -1.\n10",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Reinforcement Learning (Ex 17)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#1": "Sommario\nOpenAI GYM: Ambienti  \nDeep Q-learning \nLibreria Baseline3",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#10": "OpenAI GYM: Environments\n..\nenv = gym.make(\n \"Qbert-v0\"\n )\ndirectory = \n './video'\nenv = Recorder(env, directory)\n...\n11\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#11": "OpenAI GYM: Environments\n12\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#12": "Deep Q-learning\nPer ambienti complessi (es. 10K stati e 1K azioni), la Q-table associata ad \nogni observation può risultare complessa (10M di celle). La stima di un \ncerto valore a partire da quelli esplorati in passato richiede: \nmolta memoria per la Q-table \ntempo necessario per esplorare tutti gli stati e ricavare i valori \nNel Deep Q-learning usiamo una rete neurale per stimare i Q-value, dove \nin output abbiamo il valore stimato per ogni azione.\n13\nQ learning Deep Q learning",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#13": "Deep Q-learning: Temporal Difference\nLa rete neurale ha bisogno di un valore di loss. \nDeﬁniamo la \n Temporal Difference:   \nQ(s,a)\n  è il Q-value per una certa azione a. Dopo aver eseguito l'azione avremo \nun reward R(s,a). \n Q\nt-1\n(s,a)\n è il Q-value precedente . \nIdealmente le due parti devono coincidere, essendo la prima impiegata per \nricavare la seconda, ma la casualità dell'ambiente e il tempo di apprendimento \ncreano discostamenti. \nIl valore del loss è determinato dal discostamento (\n Temporal Difference target)  \ndal target: Q-value - Q* \nImpiegando il learning rate alpha, usiamo la TD per ricavare il nuovo Q-value.\n14\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#14": "Deep Q-learning\nNel Deep Q-learning l'azione da eseguire è determinata dal valore \nmassimo in output dalla rete (non esiste la Q-table tradizionale). Ogni \nnodo di output è una azione possibile. \nOtteniamo un problema di regressione, senza però conoscere il valore del \ntarget\n  (nell'equazione in verde) non essendoci Q-table. \nLa nuova eq per il Q-learning diverrà: \nil brackpropagation tenderà a convergere i Q-value e i reward. \n15\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#15": "Deep Q-learning: Neural Fitted Q Iteration \nLa rete ci restituisce i Q-value target per ogni azione.  \nLa loss sarà così deﬁnita: \nNota: nel Q-learning tradizionale, il Q-value viene aggiornato ad ogni \ntransizione di stato. Nel Deep Q-learning il processo è più complesso...\n16\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#16": "Deep Q-learning: Neural Fitted Q Iteration \nLa rete deve valutare sia il valore \n predetto\n  sia il \n target\n . Per tale motivo se ne \nusano 2 con stessa architettura ma pesi distinti. \nUna rete per i valori \n target\n  con i parametri \"ﬁssi\". Ad ogni C iterazioni (es. \n100) i parametri della \n prediction\n  network (aggiornata spesso, es. ogni 4 \nsteps) saranno copiati nella \n target\n  network. Questo rende il training più \nstabile poiché mantiene la funzione target stabile. Approccio \"\n Neural Fitted \nQ Iteration (NFQ)\n \" \n17\nLa target nework stima il Temporal difference target",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#17": "Experience replay\nData la numerosità degli stati possibili, conviene salvarli per poi \"rigiocarci\" \nin seguito. È una \n off-line policy\n , cioè si sfrutta l'esperienza acquisita nelle \nazioni fatte nel passato per aggiornare i parametri attuali. \nDare in input lunghe sequenze di stati correlati (es. foto di percorsi \nautostradali rettilinei) può creare bias nella rete e non permettere di \nadattarsi in altre situazione. \nA differenza del Q-learning, durante l'esecuzione i dati [state, action, \nreward, next_state] sono salvati in un buffer chiamato \n experience replay\n . \nSupponendo che l'ambiente sia un gioco, durante il training possiamo \ncampionare periodicamente (es. ogni 4 step) in modo casuale 64 frames \n(batch) dei 100K possibili in modo che abbiano scarsa correlazione tra \nloro. Questo permette di non introdurre bias dovuti alla particolare subset \ndi istanze considerate.\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#18": "Deep Q-learning: step principali\nRicava i Q-values dalla rete per ogni azione dando in input lo stato \ncorrente (es. screenshot). \nSeleziona una azione con \n epsilon-greedy policy\n , cioè random con \nprobabilità \n epsilon\n , altrimenti l'azione con Q-value massimo. \nValuta l'azione che genera il nuovo stato \n s'\n, e ricava il reward \ncorrispondente. Lo stato \n s'\n corrisponde allo screen successivo. La \ntransizione \n <s,a,r,s’>\n  è salvata nel replay buffer. \nCampiona casualmente batch di transizioni dal replay buffer e ricava la loss \ncorrispondente. \nEsegui il \n gradient descent\n  con la differenza tra \n target Q\n  e \npredicted Q \nimpiegando la rete e i parametri attuali minimizzando la loss. \nOgni C iterazioni trasferisci i parametri della rete alla rete target. \nRipeti il procedimento M episodi.\n19",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#19": "Deep Q-learning in Python: CartPole\n# codice tratto da \n https://github.com/mswang12/minDQN/blob/main/minDQN.py\nimport\n gym\nimport\n tensorflow \n as\n tf\nimport\n numpy \nas\n np\nfrom\n tensorflow \n import\n keras\nfrom\n collections \n import\n deque\nimport\n time\nimport\n random\nRANDOM_SEED = \n 5\ntf.random.set_seed(RANDOM_SEED)\nenv = gym.make(\n 'CartPole-v1'\n )\nenv.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\nprint\n(\n\"Action Space: {}\"\n .\nformat\n(env.action_space))\nprint\n(\n\"State space: {}\"\n .\nformat\n(env.observation_space))\n# An episode a full game\ntrain_episodes = \n 300\ntest_episodes = \n 100\n...\n20",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#2": "OpenAI GYM: Environments\nLa classe Env implementa il simulatore dell'ambiente in cui l'agente si \nmuove.  \nAlcuni esempi di environment disponibili in Gym: \nimport\n gym\nenv = gym.make(\n 'MountainCar-v0'\n )\nEsempio\n : nel MointainCar, un carrello deve incrementare l'inerzia per \nriuscire a passare la collina.\n3\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#20": "Deep Q-learning in Python: CartPole\n...\ndef \nagent\n(\nstate_shape\n , \naction_shape\n ):\n    # l'output è il Q-value stimato per ogni azione\n    learning_rate = \n 0.001\n    init = tf.keras.initializers.HeUniform()\n    model = keras.Sequential()\n    model.add(keras.layers.Dense(\n 24\n, input_shape=state_shape, activation=\n 'relu'\n, \nkernel_initializer=init))\n    model.add(keras.layers.Dense(\n 12\n, activation=\n 'relu'\n, kernel_initializer=init))\n    model.add(keras.layers.Dense(action_shape, activation=\n 'linear'\n , \nkernel_initializer=init))\n    model.\n compile\n(loss=tf.keras.losses.Huber(), \noptimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=[\n 'accuracy'\n ])\n    \nreturn\n model\ndef \nget_qs\n(\nmodel\n, \nstate\n, \nstep\n):\n    \nreturn\n model.predict(state.reshape([\n 1\n, state.shape[\n 0\n]]))[\n0\n]\n...\n21",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#21": "Deep Q-learning in Python: CartPole\n...\ndef \ntrain\n(\nenv\n, \nreplay_memory\n , \nmodel\n, \ntarget_model\n , \ndone\n):\n    learning_rate = \n 0.7 \n# Learning rate\n    discount_factor = \n 0.618\n    MIN_REPLAY_SIZE = \n 1000\n    \nif \nlen\n(replay_memory) < MIN_REPLAY_SIZE:\n        \n return\n    batch_size = \n 64\n * \n2\n    mini_batch = random.sample(replay_memory, batch_size)\n    current_states = np.array([transition[\n 0\n] \nfor\n transition \n in\n mini_batch])\n    current_qs_list = model.predict(current_states)\n    new_current_states = np.array([transition[\n 3\n] \nfor\n transition \n in\n mini_batch])\n    future_qs_list = target_model.predict(new_current_states)\n    X = []\n    Y = []\n...\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#22": "Deep Q-learning in Python: CartPole\n...\n    \nfor\n index, (observation, action, reward, new_observation, done) \n in \n                                       \n enumerate\n (mini_batch):\n        \n if \nnot\n done:\n            max_future_q = reward + discount_factor * \n        np.\n max\n(future_qs_list[index])\n        \n else\n:\n            max_future_q = reward\n        current_qs = current_qs_list[index]\n        current_qs[action] = (\n 1\n - learning_rate) * current_qs[action] + \n                 learning_rate * max_future_q\n        X.append(observation)\n        Y.append(current_qs)\n    model.fit(np.array(X), np.array(Y), batch_size=batch_size, verbose=\n 0\n, \n        shuffle=\n True\n)\n ...\n23",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#23": "Deep Q-learning in Python: CartPole\n...\ndef \nmain\n():\n    epsilon = \n 1 \n# inizializzato ad 1, cioè ogni azione è random\n    max_epsilon = \n 1\n    min_epsilon = \n 0.01 \n# al valore minimo, 1% sarà ancora esplorazione\n    decay = \n 0.01\n    \n# 1. Initializzazione Target e Main models\n    \n# Main Model (updated every 4 steps)\n    model = agent(env.observation_space.shape, env.action_space.n)\n    \n# Target Model (updated every 100 steps)\n    target_model = agent(env.observation_space.shape, env.action_space.n)\n    target_model.set_weights(model.get_weights())\n    replay_memory = deque(maxlen=\n 50\n_\n000\n)\n    target_update_counter = \n 0\n    \n# X = states, y = actions\n    X = []\n    y = []\n...\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#24": "Deep Q-learning in Python: CartPole\n...\n    steps_to_update_target_model = \n 0\n    \nfor\n episode \n in \nrange\n(train_episodes):\n        total_training_rewards = \n 0\n        observation = env.reset()\n        done = \n False\n        \n while \nnot\n done:\n            steps_to_update_target_model += \n 1\n            \n if True:            # Su Colab può dare problemi\n            \n    env.render()\n            random_number = np.random.rand()\n            \n # 2. Esplora con Epsilon Greedy Exploration Strategy\n            \n if\n random_number <= epsilon:\n                \n # Explore\n                action = env.action_space.sample()\n            \n else\n:\n                \n # Exploit best known action\n                \n # model dims are (batch, env.observation_space.n)\n                encoded = observation\n                encoded_reshaped = encoded.reshape([\n 1\n, encoded.shape[\n 0\n]])\n                predicted = model.predict(encoded_reshaped).flatten()\n                action = np.argmax(predicted)\n            new_observation, reward, done, info = env.step(action)\n            replay_memory.append([observation, action, reward, new_observation, done])\n...\n25",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#25": "Deep Q-learning in Python: CartPole\n...\n           \n # 3. Aggiorna la rete con la Bellman Equation\n            \n if\n steps_to_update_target_model % \n 4\n == \n0 \nor\n done:\n                train(env, replay_memory, model, target_model, done)\n            observation = new_observation\n            total_training_rewards += reward\n            \n if\n done:\n                \n print\n(\n'Total training rewards: {} after n steps = {} with final \n                      reward = {}'\n .\nformat\n(total_training_rewards, episode, reward))\n                total_training_rewards += \n 1\n                \n if\n steps_to_update_target_model >= \n 100\n:\n                    \n print\n(\n'Copying main network weights to the target network \n                           weights'\n )\n                    target_model.set_weights(model.get_weights())\n                    steps_to_update_target_model = \n 0\n                \n break\n        epsilon = min_epsilon+(max_epsilon - min_epsilon)*np.exp(-decay * episode)\n    env.close()\nif\n __name__ == \n '__main__'\n :\n    main()\n26",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#26": "Action Space: Discrete(2)\nState space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\nTotal training rewards: 19.0 after n steps = 0 with final reward = 1.0\n...\nCopying main network weights to the target network weights\nTotal training rewards: 184.0 after n steps = 291 with final reward = 1.0\nCopying main network weights to the target network weights\nTotal training rewards: 152.0 after n steps = 292 with final reward = 1.0\nCopying main network weights to the target network weights\nTotal training rewards: 47.0 after n steps = 293 with final reward = 1.0\nTotal training rewards: 20.0 after n steps = 294 with final reward = 1.0\nTotal training rewards: 121.0 after n steps = 295 with final reward = 1.0\nCopying main network weights to the target network weights\nTotal training rewards: 10.0 after n steps = 296 with final reward = 1.0\nTotal training rewards: 124.0 after n steps = 297 with final reward = 1.0\nCopying main network weights to the target network weights\nTotal training rewards: 272.0 after n steps = 298 with final reward = 1.0\nCopying main network weights to the target network weights\nTotal training rewards: 41.0 after n steps = 299 with final reward = 1.0\nDeep Q-learning in Python: CartPole\n27",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#27": "Deep Q-learning: Stable Baseline3\nStable Baselines3 (SB3) implementa algoritmi di RL in PyTorch.  \nPossono essere impiegati in OpenAI GYM. \nGithub repository: \n https://github.com/DLR-RM/stable-baselines3  \nLa classe DQN implementa l'approccio descritto in precedenza \nhttps://stable-baselines3.readthedocs.io/en/master/modules/dqn.html   \nhttps://stable-baselines3.readthedocs.io/en/master/guide/examples.html  \n28",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#28": "Deep Q-learning: Stable Baseline3\nAlgoritmi implementati:\n29\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#29": "Deep Q-learning: CartPole in GYM\n# Anaconda: conda install -c conda-forge stable-baselines3 \n!\npip install stable-baselines3[extra]\nimport\n gym\nfrom\n stable_baselines3 \n import\n DQN\nenv = gym.make(\n \"CartPole-v0\"\n )\nmodel = DQN(\n \"MlpPolicy\"\n , env, verbose=\n 1\n)\nmodel.learn(total_timesteps=\n 10000\n, log_interval=\n 4\n)\nmodel.save(\n \"dqn_cartpole\"\n )\ndel\n model \n# remove to demonstrate saving and loading\nmodel = DQN.load(\n \"dqn_cartpole\"\n )\nobs = env.reset()\nwhile \nTrue\n:\n    action, _states = model.predict(obs, deterministic=\n True\n)\n    obs, reward, done, info = env.step(action)\n    env.render()                 \n # Su colab può dare problemi\n    \nif\n done:\n      obs = env.reset()\n30",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#3": "OpenAI GYM: Environments\nLa variabile \n observation_space\n  deﬁnisce la struttura e gli stati permessi \ndell'ambiente.  \nPer esempio, posizione  rispetto all'orgine e velocità del carrello \nCartPole, rappresentati come vettore numerico. \nMa in casi più complessi è possibile fare un rendering dello stato (es. \nuno screenshot di un arcade) è impiegare una matrice di pixel come \nstato. \nLa variabile \n action_space\n  consiste nelle azioni permesse nell'ambiente. \nGym fornisce diverse strutture per rappresentare osservazioni e stati (es. \ndiscrete action space, continuous action space, ecc). \n4",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#30": "Deep Q-learning: CartPole in GYM\nL'output dipende dall'approccio RL scelto, es. per agenti PPO - Proximal \nPolicy Optimization algorithm che combina il A2C multiple workers, e \nTRPO:\n31\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#31": "Deep Q-learning: CartPole in GYM\n32\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#32": "Deep Q-learning: CartPole in GYM\n33\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#33": "Deep Q-learning: CartPole in GYM\n34\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#34": "Esercitazione\nDeﬁnisci una misura di prestazioni per confrontare diverse approcci RL \nImpiega la classe Deep Q Network (DQN) \nSperimenta diversi iperparametri e valuta le differenze: \nlearning_rate \nexploration_initial_eps  e  exploration_ﬁnal_eps \nbuffer_size \nbatch_size \ngamma \ntrain_freq \nUsa altri ambienti, es: Atlantis-v0, MountainCar-v0, o ambienti Atari.\n35",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#35": "OpenAI Gym \n https://www.gymlibrary.ml\nTesti di Riferimento\n36",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#4": "OpenAI GYM\nCome ispezionare l'ambiente. \nimport\n gym\ndef \nquery_environment\n (\nname\n):\n    env = gym.make(name)\n    spec = gym.spec(name)\n    \nprint\n(\nf\n\"Action Space: \n {env.action_space}\n \"\n)\n    \nprint\n(\nf\n\"Observation Space: \n {env.observation_space}\n \"\n)\n    \nprint\n(\nf\n\"Max Episode Steps: \n {spec.max_episode_steps}\n \"\n)\n    \nprint\n(\nf\n\"Nondeterministic: \n {spec.nondeterministic}\n \"\n)\n    \nprint\n(\nf\n\"Reward Range: \n {env.reward_range}\n \"\n)\n    \nprint\n(\nf\n\"Reward Threshold: \n {spec.reward_threshold}\n \"\n)\nquery_environment(\n \"MountainCar-v0\"\n )\n3 azioni: Accelerate forward, decelerate, backward\n>> Action Space: Discrete(3)\n2 ﬂoat: velocità e posizione; (2,) indica la struttura del dato\n>> Observation Space: \n                 Box(-1.2000000476837158, 0.6000000238418579, (2,), float32)\n200 step disponibili\n>> Max Episode Steps: 200\n>> Nondeterministic: False\nPer il reward occorre ispezionare il codice (i.e., nessun reward tranne quando il carrello riesce ad uscire)\n>> Reward Range: (-inf, inf)\n>> Reward Threshold: -110.0\n5",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#5": "OpenAI GYM\nquery_environment(\n \"CartPole-v1\"\n )\n2 valori: spingi a sinistra, spingi a destra\n>> Action Space: Discrete(2)\n4 valori: Cart Position, Cart Velocity, Pole Angle, Pole Velocity At Tip\n>> Observation Space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), \nfloat32)\n>> Max Episode Steps: 500\n>> Nondeterministic: False\nreward +1 per ogni step, e termino quando il palo cade, o se mi sposto di >2.4 unità dal centro\n>> Reward Range: (-inf, inf)\n>> Reward Threshold: 475.0\nquery_environment(\n \"MountainCarContinuous-v0\"\n )\n1 valore: quanta forza imprimere (a sinistra o destra)\n>> Action Space: Box(-1.0, 1.0, (1,), float32)\n>> Observation Space: Box(-1.2000000476837158, 0.6000000238418579, (2,), \nfloat32)\n>> Max Episode Steps: 999\n>> Nondeterministic: False\n>> Reward Range: (-inf, inf)\n>> Reward Threshold: 90.0\n6",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#6": "OpenAI GYM\nNell'ambiente Atari breakout, l'observation space può corrispondere alle \ndimensioni dell screen (210x160) o alla RAM dell'elaboratore (128 bytes). \nquery_environment(\n \"Breakout-v0\"\n )\nAction Space: Discrete(4)\nObservation Space: Box(0, 255, (210, 160, 3), uint8)\nMax Episode Steps: 10000\nNondeterministic: False\nReward Range: (-inf, inf)\nReward Threshold: None\nquery_environment(\n \"Breakout-ram-v0\"\n )\nAction Space: Discrete(4)\nObservation Space: Box(0, 255, (128,), uint8)\nMax Episode Steps: 10000\nNondeterministic: False\nReward Range: (-inf, inf)\nReward Threshold: None\n7\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#7": "OpenAI GYM: Environments\nCome applicare un'azione sull'ambiente. \n# reset \nobs = env.reset()\nprint\n(\n\"The initial observation is {}\"\n .\nformat\n(obs))\nrandom_action = env.action_space.sample()\n# Applichiamo l'azione all'ambiente\nnew_obs, reward, done, info = env.step(random_action)\nprint\n(\n\"The new observation is {}\"\n .\nformat\n(new_obs))\n>> OUTPUT:\n>> \nThe initial observation \n is\n [\n-0.48235664   \n0\n.]\n>> \nThe new observation \n is\n [\n-0.48366517  \n-0.00130853\n ]\n8",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#8": "OpenAI GYM: Environments\nPer visualizzare lo stato a video su Colab inserire il seguente codice: \n# vedi \nhttps://github.com/ryanrudes/colabgymrender  \n!\npip install gym pyvirtualdisplay > /dev/null \n 2\n>&\n1\n!\napt-get install -y xvfb python-opengl ffmpeg > /dev/null \n 2\n>&\n1\n!\npip install colabgymrender==\n 1.0.2\nimport\n gym\nfrom\n colabgymrender.recorder \n import\n Recorder\nenv = gym.make(\n \"MountainCar-v0\"\n )\ndirectory = \n './video'\nenv = Recorder(env, directory)\nobservation = env.reset()\nterminal = \n False\nwhile \nnot\n terminal:\n# Azione random\n  action = env.action_space.sample()\n  observation, reward, terminal, info = env.step(action)\nenv.play()\n9\n",
    "data_test\\rootfolder\\università\\MachineLearning\\43-Ex_17 Esercitazione RL 2-sbloccato.pdf#9": "OpenAI GYM: Environments\n...\nenv = gym.make(\n \"Atlantis-v0\"\n )\ndirectory = \n './video'\nenv = Recorder(env, directory)\n...\n10\n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#0": "Machine Learning \nUniversità Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nEsercitazione: Introduzione al Deep Learning  \n(Ex 18/19)\n1",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#1": "Sommario\nIntroduzione \nIl concetto di Deep Learning \nEsempi di applicazioni \nTranslational simmetry \nConvolutional Neural network \n•\nConvolutional layer \n•\nLocal receptive ﬁeld \n•\nStride e Padding \n•\nFilters e Feature Maps \n•\nPooling Layer \nArchitettura LeNet-5 \nArchitettura AlexNet \nArchitettura GoogleNet e Inception Module \nArchitettura Residual Network (ResNet)",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#10": "Esercizio\nRealizzo un classiﬁcatore binario che mi identiﬁca se in una \nporzione di immagine c’è un pedone. \nScorro l’immagine per trovare una porzione con un pedone  \n \n        \n11\n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#11": "Object recognition\nYolo https://pjreddie.com/darknet/yolov2/ \nhttps://www.youtube.com/watch?v=VOC3huqHrss \n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#12": "Pose estimation\nZhe Cao , Tomas Simon, Shih-En Wei, Yaser Sheikh   \nhttps://www.youtube.com/watch?v=pW6nZXeWlGM \n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#13": "Object Tracking\n Beijing DeepGlint  https://www.youtube.com/watch?v=xhp47v5OBXQ  \n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#14": "Activity Recognition\n MIT CS & AI Lab http://relation.csail.mit.edu\nhttps://www.youtube.com/watch?v=JBwSk6nJOyM \n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#15": "Tesla Self Driving Demo 2016\nTesla   https://www.youtube.com/watch?v=VG68SKoG7vE \n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#16": "Introduzione\nAlcune soﬁsticate \n architetture ML\n  sono riuscite a ottenere \n performance superiori a \nquelle umane\n  (es. il gioco degli scacchi con IBM Deep Blue). Ma solo intorno al \n2000\n  si sono ottenute\n  buone performance per  \ntask apparentemente più semplici\n , \ncome: \n•\nRiconoscere un giocattolo in una immagine \n•\nSpeech recognition - riconoscimento vocale  \nPer noi sono task semplici perché l'evoluzione ha portato il cervello a costruire \nstrutture con funzioni speciﬁche.  \nQuando le informazioni arrivano alle parti deputate al ragionamento ad alto \nlivello, sono già arricchite di features ad alto livello elaborate da queste strutture. \n•\nSebbene siamo coscienti che esiste un giocattolo, non sappiamo spiegare quale \nprocesso abbiamo seguito per identiﬁcarlo. \n•\nLe architetture \n Convolutional Neural Networks (CNN)\n  sono state sviluppate negli \nanni '80 in base agli studi della zona della corteccia deputata al riconoscimento \nvisivo. Nelle ultime 2 decadi si sono diffuse grazie alla presenza di \n GPU\n .\n17",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#17": "L'architettura della Visual cortex\nNegli anni '60 \n Hubel e Wiesel\n  hanno dimostrato che  \n•\nmolti neuroni nella parte di corteccia deputata al riconoscimento di \nimmagini possiedono un piccolo \n Local receptive ﬁeld (LRF)\n , cioè possono \nreagire agli stimoli situati in regioni limitate del campo visuale. \n•\nsebbene condividano il LRF, \n alcuni neuroni si attivano \n solo\n in presenza di \nlinee orizzontali\n , \naltri \nsolo \ncon quelle \n verticali\n . \n•\nalcuni neuroni hanno LRF più estesi\n  e \nsi attivano in presenza di certe \nconﬁgurazioni di più caratteristiche a basso livello\n .  \n•\nsi può desumere che l'attivazione di neuroni ad alto livello é basata \nsull'output di neuroni a basso-livello che sono ritenuti \"vicini\". \nAumentando la complessità, ripetendo più volte in cascata i passi riportati, \npossiamo riconoscere \n patterns visuali \n anche molto \n complessi\n . \nNota\n : il resto della lezione suppone di considerare \n immagini\n  come istanze di \ninput, ma le tecnologie introdotte possono essere usate anche per altri input.\n18",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#18": "L'architettura della Visual cortex\n19\nSecondo te è una MLP?Ad ogni livello saliamo di astrazione \nnei pattern individuati\nLocal receptive ﬁelds",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#19": "L'architettura della Visual cortex\n20\nÈ simile a una MLP , \nma ogni nodo e connesso solo  \na un piccolo insieme di neuroni viciniAd ogni livello saliamo di astrazione \nnei pattern individuati\nLocal receptive ﬁelds",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#2": "Deep Learning - Cos’è?\nInvece di una singola rete con molti parametri da individuare \ntutti insieme, si suddividono le elaborazione in più moduli \ndistinti a cascata. \nSviluppato negli anni ’80 (Geoff Hinton, Yann Lecun, Yoshua \nBengio, Jürgen Schmidhuber) ispirandosi ai risultati sulla \ncognizione umana. \nMa al tempo non c’erano le infrastrutture hardware e software \nadatte (GPU-enabled). \nUtile in scenari con grosse moli di dati complessi. \nUno degli obiettivi è ignorare la (noiosa) fase di deﬁnizione di \nfeature ad-hoc per lo speciﬁco problema da esaminare e lasciare \nalle reti neurali identiﬁcare le features più adatte.\n3",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#20": "MLP - fully connected\nPerché non usiamo una NN MLP per riconoscere gli oggetti?\n21",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#21": "MLP - fully connected\nPerché non usiamo una NN MLP per riconoscere gli oggetti? \n1.\nA causa dell'\n elevato numero di parametri da stimare  \n•\nSupponiamo di avere in input una piccola immagine di 100x100 pixel \n•\nCreiamo un primo layer di appena 1000 nodi, che perciò ﬁltra \nnotevolmente le informazioni passata ai successivi layer. \n•\nPer questo primo strato abbiamo già \n 10 milioni di parametri da stimare\n .\n22",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#22": "MLP - fully connected\nPerché non usiamo una NN MLP per riconoscere gli oggetti? \n1.\nA causa dell'\n elevato numero di parametri da stimare  \n•\nSupponiamo di avere in input una piccola immagine di 100x100 pixel \n•\nCreiamo un primo layer di appena 1000 nodi, che perciò ﬁltra notevolmente \nle informazioni passata ai successivi layer. \n•\nPer questo primo strato abbiamo già \n 10 milioni di parametri \n da stimare. \n2.\nSupponiamo che \n certi nodi \n del primo strato \n si specializzino su un certo task\n , es. \nriconoscere linee orizzontali. \n•\nI neuroni specializzati sono attivati se il pattern da identiﬁcare è localizzato in \nuna certa zona.  \n•\nMa vorremmo poter identiﬁcare lo stesso pattern indipendentemente da dove \ncompare. \nCon \ntranslational symmetry\n  intendiamo che lo stesso output deve essere \nprodotto anche a seguito di operazioni di traslazione sulla istanza in input. \n23",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#23": "MLP - fully connected\nPerché non usiamo una NN MLP per riconoscere gli oggetti? \n3. Le reti \n MLP \nnon riescono a codiﬁcare esplicitamente l'organizzazione \nspaziale delle features\n . \n•\nNel Visual cortex i neuroni degli strati più vicini all'input identiﬁcano \nfeatures analizzando piccole aree dell'immagine. \n•\nI neuroni \"ad alto livello\" combinano tali features per identiﬁcare features \nspazialmente più estese.\n24",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#24": "Esempi di \n translational simmetry\n25\nNel task a lato, per addestrare una MLP dovremmo avere \nun training set con: \n•stessa specie animale che compare in varie \nposizioni, angolazioni e dimensioni. \n•specie visualizzate parzialmente (es. sul bordo). \n•casi di overlap tra specie diverse di animali",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#25": "Ulteriore considerazione: \n sparsity\n26Per riconoscere certe caratteristiche speciﬁche analizziamo informazioni \"locali\" o ravvicinate, cioè con una \ndistanza relativa limitata. Non c'è bisogno di considerare l'intera immagine iniziale. \nUn output associato ad una certa feature (es. occhio o naso) è associato solo un certo numero di pixel in input.  ",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#26": "Convolutional NN\nLe architetture \n Convolutional NN (CNN)\n  consistono in varie tecniche \nispirate al funzionalmente del cervello.  \nIl blocco più importante è il \n convolutional layer\n  così costituito: \n•\nI nodi nel primo layer \n non sono connessi con tutti i pixel\n  dell'immagine in \ninput, ma \n solo in una regione\n  (es. un rettangolo). Tale regione è chiamata \nLocal receptive ﬁeld (LRF)\n . \n•\nQuesto permette alla rete di \n specializzarsi\n  su caratteristiche a basso \nlivello che saranno poi elaborate in caratteristiche a più alto livello nei \nsuccessivi hidden layer. \n•\nUna rete CNN è \n gerarchica\n , con più convolutional layer nascosti che \nindividuano via via caratteristiche più astratte.\n27",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#27": "CNN - Convolutional layer e LRF\n28\nnodo\ninput per il successivo hidden layer\n25x2521x21\nEsempio di input: \nimmagine 25x25 pixel\nin bianco e neroOutput dopo il primo  \nlayer convolutivo.local receptive ﬁeldOgni nodo è attivato in base \nall'input determinato \nda una certa posizione del \nLRF che scorre lungo l'input.input\nConvolutional layer\nnotiamo la riduzione della  \ndimensione rispetto all'inputmatrice delle attivazioni\nelaborazione",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#28": "CNN - Struttura gerarchica\n29Input layer: \nÈ un layer costituito da unità \na cui viene associato il valore \ndei singoli pixel dell'immagine.  \nNon c'è reale elaborazione.Primo convolutional layer\nSecondo convolutional layerDato una instanza in input, nodi vicini nel convolutional layer layer saranno attivati in base \nalle features estratte da una certa zona dell'input. Astrazione delle features\nNota: Nelle tradizionali MLP, input bidimensionali [N, M] (es. immagini in bianco e nero) sono \ncomunemente ridimensionati a vettori, ovvero matrici di dimensioni [NxM, 1].  \nNelle CNN tale ridimensionamento è controproducente poiché si perderebbe l'informazione relativa alla \nvicinanza delle features in input. Struttura gerarchica\n Nell'input layer le features \ncorrispondono ai singoli pixel",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#29": "CNN - LRF\n30Output layer precedente•In un certo layer convoluzionale, un nodo con indice (i, j) prende in input gli output dei nodi \ndel layer precedente posizionati all'interno del LRF .\n•la regione LRF va dalla riga i alla riga i+f h-1, e dalla colonna j alla colonna j+f w-1\n•fh e f w corrispondono all'altezza e larghezza del LRF. \n•i e j sono indici che scorrono da 1 a dim x-fh-1 e dim y-fh-1\nIl convolutional layer è \nrappresentato da una \ngriglia bidimensionale \nche contiene il risultato \ndelle attivazioni.forward propagation\nEsempio con LRF 3x3 \ncon stride pari a 1.<------ padding ------>\n<------ padding ------><------ dim x ------>\n<--- dimy -->\nPadding \n(discusso più avanti)",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#3": "Deep Learning - Cos’è? (2)\nIn estrema sintesi: \nSi compongono più strutture di reti neurali in cascata il cui \nscopo è analizzare l’input ed estrarre ad ogni passo un \ninsieme di features (in automatico). \nL’output di una rete neurale è l’input della successiva. \nTipicamente l’input iniziale è low-level (es. gruppi di pixel di \nuna immagine) e ogni rete genera rappresentazioni più ad \nalto livello (es. contorno viso, bocca, bocca sorridente etc.). \nLe elaborazioni degli strati intermedi sono tipicamente \nunsupervised.\n4",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#30": "CNN - Stride\n31•La distanza s tra due LRF adiacenti è chiamata stride. \n•Finora abbiamo visto stride di 1 pixel, ma la LRF può scorrere di più pixel. \nOutput layer precedenteLayer convoluzionale\n<------ padding ------>\n<------ padding ------>\nLRF di 3x3 \nStride = 2",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#31": "CNN: Padding\n32•Supponendo stride > 1, può accadere che il convolutional layer (comunque ridotto di fw-1 e \nfh-1 a causa del LRF) non abbia le stesse dimensioni del layer precedente poiché la LRF non \npuò scorrere l'intera instanza in input. \n•Il padding aggiunge dimensioni ai dati in input. Normalmente i dati inseriti sono valori nulli \n(0-padding). Si hanno i seguenti vantaggi:\n•Permettere alla LRF di scorrere per intero l'immagine in input senza ignorarne delle parti.\n•Un LRF potrebbe \"imparare\" a riconosce una certa feature quando è centrata \nnell'immagine. Se la feature è posizionata molto vicino al bordo, senza padding potrebbe \nessere ignorata.\n0-padding\n✓LRF\nOutput layer precedente senza padding Output layer precedente con padding",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#32": "CNN - Esempio di attivazione di un nodo \nL'attivazione di un nodo in un layer convoluzionale si ottiene \nanalizzando l’output dal layer precedente per mezzo del \n LRF\n. \nEsempio: la funzione d’attivazione (\n σ\n) per il nodo <\n l\n,\nk\n> si valuta \nconsiderando il bias \n b\n e la matrice \n W\n di dimensione \n f\nh  \nf\nw \nassociati al \nLRF, in questo caso pari a 3\n 3. \n \nW\n e \nb\n sono i parametri da determinare.  \ni\n e \nj\n sono gli offset riferiti al \n LRF\n. \nSe la ﬁnestra scorre un passo alla volta allora \n l\n e \nk\n fanno riferimento \nall’origine della ﬁnestra del \n LRF\n.\n×\n×\nσ\n(\nb\n+\n2\n∑\ni\n=\n0\n2\n∑\nj\n=\n0\nw\ni\n,\nj\n⋅\nx\ni\n+\nl\n,\nj\n+\nk\n)\nijlk\nLRF",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#33": "CNN: Riduzione dimensionalità e Stride\n34Output layer precedente•La presenza di stride > 1 altera gli indici iniziali e ﬁnali che identiﬁcato il LRF associato ad \nun certo nodo. \n•L'attivazione di un nodo nella posizione (i, j) di un certo layer è determinato dagli output dei \nnodi nel layer precedente posizionati nella righe da i × s h  a  i × s h + f h - 1, e nelle colonne da  \nj × s w  a  j × s w + f w - 1.\n•Per s pari a 1, si torna alla formulazione già vista.\n•Stride > 1 riducono la dimensione del layer convoluzionale a scapito della precisione.\nLayer convoluzionale\n<------ padding ------>\n<------ padding ------>stride verticale\nstride orizzontaleLRF di 3x3 \nStride = 2",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#34": "CNN: Filters\n35Filters•Supponiamo di poter rappresentare graﬁcamente i pesi associati a un certo nodo, usati per \nil calcolo della sua attivazione. Tali pesi prendono il nome di ﬁlters o convolution kernels  \n(o kernels )\n•Ad esempio, una LRF 7 7 corrisponderà ad un ﬁltro con medesime dimensioni. ×\nNell'esempio ci sono due ﬁltri Vertical ﬁlter e Horizontal ﬁlter entrambi con matrice tutta di 0, \ntranne una colonna di 1 e una riga di 1, rispettivamente.\nInput",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#35": "Esempi di ﬁltri e attivazioni (1)\n36Esempio di input \nimmagine 25x25 pixel\nOutput dopo il primo  \nlayer convolutivo.\nImmagine in input\nImmagine in inputOutput\nOutputFiltro\nFiltroAttivazioni\nAttivazioni",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#36": "Esempi di ﬁltri e attivazioni (2)\nhttp://brohrer.github.io/how_convolutional_neural_networks_work.html\n1-1-1\n-11-1\n-1-11\n0.33 -0.11 0.55 0.33 0.11 -0.11 0.77\n-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11\n0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11\n0.33 0.33 -0.33 0.55 -0.33 0.33 0.33\n0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55\n-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11\n0.77 -0.11 0.11 0.33 0.55 -0.11 0.33-1-1-1-1-1-1-1-1-1\n-11-1-1-1-1-11-1\n-1-11-1-1-11-1-1\n-1-1-11-11-1-1-1\n-1-1-1-11-1-1-1-1\n-1-1-11-11-1-1-1\n-1-11-1-1-11-1-1\n-11-1-1-1-1-11-1\n-1-1-1-1-1-1-1-1-1=0.77 -0.11 0.11 0.33 0.55 -0.11 0.33\n-0.11 1.00 -0.11 0.33 -0.11 0.11 -0.11\n0.11 -0.11 1.00 -0.33 0.11 -0.11 0.55\n0.33 0.33 -0.33 0.55 -0.33 0.33 0.33\n0.55 -0.11 0.11 -0.33 1.00 -0.11 0.11\n-0.11 0.11 -0.11 0.33 -0.11 1.00 -0.11\n0.33 -0.11 0.55 0.33 0.11 -0.11 0.77\n-1-11\n-11-1\n1-1-11-11\n-11-1\n1-110.33 -0.55 0.11 -0.11 0.11 -0.55 0.33\n-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55\n0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11\n-0.11 0.33 -0.77 1.00 -0.77 0.33 -0.11\n0.11 -0.55 0.55 -0.77 0.55 -0.55 0.11\n-0.55 0.55 -0.55 0.33 -0.55 0.55 -0.55\n0.33 -0.55 0.11 -0.11 0.11 -0.55 0.33=\n=-1-1-1-1-1-1-1-1-1\n-11-1-1-1-1-11-1\n-1-11-1-1-11-1-1\n-1-1-11-11-1-1-1\n-1-1-1-11-1-1-1-1\n-1-1-11-11-1-1-1\n-1-11-1-1-11-1-1\n-11-1-1-1-1-11-1\n-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1\n-11-1-1-1-1-11-1\n-1-11-1-1-11-1-1\n-1-1-11-11-1-1-1\n-1-1-1-11-1-1-1-1\n-1-1-11-11-1-1-1\n-1-11-1-1-11-1-1\n-11-1-1-1-1-11-1\n-1-1-1-1-1-1-1-1-1ﬁltroattivazioni\nﬁltro\nﬁltro",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#37": "CNN: Feature Maps\n38Filters•Le LRF scorrono sulla immagine in input. Supponiamo di mantenere costante i valori del \nﬁltro usato per il calcolo dell'attivazione. Tale approccio prende il nome di shared weights. \n•L'insieme delle attivazioni ottenute con lo stesso ﬁltro viene chiamato feature map. Esse \npossono essere visualizzate come una immagine.\nNell'esempio si nota che il Vertical ﬁlter crea una feature map dove le zone dell'input simili a una \nlinea verticale sono più evidenziate (cioè più attivazione), mentre le zone  meno simili saranno \npiù scure e sfocate. Discorso duale per il ﬁltro Horizontal ﬁlter.Feature maps\nInput",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#38": "CNN: Stacking feature maps\nIn \nogni layer\n  possiamo contemplare \n più ﬁltri con le medesime dimensioni\n . \nOgni ﬁltro produrrà una diversa feature map. Ogni layer sarà così costituito \nda una sequenza di matrici di attivazioni, perciò una \n struttura 3d\n . \nDurante il \n forward propagation\n  è fondamentale che i ﬁltri, cioè i parametri \npesi\n e \nbias\n che costituiscono il layer convoluzionale, rimangano costanti, \nsebbene il valore delle attivazioni, ovvero la \n feature map\n , cambiano in base \nalla posizione del \n LRF\n. Questo permette di: \n•\nAvere un numero molto minore di parametri da stimare rispetto a un layer \nMLP. \n•\nDurante la backpropagation, adattare ogni ﬁltro ad una particolare \ncaratteristica saliente.  \n•\nLa possibilità di usare lo stesso ﬁltro in diverse zone dell'immagine garantisce la \ntranslational simmetry\n , cioè possiamo riconoscere la caratteristica in diverse \nposizioni. Una rete Fully connected (\n FC\n) potrebbe riconoscere una caratteristica \nin una posizione stimando certi parametri, ma non sarebbe in grado di \nriutilizzarli in altre posizioni.\n39",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#39": "CNN: Feature Maps\n40...Input\nConvolutional layer 2\nConvolutional layer 1\nUna immagine a colori con 3 matrici \nassociate ai canali RGB.Possiamo deﬁnire un certo numero di ﬁltri (es. 12) per riconoscere diverse caratteristiche salienti dell'immagine iniziale. I ﬁltri analizzano contemporaneamente 3 canali RGB, perciò i ﬁltri saranno deﬁniti con matrici a 3 dimensioni. Un ﬁltro applicato all'immagine in input produce un singolo convolutional layer.I successivi layer convoluzionali analizzato le attivazioni di più ﬁltri contemporaneamente. I ﬁltri di questo layer riconosceranno caratteristiche più astratte.depth = 3 depth = 12 depth = 7",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#4": "Deep Learning - Principali vantaggi\nRispetto ad altri approcci: \nSi può sviluppare un unico framework computazionale che \npuò essere implementato ed eseguito su varie piattaforme \nhardware e cloud. \nIl framework offre funzionalità valide per molte architetture di \nreti e tasks (es. natural language processing, computer vision, \nspeech recognition, etc.) \nSi possono condividere e riutilizzare i parametri ottenuti \ndurante l’apprendimento per uno speciﬁco task in altri \ncontesti.\n5",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#40": "TensorFlow: Padding\nTensorFlow fornisce il parametro \n padding\n  che può assumere due valori: \n•\n\"\nVALID\n \" nel caso in cui si voglia ignorare il padding  \n•\n\"\nSAME\n \" per aggiungere automaticamente righe e colonne composte da \nvalori 0 in modo bilanciato per garantire che il LRF scorra l'intera matrice \nin input.\n4101234567891011121300 12345678910111213\nsenza padding ('VALID') con padding ('SAME')ignorati\nstride=5padding P=+3",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#41": "Tuning delle CNN\nRispetto a una MLP abbiamo \n molti più iperparametri da stimare\n : \nNumero di ﬁltri per layer (o \n depth\n ) \nDimensione del LRF \nStride e padding \nInvece di usare tecniche automatiche per il tuning,\n  ci si ispira ad \narchitetture già studiate \n in letteratura per avere una conﬁgurazione \nverosimilmente già ottimizzata.\n42",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#42": "Risorse di memoria: considerazioni\nLa backpropagation richiede di memorizzare tutti i valor intermedi calcolati \ndurante la forward propagation\n . \n•\nAd esempio, \n convolutional layer \n con ﬁltri 5\n 5 e con 200 feature maps di \ndimensione 150\n 100 con stride 1 e padding SAME: se in input abbiamo \nimmagini RGB 150\n 100, il numero di \n parametri\n  è (5\n 5\n3+1)\n 200 = \n 15.200 \n•\nNella \n MLP\n, un layer 150\n 100 completamente connesso col layer in input \nrichiederebbe 150\n 100\n 150\n 100\n 3 = \n67.5M di parametri\n . \n•\nOgnuna delle 200 mappe contiene 150\n 100 nodi, ed ogni nodo ricava \nl'attivazione valutando 5\n 5\n3 input, che corrispondono a \n 225 milioni di \nmoltiplicazioni\n  in virgola mobile. \n•\nCon ﬂoat di \n 32bit\n  il layer di output impiega 200\n 150\n 100\n 32 = \n 11.5Mb \ncirca\n  per ogni istanza. Per 100 istanze il layer occuperebbe più di un \n 1Gb\n. \nIn produzione, le attivazioni di un layer possono essere dimenticate appena i \ncalcoli sul layer successivo sono terminati, richiedendo molta meno memoria \n(cioè al massimo quella di 2 layer contemporaneamente). \n×\n×\n×\n ×\n×\n ×\n×\n×\n ×\n ×\n ×\n×\n×\n×\n×\n ×\n ×\n43",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#43": "Pooling layer (1)\nI \nlayer di pooling \n ha lo scopo di \n ridurre il numero di parametri \n operando un \ncampionamento\n  (o \ndown-sampling\n ) dei dati. I vantaggi sono i seguenti: \n•\nMeno complessità computazione \n•\nMeno risorse di memoria \n•\nMeno parametri (e ridurre l'overﬁtting come effetto collaterale) \nCome nel convolutional layer, \n ogni nodo è connesso con un numero limitato di \nnodi del layer precedente \n posizionati in un certo LRF. \n•\nOccorre deﬁnire dimensione, stride e padding \nIl \npooling layer non ha parametri.\n  Opera semplicemente una \"\n aggregazione\n \" dei \nvalori associati ai nodi, ad esempio calcolando \n media\n  o \nvalore massimo\n . \nSpesso il calcolo è fatto per ogni canale in input, cioè su un singolo strato alla volta \nrispetto all'intera profondità del layer precedente (es. sul canale R, G e B \nseparatamente).  \n•\nLa profondità (numero di layer) in uscita corrisponderà a quella che si ha in \ningresso. \n44",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#44": "Pooling layer (2)\nNon ha parametri da inferire\n , ma solo iperparametri, cioè dimensione del \nﬁeld (\n pooling size\n ), il \npooling stride\n , e tipo di aggregazione. \n•\nSpesso pooling size e stride corrispondono. \nIn molti scenari \n non è fondamentale la posizione esatta di una certa \ncaratteristica\n , ma il fatto che esista in una certa zona, o che sia identiﬁcata \nuna certa sequenza (o pattern) di features senza considerare esattamente le \nrispettive distanze reciproche. \n•\nAd esempio, nella face detection ho interesse a riconoscere due occhi \nvicini, ma non mi interessa la distanza esatta. \nEsistono \n due tipi principali di aggregazione\n : \n•\nmax-pooling:  \nun nodo assume l’attivazione massima tra i valori presenti \nnel ﬁeld considerato. \n•\naverage pooling:\n  considero il valor medio nel ﬁeld.\n45",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#45": "Esempio: Pooling layer\nNell'esempio il pooling kernel è di 2\n 2, lo stride pari a 2, padding VALID e \naggregazione max. \n•\nIl layer di output contiene il 75% in meno dei valori del layer precedente.\n×\n46\nA causa del padding VALID \nil valore di alcuni nodi sarà ignorato.\nSe in input abbiamo un canale con un layer NN,  f po è il pooling size, s po il pooling stride,  \n \nuna dimensione del layer di output è:  ×\nN−fpo\nspo+1",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#46": "CNN: Convolutional layer e dimensione output\nLa dimensione dell'output di un \n convolutional layer\n  si ricava a \npartire dalla dimensione dell'input e dal valore degli iperparametri. \nSe per semplicità assumiamo input \n N\nN\n, e la dimensione del \n LRF \n \nf\nh\n = f\n w\n = \nf\n, lo stride \n s,\n e le righe (o colonne) \n p\n aggiunte come \npadding, allora una delle due dimensione del layer di output è la \nseguente: \n \nLa dimensione in output perciò corrisponde a \n O\nO.\n×\nO\n=\nN\n−\nf\n+\np\ns\n+\n1\n×",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#47": "AlexNet\n  (2012) è una delle prime architetture di reti neurali che combina CNN e \nGPU nell'ambito della classiﬁcazione degli oggetti.\nEsempio: calcolo parametri AlexNetoutput depth = 96input depth = 3\nRicordiamoci  che il local receptive ﬁeld  \nha una profondità pari a quella dell’inputEsempi di calcolo dei parametri nel primo layer \nhidden: \n•Dim. immagine in Input = 227 227 3 \n•Dim. LRF = 11 11 \n•Stride = 4; padding VALID \n•Numero ﬁltri (o depth) = 96 \n•L’output per ogni ﬁltro avrà dimensione di lato (227-11)/4 + 1 = 55. Cioè 55 55 per ﬁltro. \n•Considerando la profondità si ha: 55x55x96 =290.400 nodi. \n•L'attivazione di un nodo si ricava considerando 11x11x3 nodi del layer precedente.  \n•In una MLP si avrebbero 105.415.200 parametri. \n•Per la proprietà degli shared weights, nella CNN il numero di parametri sarà 11x11x3x96 + 96 = 34.944. × ×\n×\n×\nfeature mapscomputazione",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#48": "Architettura LeNet-5 per OCR\nLeNet-5\n  (1989) è una delle prime architetture CNN.  \n•\nE' stata ideata per fare OCR garantendo un errore <1% su MNIST. \nCombina layers \n CNN\n  con una rete tradizionale \n MLP\n a valle.  \n•\nLo scopo è di impiegare le caratteristiche salienti identiﬁcate dalle CNN \nper fare classiﬁcazione per mezzo della MLP. \n•\nUna rete interamente \n MLP fully connected avrebbe richiesto molti più \nparametri\n  per ottenere le stesse prestazioni.",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#49": "Demo LeNet-5\nda http://yann.lecun.com/exdb/lenet/ ",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#5": "DeepMind e Atari Breakout\nGoogle Deepminds https://deepmind.com \nhttps://www.youtube.com/watch?v=eG1Ed8PTJ18 ",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#50": "Architettura LeNet-5\nconvolutional layer#1 conv. layer\nfeature maps:  \n28x28, depth 6#3 conv. layer \nfeature maps: \n10x10, depth 16\navg.  \npoolingconv. layeravg.  \npooling#2 pooling layer\nfeature maps: \n14x14, depth 6#4 pooling layer\nfeature maps: \n5x5, depth 16\nconv. layer#6 fully connected layer \nnodi 84#5 conv. layer \nfeature maps:  \n1x1, depth 120\nImmagini  \n32x32x1 (gray scale)LRF\nL'output dell'ultimo \nconvolution layer è \nconvertito in un vettore \n120x1, adatto come input di \nun fully connected layer.\nLa ReLU non era ancora \nstata approfondita ai tempi di \nLeNet-5. Si è impiegata la \npiù tradizionale tanh.#7 fully connected layer \nnodi 10\nLa conﬁgurazione degli \niperparametri e la dimensione \ndell'input non necessita di \nimpiegare il padding.",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#51": "LeNet-5 in Keras\nCon Keras l'implementazione di LeNet-5 per il dataset MNIST è rapida poiché i \nlayer di pooling e di convoluzione sono già fatti:  \nmodel = keras.Sequential()\nmodel.add(layers.Conv2D(filters=\n 6\n, kernel_size=(\n 3\n, \n3\n), activation=\n 'relu'\n, \n                     input_shape=(\n 32\n,\n32\n,\n1\n)))\nmodel.add(layers.AveragePooling2D())\nmodel.add(layers.Conv2D(filters=\n 16\n, kernel_size=(\n 3\n, \n3\n), activation=\n 'relu'\n))\nmodel.add(layers.AveragePooling2D())\n# cambio il formato da matrice a vettore\nmodel.add(layers.Flatten())\n# layer fully connected o denso\nmodel.add(layers.Dense(units=\n 120\n, activation=\n 'relu'\n))\nmodel.add(layers.Dense(units=\n 84\n, activation=\n 'relu'\n))\nmodel.add(layers.Dense(units=\n 10\n, activation = \n 'softmax'\n ))",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#52": "CNN - Esercizio\nSe le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema?\n53",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#53": "CNN - Esercizio\nSe le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema? \n1.\nRidurre la \n dimensione del mini-batch\n .\n54",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#54": "CNN - Esercizio\nSe le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema? \n1.\nRidurre la \n dimensione del mini-batch\n . \n2.\nRidurre la \n dimensionalità nella rete\n , ad esempio con stride > 1 in uno o più \nlayers, o con pooling layers. \n•\nAnche un convolutional layer riduce la dimensione del layer precedente ma, a \ndifferena del pooling layer, introduce ulteriori parametri da apprendere.\n55",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#55": "CNN - Esercizio\nSe le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema? \n1.\nRidurre la \n dimensione del mini-batch\n . \n2.\nRidurre la \n dimensionalità nella rete\n , ad esempio con stride > 1 in uno o più \nlayers, o con pooling layers. \n•\nAnche un convolutional layer riduce la dimensione del layer precedente ma, a \ndifferena del pooling layer, introduce ulteriori parametri da apprendere. \n3.\nCambiare l'architettura \n rimuovendo un layer\n .\n56",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#56": "CNN - Esercizio\nSe le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema? \n1.\nRidurre la \n dimensione del mini-batch\n . \n2.\nRidurre la \n dimensionalità nella rete\n , ad esempio con stride > 1 in uno o più \nlayers, o con pooling layers. \n•\nAnche un convolutional layer riduce la dimensione del layer precedente ma, a \ndifferena del pooling layer, introduce ulteriori parametri da apprendere. \n3.\nCambiare l'architettura \n rimuovendo un layer\n . \n4.\nUsare rappresentazioni\n  ﬂoat a 16\n  bit invece che 32.\n57",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#57": "CNN - Esercizio\nSe le tue GPU non hanno memoria sufﬁciente per una rete CNN, quali sono le \n5 cose che puoi fare per risolvere il problema? \n1.\nRidurre la \n dimensione del mini-batch\n . \n2.\nRidurre la \n dimensionalità nella rete\n , ad esempio con stride > 1 in uno o più \nlayers, o con pooling layers. \n•\nAnche un convolutional layer riduce la dimensione del layer precedente ma, a \ndifferena del pooling layer, introduce ulteriori parametri da apprendere. \n3.\nCambiare l'architettura \n rimuovendo un layer\n . \n4.\nUsare rappresentazioni\n  ﬂoat a 16\n  bit invece che 32. \n5.\nDistribuire la computazione\n  su più elaboratori.\n58",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#58": "Architettura AlexNet\nArchitettura CNN vincitrice della challenge object detection ILSVRC 2012 con un \ntop-5 error del 17% (il secondo ha ottenuto 26%).  \nE' molto simile a \n LeNet-5\n  ma con più profondità, con stacking dei pooling layer \nuno dopo l'altro (senza strato di pooling). \n•\nPrimo tentativo di sfruttare piattaforme hardware GPU-enabled per addestrare reti \ncomplesse.\nDopo i 5 convolutional \nlayers (11x11, 5x5 e 3x3) \nc'è il max pooling, e una \nrete FC da 3 layer. \nImpiega ReLI, SGD e \nmomentum. \n \nLa doppia pipeline è \ndovuta all’hardware \nimpiegato per \nl’addestramento (2 gpu)",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#59": "Architettura AlexNet (2)\nImpiega \n dropout\n  sugli strati FC, e \n data augumentation\n . Nei layer C1 e C3 impiega \nla \nLocal response normalization:\n  se un nodo riceve una attivazione signiﬁcativa, \nsi inibiscono i nodi nella stessa posizione ma in altre feature maps.  \n•\nL'ipotesi è quella di favorire la competitività, specializzando ogni feature map su \ncaratteristiche distinte.\n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#6": "Robot Learns to Flip Pancakes\nPetar Kormushev (IIT): https://www.youtube.com/watch?v=W_gxLKSsSIE \n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#60": "CNN: Alcune problematiche \nNei seguenti esempi riconosciamo un cane, ma la posizione e \ndimensione dell’animale sono molto diverse tra loro.  \n•\nNon è facile determinare la giusta dimensione (e il numero) dei \nﬁltri negli strati iniziali. \nE nonostante le tecnologie di apprendimento introdotte, in \narchitetture molto deep (con molti strati) può sempre riproporsi il \nvanishing gradient problem\n . \n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#61": "CNN: Inception module (GoogleNet)\nL'\ninception module\n  si basa sulla ipotesi che \n combinare\n  le \ninformazioni provenienti da diverse pipeline di processamento basate \nconvolutional layer permetta di estendere le caratteristiche salienti \nidentiﬁcate. \n•\nPiù convolution layer in parallelo\n , ognuno con una \n diversa \ndimensione dei ﬁltri\n . Gli output dei convolution layers sono \n\"combinati\" in una singola struttura che consisterà nell'input per il \nlayer successivo. \n•\nSi impiegano ﬁltri con dimensioni pari a \n 1x1\n, \n3x3\n e \n5x5\n, tutti con \nstride 1\n , \nSAME\n  padding e \n ReLU\n  activation function. \nIn pratica si processa lo stesso input contemporaneamente \nconsiderando più dimensioni di LRF.  \nL'inception module è stato impiegato per la prima volta \nnell'architettura \n GoogleLeNet\n .",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#62": "Inception module\nL'input è dato contemporaneamente a \n 3 convolution layers\n  e un \n 3x3 \nmax pooling\n .  \n•\nLe \n1x1 convolution \n \"\ncomprimono\n \" la profondità dell'input, utili \nsoprattutto per \n sempliﬁcare i dati in input \n alle convoluzioni 3x3 e \n5x5 che richiedono risorse computazionali. \n•\nLa combinazione \n 1x1+3x3\n  e \n1x1+5x5\n  hanno più possibilità di \nrappresentare \n feature più complesse \n rispetto ai singoli 3x3 e 5x5. \n•\nSperimentalmente si nota come gli inception module sono più \nefﬁcienti se usati negli higher layers. \nInception module\n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#63": "Architettura GoogLeNet v1\nL’architettura vincitrice della object detection challenge ILSRC 2014 \nraggiungendo un top-5 error < 7%.  \nLa principale caratteristica è la profondità: \n 22 layer\n  (27 considerando anche i \npooling layers) con 9 \n inception module\n  in cascata.  \n•\nDopo ogni \n inception module\n  si opera una average pooling per ridurre il \nnumero di parametri. \n•\nSebbene più profonda, possiede 1/10 dei parametri di AlexNet (6 milioni \ncirca)\nAltre tecniche impiegate: batch \nnormalization, image distortions e RMSprop?? inception module",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#64": "Architettura GoogLeNet v1 (2)\nL’\noutput di due inception module intermedi (3º e 6º inception module) è valutato \npreliminarmente nel task della classiﬁcazione \n per mezzo di una softmax. \nSi affrontare il problema del \n vanishing gradient problem\n , dato che si generano \ngradienti addizionali negli hidden layer lontani dall'ultimo layer. \nIl valore della loss intermedia è chiamato \n auxiliary loss\n . Durante il training \nviene combinato linearmente (scalato del 70%) con la loss dell'intera rete.  \nIn produzione e nel test set non vengono impiegati. \nNota\n : le versioni v2, v3 e v4 di GoogleNet introducono molti espedienti per \nrendere più efﬁciente il training e migliorare l’accuracy.\nauxiliary classiﬁerauxiliary classiﬁer",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#65": "GoogLeNet: esempio di ﬁltri\n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#66": "Architettura Residual Network (ResNet)\nResNet\n  è stata presentata a ILSVRC 2015 (top-5: 3.6%) e consiste in 152 layers. \nUna rete con tale profondità non potrebbe essere addestrata a causa del \nvanishing gradient problem. \nSi introducono le \n skip connections\n , che propagano l'output di un certo layer \nnell'input di un layer che è posizionato più a valle.   \n•\nL'ipotesi è di rendere \n più semplice propagare segnali \n su varie parti della rete. \n•\nNelle fasi iniziali (comportamento random) si obbliga parti della rete ad \ncomportarsi in modo da riproporre i valori in input, rendendo \n più veloce \nl'apprendimento\n .\n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#67": "ResNet: Residual learning\nAddestrare una rete neurale può essere interpretato come approssimare una \nfunzione h(\n x\n). Se aggiungi un valore x all'output della rete, allora la rete è \nobbligata a modellare la funzione f(\n x\n) = h(\n x\n) - \nx\n. Tale approccio è chiamato \nresidual learning\n . \nDal punto di vista operativo, è sufﬁciente combinare l'output di un layer con \nl'output di un layer posizionato più a monte prima di valutare la funzione di \nattivazione (ReLU).\n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#68": "Architetture CNN\nPrincipali architetture CNN per le immagini, complessità, numero di operazioni \nrichieste per l'addestramento e accuratezza. \n69\n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#7": "Chess Game\nStati possibili: ~1047\n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#8": "Driverless cars\nStati possibili: ?Microsoft AirSim simulator \nhttps://www.youtube.com/watch?v=fv-oFP AqSZ4 \n",
    "data_test\\rootfolder\\università\\MachineLearning\\44-Ex18 Intro DL-sbloccato.pdf#9": "Esercizio\nVoglio sapere se c’è un pedone di fronte a me analizzando \nl’immagine di una camera dalla mia auto, come procedo? \n10\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nRidge Regression \nCross Validation\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#1": "Sommario\nOverﬁtting nella polynomial  regression \nSintomi dell’Overﬁtting \nFunzione di Costo nella Ridge Regression \nMinimizzazione della Funzione di Costo \nForma Chiusa \nGradient Descent \nK-fold Cross Validation\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#10": "Overﬁtting e #input\n \n11\nAnche il numero di input inﬂuenza l’overﬁtting: \n1 input (e.g., sq.ft)  → per evitare l’overﬁtting servono \nosservazioni che sono molto “dense” sull’asse delle ascisse. \nServono in sostanza osservazioni rappresentative di tutte le \ncoppie (x, y), cosa  difﬁcile da ottenere.  \nd input (e.g., sq.ft, #bagni, #camere-letto, anno di costruzione, \necc.) → è ancora  più difﬁcile avere molte osservazioni \nrappresentative delle coppie (x, y) .\nAreaPrezzoy\nx",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#11": "Funzione di Costo \nnella Ridge Regression\n \n12\nL’idea alla base della Ridge Regression è quella di limitare \nil valore assoluto dei coefﬁcienti wi deﬁnendo come \nsegue la funzione di costo totale (da minimizzare nella \nfase di training): \ncosto_ridge  = misura del “ﬁt” + misura della grandezza dei coefﬁcienti\nPer misura del “ﬁt” intendiamo una funzione come la RSS. \nLa misura dei coefﬁcienti possiamo deﬁnirla in vari modi. ",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#12": "Misura dei Coefﬁcienti  \ndi Regressione\n \n13\nSomma dei valori:                                                  \nSomma dei valori assoluti ( L1 norm ): \nSomma dei quadrati (quadrato della L2 norm ): w0+w1+w2+···+wD\n|w0|+|w1|+|w2|+···+|wD|=DX\nj=0|wj|,kwk1\n👍\n👎\n👍\nw2\n0+w2\n1+w2\n2+···+w2\nD=DX\nj=0w2\nj,kwk2\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#13": "Funzione di Costo \nnella Ridge Regression\n \n14\nLa Ridge Regression usa la somma dei quadrati ( L2 \nRegularization ). \nLa funzione che rappresenta il costo totale nella Ridge è \ndunque la seguente:    \ndove il parametro λ (tuning parameter ) serve per \nbilanciare i due termini.                                              costo ridge(w)=R S S ( w)+\u0000·kwk2\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#14": " \n15Vediamo cosa accade a fronte di diversi valori del parametro λ: \nSe λ = 0: \nci riconduciamo alla vecchia soluzione, ossia minimizzazione \ndell’ RSS( w) → ŵLS \nSe λ → ∞: \nper soluzioni dove ŵ ≠ 0, il costo totale → ∞ \nl’unica soluzione per minimizzare il costo è: ŵ = 0 \nSe 0 < λ < ∞: \nFunzione di Costo \nnella Ridge Regression\n0kˆwk2\n2kˆwLSk2\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#15": "Bias-Variance tradeoff\n \n16\nParametro λ elevato: \nhigh bias, low variance  (e.g., ŵ = 0 per λ = ∞) \nParametro λ piccolo: \nlow bias, high variance  (e.g., standard least squares ﬁt \nper polinomi di grado elevato) ",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#16": "Esempio di polynomial ﬁt \nrivisitato\n \n17\nRivediamo ora la demo relativa al polinomio di grado 16, \napplicando però l’approccio della Ridge Regression con \ndiversi valori del parametro λ. ",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#17": "Polinomio di grado 16 \nlambda = 1.00e-25\n \n18\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#18": "Polinomio di grado 16 \nlambda = 1.00e-10\n \n19\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#19": "Polinomio di grado 16 \nlambda = 1.00e-06\n \n20\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#2": "Il problema dell’Overﬁtting \nnella polynomial regression\n \n3\nRicordiamo il nostro modello nella polynomial  \nregression:\nA seconda del grado del polinomio possiamo avere \ndiverse situazioni:\noverﬁt\nyi=w0+w1xi+w2x2\ni+···+wpxp\ni+✏i\ny\nArea xPrezzo\nAreaPrezzoy\nx",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#20": "Polinomio di grado 16 \nlambda = 1.00e-03 \n \n21\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#21": "Polinomio di grado 16 \nlambda = 1.00e+02\n \n22\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#22": " \n23costo ridge(w)=R S S ( w)+\u0000·kwk2\n2=(y\u0000\u0000w)T(y\u0000\u0000w)+\u0000·wTw\nkwk2\n2=w2\n0+w2\n1+w2\n2+···+w2\nD=wT·w\nGradiente della Funzione di Costo \nPer il calcolo del gradiente della funzione di costo, \nriscriviamo tale funzione in notazione matriciale:\npoiché:",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#23": "Gradiente della Funzione di Costo \n \n24rcosto ridge(w)= r[(y\u0000\u0000w)T(y\u0000\u0000w)+\u0000·wTw]=\n=r[(y\u0000\u0000w)T(y\u0000\u0000w)] +\u0000·r[wTw]=\n=\u00002\u0000T(y\u0000\u0000w)+\u0000·2w\nIl gradiente della funzione è il seguente:",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#24": "Algoritmi per adattare il modello \n[caso della Ridge Regression]\nAnche nel caso della Ridge Regression, una volta calcolato \nil gradiente della funzione \n costo_ridge\n  ci sono due possibili \napprocci per minimizzare la funzione di costo: \n“\nForma chiusa\n ”: Si uguaglia il gradiente a zero e si risolvono le equazioni \n(non sempre è possibile o conveniente dal punto di vista computazionale) \nAlgoritmo di Discesa del Gradiente (\n Gradient Descent\n ) (richiede la \ndeﬁnizione del criterio di convergenza e dello “step size”)\n \n25",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#25": "Forma Chiusa \n[caso della Ridge Regression] \n \n26Poniamo il gradiente uguale a zero:\nrcosto ridge( w)=\u00002\u0000T(y\u0000\u0000w)+2 ·\u0000w=0\n\u00002\u0000Ty+2\u0000T\u0000ˆw+2 ·\u0000ˆw=0\n\u0000\u0000Ty+\u0000T\u0000ˆw+\u0000Iˆ w =0\n\u0000T\u0000ˆw+\u0000Iˆ w =\u0000Ty\n(\u0000T\u0000+\u0000I)ˆw=\u0000Ty\n(\u0000T\u0000+\u0000I)\u00001(\u0000T\u0000+\u0000I)ˆw=(\u0000T\u0000+\u0000I)\u00001\u0000Ty\nIˆ w =(\u0000T\u0000+\u0000I)\u00001\u0000Ty\nˆwridge=(\u0000T\u0000+\u0000I)\u00001\u0000Tyda cui si ha:",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#26": "Gradient Descent (1/4) \n[caso della Ridge Regression] \n \n27w(t+1) w(t)\u0000↵·rcosto ridge(w(t))\nw(t+1)\n0 w(t)\n0\u0000↵·@costo ridge(w(t))\n@w0\nw(t+1)\n1 w(t)\n1\u0000↵·@costo ridge(w(t))\n@w1\n······ ·····················\nw(t+1)\nj w(t)\nj\u0000↵·@costo ridge(w(t))\n@wj\n······ ·····················\nw(t+1)\nD w(t)\nD\u0000↵·@costo ridge(w(t))\n@wD\nI singoli pesi devono pertanto essere aggiornati come segue:\nDobbiamo aggiornare il vettore dei pesi in modo tale da \nspostarci nel verso opposto al gradiente:",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#27": "Gradient Descent (2/4) \n[caso della Ridge Regression] \n \n28@costo ridge(w(t))\n@wj=@RSS(w(t))\n@wj+\u0000·@(w(t)T·w(t))\n@wjcosto ridge(w)=R S S ( w)+\u0000·kwk2\n2=R S S ( w)+\u0000·wTw\nPer il calcolo delle derivate parziali precedenti, consideriamo \ndi nuovo l’espressione della funzione costo_ridge:\nLa derivata parziale della funzione di costo rispetto al \ngenerico peso w j è dunque:",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#28": "Gradient Descent (3/4) \n[caso della Ridge Regression] \n \n29@RSS(w(t))\n@wj=\u00002NX\ni=1\u0000j(xi)[yi\u0000ˆyi(w(t))]\n@(w(t)T·w(t))\n@wj=2 ·w(t)\nj\nPoiché:\nabbiamo:",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#29": "Gradient Descent (4/4) \n[caso della Ridge Regression] \n \n30\nL’aggiornamento del generico peso w j:\ndiventa:\nossia:",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#3": "Sintomi dell’Overﬁtting\n \n4\nSpesso, quando il fenomeno dell’overﬁtting si manifesta, \naccade che i valori assoluti dei parametri stimati ŵ \nassumono valori molto alti. \nVediamo ora una semplice demo in cui si mostra questo \nfenomeno.",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#30": "Algoritmo di Gradient Descent \n[caso della Ridge Regression] \n \n31w(1)= 0 (oppure lo inizializziamo in modo casuale)\nt=1\nwhilekrcosto ridge( w(t))k2>✏\nfor j=0,1,. . . ,D\nderivata parziale RSS[ j]=\u00002NX\ni=1\u0000j(xi)[yi\u0000ˆyi(w(t))]\nw(t+1)\nj (1\u00002↵\u0000)w(t)\nj\u0000↵⇤derivata parziale RSS[ j]\nt t+1",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#31": "Andamento Coefﬁcienti \nRidge\n \n32\nλ ",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#32": " \n33\nSelezione dei parametri  \nvia Cross Validation \nUn problema importante è quello relativo alla scelta del \nparametro λ. Lo affrontiamo per la Ridge, ma le \nconsiderazioni sono più generali. \nCome è stato detto in precedenza, per ogni valore di λ che \nvogliamo considerare possiamo addestrare il nostro modello \nsui dati di training, valutarlo sul validation set e scegliere il \nvalore di λ che ottiene i migliori risultati (validation error più \nbasso). \nPossiamo poi valutare le prestazioni del modello selezionato \nsul test set.",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#33": "Tutto ciò è certamente possibile, a patto di avere un numero \nsufﬁciente di dati:\n \n34\nTraining \nSetTest \nSet\nValidation\n Set\nﬁt ŵλ \ntest prestazioni di ŵλ  \nper selezionare λ* \nvalutare il  \ntrue error di ŵλ*  \nSelezione dei parametri  \nvia Cross Validation ",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#34": "La domanda che dobbiamo porci è però la seguente: cosa \naccade se non abbiamo dati sufﬁcienti per dividerli nei tre \nsottoinsiemi necessari? \n \n35\nDati disponibili\nResto dei dati Test \nSet\nSelezione dei parametri  \nvia Cross Validation \nSupponiamo dunque di trovarci in questa situazione, in cui i \ndati disponibili sono pochi:\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#35": " \n36\nDopo aver scorporato il test set di dimensione adeguata, \nvediamo come poter gestire il resto dei dati da utilizzare  per \nil training e la validation.\nUn uso ingenuo potrebbe essere il seguente:\nSelezione dei parametri  \nvia Cross Validation \nResto dei dati \nTraining \nSet\nValidation\n Set\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#36": " \n37\nIl metodo però non funzionerebbe perché, con pochi dati a \ndisposizione, il validation set non sarebbe sufﬁcientemente \nampio per consentire una valutazione adeguata.\nQuesto varrebbe per la suddivisione mostrata nella ﬁgura \nprecedente, ma anche per altre suddivisioni, come ad es.:\nSelezione dei parametri  \nvia Cross Validation \nValidation\n Set\nValidation\n Set",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#37": " \n38\nOssia vale per qualsiasi scelta di un sottoinsieme dei dati \ndisponibili, da utilizzare come validation set.\nQuale di tali sottoinsiemi possiamo utilizzare? Sappiamo che \nciascuno di essi è troppo piccolo per le valutazioni di nostro \ninteresse.\nSelezione dei parametri  \nvia Cross Validation \nLa risposta è la seguente: li utilizziamo tutti, effettuando una \n“averge performance” su tutte le scelte. \nIn tal modo (cross validation) si evita la “sensitivity” dei \nrisultati in base al particolare sottoinsieme scelto, causata \ndelle poche osservazioni che contiene.",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#38": " \n39\nk-fold Cross Validation \nConsideriamo dunque il resto dei dati (N dati), ottenuto \nscorporando un training set di dimensione adeguata dai dati \ndisponibili.\nSuddividiamo tali N dati in K blocchi, assegnando casualmente  \ni dati a ciascuno dei blocchi:\nResto dei dati \nN/K N/K N/K ………….1 2 K ……….",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#39": " \n40\nk-fold Cross Validation \nPer ciascuno dei K blocchi, operiamo considerandolo il \nValidation Set, utilizzando quindi i dati rimanenti come \nTraining Set.\nIn sostanza, dopo aver ﬁssato un valore per λ, operiamo \ncome segue per il primo blocco (ricordiamoci che in verde \nabbiamo il Training Set):\nValidation\n Set\nˆw(1)\n\u0000error 1(\u0000)1",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#4": "Esempio di funzione\n \n5\nApplichiamo rumore gaussiano, campioniamo 30 \nosservazioni e addestriamo vari modelli:y=s i n ( 4 x)",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#40": " \n41\nk-fold Cross Validation \nPer il secondo blocco abbiamo:\nValidation\n Set\nˆw(2)\n\u0000 error 2(\u0000)2",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#41": " \n42\nk-fold Cross Validation \n… e così via ﬁno al blocco K:\nValidation\n Set\nˆw(K)\n\u0000errorK(\u0000)K",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#42": " \n43\nk-fold Cross Validation \nL’algoritmo è il seguente:\nPer ogni scelta del valore di λ:\n for k = 1, 2, …., K \n   1. stima di ŵλ sui blocchi di training \n   2. calcolo dell’errore sul “validation block”:\nCalcolo dell’Average Error: CV(\u0000)=1\nK·KX\nk=1error k(\u0000)\nScelta di λ* che minimizza l’errore CV( λ)error k(\u0000)",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#43": " \n44\nleave-one-out Cross Validation \nFormalmente, la migliore approssimazione si ha per validation \nset di dimensione 1 (K = N).\nIn tal caso si parla di leave-one-out cross validation :\n123 n\n1 2 3 N\n2 3 N\n1 2 3 N\n1 2 3 N\n……………1…\n…\n…\n…\n…1 2 3 N",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#44": "Scelta del valore K \n \n45\nIl Leave-one-out è molto pesante dal punto di vista \ncomputazionale: \nrichiede il calcolo di N “ﬁt” del modello per ogni λ. \nIn genere, tipici valori utilizzati per K sono: \nK = 5 (5-fold CV) \nK = 10 (10-fold CV)",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#45": " \n46\nLa gestione dell’intercetta \nNella discussione su Ridge e Cross Validation non abbiamo \nconsiderato il come gestire l’intercetta, che compare in tanti  \nmodelli.\nyi=w0\u00000(xi)+w1\u00001(xi)+ ···+wD\u0000D(xi)+✏i=\n=DX\nj=0wj\u0000j(xi)+✏i\nRicordiamoci innanzi tutto il modello a “multiple regression”:\nSappiamo che spesso la feature ɸ0 è posta uguale a 1. In tal \ncaso il coefﬁciente w 0 rappresenta per l’appunto l’intercetta \ndel modello.",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#46": " \n47\nLa gestione dell’intercetta \nConosciamo bene la funzione di costo per la Ridge:\nMinimizzando tale funzione, anche l’intercetta w 0 (così \ncome gli altri coefﬁcienti) tende ad assumere piccoli valori.RSS(w)+\u0000·kwk2\n2\nIn realtà ciò non sarebbe necessario. L’intercetta non è \nindicativa dell’overﬁtting.",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#47": " \n48\nLa gestione dell’intercetta \nPossiamo dunque considerare una versione modiﬁcata della \nfunzione di costo per la Ridge:\nIn tal modo, la parte relativa alla L 2-norm (penalty) non \nconsidera w 0.\nVediamo come possiamo implementare ciò nel caso in cui si \nusi l’algoritmo di Gradient Descent.RSS(w0,wresto)+\u0000·kwrestok2\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#48": " \n49\nL’algoritmo viene modiﬁcato come segue:\nAlgoritmo di Gradient Descent \n[caso della Ridge Regression senza penalizzazione dell’intercetta] \nw(1)= 0 (oppure lo inizializziamo in modo casuale)\nt=1\nwhilekrcosto ridge( w(t))k2>✏\nfor j=0,1,. . . ,D\nderivata parziale RSS[ j]=\u00002NX\ni=1\u0000j(xi)[yi\u0000ˆyi(w(t))]\nifj=0\nw(t+1)\nj w(t)\nj\u0000↵⇤derivata parziale RSS[ j]\nelse\nw(t+1)\nj (1\u00002↵\u0000)w(t)\nj\u0000↵⇤derivata parziale RSS[ j]\nt t+1",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#49": "Riferimenti\n \n50\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , 3a edizione, \nApogeo, 2015. \nMachine Learning: Regression\n , University of Washington - Coursera, 2015. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. ",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#5": "Polinomio di grado 2\n \n6\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#6": "Polinomio di grado 4\n \n7\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#7": "Polinomio di grado 16\n \n8\n",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#8": "Overﬁtting con molte feature\n \n9\nQuesto fenomeno accade non solo nella polynomial \nregression, ma anche: \n quando è elevato il numero degli input d (e.g., per il \ncaso degli appartamenti, oltre alla metratura abbiamo \nil #bagni, ecc.); \ne, più in generale, quando è elevato il numero delle \nfeature ( D elevato):\nyi=DX\nj=0wj\u0000j(xi)+✏i",
    "data_test\\rootfolder\\università\\MachineLearning\\5-Ridge Regression - Cross Validation-sbloccato.pdf#9": "Overﬁtting e #osservazioni\n \n10\nIl problema dell’overﬁtting, che in genere aumenta \nall’aumentare della complessità del modello, dipende \nanche dal numero delle osservazioni di cui disponiamo: \nPoche osservazioni (N piccolo) → è facile avere overﬁt al crescere \ndella complessità del modello. \nTante osservazioni (N molto grande)  → è più  difﬁcile avere overﬁt.Prezzo\nPrezzo\nArea Area",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nFeature Selection e LASSO\nMachine Learning \n \n1",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#1": "Sommario\nLa Selezione delle Feature nella Regression \nAlgoritmo All Subsets \nApproccio Greedy per Feature Selection (Forward Stepsize \nAlgorithm) \nAlgoritmo Coordinate Descent \nLASSO \nConfronto tra Ridge e LASSO\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#10": " \n11\nLa scelta del Modello \nCi sono varie possibilità: \nValutazione delle prestazioni sul validation set (se abbiamo dati sufﬁcienti) \nCross Validation \nAltre metriche proposte in letteratura che penalizzano la “model \ncomplexity”\nLa domanda ora è la seguente: quale conﬁgurazione di \nfeature scegliamo? \nCome sappiamo, non conviene scegliere il modello con RSS \npiù basso, che diminuisce all’aumentare della complessità del \nmodello.",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#11": "Complessità di “All Subsets”\n \n12\nLa complessità computazionale dell’algoritmo è elevata: basti \nconsiderare il numero di modelli da valutare! E’ esponenziale \nrispetto al numero delle feature:\n[000 ···0]\n[100 ···0]\n[010 ···0]\n···\n[110 ···0]\n···\n[111 ···1]yi= ✏i\nyi=w0\u00000(xi)+✏i\nyi=w1\u00001(xi)+✏i\n··· ··· ···\nyi=w0\u00000(xi)+w1\u00001(xi)+✏i\n··· ··· ···\nyi=w0\u00000(xi)+w1\u00001(xi)+ ···+wD\u0000D(xi)+✏i\n2D+1feature vector",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#12": "Algoritmi Greedy\n \n13\nUn approccio alternativo è quello di utilizzare algoritmi \ngreedy che ci consentono di ottenere soluzioni sub-ottime, \nma con complessità computazionale molto più bassa.\nL’algoritmo che ora vedremo si chiama Forward Stepsize \nAlgorithm. Esso si distingue dal precedente perché, \nall’aumentare del numero di feature, sceglie solo una nuova \nfeature conservando quelle scelte nei passi precedenti.",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#13": "Forward Stepsize Algorithm\n \n14\nPartiamo dalla ﬁgura che rappresenta la fase ﬁnale di All Subsets:\n# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#14": " \n15\nVediamo come il Forward Stepsize si differenzia:\n# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nForward Stepsize Algorithm",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#15": " \n16\nPer #features = 1 sceglie la migliore:\n# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nForward Stepsize Algorithm",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#16": " \n17\n# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nForward Stepsize Algorithm\nderiva dal passo  \nprecedente\nPer #features = 2 aggiunge alla 1\n a\n già scelta la 2\n a\n migliore:",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#17": " \n18\nPer #features = 2 aggiunge alla 1\n a\n già scelta la 2\n a\n migliore:\n# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nForward Stepsize Algorithm\nseconda feature \nselezionata",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#18": " \n19\nE’ evidente la differenza rispetto all’algoritmo All Subset:\n# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nForward Stepsize Algorithm\nfeature selezionate da \n“all subset algorithm”",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#19": " \n20\n… e così via …\n# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nForward Stepsize Algorithm",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#2": "Selezione delle Feature\n \n3\nLa selezione delle feature nella regression è una fase molto \nimportante per due motivi: \n1. Efﬁcienza di elaborazione : \n•Se la dimensione di w è elevata (e.g., 100B) la predizione è \nmolto pesante computazionalmente. \n•Del resto, se ŵ è sparso, il calcolo dipende solo dai valori \nnon nulli. \n2. Interpretabilità : \n• Quali feature sono rilevanti per la nostra  predizione? ",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#20": " \n21\n… ﬁno al caso che considera tutte le feature:\n# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nForward Stepsize Algorithm",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#21": " \n22\nConsideriamo il dizionario delle feature {\n ɸ\n0\n, \nɸ\n1\n, … , \nɸ\nD\n} \nImpostiamo l’insieme delle feature F come segue: F\n 0\n = \n∅\n   (\no impostiamo \n ɸ\n0\n a 1\n); \naddestriamo e calcoliamo l’errore. \nt = 0 \n•\nPer ogni j (≠ dalle feature correnti), addestriamo il modello usando le \nfeature correnti F\n t\n + {\nɸ\nj\n(x)} per ottenere il vettore dei pesi \n ŵ\n per j. \n•\nSelezioniamo la best feature \n ɸ\nj*\n(x) (e.g., quella che dà luogo al training \nerror più basso quando addestriamo con F\n t\n + {\nɸ\nj*\n(x)}) \n•\nSet  F\n t+1\n <— F\n t \n+ {\nɸ\nj*\n(x)};  \n•\nt = t + 1 \n•\nRipetere il ciclo \nForward Stepsize Algorithm\nL’algoritmo in sintesi è il seguente:",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#22": " \n23\nLa complessità computazionale di questo algoritmo è \nsensibilmente minore di quella dell’All Stepsize Algorithm. \nInfatti, il numero di modelli valutati (con D feature) è il \nseguente: \n1° step: D modelli \n2° step: D-1 modelli (si aggiunge 1 feature tra le D-1 possibili) \n3° step: D-2 modelli (si aggiunge 1 feature tra le D-2 possibili) \necc.\nForward Stepsize Algorithm\nIl numero massimo di step è uguale a D. Abbiamo dunque: \nO(D2)",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#23": " \n24\nQuesto metodo, proposto da Robert Tibshirani nel 1996, consente \ndi effettuare una feature selection, oltre a limitare i valori assoluti \ndei coefﬁcienti w. \nLasso Regression usa la somma dei valori assoluti dei pesi ( L1 \nRegularization ). \nLa funzione che rappresenta il costo totale nel Lasso è dunque la \nseguente:    \ndove il parametro λ (tuning parameter ) serve per bilanciare i due \ntermini.                                              costo lasso(w)=R S S ( w)+\u0000·kwk1\nLASSO \n(\nLeast Absolute Shrinkage and Selection Operator\n )",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#24": " \n25Vediamo cosa accade a fronte di diversi valori del parametro λ: \nSe λ = 0: \nci riconduciamo alla vecchia soluzione, ossia minimizzazione \ndell’ RSS( w) → ŵLS \nSe λ → ∞: \nper soluzioni dove ŵ ≠ 0, il costo totale → ∞ \nl’unica soluzione per minimizzare il costo è: ŵlasso = 0 \nSe 0 < λ < ∞: \nSoluzioni Lasso \nper diversi valori \n λ\n0kˆwlassok1kˆwLSk1",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#25": "Andamento Coefﬁcienti \nRidge e Lasso\n \n26\nRidge Lasso\nλ λ ",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#26": "Visualizzazione costo Ridge\n \n27\nellissicosto ridge(w)=R S S ( w)+\u0000·kwk2\n2\nRSS(w)=NX\ni=1[yi\u0000w0\u00000(xi)\u0000w1\u00001(xi)]2",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#27": " \n28\ncirconferenzecosto ridge(w)=R S S ( w)+\u0000·kwk2\n2\nkwk2\n2=w2\n0+w2\n1\nVisualizzazione costo Ridge",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#28": "Simulazione Ridge\n \n29\nλ = 0\nλ→∞ˆwridge\nˆwridgeˆwridge\nˆwridge ˆwridge ˆwridge",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#29": " \n30\ncosto lasso(w)=R S S ( w)+\u0000·kwk1\nRSS(w)=NX\ni=1[yi\u0000w0\u00000(xi)\u0000w1\u00001(xi)]2ellissi\nVisualizzazione costo Lasso",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#3": "Selezione delle Feature\n \n4\nUn approccio che possiamo adottare per selezionare le \nmigliori feature consiste nel considerare ogni possibile \ncombinazione delle feature che abbiamo disponibili, \nveriﬁcando le prestazioni di ciascuna scelta. \nQuesto è esattamente ciò che fa l’ All Subset Algorithm  che \nora vediamo. \nEsso comincia considerando 0 feature, poi tutte le \npossibilità per 1 feature, poi tutte le possibilità per 2 \nfeature, ecc., scegliendo ogni volta la migliore \ncombinazione.",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#30": " \n31\nkwk1= |w0|+|w1|costo lasso(w)=R S S ( w)+\u0000·kwk1\ndiamonds \nVisualizzazione costo Lasso",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#31": "Simulazione Lasso\n \n32\nλ→∞λ = 0\nˆwlasso\nˆwlassoˆwlasso\nˆwlasso ˆwlasso ˆwlasso",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#32": "Confronto tra Ridge e Lasso\n \n33\nPer ogni valore di \n λ\n, per la Ridge esiste un certo valore \n s\n tale \nche le seguenti due equazioni forniscono le stesse stime dei \ncoefﬁcienti w\n ridge\n:\nargmin\nwRSS(w)\nsotto la condizione:DX\nj=0w2\njsargmin\nw[RSS(w)+\u0000·kwk2\n2]",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#33": "Confronto tra Ridge e Lasso\n \n34w1\nw0\nw2\n0+w2\n1s\nargmin\nwRSS(w)\nsotto la condizione:DX\nj=0w2\njs\nConsideriamo per semplicità il caso a 2 dimensioni. L’equazione: \nindica che i coefﬁcienti ŵridge stimati sono quelli che hanno il più \npiccolo RSS tra i punti appartenenti al cerchio deﬁnito da: w2\n0+w2\n1s",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#34": "Confronto tra Ridge e Lasso\n \n35\nAnalogamente, per ogni valore di \n λ\n, per il Lasso esiste un \ncerto valore \n s\n tale che le seguenti due equazioni forniscono \nle stesse stime dei coefﬁcienti w\n lasso\n:\nargmin\nwRSS(w)\nsotto la condizione:DX\nj=0|wj|sargmin\nw[RSS(w)+\u0000·kwk1]",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#35": "Confronto tra Ridge e Lasso\n \n36|w0|+|w1|sw0w1\n|w0|+|w1|s\nAnalogamente, la seguente equazione:  \nindica che i coefﬁcienti ŵlasso stimati sono quelli che hanno il più \npiccolo RSS tra i punti appartenenti al “diamante”: argmin\nwRSS(w)\nsotto la condizione:DX\nj=0|wj|s",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#36": "Confronto tra Ridge e Lasso\n \n37\nLa ﬁgura seguente ci mostra i punti di minimo per i due casi, e il \nperché Lasso spesso consente di eliminare alcune feature. In rosso \nsono indicate le curve di livello per RSS.\n|w0|+|w1|s w2\n0+w2\n1s\nw0w1\nw0w1\nˆwLSˆwLS\nˆwlasso ˆwridge",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#37": "Confronto tra Ridge e Lasso\n \n38\nSe \ns\n è sufﬁcientemente grande, le regioni in verde conterranno la \nsoluzione Least Squares. Pertanto le stime della Ridge regression e \ndel Lasso saranno le stesse della Least Squares (tale grande valore per \ns\n corrisponde a \n λ\n = 0) \nSe invece la soluzione Least Squares sta al di fuori delle regioni in \nverde, essa non può essere la soluzione perché non rispetta i vincoli \ncitati in precedenza. \nI punti di minimo sono dunque quelli che corrispondono alla curva \ndi livello più “stretta” che passa per l’area in verde (ricordiamoci che \nle curve di livello per RSS corrispondono a valori sempre più alti \nmano a mano che si “allargano” rispetto alla soluzione LS)",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#38": "Confronto tra Ridge e Lasso\n \n39\nNella ﬁgura abbiamo considerato il caso di 2 dimensioni per il \nvettore \n w\n. \nNel caso di 3 dimensioni la “constraint region” in verde diventa una \nsfera per la Ridge e un poliedro per il Lasso. \nNel caso di dimensione > 3, essa diventa una ipersfera per la Ridge e \nun politopo per il Lasso (politopo è un termine coniato da Alicia \nBoole, ﬁglia di George Boole)",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#39": "Minimizzazione della  \nfunzione di costo Lasso\nIn precedenza abbiamo visto come poter minimizzare la \nfunzione di costo (per LS e per Ridge) mediante: \nLa forma chiusa (uguagliando a zero il gradiente della \nfunzione) \nGradient Descent \nPer il Lasso ci sono delle difﬁcoltà per il calcolo del gradiente.\n \n40",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#4": "Ricerca delle migliori feature \nSize: 0\n \n5# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\n",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#40": "Minimizzazione della  \nfunzione di costo Lasso\nLa funzione da minimizzare è la seguente: \n \n41\nwj\n|wj|\nderivata = +1 derivata = -1\nnon derivabile\ncosto lasso(w)=R S S ( w)+\u0000·kwk1\ncome calcolare \nla derivata?",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#41": "Minimizzazione della  \nfunzione di costo\nNon possiamo quindi calcolare il gradiente della funzione. \nSuccessivamente vedremo come utilizzare il concetto di \nsubgradient\n  per superare la difﬁcoltà appena vista. \nOra cogliamo l’occasione per vedere un nuovo algoritmo per \nminimizzare una funzione di costo, chiamato \n Coordinate \nDescent\n . \nPresenteremo l’algoritmo in generale, per poi vedere come esso \npossa essere usato convenientemente per minimizzare la \nfunzione di costo per il Lasso.\n \n42",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#42": "Il nostro scopo è quello di minimizzare una certa funzione:\nAlgoritmo Coordinate Descent\ng(w)=g(w0,w1,···,wD)\nLa caratteristica distintiva del Coordinate Descent è che la \nminimizzazione avviene lungo una singola dimensione per \nvolta, come illustrato qui di seguito nel semplice caso di \nfunzione di due variabili w\n 0\n e w\n 1\n. \n \n43",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#43": "Algoritmo Coordinate Descent\nCurve di livello di una funzione g(\n w\n) da minimizzare:\n \n44\nw0w1\nscegliamo il \npunto inizialevalori di g( w) maggiori per  \ncurve di livello più esterne ",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#44": "Facciamo variare una sola coordinata:\n \n45\nw0w1\nw0\n0\nAlgoritmo Coordinate Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#45": "Troviamo il minimo e spostiamoci su tale punto (axis-alined move):\n \n46\nw0w1\nw0\n0\nAlgoritmo Coordinate Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#46": "Facciamo variare una sola altra coordinata:\n \n47\nw0w1\nw0\n1\nw0\n0\nAlgoritmo Coordinate Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#47": "Troviamo il minimo e passiamo su tale punto:\n \n48\nw0w1\nw0\n1\nw0\n0\nAlgoritmo Coordinate Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#48": "……. e così via …….\n \n49\nw0w1\nw0\n1\nw00\n0w0\n0\nAlgoritmo Coordinate Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#49": "………\n \n50\nw0w1\nw0\n1\nw00\n0w0\n0\nAlgoritmo Coordinate Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#5": " \n6# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nRicerca delle migliori feature \nSize: 1",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#50": "………\n \n51\nw0w1\nw0\n1w00\n1\nw00\n0w0\n0\nAlgoritmo Coordinate Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#51": "………\n \n52\nw0w1\nw0\n1w00\n1\nw00\n0w0\n0\nAlgoritmo Coordinate Descent",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#52": "…. ﬁno ad arrivare al minimo globale:\n \n53\nw0w1\nw0\n1w00\n1\nw00\n0w0\n0\n……\nAlgoritmo Coordinate Descent\nper problemi convessi, \nstep sempre più piccoli \nman mano che ci  \navviciniamo alla soluzione",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#53": "Algoritmo Coordinate Descent\n \n54\nInizializza ŵ = 0 (o in modo “smart”) \nwhile  not converged: \n   scegli una coordinata j\nsi minimizza solo sulla j-esima coordinataˆwj argmin\n!g(ˆw0,ˆw1,···,ˆwj\u00001,!,ˆwj+1,···,ˆwD)",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#54": "Algoritmo Coordinate Descent\n \n55\nCome scegliere nell’algoritmo la coordinata successiva? \nIn modo casuale (“random” o “stochastic\" coordinate descent) \nIn modo “round robin” \necc. \nSi noti che in questo algoritmo non è necessario scegliere lo step size! \nTale approccio è utilissimo per numerosi problemi \nConverge ad un ottimo in vari altri casi (e.g., funzione “strongly \nconvex”) \nConverge per la funzione obiettivo Lasso ",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#55": "Normalizzazione delle Feature\n \n56\nL’applicazione dell’algoritmo Coordinate Descent per il Lasso è \nsempliﬁcata se operiamo una normalizzazione delle feature. \nPer far questo dobbiamo prendere in considerazione la matrice \ndelle feature   usata in precedenza, nella quale ogni colonna \ncorrisponde ad una feature (0, 1, … D) applicata ai vari ingressi xi \ndei training data. \u0000",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#56": "Normalizzazione Feature\n \n57\u0000=2\n664\u00000(x1)\u00001(x1) ... \u0000j(x1) ... \u0000D(x1)\n\u00000(x2)\u00001(x2) ... \u0000j(x2) ... \u0000D(x2)\n... ... ... ... ... ...\n\u00000(xN)\u00001(xN) ... \u0000j(xN) ... \u0000D(xN)3\n775\n\u0000j(xk)=\u0000j(xk)qPN\ni=1\u00002\nj(xi)feature generica normalizzata:",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#57": "Normalizzazione delle Feature\n \n58Zj=vuutNX\ni=1\u00002\nj(xi)\nPer normalizzare abbiamo usato a denominatore il seguente \n“normalizer”: \nRicordiamoci che per i test data dovremo applicare lo stesso \nnormalizer.  ",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#58": "Coordinate Descent per \nUnregularized Regression\n \n59\nVediamo ora come sia possibile applicare l’algoritmo Coordinate \nDescent nel caso di regressione senza regularization, ossia nel \ncaso Least Squares. \nIl passo successivo sarà la sua applicazione al Lasso. \nPer l’applicazione al caso Least Squares (con feature \nnormalizzate) dobbiamo calcolare le derivare parziali della \nfunzione di costo RSS (necessarie per minimizzare sulla singola \ncoordinata): \nRSS(w)=NX\ni=1[yi\u0000DX\nj=0wj\u0000j(xi)]2",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#59": "Derivate di RSS \ncon feature normalizzate\n \n60@RSS(w)\n@wj=\u00002NX\ni=1\u0000j(xi)[yi\u0000ˆyi(w)] =\u00002NX\ni=1\u0000j(xi)[yi\u0000DX\nj=0wj\u0000j(xi)] =\n=\u00002NX\ni=1\u0000j(xi)[yi\u0000X\nk 6=jwk\u0000k(xi)\u0000wj\u0000j(xi)] =\n=\u00002⇢jz }| {\nNX\ni=1\u0000j(xi)[yi\u0000X\nk 6=jwk\u0000k(xi)]\n| {z }\nprediz. senza \u0000j+2wj,1z}|{\nNX\ni=1\u00002\nj(xi)=\n=\u00002⇢j+2wj",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#6": " \n7# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nmigliore feature\nRicerca delle migliori feature \nSize: 1",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#60": "Ricerca del minimo per una \ncoordinata\n \n61⇢j=NX\ni=1\u0000j(xi)[yi\u0000X\nk6=jwk\u0000k(xi)] =NX\ni=1\u0000j(xi)[yi\u0000ˆyi(ˆw\u0000j)]@RSS(w)\n@wj=\u00002⇢j+2wj=0\nˆwj=⇢j\ndove:",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#61": "Algoritmo Coordinate Descent \nper Least Squares\n \n62set:calcola:\nInizializza ŵ = 0 (o in altro modo) \nwhile  not converged: \n   for j = 0, 1, …, D:\n⇢j=NX\ni=1\u0000j(xi)[z}| {\nyi\u0000ˆyi(ˆw\u0000j)|{z}]residual senza la feature j\npredizione senza \nla feature j\nˆwj=⇢j",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#62": " \n63ˆwj=8\n<\n:⇢j+\u0000\n2se⇢j<\u0000\u0000\n2\n0 se ⇢j2[\u0000\u0000\n2,\u0000\n2]\n⇢j\u0000\u0000\n2se⇢j>\u0000\n2\nAlgoritmo Coordinate Descent \nper Lasso\nVediamo ora la versione dell’algoritmo per il caso del Lasso. \nIn questo caso l’impostazione per il peso \n ŵ\nj\n dipende dal valore \nassunto dal parametro \n λ\n: \nUna dimostrazione formale è mostrata nella prossima lezione. ",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#63": "Coefﬁcienti per LS, Ridge e Lasso\n \n64ˆwj=8\n<\n:⇢j+\u0000\n2se⇢j<\u0000\u0000\n2\n0 se ⇢j2[\u0000\u0000\n2,\u0000\n2]\n⇢j\u0000\u0000\n2se⇢j>\u0000\n2\nsoft thresholding\n+\u0000\n2\u0000\u0000\n2⇢i 0 0 ⇢i0 0ˆwj ˆwj",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#64": "Algoritmo Coordinate Descent \nper Lasso  \n[versione con feature normalizzate]\n \n65ˆwj=8\n<\n:⇢j+\u0000\n2se⇢j<\u0000\u0000\n2\n0 se ⇢j2[\u0000\u0000\n2,\u0000\n2]\n⇢j\u0000\u0000\n2se⇢j>\u0000\n2set:calcola:\nInizializza ŵ = 0 (o in altro modo) \nwhile  not converged: \n   for j = 0, 1, …, D:\n⇢j=NX\ni=1\u0000j(xi)[yi\u0000ˆyi(ˆw\u0000j)]",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#65": "Algoritmo Coordinate Descent \nper Lasso  \n[versione con feature non normalizzate]\n \n66\ncalcola:  \nInizializza ŵ = 0 (o in altro modo) \nwhile  not converged: \n   for j = 0, 1, …, D:\nset:calcola:\nˆwj=8\n><\n>:⇢j+\u0000\n2\nzjse⇢j<\u0000\u0000\n2\n0 se ⇢j2[\u0000\u0000\n2,\u0000\n2]\n⇢j\u0000\u0000\n2\nzjse⇢j>\u0000\n2zj=NX\ni=1\u0000j(xi)2\n⇢j=NX\ni=1\u0000j(xi)[yi\u0000ˆyi(ˆw\u0000j)]",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#66": " \n67\nUn aspetto importante è il criterio di convergenza. \nPer problemi convessi (in particolare strongly convex) gli step \nsono sempre più piccoli mano a mano che ci si avvicina al \npunto di ottimo:\nAlgoritmo Coordinate Descent \nper Lasso\nUn criterio che possiamo utilizzare per la convergenza è quello \ndi considerare una misura degli step fatti in un ciclo completo su \ntutte le feature e fermarsi quando: \n max step < \n ε",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#67": "Scelta del parametro \n λ\nper approfondimenti: \nMurphy, K. “\n Machine Learning: A Probabilistic Perspective\n ”. The MIT Press, \n2012.\n \n68\nIl parametro \n λ\n può essere scelto avvalendosi dell’approccio che \nusa il validation set, a patto di avere un numero sufﬁciente di \nosservazioni. \nAltrimenti possiamo usare la k-fold cross validation. \nQuest’ultima tende a scegliere il parametro che ottiene la \nmigliore “predictive accuracy”. Essa tende a favorire soluzioni \nmeno “sparse”, ossia con piccoli valori di \n λ\n, anziché soluzioni \ncon maggiore feature selection.",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#68": "Riferimenti\n \n69\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , Apogeo, 2015. \nMachine Learning: Regression\n , University of Washington - Coursera, 2015. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. \nMurphy, K.P. \n Machine Learning - A Probabilistic Approach\n , The MIT Press, 2012.",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#7": " \n8# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nmigliori 2 feature\nRicerca delle migliori feature \nSize: 2",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#8": " \n9\nRicerca delle migliori feature \nSize: 8\n# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront",
    "data_test\\rootfolder\\università\\MachineLearning\\6-Regression - FS  Lasso-sbloccato.pdf#9": " \n10# di featuresRSS(ŵ)\n0 1 2 3 4 5 6 7 8 •# bedrooms \n•# bathrooms \n•sq.ft. living \n•sq.ft. lot \n•ﬂoors \n•year built \n•year renovated \n•waterfront\nRicerca delle migliori feature  \nandamento in base al numero di feature",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nDimostrazioni Formali Lasso\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#1": "Sommario\n \n2Dimostrazione della formula di aggiornamento dei \ncoefﬁcienti nell’algoritmo coordinate descent per \nLASSO\n",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#10": "Differential set della  \nfunzione di costo Lasso\n \n11\nIl differential set rispetto al generico peso w\n j\n è pertanto il seguente:\n@wj[costo lasso] = 2 zjwj\u00002⇢j+\u0000·@wj|wj|da RSS da L 1 penalty\n@wj[costo lasso] = 2 zjwj\u00002⇢j+8\n<\n:\u0000\u0000 sewj<0\n[\u0000\u0000,\u0000]s e wj=0\n\u0000 sewj>0\n",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#11": "Differential Set della  \nfunzione di costo Lasso  \n \n12\nAbbiamo pertanto la seguente espressione ﬁnale:\n@wj[costo lasso] =8\n<\n:2zjwj\u00002⇢j\u0000\u0000 sewj<0\n[\u00002⇢j\u0000\u0000,\u00002⇢j+\u0000]s e wj=0\n2zjwj\u00002⇢j+\u0000 sewj>0",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#12": "Soluzione ottima \n \n13\nSe uguagliamo a zero la precedente espressione, abbiamo tre casi:\ncaso 1 (\n w\nj  \n< 0\n):2zjˆwj\u00002⇢j\u0000\u0000=0\nˆwj=2⇢j+\u0000\n2zj=⇢j+\u0000\n2\nzj\nˆwj=⇢j+\u0000\n2\nzj<0 ⇢j+\u0000\n2<0 ⇢j<\u0000\u0000\n2\nda cui otteniamo:\nPoiché \n ŵ\nj  \n< 0, abbiamo:",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#13": "Soluzione ottima \n \n14\nAbbiamo dunque:\nIn deﬁnitiva:\ncaso 2 ( wj  = 0): l’intervallo                                            deve contenere 0 [\u00002⇢j\u0000\u0000,\u00002⇢j+\u0000]\n\u0000\u0000\n2⇢j\u0000\n2\u00002⇢j+\u0000\u00000\u00002⇢j\u0000\u00000\n⇢j\u0000\n2⇢j\u0000\u0000\u0000\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#14": "Soluzione ottima \n \n15\ncaso 3 (\n w\nj  \n> 0\n):\nda cui otteniamo:\nPoiché \n ŵ\nj  \n> 0, abbiamo:2zjˆwj\u00002⇢j+\u0000=0\nˆwj=2⇢j\u0000\u0000\n2zj=⇢j\u0000\u0000\n2\nzj\nˆwj=⇢j\u0000\u0000\n2\nzj>0 ⇢j\u0000\u0000\n2>0 ⇢j>\u0000\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#15": " \n16\nIn conclusione:\nˆwj=8\n><\n>:⇢j+\u0000\n2\nzjse⇢j<\u0000\u0000\n2\n0 se ⇢j2[\u0000\u0000\n2,\u0000\n2]\n⇢j\u0000\u0000\n2\nzjse⇢j>\u0000\n2@wj[costo lasso] =8\n<\n:2zjwj\u00002⇢j\u0000\u0000 sewj<0\n[\u00002⇢j\u0000\u0000,\u00002⇢j+\u0000]s e wj=0\n2zjwj\u00002⇢j+\u0000 sewj>0\nSoluzione ottima ",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#16": "Algoritmo Coordinate Descent \nper Lasso  \n[versione con feature non normalizzate]\n \n17\ncalcola:  \nInizializza ŵ = 0 (o in altro modo) \nwhile  not converged: \n   for j = 0, 1, …, D:\nset:calcola:\nˆwj=8\n><\n>:⇢j+\u0000\n2\nzjse⇢j<\u0000\u0000\n2\n0 se ⇢j2[\u0000\u0000\n2,\u0000\n2]\n⇢j\u0000\u0000\n2\nzjse⇢j>\u0000\n2zj=NX\ni=1\u0000j(xi)2\n⇢j=NX\ni=1\u0000j(xi)[yi\u0000ˆyi(ˆw\u0000j)]",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#17": "Coefﬁcienti per LS, Ridge e Lasso\n \n18\nsoft thresholding\n+\u0000\n2\u0000\u0000\n2⇢i 0 0 ⇢i0 0ˆwj ˆwjˆwj=8\n><\n>:⇢j+\u0000\n2\nzjse⇢j<\u0000\u0000\n2\n0 se ⇢j2[\u0000\u0000\n2,\u0000\n2]\n⇢j\u0000\u0000\n2\nzjse⇢j>\u0000\n2",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#18": "Riferimenti\n \n19\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , Apogeo, 2015. \nMachine Learning: Regression\n , University of Washington - Coursera, 2015. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. \nMurphy, K.P. \n Machine Learning - A Probabilistic Approach\n , The MIT Press, 2012.",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#2": "Ottimizzazione Lasso\n \n3\nCome sappiamo, la Funzione Obiettivo per il Lasso da ottimizzare \nmediante Coordinate Descent è la seguente:\nRSS(w)+\u0000·kwk1=NX\ni=1[yi\u0000DX\nj=0wj\u0000j(xi)]2+\u0000DX\nj=0|wj|\nVediamo come calcolare le derivate parziali dei due termini \npresenti nell’espressione rispetto ai pesi w j.",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#3": "Derivazione del termine RSS\n \n4RSS(w)+\u0000·kwk1=NX\ni=1[yi\u0000DX\nj=0wj\u0000j(xi)]2+\u0000DX\nj=0|wj|\n@RSS(w)\n@wj=\u00002NX\ni=1\u0000j(xi)[yi\u0000ˆyi(w)] =\u00002NX\ni=1\u0000j(xi)[yi\u0000DX\nj=0wj\u0000j(xi)] =\n=\u00002NX\ni=1\u0000j(xi)[yi\u0000X\nk 6=jwk\u0000k(xi)\u0000wj\u0000j(xi)] =\n=\u00002⇢jz }| {\nNX\ni=1\u0000j(xi)[yi\u0000X\nk 6=jwk\u0000k(xi)]\n| {z }\nprediz. senza \u0000j+2wj,zjz}|{\nNX\ni=1\u00002\nj(xi)=\n=\u00002⇢j+2wjzj",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#4": " \n5\nIn questo caso c’è il problema del calcolo della derivata parziale:\nRSS(w)+\u0000·kwk1=NX\ni=1[yi\u0000DX\nj=0wj\u0000j(xi)]2+\u0000DX\nj=0|wj|\n\u0000·@|wj|\n@wj=?\nDerivazione del termine L\n 1\n penalty\nderivata = +1 derivata = -1\nnon derivabilewj|wj|\n",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#5": "Subgradiente di Funzioni Convesse \n 6\nI metodi che conosciamo (e.g., Gradient Descent, Coordinate \nDescent) richiedono che la funzione da ottimizzare sia \ndifferenziabile. \nE’ possibile però generalizzare la discussione andando al di là \ndelle funzioni differenziabili. \nE’ possibile ad esempio mostrare come i precedenti algoritmi \npossano essere applicati anche per funzioni non differenziabili, \nutilizzando il subgradiente anziché il gradiente.",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#6": "Subgradiente di Funzioni Convesse\n \n7Un vettore S che soddisfa la: \nè detto subgradiente di g in v.g(w)\u0000g(v)+ST(w\u0000v)\n.wg(w)\nvS1pendenza \nS2 pendenza \n. \n. \n.g:R!R\nL’insieme dei subgradienti di g in v è chiamato “differential set” e \nindicato: @g(v)",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#7": "Subgradiente della funzione  \nValore Assoluto\n \n8\nNel punto non derivabile della funzione “valore assoluto” i \nsubgradienti variano da -1 a +1:\nderivata = +1 derivata = -1\nwj|wj|",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#8": "Subgradiente della funzione  \nValore Assoluto\n \n9\nIl “differential set” è dunque il seguente per i vari punti:\n@wj|wj|=8\n<\n:{\u00001} sewj<0\n[\u00001,1] se wj=0\n{1} sewj>0",
    "data_test\\rootfolder\\università\\MachineLearning\\7-Dimostrazioni-Lasso-sbloccato.pdf#9": "Subgradiente di L\n 1\n term\n \n10\nNel caso del Lasso abbiamo:\n\u0000·@wj|wj|=8\n<\n:\u0000\u0000 sewj<0\n[\u0000\u0000,\u0000]s e wj=0\n\u0000 sewj>0",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nRegressione:  \nFonti di Errore \nExpected Prediction Error\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#1": "Sommario\nLe tre fonti di errore: Noise, Bias, Variance \nDeﬁnizione e derivazione formale delle tre fonti di \nerrore \nExpected Prediction Error \n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#10": "Noise: \nVarianza dell’Errore del modello\n \n11\nEPE( xt)=\u00002+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]\ny=fw(true)(x)+ ✏\n\u00002= varianza di ✏",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#11": "Bias della funzione stimata \n \n12bias( fˆw(xt)) = fw(true) (xt)\u0000f¯w(xt)EPE( xt)=\u00002+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]\nx\nt(true) (true)\n(true)average \nestimated \nfunction:\nf¯w(xt),Etrain [fˆw(xt)]",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#12": "Varianza della funzione stimata \n \n13EPE( xt)=\u00002+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]\nvar(fˆw(xt)) =Etrain [(fˆw(xt)\u0000f¯w(xt))2]",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#13": "Dimostrazione per  \nl’Expected Prediction Error (EPE)\nVediamo ora come dimostrare la formula dell’EPE, in cui \nentrano in gioco i tre termini che abbiamo deﬁniti \nformalmente in precedenza:\n \n14EPE( xt)=\u00002+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#14": "Dimostrazione per  \nl’Expected Prediction Error (EPE)\nA tal ﬁne, ricordiamo innanzi tutto la deﬁnizione di tale \nerrore:\n \n15EPE = Etrain[Generalization Error per ˆw(train)] =\n=Etrain[Ex,y[L(y,f ˆw(train) (x))]]\n1.\n Consideriamo: \n2.\n Riferiamoci ad uno speciﬁco \n x\ntL[y, f ˆw(x)] = ( y\u0000ˆy)2=[y\u0000fˆw(x)]2\nFacciamo poi le seguenti due assunzioni (già citate prima):",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#15": "Dimostrazione per  \nl’Expected Prediction Error (EPE)\nCon le due assunzioni precedenti l’espressione per l’EPE \nsi sempliﬁca come segue:\n \n16EPE( xt)=Etrain ,yt[(yt\u0000ˆyt)2]=Etrain ,yt[(yt\u0000fˆw(train) (xt))2]\ndove non abbiamo più l’Expectation su \n x\n, avendo ﬁssato \nuno speciﬁco \n x\nt\n, e dove l’Expectation su y è diventata \nl’Expectation su y\n t\n perché dobbiamo considerare solo le \nosservazioni che abbiamo a fronte dell’input \n x\nt\n.",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#16": "Expected Prediction Error\nPartendo da tale espressione, vediamo come dimostrare la \nformula dell’EPE:\n \n17EPE( xt)= Etrain ,yt[(yt\u0000ˆyt)2]=Etrain ,yt[(yt\u0000fˆw(train) (xt))2]=\n=Etrain ,yt[(yt\u0000fz }| {\nfw(true) (xt)+fz }| {\nfw(true) (xt)\u0000ˆfz }| {\nfˆw(train) (xt))2]=\n=Etrain ,yt[((yt\u0000f)+(f\u0000ˆf))2]=\n=Etrain ,yt[(yt\u0000f)2+ 2(yt\u0000f)·(f\u0000ˆf)+(f\u0000ˆf)2]=\n=Etrain ,yt[(yt\u0000f)2]+2 ·Etrain ,yt[(yt\u0000f)·(f\u0000ˆf)] +Etrain ,yt[(f\u0000ˆf)2]",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#17": "Expected Prediction Error\n1° termine: Si sempliﬁca come segue, poiché  y\n t\n e f non \ndipendono dal training set:\n \n18\nSi noti che l’Expectation del quadrato dell’errore \n ε\n è la \nvarianza di \n ε\n, avendo esso media nulla.Etrain ,yt[(yt\u0000f)2]=Eyt[(yt\u0000f)2]=Eyt[✏2],\u00002",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#18": "Expected Prediction Error\n2° termine:\n \n192·Etrain ,yt[(yt\u0000f)·(f\u0000ˆf)] = 2 ·Etrain ,yt[(✏)·(f\u0000ˆf)] =\n=2 ·Etrain ,yt[✏]·Etrain ,yt[(f\u0000ˆf)] =\n=2 ·0·Etrain ,yt[(f\u0000ˆf)] = 0\nSi noti che ε è indipendente da  e da , e quindi è \nindipendente da           .  \nSi ricordi, inoltre, che l’Expectation dell’errore ε è uguale \na zero.ˆf f\n(f\u0000ˆf)",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#19": "Expected Prediction Error\n3° termine:\n \n20\nL’espressione per l’errore EPE può essere dunque scritta \ncosì:\nAbbiamo: Etrain ,yt[(f\u0000ˆf)2]=Etrain [(f\u0000ˆf)2]\nEPE( xt)=\u00002+M S E ( ˆf)MSE( ˆf),Etrain[(f\u0000ˆf)2]\nConsideriamo ora il Means Squared Error (MSE), deﬁnito \ncome segue:",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#2": "Deﬁnizione e derivazione \nformale\nOccupiamoci della deﬁnizione e derivazione formale delle \ntre sorgenti di errore: \nnoise \nbias \nvariance \nA tal ﬁne introduciamo innanzi tutto l’Expected Prediction \nError, le cui componenti sono le suddette sorgenti di errore.\n \n3",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#20": "Means Squared Error\nDobbiamo ora dimostrare che:\n \n21MSE[ fˆw(train) (xt)] = Etrain[(fw(true) (xt)\u0000fˆw(train) (xt))2]=\n=Etrain[(fz }| {\nfw(true) (xt)\u0000¯fz}|{\nf¯w(xt)+¯fz}|{\nf¯w(xt)\u0000ˆfz }| {\nfˆw(train) (xt))2]=\n=Etrain[((f\u0000¯f)+( ¯f\u0000ˆf))2]=\n=Etrain[(f\u0000¯f)2+ 2(f\u0000¯f)·(¯f\u0000ˆf)+( ¯f\u0000ˆf)2]=\n=Etrain[(f\u0000¯f)2]+2 ·Etrain[(f\u0000¯f)·(¯f\u0000ˆf)] +Etrain[(¯f\u0000ˆf)2]MSE( ˆf) = [bias( ˆf)]2+ var( ˆf)",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#21": "1° termine: ricordiamo che\n \n22\nNe consegue che:\npoiché   e    non dipendono dal training set. f¯f\nMeans Squared Error\n¯f,Etrain [ˆf]\nEtrain [(f\u0000¯f)2]=(f\u0000¯f)2,[bias( ˆf)]2",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#22": "2° termine:\n \n232·Etrain [(f\u0000¯f)·(¯f\u0000ˆf)] = 2 ·(f\u0000¯f)·Etrain [(¯f\u0000ˆf)] =\n=2 ·(f\u0000¯f)·(¯f\u0000Etrain [ˆf]) =\n=2 ·(f\u0000¯f)·(¯f\u0000¯f)=\n=2 ·(f\u0000¯f)·0=0\nMeans Squared Error",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#23": "Means Squared Error\n3° termine:\n \n24Etrain [(¯f\u0000ˆf)2]=Etrain [(ˆf\u0000¯f)2],var( ˆf)",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#24": "E’ in tal modo dimostrato che:\n \n25MSE( ˆf) = [bias( ˆf)]2+ var( ˆf)\nMeans Squared Error",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#25": "In conclusione:\n \n26EPE( xt)=\u00002+M S E [ fˆw(xt)] =\u00002+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]\nle 3 sorgenti di errore\nEspressione per \nExpected Prediction Error",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#26": "Riferimenti\n \n27\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , 3a edizione, \nApogeo, 2015. \nMachine Learning: Regression\n , University of Washington - Coursera, 2015. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. ",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#3": "Training Set Randomness\nUn Training Set è un campione di N osservazioni (e.g., N \nappartamenti venduti di cui conosciamo le features e il \nprezzo).  \nCosa accade se il Training Set è costituito da altre N \nosservazioni diverse dalle precedenti?  \nCome cambiano le prestazioni del sistema?\n \n4",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#4": "Training Set Randomness\nAd esempio, nella ﬁgura sono mostrate due situazioni \nrelative a due diverse scelte del training set:\n \n5Test Set\nPer valutare la prestazione dei due “ﬁt” dobbiamo \nprendere in considerazione il Generalization Error.",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#5": "Training Set Randomness\nNei due casi otterremo due diversi valori del \nGeneralization Error:\n \n6Test Set\n",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#6": "Expected Prediction Error\nIdealmente, vorremmo poter ottenere una misura delle \nprestazioni del sistema, mediata su tutti i possibili training \nset. \nPossiamo deﬁnire formalmente tale quantità, che \nchiamiamo Expected Prediction Error (EPE), come segue: \n \n7EPE = Etrain[Generalization Error per ˆw(train)]\n“averaging” su tutti i possibili Training Set \n(pesati in base alle loro probabilità)parametri calcolati su \nuno speciﬁco Training Set",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#7": "Expected Prediction Error \nsu un target input\nPer analizzare questo tipo di errore, cominciamo a \nprendere in considerazione uno speciﬁco punto \n x\nt\n: \n \n8Test \nx\nt\nSupponiamo  inoltre che la Loss function sia la seguente: \nL[y, f ˆw(x)] = ( y\u0000ˆy)2=[y\u0000fˆw(x)]2",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#8": "Expected Prediction Error \nsu un target input\nE’ possibile dimostrare che l’errore EPE in \n x\nt\n è uguale alla \nsomma di tre termini:\n \n9\nVediamo ora di illustrare adeguatamente tali tre termini.EPE( xt)=\u00002+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]",
    "data_test\\rootfolder\\università\\MachineLearning\\8-Expected Prediction Error-sbloccato.pdf#9": "Noise: \nVarianza dell’Errore del modello\n \n10EPE( xt)=\u00002+ [bias( fˆw(xt))]2+ var[ fˆw(xt)]\nfw(true) (x)\n",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#0": "Università Roma Tre \nDipartimento di Ingegneria \nAnno Accademico 2021 - 2022 \nIntroduzione  \nalla  \nClassiﬁcazione\nMachine Learning ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#1": "Sommario\nIntroduzione alla Classiﬁcazione \nEsempi di applicazione della Classiﬁcazione \nDecision Boundary \nLogistic Regression \nMaximum Likelihood Estimation \nTraining mediante Gradient Ascent\n \n2",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#10": "Introduzione alla Classiﬁcazione\n \n11\n•Come si vede in ﬁgura, tutte le immagini del test set, tranne una, \nsono classiﬁcate correttamente. \n•L’errore per il Boston terrier  è dovuto completamente alla nostra \nscelta delle features, scelta fatta basandoci sul training set \ndisponibile (un po’ troppo piccolo). \n•Per migliorare dobbiamo perciò ricominciare, collezionando più \ndati e individuare più features.",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#11": "Learning Pipeline\n \n12\n•In ﬁgura è rappresentata la learning pipeline del problema di \nclassiﬁcazione che stiamo considerando. \n•Lo stesso processo è usato essenzialmente per tutti i task di \nMachine Learning, non solo per la classiﬁcazione. ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#12": "Learning Pipeline\n \n13•Deﬁnire il problema . Qual è il task che vogliamo sia appreso dal \ncomputer? \n•Collezionare i dati . Raccogliere i dati per il training set e il test set. Più \ni dati sono numerosi e diversiﬁcati, meglio è per il successo del \nsistema da realizzare. \n•Individuare le features . Quali sono le features migliori per descrivere i \ndati? \n•Addestrare il modello . Scegliere il modello e calibrare i suoi parametri \nsul training set mediante metodi di ottimizzazione. \n•Testare il modello . Valutare sul test set le prestazioni del modello \naddestrato. Se i risultati non sono soddisfacenti, ripensare la scelta \ndelle features utilizzate e collezionare, se possibile, più dati. ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#13": "Minimizzazione di una funzione di costo\n \n14\nCaso della regressione:",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#14": "Minimizzazione di una funzione di costo\n \n15\nCaso della classiﬁcazione:",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#15": "Esempi di applicazione \nObject Detection\n \n16\n",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#16": "Esempi di applicazione \nSpam Filtering\n \n17(Testo della email, \nmittente, IP, ecc.)\nInput: x Output: ŷ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#17": "Esempi di applicazione \nImage Classiﬁcation\n \n18\nInput: x Output: ŷ\n(pixel dell’immagine) (categoria predetta)",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#18": "Esempi di applicazione \nDiagnosi Mediche Personalizzate \n \n19Input: x Output: ŷ\n",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#19": "Esempi di applicazione \nReading Your Mind\n \n20\nOutput: ŷ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#2": "Introduzione alla Classiﬁcazione\nIl task della \n Classiﬁcazione\n  è simile in linea di principio a \nquello della \n Regressione  \nLa vera differenza tra i due è che, anziché predire un valore di \noutput continuo, nella classiﬁcazione cerchiamo di prevedere \nvalori discreti o \n classi \n \n3",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#20": "Esempi di applicazione \n \n21Sentiment Analysis\nEsempio: classiﬁcatore di reviews di ristorantiInput: xOutput: ŷ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#21": "Esempi di applicazione \nSentiment Analysis\n \n22\nInput x:  In questo ristorante preparano i migliori  \n“spaghetti alla carbonara” di Roma\nŷ = +1",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#22": "Punteggio di una frase \n(\nScore\n ) \n \n23Termine Peso w\nmigliore 1.5\nbuono 1.0\ncattivo -1.0\nmagniﬁco 2.0\nterribile -2.1\neccezionale 2.7\nil, noi, dove, ecc. 0.0Un modo che possiamo adottare per classiﬁcare una review come \npositiva o negativa consiste nel considerare alcuni “termini” che \nriteniamo rilevanti ai ﬁni della classiﬁcazione, calcolando per ciascuno \ndi essi il numero di occorrenze con cui compare nella review e un \n“valore di rilevanza” (peso) da utilizzare per calcolare un “punteggio”. \nAd esempio:",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#23": " \n24x1 = #eccezionalex2 = #terribile\n+\n++ ++-\n--\n-\n+Score( x) = 2.7 x1 - 2.1 x2Termine Peso w\neccezionale 2.7\nterribile -2.1\nPunteggio di una frase \n(\nScore\n ) \n-Score( x) < 0\nScore( x) > 0r:  2.7 x1 - 2.1 x2 = 0  \n      (decision boundary)",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#24": " \n25+\n++ ++-\n--\n-\n+Termine Peso w\neccezionale 2.7\nterribile -2.1\nPunteggio di una frase \n(\nScore\n ) \n+Score( x) < 0\nScore( x) > 0\nx1 = #eccezionalex2 = #terribiler:  1.0 + 2.7 x1 - 2.1 x2 = 0 \n    (decision boundary)Score( x) = 1.0 + 2.7 x1 - 2.1 x2",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#25": " 26\nˆyi= sign[Score( xi)]Nel caso in cui i termini siano d possiamo calcolare il punteggio \ncome segue:\ne classiﬁcare la review in questo modo:\nPunteggio di una frase \n(\nScore\n ) \ndove:\nsign(Score) =⇢+1 se Score >0\n\u00001 se Score <0",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#26": " 27ˆyi= sign[Score( xi)]Score( xi)= w0\u00000(xi)+w1\u00001(xi)+ ···+wD\u0000D(xi)=\n=DX\nj=0wj\u0000j(xi)=wT·\u0000(xi)Nel caso generale di classiﬁcazione binaria abbiamo:\nPunteggio di una frase \n(\nScore\n ) ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#27": "Afﬁdabilità della Previsione \n 28•La funzione sign vista in precedenza ci fornisce una \nclassiﬁcazione binaria del sentiment della revisione. \n•Potremmo però essere interessati anche ad avere un grado di \nconﬁdenza della previsione. \n•Ad esempio, potremmo voler distinguere il caso di uno \nScore di poco superiore allo zero (e.g., 0.1) dal caso di uno \nScore ben più elevato (e.g., 4.0), punteggi che in entrambi i \ncasi danno luogo a review positive. ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#28": "Probabilità come “degree of belief” \n 290 1P(yi = +1)\nAssolutamente certo \nreview negative0.5\nAssolutamente certo \nreview positive\nNon so se le review  \nsono positive o negative•A tale scopo possiamo avvalerci del calcolo delle probabilità. \n•Se diciamo che la probabilità di avere y i = +1 è di 0.7, vogliamo \ndire che ci aspettiamo di avere nell’insieme delle review \ndisponibili il 70% di review positive. ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#29": "Probabilità come “degree of belief” \nProbabilità Condizionate \n 30•E’ molto utile in tale contesto considerare le probabilità \ncondizionate. \n•Se diciamo ad esempio che la probabilità di avere una review \npositiva, condizionata al fatto di avere nella review 3 occorrenze \ndi “eccezionale” ed 1 di “terribile”, è di 0.9, vogliamo dire che ci \naspettiamo il 90% delle review positive nella lista delle review \ndisponibili, considerando però solo quelle che hanno 3 \n“eccezionale” e 1 “terribile” (in verde nella ﬁgura che segue). ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#3": "Introduzione alla Classiﬁcazione\nIn buona sostanza, un classiﬁcatore realizza un mapping: \ndove  \n    è l’\n instance space\n , ossia l’insieme di tutte le possibili \nistanze del problema. Se esse sono descritte da un numero \nprecisato di features, abbiamo: \n \n    è un ﬁnito e in genere piccolo insieme di \n class labels\n : \n \n4C\nC=[C1,C2,...,C k]X!C\nX=[F1⇥F2⇥···⇥FD]X",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#30": " \n31 xi : testo della review yi: sentiment\nIl cacio e pepe era delizioso. +1\nLa carbonara era eccezionale. L’ambiente terribile. Il servizio eccezionale. \nComplessivamente un ristorante eccezionale.+1\nMia moglie ha preso i carcioﬁ alla romana, che erano pessimi. -1\n………… -1\n………… +1\n……. eccezionale ……… terribile …… eccezionale …… eccezionale -1\n………… +1\n……. eccezionale ……… terribile …… eccezionale …… eccezionale +1P(y i = +1| 3 eccezionale & 1 terribile) = 0.9Probabilità come “degree of belief” \nProbabilità Condizionate ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#31": " 320 1P(yi = +1| xi)\nAssolutamente certo \nche xi è negativa0.5\nAssolutamente certo \nche xi è positiva\nNon sono sicuro se la xi  \nè positiva o negativaIn generale, dato un input xi, (e.g., una review) abbiamo la \nseguente situazione: Probabilità come “degree of belief” \nProbabilità Condizionate ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#32": "Link Function \n 33Score( xi, w)- ∞ + ∞ •Il problema che dobbiamo risolvere, se vogliamo avvalerci delle \nprobabilità condizionate, è capire come passare dai valori dello \nScore a quelli delle probabilità. \n•La funzione Score ha un range che va da -∞ a +∞: \n•La probabilità, come sappiamo, può variare da 0 a 1:  \n0 1P(yi = +1| xi)",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#33": " 34Score( xi, w)\n- ∞ + ∞ \n0 10\n0.5\nP(yi = +1| xi, w) = g[Score( xi, w)]Link Function \n•Dobbiamo pertanto deﬁnire una “link function” g (generalized \nlinear model ) che realizzi un mapping tra i due intervalli: ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#34": " \n35\n•Una funzione tipicamente usata in questi casi è la funzione \nlogistica , o sigmoide , così deﬁnita:Link Function \n•Essa, come si vede, ha l’insieme di deﬁnizione costituito \ndall’intervallo (-∞, +∞) e come codominio l’intervallo [0, 1].  ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#35": " 36Score( xi, w)\n- ∞ + ∞ \n0 10\n0.5\nP(yi = +1| xi, w) = sigmoid [Score( xi, w)]Logistic Regression Model \n•Il nostro modello diventa dunque il seguente: ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#36": " 37Logistic Regression Model \n•L’espressione per la probabilità, dato un ingresso xi ed un vettore \ndei pesi calcolato ŵ, è dunque la seguente: \nˆP(yi=+ 1 |xi,ˆw)=1\n1+e\u0000ˆwT·\u0000(xi)",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#37": " 38Il Processo di Training \n•Il processo di training consiste nel deﬁnire una funzione di costo, \no una funzione che misura la “qualità” della previsione, e nel \ndeterminare la conﬁgurazione dei pesi (vettore w) che ottimizza \nla funzione per gli esempi di training. \n•Nella ﬁgura che segue sono mostrati i passi relativi a tale \nprocesso. ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#38": "Il Processo di Training \n[caso della Classiﬁcazione]\nDati di \nTraining\nEstrazione \ndelle \nFeatures  \nModello \ndi ML\nmetrica \nvalutazione \nqualità\nCalcolo vettore \ndei pesi ŵyi osservato(xi)\n 39xi\nFunzione  \nvalutazione \nqualitàŵɸ\n(N esempi)\nAlgoritmo di \nApprendimentoˆP(yi=+ 1 |xi,ˆw)",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#39": "Funzione per Valutazione Qualità \n \n40•Dobbiamo ora deﬁnire una funzione che possiamo usare per la \nvalutazione della qualità delle prestazioni del sistema. \n•A tal ﬁne possiamo prendere in considerazione le probabilità \ncondizionate deﬁnite in precedenza. \n•in particolare, per ciascuno degli esempi di training ( xi, yi) che \nabbiamo disponibili, possiamo calcolare la probabilità di avere in \nuscita un valore y i dato un vettore di pesi w (vedi ﬁgura seguente). ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#4": "Introduzione alla Classiﬁcazione\n \n5\nVediamo un semplice esempio di classiﬁcazione: \nSupponiamo di voler addestrare un computer a distinguere \nimmagini di gatti da immagini di cani (\n task\n). \n•\nDobbiamo innanzi tutto procurarci un certo numero di \nimmagini (\n training set\n ) in modo da poter addestrare il \ncomputer: \n",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#40": "Maximum Likelihood Estimation \n(\nMLE\n)\n \n41Data Point xi,1 xi,2 yi Scegliere w che massimizza:\nx1, y1 2 1 +1 P(y 1=+1| x1, w)\nx2, y2 0 2 -1 P(y 2=-1| x2, w)\nx3, y3 3 3 -1 P(y 3=-1| x3, w)\nx4, y4 4 1 +1 P(y 4=+1| x4, w)\nL(w)=P(y1|x1,w)·P(y2|x2,w)·P(y3|x3,w)·P(y4|x4,w)La funzione che possiamo usare per la valutazione della qualità è: ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#41": " \n42L(w)=NY\ni=1P(yi|xi,w)La forma generale della funzione Likelihood  è:\nL’obiettivo è dunque quello di massimizzare tale funzione, ad \nesempio mediante Hill Climbing (o Gradient Ascent ), visto che \nnon si ha una forma chiusa:\nmax\nwL(w) = max\nwNY\ni=1P(yi|xi,w)\nMaximum Likelihood Estimation \n(\nMLE\n)",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#42": " \n43•Per il calcolo del gradiente dobbiamo calcolare le varie derivate parziali \ndella funzione. \n•Possiamo sempliﬁcare tale calcolo trasformando la funzione,  \nconsiderando il logaritmo naturale del Likelihood: \n•In tal modo trasformiamo i prodotti in somme, pur non cambiando il \npunto di massimo assoluto. Infatti si ha:lnL(w)=l nNY\ni=1P(yi|xi,w)=NX\ni=1lnP(yi|xi,w)\nˆw= argmax\nwL(w) ˆwln= argmax\nwlnL(w) ˆw=ˆwln\nLog-Likelihood \n[facilita l'operazione di derivazione]",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#43": "Log-Likelihood \n[facilita l'operazione di derivazione]\n \n44\ndove è stata utilizzata la Indicator Function :Per facilitare i calcoli possiamo riscrivere la funzione come segue:\nlnL(w)=NX\ni=1lnP(yi|xi,w)=\n=NX\ni=1{I[yi= +1] ·lnP(yi=+ 1 |xi,w)+I[yi=\u00001]·lnP(yi=\u00001|xi,w)}",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#44": " \n45\nLog-Likelihood \n[facilita l'operazione di derivazione]\nSostituendo alle probabilità P le seguenti espressioni:\notteniamo, per un solo punto  i, la forma che segue:P(yi=+ 1 |xi,w)=1\n1+e\u0000wT·\u0000(xi)\nP(yi=\u00001|xi,w)=1 \u0000P(yi=+ 1 |xi,w)=1\u00001\n1+e\u0000wT·\u0000(xi)=\n=1+e\u0000wT·\u0000(xi)\u00001\n1+e\u0000wT·\u0000(xi)=e\u0000wT·\u0000(xi)\n1+e\u0000wT·\u0000(xi)",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#45": "Forma della Funzione da Derivare \n[per un punto \n i\n] \n \n46lnL(w)= I[yi= +1] ·lnP(yi=+ 1 |xi,w)+I[yi=\u00001]·lnP(yi=\u00001|xi,w)=\n= I[yi= +1] ·ln1\n1+e\u0000wT·\u0000(xi)+( 1\u0000I[yi= +1]) ·lne\u0000wT·\u0000(xi)\n1+e\u0000wT·\u0000(xi)=\n=\u0000I[yi= +1] ·ln(1 + e\u0000wT·\u0000(xi))+\n+(1\u0000I[yi= +1]) ·[\u0000wT·\u0000(xi)\u0000ln(1 + e\u0000wT·\u0000(xi))] =\n=\u0000(1\u0000I[yi= +1]) wT·\u0000(xi)\u0000ln(1 + e\u0000wT·\u0000(xi))",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#46": " \n47\nRegole applicate:\nlne\u0000wT·\u0000(xi)\n1+e\u0000wT·\u0000(xi)=l n ( e\u0000wT·\u0000(xi))\u0000ln(1 + e\u0000wT·\u0000(xi))=\n=\u0000wT·\u0000(xi)\u0000ln(1 + e\u0000wT·\u0000(xi))ln1\n1+e\u0000wT·\u0000(xi)=\u0000ln(1 + e\u0000wT·\u0000(xi))\nForma della Funzione da Derivare \n[per un punto \n i\n] ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#47": " \n48lnL(w)=\u0000(1\u0000I[yi= +1]) wT·\u0000(xi)\u0000ln(1 + e\u0000wT·\u0000(xi))\nForma della Funzione da Derivare \n[per un punto \n i\n] ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#48": "Derivata Parziale per un punto\n \n49dove:\ne:Per uno solo punto i abbiamo:\n@(wT·\u0000(xi))\n@wj=\u0000j(xi)@lnL(w)\n@wj=\u0000(1\u0000I[yi= +1]) ·@(wT·\u0000(xi))\n@wj\u0000@\n@wjln(1 + e\u0000wT·\u0000(xi))=\n=\u0000(1\u0000I[yi= +1]) ·\u0000j(xi)+\u0000j(xi)·P(yi=\u00001|xi,w)=\n=\u0000j(xi){I[yi= +1]\u0000P(yi=+ 1 |xi,w)}\n@\n@wjln(1 + e\u0000wT·\u0000(xi))=\u0000\u0000j(xi)·e\u0000wT·\u0000(xi)\n1+e\u0000wT·\u0000(xi)=\u0000\u0000j(xi)·P(yi=\u00001|xi,w)",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#49": "Derivata parziale su tutti i punti\n \n50Sommando su tutti i punti i otteniamo:\nQuesta è la forma della derivata parziale che possiamo usare \nnell’algoritmo di Gradient Ascent  per trovare il vettore ŵ che \nottimizza la funzione:@lnL(w)\n@wj=NX\ni=1\u0000j(xi){\u0000tra valore vero e predettoz }| {\nI[yi= +1]\u0000P(yi=+ 1 |xi,w)}",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#5": "Introduzione alla Classiﬁcazione\n \n6\n•\nDobbiamo poi identiﬁcare le caratteristiche distintive \n(\nfeatures\n ) che ci possano consentire di distinguere le due \ntipologie di immagini. Nel nostro caso potremmo ad esempio \nscegliere le due seguenti: \n•\nDimensione del naso (da piccolo a grande) \n•\nForma delle orecchie (da arrotondate ad appuntite) \nsupponendo di essere in grado di estrarle dalle immagini. ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#50": "Algoritmo di Gradient Ascent\n \n51w(1)= 0 (oppure lo inizializziamo in modo casuale)\nt=1\nwhilekrlnL(w(t))k2>✏\nfor j=0,1,. . . ,D\nderivata parziale[ j]=NX\ni=1\u0000j(xi){I[yi= +1]\u0000P(yi=+ 1 |xi,w(t))}\nw(t+1)\nj w(t)\nj+↵⇤derivata parziale[ j]\nt t+1",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#51": "Riferimenti\n \n52\nWatt, J., Borhani, R., Katsaggelos, A.K. \n Machine Learning Reﬁned\n , 2nd edition, \nCambridge University Press, 2020. \nJames, G., Witten, D., Hastie, T., Tibishirani, R. \n An Introduction to Statistical \nLearning\n , Springer, 2013. \nRoss, S.M. \n Probabilità e Statistica per l’Ingegneria e le Scienze\n , 3a edizione, \nApogeo, 2015. \nMachine Learning: Classiﬁcation\n , University of Washington - Coursera, 2017. \nFlach, P. \n Machine Learning - The Art and Science of Algorithms that Make Sense of \nData\n, Cambridge University Press, 2012. ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#6": "Introduzione alla Classiﬁcazione\n \n7\n•Se rappresentiamo le immagini del training set nello spazio \ndelle features , abbiamo le seguente situazione, in cui le varie \nimmagini appaiono ben aggregate:",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#7": "Introduzione alla Classiﬁcazione\n \n8•Ora che abbiamo una buona rappresentazione dei dati di \ntraining nello spazio delle features, l’ultimo passo per \naddestrare il computer a distinguere le immagini dei gatti da \nquelle dei cani è un problema geometrico: \n•identiﬁcare un modello (ad esempio un linear model ) che \nsepari chiaramente i gatti dai cani nello spazio delle \nfeatures.",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#8": "Introduzione alla Classiﬁcazione\n \n9\n•La ﬁgura che segue mostra un modello lineare (la retta in nero) \n“addestrato” ( trained linear model ), che divide lo spazio delle \nfeatures in due regioni. \n•Una volta determinata questa linea, una nuova immagine la cui \nrappresentazione sta al di sopra della linea (regione blu) sarà \nconsiderata dal computer relativa ad un gatto. Se invece sta \nsotto la linea sarà considerata relativa ad un cane. ",
    "data_test\\rootfolder\\università\\MachineLearning\\9-Classification - IntroduzioneLR-sbloccato.pdf#9": "Introduzione alla Classiﬁcazione\n \n10\n•Per veriﬁcare l’efﬁcacia del sistema dobbiamo valutare le sue \nprestazioni su un insieme di immagini ( test set ) distinte da \nquelle usate per l’addestramento: ",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#0": "Diagrammi a Blocchi",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#1": "Cos’è un diagramma a blocchi?Il diagramma a blocchi (diagramma di flusso o flow chart) è uno schema a blocchi utilizzato per rappresentare gli algoritmi.\nSi tratta di una rappresentazione grafica che utilizza delle forme geometriche per descrivere gli algoritmi.",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#10": "Cos’è una variabile?Le variabili sono aree di memoria RAM dove vengono memorizzati i dati e che possono essere cambiati durante l’esecuzione di un’applicazione.\nLe costanti invece contengono un valore non modificabile.\nPer entrambe è opportuno dare dei nomi sensati, non troppo lunghi e non separati da spazi.",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#11": "Esercizi struttura sequenziale (1)Eseguire il prodotto tra due numeri;\nCalcolare l'ipotenusa date le misure dei cateti di un triangolo rettangolo\nDate 2 variabili, scambiarne il contenuto;\nCalcolare il numero minimo di banconote per un importo in euro, tenendo conto dei diversi tagli da 500, 200, 100, 50, 20, 10, 5 euro.\n\n",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#12": "Esercizi struttura condizionale (1)",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#13": "Esercizi struttura iterativa (1)",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#14": "Esercizi vettori (1)Caricamento di 10 numeri in un vettore;\nSomma degli elementi di un vettore;\nRicerca di un valore all’interno di un vettore.",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#2": "Cos’è un algoritmo? A cosa serve?Per algoritmo si intende una successione di passi (o istruzioni) che definiscono le operazioni da eseguire sui dati per ottenere i risultati.\nEsempi di algoritmi ne troviamo tantissimi, anche nella vita di tutti i giorni. Tipicamente è necessario un algoritmo a fronte di un problema, come ad esempio: andare a scuola; per risolvere questo problema dobbiamo seguire una sequenza ordinata e finita di passi (algoritmo), come ad esempio:\nSvegliarsi  Fare colazione  Vestirsi  Uscire di casa  Prendere l’autobus  Entrare in classe\nQuindi, l’insieme dei passi che consentono di risolvere un problema prende nome di algoritmo.",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#3": "Come si descrive un algoritmo?Ci sono tanti modi per rappresentare un algoritmo, un metodo molto utilizzato è quello basato sui diagrammi a blocchi, conosciuti anche con il nome di flow chart (letteralmente diagrammi di flusso).\nSono dunque utilizzati dei blocchi, cioè delle forme geometriche e ciascuna di essa ha un significato ben preciso.",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#4": "Quanti e quali blocchi abbiamo in un diagramma?I blocchi convenzionalmente utilizzati in un flow chart sono:\nEllisse\nParallelogramma\nRettangolo\nRombo",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#5": "EllisseL’ellisse è utilizzata semplicemente solo per indicare l’inizio e la fine di un diagramma a blocchi.\nQuindi ciascun diagramma inizierà con il blocco inizio e terminerà, dopo aver risolto il compito assegnato, con il blocco fine.",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#6": "ParallelogrammaIl parallelogramma è utilizzato per prendere dei dati in INPUT o per visualizzare dei dati in OUTPUT. \nNel caso in cui deve prendere dei dati in input è consigliabile inserire una I in alto a sinistra, seguita dai due punti. Similmente per l’output, che si è soliti indicare con una O in alto a sinistra, sempre seguita dai due punti (ma va bene una qualunque altra convenzione).",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#7": "RettangoloIl rettangolo è utilizzato per eseguire dei calcoli, ovvero per elaborare dei dati. \nAd esempio: per calcolare la somma tra due numeri, l’area di un rettangolo, la media fra tre numeri, …",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#8": "RomboIl rombo è utilizzato per le istruzioni condizionali, ovvero per porre una domanda. All’interno dunque viene fatto un test, per cui si valuta una condizione che può essere o vera o falsa, quindi si sceglie tra due strade diverse. \nUn esempio di semplice test potrebbe essere quello di vedere se un numero è positivo o negativo.",
    "data_test\\rootfolder\\varie\\DiagrammiABlocchi.pptx#9": "RomboIl rombo viene spesso utilizzato anche per i cicli while e do-while.",
    "data_test\\rootfolder\\varie\\HTML&CSS.pptx#0": "HTML e CSS",
    "data_test\\rootfolder\\varie\\HTML&CSS.pptx#1": "Tag base dell’HTML: <p>, <div> e <span><p>, <div> e <span> sono tre diversi tipi di contenitori (di testo o altro), e si comportano in modo diverso:\n<p> è un elemento di blocco e lascia spazio prima e dopo la propria chiusura;\n<div> è un elemento di blocco, non lascia spazio prima e dopo la propria chiusura, ma va a capo;\n<span> è un elemento inline e quindi non va a capo.",
    "data_test\\rootfolder\\varie\\HTML&CSS.pptx#2": "Tag base dell’HTML: <ul>, <ol> e <li><ul> e <ol> sono tag che descrivono l’inizio di una lista, in particolare:\n<ul> per le liste non ordinate;\n<ol> per le liste ordinate.\n<li> serve a descrivere l’inizio di un elemento della lista.\nEsempio di utilizzo:\n",
    "data_test\\rootfolder\\varie\\HTML&CSS.pptx#3": "Tag base dell’HTML: <table>, <tr>, <th> e <td><table> descrive l’inizio di una tabella, e contiene al suo interno i tag <tr>, che descrivono l’inizio di una riga; i tag <tr> a loro volta possono contenere due tag:\n<th> per descrivere una cella di «testata»;\n<td> per descrivere una generica cella di contenuto.",
    "data_test\\rootfolder\\varie\\HTML&CSS.pptx#4": "Tag base dell’HTML: <img><img> serve per inserire un’immagine all’interno della pagina, l’attributo «src» dei questo tag serve a specificare quale immagine caricare.",
    "data_test\\rootfolder\\varie\\HTML&CSS.pptx#5": "Tag base dell’HTML: <form>Un form (modulo) è una sezione di documento HTML che contiene elementi di controllo che l’utente può utilizzare per inserire dati o in generale per interagire. I dati inseriti possono essere poi inoltrati al server dove un agente può processarli. Gli elementi di controllo sono caratterizzati da un valore iniziale e da un valore corrente. Gli elementi di controllo possono essere: \nBottoni di azione\nCheckbox (caselle di spunta)\nRadio Button (bottoni mutuamente esclusivi)\nListe di selezione (lista di opzioni)\nCaselle di inserimento di testo",
    "data_test\\rootfolder\\varie\\HTML&CSS.pptx#6": "Esercizi",
    "data_test\\rootfolder\\varie\\homework\\id-homework-1.pptx#0": "Ingegneria dei dati 2022/2023\u000bHomework 1Paolo Merialdo",
    "data_test\\rootfolder\\varie\\homework\\id-homework-1.pptx#1": "Homework 1Leggere l'articolo (divulgativo) di Andrew Ng \"Data-centric AI\" \u000b(https://spectrum.ieee.org/andrew-ng-data-centric-ai)\nIn una relazione di circa 300 parole: 1) descrivi quella consideri la tesi più importante dell'autore e 2) esprimi la tua posizione rispetto ad essa. \n\nTermini di consegna: inviare la relazione entro le ore 12:00 del14 ottobre 2022 attraverso il seguente modulo online:\u000b\u000bhttps://forms.office.com/r/PYP0ncXYqc ",
    "data_test\\rootfolder\\varie\\homework\\id-homework-2.pptx#0": "Ingegneria dei dati 2022/2023\u000bHomework 2\u000b(da svolgere individualmente)Paolo Merialdo",
    "data_test\\rootfolder\\varie\\homework\\id-homework-2.pptx#1": "Homework 2A partire dal codice github dell'ing. Tommaso Teofili (https://github.com/tteofili/lucenex):\nscrivere un programma Java che indicizza i file .txt contenuti in una directory del proprio laptop. In particolare, si devono considerare due campi (e quindi creare due indici): il nome del file, il contenuto del file. Per ciascun campo utilizzare un analyzer appropriato\nscrivere un programma Java che legge una query da console, interroga l'indice e stampa il risultato. Usare una semplice sintassi per la query (ad esempio, una query inizia con la parola chiave nome o contentuto seguita da una sequenza di termini (eventualmente racchiusi tra virgolette per esprimere una phrase query)\ntestare il sistema con una decina di query diverse\n\nScrivere una relazione che, oltre a riportare l'url del proprio progetto su Github (o analogo) descriva:\ngli analyzer che si è scelto di utilizzare (motivando le scelte)\nil numero di file indicizzati e i tempi di indicizzazione\nle query usate per testare il sistema",
    "data_test\\rootfolder\\varie\\homework\\id-homework-2.pptx#2": "Homework 2\nTermini di consegna: inviare la relazione entro le ore 21:00 del 22 ottobre 2022 attraverso il seguente modulo online:\u000b\u000bhttps://forms.office.com/r/PYP0ncXYqc ",
    "data_test\\rootfolder\\varie\\homework\\id-homework-3.pptx#0": "Ingegneria dei dati\u000bHomework 3\u000b(da svolgere in gruppo)Paolo Merialdo",
    "data_test\\rootfolder\\varie\\homework\\id-homework-3.pptx#1": "Homework 3Implementare l'algoritmo \"MergeList\" per la soluzione al problema \"Joinable Table Search\"\nUtilizzare la libreria Apache Lucene\nTestare la correttezza dell'algoritmo su un piccolo insieme di tabelle, appositamente costruito\nTestare l'efficacia e l'efficienza dell'algoritmo sulle tabelle contenute nel dataset \"tables\" del progetto Mentor: https://gitlab.com/Rm3UofA/Mentor/Datasets",
    "data_test\\rootfolder\\varie\\homework\\id-homework-3.pptx#2": "Homework 3Ogni team deve preparare \nuna presentazione di 5' per illustrare le caratteristiche del dataset \nuna presentazione di 10' minuti per illustrare la valutazione sperimentale della propria implementazione dell'algoritmo \"MergeList\"\nTermini di consegna: entro le ore 19:00 del 2 novembre 2022 ogni membro del team deve inviare le due presentazioni al docente compilando il seguente modulo (compilare il modulo due volte, una per ciascuna presentazione):\u000b\n             https://forms.office.com/r/PYP0ncXYqc \n\nQuattro team (scelti dal docente) presenteranno il proprio lavoro nella lezione del 3 novembre 2022\n\n\n",
    "data_test\\rootfolder\\varie\\homework\\id-homework-3.pptx#3": "Presentazione Caratteristiche del DatasetDurata 5'\nDeve riportare statistiche sul dataset \"tables\" che possano essere utili all'analisi del problema, all'implementazione dell'algoritmo di soluzione e alla sua valutazione. \nAd esempio:\nNumero di tabelle\nNumero medio di righe\nNumero medio di colonne\nNumero medio di valori nulli per tabella\nDistribuzione numero di righe (quante tabelle hanno 1, 2, 3, 4, etc. righe)\nDistribuzione numero di colonne (quante tabelle hanno 1, 2, 3, 4, etc. colonne)\nDistribuzione valori distinti (quante colonne hanno 1, 2, 3, 4, etc valori distinti)\nAltro a vostra scelta\nPresentare le statiche in maniera opportuna, anche attraverso l'uso di rappresentazioni grafiche\n",
    "data_test\\rootfolder\\varie\\homework\\id-homework-3.pptx#4": "Presentazione Valutazione SperimentaleDurata 10'\nDeve includere\nDescrizione ad alto livello dell'implementazione (classi e metodi principali)\nPrincipali problemi riscontrati nell'implementazione\nValutazione sperimentale:\nCon una descrizione chiara e precisa di obiettivi e metriche di ciascun esperimento",
    "data_test\\rootfolder\\varie\\homework\\id-homework-4.pptx#0": "Ingegneria dei dati\u000bHomework 4\u000b(da svolgere individualmente)Paolo Merialdo",
    "data_test\\rootfolder\\varie\\homework\\id-homework-4.pptx#1": "Homework 4 - Esercizio 1Scegliere una tipologia di prodotti su amazon.it \u000b(ad esempio fotocamere, oppure prodotti senza glutine)\nScegliere un pagina con un prodotto della tipologia scelta\nIndividuare nella pagina almeno 5 caratteristiche del prodotto\nScrivere un'espressione XPath per estrarre il nome, il prezzo e il valore di ciascuna delle caratteristiche individuate al punto precedente\nVerificare che le espressioni XPath funzionino correttamente su almeno altre 10 pagine di prodotti della stessa categoria\nSe una regola XPath non funziona, correggerla affinchè funzioni correttamente su tutte e 10 le pagine\n\n",
    "data_test\\rootfolder\\varie\\homework\\id-homework-4.pptx#2": "Homework 4 - Esercizio 2Scegliere un tipo di entità di interesse (ad esempio, giocatori di basketball, aziende, università, etc.)\nCercare 5 sorgenti Web che pubblicano pagine di dettaglio di istanze dell'entità scelta (ad esempio siti web che pubblicano pagine di giocatori di basketball)\nSu ogni sorgente scegliere 5 pagine di dettaglio\nScrivere espressioni XPath per estrarre I valori di (almeno) 5 attributi rilevanti su tutte le pagine scelte\n",
    "data_test\\rootfolder\\varie\\homework\\id-homework-4.pptx#3": "Termini di consegnaOgni studente deve preparare individualmente una relazione in cui descrive l'attività svolta per portare a termine l'homework\nTermini di consegna: entro le ore 19:00 del 19 novembre 2022 inviare la relazione al docente compilando il seguente modulo:\u000b\n             https://forms.office.com/r/PYP0ncXYqc \n\n\n",
    "data_test\\rootfolder\\varie\\homework\\id-homework-5.pptx#0": "Ingegneria dei dati\u000bHomework 5\u000b(da svolgere in gruppo)Paolo Merialdo",
    "data_test\\rootfolder\\varie\\homework\\id-homework-5.pptx#1": "Homework 5Obiettivo: creare un dataset strutturato con dati estratti da sorgenti Web\nCi interessano dati su una tipologia di entità: aziende\nPer semplicità, ci concentriamo su sorgenti in lingua inglese\nScrivere un programma di estrazione dati per almeno 1000 istanze da almeno 4 sorgenti web",
    "data_test\\rootfolder\\varie\\homework\\id-homework-5.pptx#2": "TecnologieE' possibile usare una delle seguenti tecnologie (ma è possibile usarne altre)\n\nIn Python: \nhttps://scrapy.org/ \nhttps://www.crummy.com/software/BeautifulSoup/\nIn Java: \nhttps://www.selenium.dev/ \nhttps://jsoup.org/ \n\n",
    "data_test\\rootfolder\\varie\\homework\\id-homework-5.pptx#3": "Termini di consegnaOgni team deve preparare una presentazione così strutturata\n1 minuto per illustrare come è stata scelta la tecnologia per implementare il sistema di estrazione\n2 minuti per illustrare l'architettura del sistema di estrazione dati realizzato\n3 minuti per illustrare le prestazioni del sistema di estrazione\n4 minuti per illustrare le caratteristiche delle sorgenti e le caratteristiche del dataset ottenuto\nTermini di consegna: \nentro le ore 19:00 del 9 dicembre 2022 inviare la presentazione al docente compilando il seguente modulo: https://forms.office.com/r/PYP0ncXYqc \nIl 13 dicembre, ogni team dovrà consegnare il dataset con i dati estratti al docente (in un file compresso). Ogni team può liberamente scegliere in che modo strutturare il dataset\nQuattro team (scelti dal docente) presenteranno il proprio lavoro nelle lezioni del 13 e del 15 dicembre 2022\n",
    "data_test\\rootfolder\\varie\\homework\\id-homework-6.pptx#0": "Ingegneria dei dati\u000bHomework 6\u000b(da svolgere individualmente)Paolo Merialdo",
    "data_test\\rootfolder\\varie\\homework\\id-homework-6.pptx#1": "Homework 6Leggere uno tra questi due articoli: \nY. Suhara et at \"Annotating Columns with Pre-trained Language Models\" (https://arxiv.org/pdf/2104.01785.pdf) \nK. Koutras et at \"Valentine: Evaluating Matching Techniques for Dataset Discovery\"\u000b(https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458921) \nIn una relazione di circa 900 parole, descrivere: \u000b1) descrivere  il problema che affronta l'articolo, 2) le soluzioni che propone, 3) l'impostazione sperimentale per la valutazione dei risultati. \nLeggere l'articolo (scientifico):\nP. Konda et al. \"Magellan: Toward Building Entity Matching Management Systems\" \u000b(http://www.vldb.org/pvldb/vol9/p1197-pkonda.pdf)\nIn una relazione di circa 900 parole, descrivere: \u000b1) il problema che affronta l'articolo, 2) le soluzioni che propone, 3) l'impostazione sperimentale per la valutazione dei risultati. \n\nTermini di consegna: inviare le due relazioni entro le ore 18:00 del 5 gennaio 2023 attraverso il seguente modulo online:\u000bhttps://forms.office.com/r/PYP0ncXYqc ",
    "data_test\\rootfolder\\varie\\homework\\id-homework-7.pptx#0": "Ingegneria dei dati\u000bHomework 7\u000b(da svolgere individualmente)Paolo Merialdo",
    "data_test\\rootfolder\\varie\\homework\\id-homework-7.pptx#1": "Homework 7L'obiettivo dell'homework è quello di valutare il sistema CERTA per la generazione di spiegazioni di diversi sistemi di Record Linkage basati su tecniche di deep learning\n\nSeguire le istruzioni riportate a questo indirizzo:\n\t https://gist.github.com/tteofili/eaaeaaa8af2d22005fe199f1dc8874ad \n\nTermini di consegna: entro le ore 18.00 del 21 gennaio 2023 caricare il file cvv nel seguente modulo:\n\thttps://forms.office.com/r/PYP0ncXYqc ",
    "data_test\\rootfolder\\varie\\homework\\id-homework-8-progetto-finale.pptx#0": "Ingegneria dei dati\u000bHomework 8\u000b(da svolgere in gruppo)Paolo Merialdo",
    "data_test\\rootfolder\\varie\\homework\\id-homework-8-progetto-finale.pptx#1": "Homework 8L'obiettivo dell'homework è quello di integrare le sorgenti dati collezionate da tutti i team nell'homework 5 e di arricchirle con le tecniche sviluppate nell'homework 3 \nAnalizzare le sorgenti dati e individuare le principali eterogeneità\nDefinire uno schema mediato opportuno ed allineare gli schemi delle sorgenti allo schema mediato. È possibile usare:\nUna soluzione custom (anche manuale)\nFlexMatcher https://flexmatcher.readthedocs.io/en/latest/ \nComa https://sourceforge.net/projects/coma-ce/  \nUno dei tool del progetto Valentine https://github.com/delftdata/valentine\nCalcolare il Record linkage. E' possibile usare:\nUna soluzione custom\nPython Record Linkage Toolkit https://recordlinkage.readthedocs.io/en/latest/ \nMagellan https://github.com/anhaidgroup/deepmatcher\nDeepMatcher (soluzione neural network) https://github.com/anhaidgroup/deepmatcher \nDitto (soluzione neural network) https://github.com/megagonlabs/ditto \nEMT (soluzione neural network molto simile a Ditto) https://github.com/brunnurs/entity-matching-transformer \nUn sistema non supervisionato  https://github.com/uestc-db/Unsupervised-Entity-Resolution oppure https://github.com/chu-data-lab/zeroer\nArricchire i dati integrati usando le tecniche (e il dataset di tabelle) sviluppate nell'homework 3\n",
    "data_test\\rootfolder\\varie\\homework\\id-homework-8-progetto-finale.pptx#2": "Termini di consegnaPreparare un documento scritto di 4 pagine e una presentazione di 15' che descrivano:\nLe caratteristiche salienti delle sorgenti\nI benefici potenziali di integrare i loro dati\nLo schema mediato\nLe soluzioni che avete scelto per integrare i dati\nLe prestazioni (in termini id precision, recall, F-measure, tempi di calcolo, sforzo umano)\nI dati tabulari che avete trovato per arricchire le informazioni integrate dalle sorgenti\nIl documento e la presentazione vanno consegnati caricandoli attraverso il modulo all'indirizzo:\n\thttps://forms.office.com/r/PYP0ncXYqc\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#0": "Caratteristiche del dataset tables - Homework 3 Federico Bianchi\t--  Matr. 534835\nAndrea de Donato  -- Matr. 536795\nPaolo Di Simone  -- Matr. 584638",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#1": "Formato del dataset",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#10": "Distribuzione numero di colonne",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#11": "Distribuzione numero di valori distinti per colonna",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#12": "Distribuzione percentuale di valori distinti per colonna",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#2": "Formato del dataset",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#3": "Formato delle celle\n\t- Celle vuote e «None»\n\t- Classificazione tipi di cella",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#4": "Formato delle celle\n\t- Frequenza di termini all’interno del dataset",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#5": "Formato delle celle\n\t- Frequenza di termini all’interno del dataset",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#6": "Formato delle righe\n\t- Righe con celle vuote e con celle «None»",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#7": "Formato delle colonne\n\t- Colonne con celle vuote e con celle «None»\n\t- Classificazione tipi di colonna",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#8": "Distribuzione numero di righe",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-AnalisiDelDataset.pptx#9": "Fun Fact\n\t- Tabelle con 100 righe: 5 076",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#0": "Ingegneria Dei Dati:\u000bValutazione Sperimentale Homework 3 Federico Bianchi\t--  Matr. 534835\nAndrea de Donato  -- Matr. 536795\nPaolo Di Simone  -- Matr. 584638dedo99/Homework3 (github.com)Link Repository Progetto:",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#1": "Organizzazione del progetto: packageIndex\nindicizzazione di tutto il file in inputModel\nmodello utilizzato per estrarre i dati dal datasetQuery\nesecuzione delle query ed estrazione dei documenti ritenuti compatibili",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#10": "Valutazione sperimentale del progetto (2)Tempo necessario per l’indicizzazione dell’intero file JSON contenente 550.271 tabelle (14,2 Gb): 297.882 s (c.a. 5 minuti)\n\nQuery d’esempio [«singlular», «plural», «fmou», «dual»], tempo di esecuzione:\nCon SimpleTextCodec: 18 minuti\nSenza SimpleTextCodec: 6 secondi",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#11": "Valutazione sperimentale del progetto (3)Per testare l’efficacia e l’efficienza del sistema sono state effettuate tre tipologie di test:\n\nTest al variare di k\n\nTest al variare della lunghezza della query\n\nPrecision, Recall, F1 e Accuracy su dataset di test",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#12": "Test al variare di k",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#13": "Test al variare della lunghezza della query",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#14": "Dataset di testÈ stato costruito un dataset per testare l’efficacia del sistema, con le seguenti caratteristiche:\n\n30 tabelle\n\nOgni tabella riporta informazioni su film, libri, autori, attori, …",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#15": "Dataset di test",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#16": "Dataset di test: distribuzione righe",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#17": "Dataset di test: distribuzione colonne",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#18": "Dataset di test: distribuzione valori distinti",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#19": "QuerySono state costruite 23 query di test, ottenute calcolando lo score Jaccard fra tutte le possibili coppie di colonne all’interno del dataset. Ogni query di test contiene:\n\nColonna di valori che rappresenta la query\n\nTop 3 colonne con score Jaccard più alto",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#2": "Le classiIndexCellModelCoordinatesQueryJSONObjectJSONIndexerQueryManager",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#20": "Query",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#21": "Precision, Recall, F1 e Accuracy",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#22": "QuerySolo per una query il sistema non restituisce alcun risultato corretto:\n[«USA», «USA», «USA», «USA», «USA», «USA», «USA»]\n\nLe altre query su cui il sistema fatica a restituire il risultato corretto sono molto simili:\n[«USA», «Italia», «Italia», «Francia», «Inghilterra», …]",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#3": "Classe JSONIndexer (1)La classe JSONIndexer è composta da due metodi:\n\n\nreadJsonStream(InputStream in, Codec codec): lettura dell’input dal file JSON\n\n\nindexJSONStream(JsonReader reader, Codec codec): estrazioni degli oggetti JSON (tabelle) dal reader, parsing in un oggetto Java e successiva indicizzazione. I documenti inseriti nell’indice corrispondono ciascuno ad una colonna di una tabella.\n\n\nUso della libreria Gson per convertire rappresentazioni JSON in oggetti Java e viceversa.",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#4": "Classe JSONIndexer (2)Definizione di un Tokenizer CustomCreazione dei documentiAnalyzer analyzer = CustomAnalyzer.builder()\u000b        .withTokenizer(PatternTokenizerFactory.NAME, \"pattern\", \"~\", \"group\", \"-1\")\u000b        .build();for(Cell c : obj.getCells())\u000b    if (!c.getHeader()) {\u000b        if(colonnaXvalori.containsKey(obj.getId() + \"_\" + c.getCoordinates().getColumn().toString())) {\u000b            String value = colonnaXvalori.get(obj.getId() + \"_\" + c.getCoordinates().getColumn().toString());\u000b            colonnaXvalori.put(obj.getId() + \"_\" + c.getCoordinates().getColumn().toString(), value + \"~\" + c.getCleanedText());\u000b        } else\u000b            colonnaXvalori.put(obj.getId() + \"_\" + c.getCoordinates().getColumn().toString(), c.getCleanedText());\u000b    }",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#5": "Classi JsonObject, Cell e CoordinatesLe classi JsonObject, Cell e Coordinates sono stati realizzate per rendere agevole la trasformazione da un oggetto Json ad un oggetto Java.\n\nLe seguenti classi sono dotate di variabili di istanza, relative alle sole informazioni necessarie rispetto al completo contenuto dell’oggetto Json, e i corrispondenti metodi setter e getter.public class JSONObject {\n String id;\n Cell[] cells;\n}public class Cell {\n Boolean isHeader;\n String cleanedText;\n Coordinates Coordinates;\n}public class Coordinates {\n Double row;\n Double column;\n}",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#6": "Classe QueryManager\nmergeList(int n, String[] queryString) restituisce le prime n colonne tra tutte le tabelle che hanno corrispondenze con il maggior numero di termini nella query\n\nexecuteQuery(String field, String[] queryString) genera una mappa (idTabella_idcolonna -> numero corrispondenze) scansionando tutti gli elementi presenti nella query\n\nsortMapByValues(Map<String, Integer> columnsXcount) effettua l’ordinamento della mappa sull’intero contenuto nel campo valore\n\nrunQuery(IndexSearcher searcher, Query query,  Map<String, Integer> columnsXcount) restituisce per ciascun elemento della query una mappa con le colonne delle tabelle in cui è presente\n\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#7": "Problemi riscontratiIndividuare la corretta rappresentazione dei documenti nell’indice\n\nIndividuare un modo corretto di tokenizzare i documenti (nello specifico il campo ‘value’)\n\nTempi di indicizzazione",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#8": "ObiettiviImplementare nel modo più efficiente l’indicizzazione di una grande quantità di dati\n\nRestituire, a seguito di una query, le tabelle con la relativa colonna in cui sono state incontrate delle corrispondenze senza includere nel conteggio eventuali ripetizioni dello stesso termine nella colonna \n\nRestituire in ordine decrescente i risultati sulla base del numero di corrispondenze ottenute",
    "data_test\\rootfolder\\varie\\relazioni\\HW3-ValutazioneSperimentale.pptx#9": "Valutazione sperimentale del progetto (1)Tutti i risultati sono stati ottenuti utilizzando un calcolatore con le seguenti specifiche:\n\nProcessore Intel core i7 di 8° gen\n\nRAM 8Gb\n\nSSD 512Gb",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#0": "Web Scraping:\u000bScraping business information\u000b\u000b\u000b\u000bDipartimento di Ingegneria\nCorso di Laurea Magistrale in Ingegneria InformaticaAnno Accademico \n2022-2023\n13 Dicembre 2022Corso\u000b Ingegneria dei datiProfessore\nPaolo MerialdoStudenti\nPaolo Di Simone\nPietro Baroni\nMatteo WisselGitHub: Web Scraping- Homework5",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#1": "Purpose del progettoIntroduzioneAutomatizzazione della ricerca ed estrazione di informazioni relative ad aziende\n\n\nUtilità\n\nCreazione di un dataset relativo ad aziende per diversi task:\u000b\nAddestramento modello AI\u000b\nAnalytics\n\nData IntegrationScopo",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#10": "Sorgente: gov.ukLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#11": "Sorgente: gov.ukLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#12": "Efficacia X-Paths: Data ConsistencyAnalisi pattern\n\nAddress, Business code, Business name (E-business), Date, ecc…\n\nAnalisi frequenza valori celle \u000b\nLegal form, Status, ecc…\n\n\n\nAnalisi frequenza token\u000b \nBusiness name, ecc…Lilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#13": "Efficacia X-Paths: Analisi PatternTable: GOV.UK\n\nField: Address\n\nExample values: '38SpringfieldRoad Gillingham Kent England ME71YJ’\n\n\n\n    \nRegex: \n\t([Gg][Ii][Rr] 0[Aa]{2})|((([A-Za-z][0-9]{1,2})|\n\t(([A-Za-z][A-Ha-hJ-Yj-y][0-9]{1,2})|(([A-Za-z][0-9][A-Za-z])|\n\t([A-Za-z][A-Ha-hJ-Yj-y][0-9][A-Za-z]?))))\\s?[0-9][A-Za-z]{2})\nUK Postal codeLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#14": "Efficacia X-Paths: Analisi PatternIndirizzi non conformi\n\nAustrasse429490 Vaduz Liechtenstein\n\nPasiadou5KatoLakatamia 2332Nicosia Nicosia Cyprus\n\nLaChausseeStreet PortLouis MauritiusLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#15": "Efficacia X-Paths: Frequenza ValoriTable: E-Business\n\nField: Legal form\n\nExample values:\nPrivate limited company, Public limited company, Non-profit association, ecc…\n\n\n    \nLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#16": "Efficacia X-Paths: Frequenza ValoriLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#17": "Efficacia X-Paths: Frequenza TokenTable: GOV.UK\n\nField: Name\n\nExample values: P & A PROPERTY (WESTON) LIMITED, P A JONES LIMITED, P A H \t\t       CARPENTRY & JOINERY LTD  \n\n\t\n    \nLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#18": "Efficacia X-Paths: Frequenza TokenTable: GOV.UK\n\nField: Name\n\nMost frequent tokens:\nLimited, LTD,LTD., Services, …\n\n\n    \nAnalisi\n\n1466 su 1469 hanno nel loro nome \n      i 10 token più frequenti\n1 ) LIMITED -> 728\n2 ) LTD -> 533\n3 ) SERVICES -> 94\n4 ) ELECTRICAL -> 38\n5 ) CONSTRUCTION -> 37\n6 ) BUSINESS -> 36\n7 ) CORP. -> 35\n8 ) PROPERTIES -> 34\n9 ) HOMES -> 27\n10 ) LTD. -> 26\nLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#19": "Test sistema: WorkflowIl sistema è stato testato nel seguente modo:\nCampionamento casuale del dataset estratto:\nCompaniesmarketcap  30 URL\nInfoclipper  50 URL\nGovUK  29 URL\nEbusiness  30 URL\nEstrazione manuale dei dati contenuti nel campione selezionato\nConfronto dati estratti dal sistema e dati ottenuti manualmente\nLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#2": "Ricerca sitiFiltraggio sitiSchema datiParsing dati &\nData ConsistencyAcquisizione datiAnalisi datiRoad mapIntroduzione",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#20": "Test sistema: companiesmarketcap.comLilla SystemErrori dovuti esclusivamente alla variabilità giornaliera dei campi\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#21": "Test sistema: e-BusinessLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#22": "Test sistema: info-clipper.comLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#23": "Test sistema: info-clipper.comLilla SystemPostalcode\nLe differenze sono dovute al fatto che le celle formattate come intere eliminano gli 0 a sinistra della stringa  {187’, 00187’} \nState\nNel nostro sistema nel campo state inseriamo anche la sigla dello stato, nei test l’utente non inserisce nel campo State la sigla  {'California(CA)', 'California'} ",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#24": "Test sistema: gov.ukLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#25": "Test sistema: gov.ukLilla SystemCompany ID\nLe differenze sono dovute al fatto che le celle formattate come intere eliminano gli 0 a sinistra della stringa  {'6174105', '06174105’} \nCompany Status\nGli errori sono dovuti al cambiamento di status dell’azienda  {'Active', 'Dissolved'}\nDissolution Date\nL’azienda nel frattempo è stata dissolta  {'nan', 14 February 2023 '} \n",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#26": "Efficienza temporale: Estrazione datiTempo complessivo\n\nTempo di request \n\nTempo di estrazione del dato (navigazione del dom via X-Path)\nLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#27": "Efficienza temporale: RequestLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#28": "Efficienza temporale: Estrazione datiLilla System//div[@class = \"company-code\"]//*[@id=\"cmkt\"]/div[3]/div[1]/div[2]/div[3]/div[1]/a/text()",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#29": "Dataset: companiesmarketcap.comLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#3": "\nBeautiful soup\n\nRequest\n\nLXML & Etree\nWeb ScrapingPandas & numpy                    \t\nMatplotlib\n\nGeopandas\nData ProfilingTecnologieLilla SystemPython",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#30": "Dataset: companiesmarketcap.com   Analisi campi\n\nName: Nome dell’azienda\nCompany Code: Codice identificativo delle società quotate in borsa (WMT, AMZN, UPS, KR, …)\nMarketcap: Somma del valore totale delle azioni in circolo\nShare Price: Costo singola azione\nEarnings: Profitto annuo\nRevenue: Ricavi annui\nShares: Numero totale di azioni in circolo\nEmployees: Numero totale di dipendenti\n\n\n  Numeriche generali\n\nTotale istanze: 1400\nTotale colonne: 10\n\n\nCelle totali: 14000\nValori nulli: 21Lilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#31": "Dataset: companiesmarketcap.comLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#32": "Dataset: companiesmarketcap.comLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#33": "Dataset: e-BusinessLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#34": "Dataset: e-BusinessAnalisi campi\n\nName: Nome dell’azienda\nCompany code: Codice identificativo dell’azienda\nLegal Form: Forma giuridica dell’azienda\nStatus: Status dell’azienda (Deleted, Entered into the register, ecc…)\nRegistration Date: Data di inserimento dell’azienda nel registro\nCapital: Capitale dell’azienda\nAddress: Indirizzo sede dell’azienda\nDeletion Time: Data di eliminazione dell’azienda dal registro\n\n  Numeriche generali\n\nTotale istanze: 1469\nTotale colonne: 10\n\n\n\nCelle totali: 14690\nValori nulli: 2120 Lilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#35": "Dataset: e-BusinessLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#36": "Dataset: e-BusinessESTONIALilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#37": "Dataset: info-clipper.comAnalisi campi\n\nName: Nome dell’azienda\nTrade Name: Nome commerciale dell’azienda\nAddress: Indirizzo sede dell’azienda\nCity: Città \nPostalcode: Codice postale nei formati UK, USA, Italia, Estonia\nState: Stato Americano di residenza o Nazione di residenza\nCountry: Nazione di residenza\nLocation type: Tipo di sede (es. Headquarter, Secondary Office, ecc…)\n\n\n\n  Numeriche generali\n\nTotale istanze: 1504\nTotale colonne: 10\n\n\n\nCelle totali: 15040\nValori nulli: 1289Lilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#38": "Dataset: info-clipper.com\n\n\nLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#39": "Dataset: info-clipper.com\n\n\nSTATI UNITILilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#4": "Lilla\nSystemGeneral web pageRequest: get informationResponse: list of linksRequest: get all linksResponse:  informationCreate datasetSpecific web pageDatasetData Parsing and\nData ConsistencyArchitetturaLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#40": "Dataset: info-clipper.com\n\n\nESTONIALilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#41": "Dataset: info-clipper.com\n\n\nITALIALilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#42": "Dataset: info-clipper.com\n\n\nINGHILTERRALilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#43": "Analisi campi\n\nName: Nome dell’azienda\nCompany ID: Codice identificativo dell’azienda\nCompany Status: Status dell’azienda (Active, Dissolved, Registered, Liquidated)\nCompany Type: Tipo dell’azienda (Overseas Entity, Private Limited Company, ecc…)\nRegistration Date: Data di registrazione di aziende estere\nIncorporation Date: Data di inserimento delle aziende inglesi nel registro\nDissolution Date: Data di dissoluzione dell’azienda\nOffice Address: Indirizzo dell’azienda\n\n\nDataset: gov.uk  Numeriche generali\n\nTotale istanze: 1331\nTotale colonne: 10\n\n\n\nCelle totali: 13310\nValori nulli: 2555Lilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#44": "Dataset: gov.ukLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#45": "Dataset: gov.ukREGNO UNITOLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#46": "Dataset: gov.ukINGHILTERRALilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#47": "Member: Pietro Baroni\nMatricola: 536373\nTask: Algoritmi\nLinkedin: Pietro BaroniMember: Paolo Di Simone\nMatricola: 584638\nTask: Analytics\nLinkedin: Paolo Di SimoneMember: Matteo Wissel\nMatricola: 534693 \nTask: Algoritmi\u000bLinkedin: Matteo WisselTeamLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#48": "GRAZIE PER L’ATTENZIONERoma, 13  Dicembre 2022GitHub: Web Scraping- Homework5",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#5": "Sorgente: companiesmarketcap.comLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#6": "Sorgente: ariregister.rik.ee (e-Business)Lilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#7": "Sorgente: ariregister.rik.ee (e-Business)Lilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#8": "Sorgente: info-clipper.comLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW5-WebScarping.pptx#9": "Sorgente: info-clipper.comLilla System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#0": "Data integration:\u000bArlecchino system\u000b\u000b\u000b\u000bDipartimento di Ingegneria\nCorso di Laurea Magistrale in Ingegneria InformaticaAnno Accademico \n2022-2023\n22 Febbraio 2023Corso\u000b Ingegneria dei datiProfessore\nPaolo MerialdoStudenti\nPaolo Di Simone\nPietro Baroni\nMatteo WisselArlecchino System\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#1": "Purpose del progettoIntroduzioneUse Case\n\nIntegrazione di dataset aziendali\u000bScopo\n\nImplementazione di un sistema di Data IntegrationDataset\n\nDataset_Corso_Ingegneria_dei_Dati_2022/23\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#10": "ParsingArlecchino SystemParsing nomi colonne\u000b\nTrasformazione in lower case  \nEliminazione caratteri speciali (-, /, …)\nEliminazione di skip words (of, the, del, di, …)  Parsing valori celle \n\nParsing di stringhe: \nTrasformazione in lower case\nEliminazione caratteri speciali (-, /, …)\nEliminazione di skip words (of, the, del, di, …)\nEsempio: Amazon -> amazon\n  \nParsing di valori monetari:\nNormalizzazione valori \nInserimento unità di misura\nEsempio: $102 million -> doll_ 0.102 b \n\nParsing valori percentuali\nParsing valori rank\nParsing valori date\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#11": "Schema matching: Formulazione problemaArlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#12": "Schema Matching: Matching Module (SMM)Arlecchino SystemPre-processing module\n\nInput: colonne e samples di valori \nOutput: un dizionario parziale di sinonimi\nUtilità: 1. riduzione del search space del JaccardModule\n    2. inferisce informazioni al JaccardModule  \nJaccardModule\n\nInput: dizionario sinonimi_preprocessing\nOutput: dizionario sinonimi_finale\nUtilità: trova le reali correlazioni semantiche tra le colonneUser",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#13": "SMM: MotivazioniArlecchino SystemAnalisi senza pre-processingAnalisi con pre-processingSample data: 1000 per colonna\u000b\nColonne totali: 18\u000b\nNumero medio di sinonimi reali: 1.6\u000b \n\nStima confronti totali: ≈ 153\nNumero medio confronti per colonna: ≈ 18\nNumero medio di confronti inutili: ≈ 17\nEsempio \ncluster cbinsightsSample data: 1000 per colonna\n\nColonne totali: 18\n\nNumero medio di sinonimi reali: 1.6\n\nStima confronti totali: 14\nNumero medio confronti per colonna:  2.5\nNumero medio di confronti inutili: 0.84\n\nFattore di riduzione: ≈ 12",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#14": "Pre-processing: Name SimilarityArlecchino SystemName similarity di colonne\n\nInput: (column_names, dizionario_sinonimi_pregressi)\nOutput: un dizionario parziale di sinonimi\nUtilità: individua i sinonimi schema-wise \n\t(dettati da similarità di nome)Logica:\t\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#15": "Pre-processing: Data CorrelationArlecchino System\n\nData similarity di colonne [1]\n\nInput: (sample_dati_colonne)\nOutput: un dizionario sinonimi4cluster\nUtilità: individua i sinonimi data-wise\n\t(dettati da similarità di dati) [1] Schema Matching using Machine LearningTanvi Sahay, Ankita Mehta, Shruti Jadon",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#16": "SMM: Features EngineeringArlecchino SystemFeatures selezionate\nMin_val\nMax_val\nAvg\nVariance\nStandard_Dev\nIs_incremental\nIs_year Type_of_string (1 perc_, 2 rank_, 3 link, 4-5 monetari, 6 resto)\nAVG_monetary_value\nAVG_len_of_field\nVAR_len_of_field\nSDEV_len_of_field\nRatio_white_space\nRatio_numeric_values\nIs_country (1 se country, 0 altrimenti)\nIs_sector (1 se sector, 0 altrimenti)1. Type_of_data (0 string, 1 integer, 2 date)for Integerfor stringsfor date",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#17": "Pre-processing: Analisi OutputArlecchino SystemDizionario sinonimi_preprocessing (largo)\n\nUnione dei dizionari di sinonimi prodotti dai due step di \u000bpre-processing\nScopo: limitare eventuali errori (high recall)\u000b\nEsempio (companiesmarketcap):\u000b\nToken: market_cap\n\nTrue_sinonimi\n\tmarket_cap->{marketcap, market_capitalization, pricecap, …}\u000b\nsinonimi4NameCorr\n\tmarket_cap->{marketcap, market_capitalization,…}\n\nsinonimi4Clusters\n\tmarket_cap->{marketcap, pricecap, …}\n\nsinonimi_preprocessing\n\tmarket_cap->{marketcap, market_capitalization, pricecap, …}\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#18": "SMM: JaccardModuleArlecchino SystemJaccardModule\n\nInput: sinonimi_preprocessing\n\nLogica: per ogni colonna c presente nel dizionario dei sinonimi_preprocessing, il sistema genera un file .csv contenente tutte le colonne giudicate sinonimi",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#19": "SMM: OutputArlecchino SystemDizionario sinonimi finali\n\nRisultato finale del Matching module\u000b\nPer ogni colonna dello schema mediato è definita  una lista di  possibili sinonimi \u000b(colonne semanticamente simili)\n\nL’utente seleziona i match opportuni eliminando eventuali errori del sistema\n\nAl netto della validazione dell’utente, il sistema aggiorna il dizionario dei sinonimi pregressi\u000b\n\n\nUser",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#2": "Caratteristiche dei sorgenti: ClusterSorgenti\t",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#20": "Schema MediatoArlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#21": "Record LinkageArlecchino SystemInput: schema mediato (184.587 record)\n\nOutput: dataset finale\n\nScopo: Trovare nella tabella in input i record relativi alla stessa entità ed unirli in un unico record\n\n Record Linkage\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#22": "Record Linkage: BlockingArlecchino SystemNumero di confronti iniziali: 34.072.360.569 Numero di confronti post-blocking: 2.177.713Tempi: 76 min 36 secBlocking step1. overlap di una parola nel nome delle aziende\n\n2. overlap di una parola nel paese delle aziende (se presente)\n\n3. Indice di Levenshtein < 0.7 tra i nomi\n delle aziende\n\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#23": "Record Linkage: Training SetArlecchino SystemTotale record: 1300\n\nDivisi in training set, test set e validation set (ratio 3:1:1)\n\nLabel Match: 695\n\nLabel No-Match: 605\n\nTraining set",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#24": "Record Linkage: Model TrainingArlecchino SystemIperparametri:\nEpoche = 10\nDimensione batch = 16 \nStatistiche:\nTempo impiegato: 10 min 29 secModello utilizzato: Matching Model di Deep MatcherModel Training",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#25": "Record Linkage: PredictionArlecchino SystemStatistiche:\nPredizioni effettuate: 2.177.713\nPredizioni Match: 1.480.727\nTempo impiegato: 14 ore e 45 minuti\nUtilizzo del modello addestrato per eseguire le predizioni sulle coppie non bloccatePrediction",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#26": "Record Linkage: JoinArlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#27": "Schema IntegratoArlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#28": "ArricchimentoColonna usate come input:\nNome dell’azienda\nCEO dell’aziendaTabelle con più occorrenze in output:\nList of S&P 500 companies\nList of largest companies by revenue\nList of largest European manufacturing companies by revenue\nList of multinationals with research and development centres in Israel\nList of largest Nordic companies\nAutomotive industryPMF \u000bsystem\u000b(HW3)Top table ids Dataset utenteinput (Schema mediato, \n[name, ceo] )Indice HW3Arlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#29": "Schema ArricchitoArlecchino System142 celle riempite",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#3": "Caratteristiche dei sorgenti: ClusterSorgenti\t",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#30": "Testing SMM: MetricheArlecchino SystemLogica\n\n Confronto tra i sinonimi computati per una colonna dello schema mediato S e i sinonimi veri S’\n\nMetriche\n\nNumero di confronti inutili effettuato per sorgente\n\nSimilarità tra sinonimi computati:\nPrecision\nRecall\nF1",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#31": "Testing: Pre-Processing per clustering (Conf.)Arlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#32": "Testing: performance SMM clusterArlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#33": "Testing: Pre-Processing per clusteringArlecchino SystemRisultati\n",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#34": "Testing: JaccardModule for cluster Arlecchino SystemConfigurazione\n\nThreshold Jaccard*: 0.1\n\nThreshold edit: 0.5 ",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#35": "Testing: Pre-processing for schema mediatoArlecchino SystemRisultati",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#36": "Testing: performance SMM schema finaleArlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#37": "Testing: Schema MediatoArlecchino SystemConfigurazione\n\nThreshold Jaccard*: 0.1\n\nThreshold edit: 0..5Pre-processingJaccardModule",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#38": "Testing: Record LinkageArlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#39": "MiglioramentiArlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#4": "Caratteristiche dei sorgenti: ClusterSorgenti\t",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#40": "Member: Pietro Baroni\nMatricola: 536373\nLinkedin: Pietro BaroniMember: Paolo Di Simone\nMatricola: 584638\nLinkedin: Paolo Di SimoneMember: Matteo Wissel\nMatricola: 534693\u000bLinkedin: Matteo WisselTeamArlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#41": "GRAZIE PER L’ATTENZIONERoma, 22 Febbraio 2023GitHub: Arlecchino System",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#5": "Analisi dei sorgentiDati finanziari\nDati giuridici\nDati geografici\nDati di personale\nEtichette tipologie datiSorgenti\t",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#6": "Struttura dello schema mediato Schema mediatoVisione unificata delle informazioni\n\n\nSchema mediato\nBenefici",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#7": "Arlecchino SystemArlecchino System…",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#8": "TecnologieArlecchino SystemSchema Matching\n\nPreprocessing Module - custom\nJaccardModule - customRecord Linkage\n\nMagellan (py_entitymatching)\nDeepMatcherData Enrichment\n\n Sistema HW3",
    "data_test\\rootfolder\\varie\\relazioni\\HW8-DataIntegration.pptx#9": "ArchitetturaArlecchino SystemParsing&CleaningSchema MatchingRecord Linkage"
}